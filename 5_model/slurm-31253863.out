fold 0
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 2772, 6, 3)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 2772, 6, 32)    │         1,760 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 2772, 6, 64)    │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 2772, 1, 64)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 2772, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 2772, 64),     │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 2772)]             │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 76,322 (298.13 KB)
 Trainable params: 76,322 (298.13 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 538s - 2s/step - auc-prc: 0.6284 - loss: 9.8691 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 2/100
292/292 - 534s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 3/100
292/292 - 532s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 4/100
292/292 - 546s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 5/100
292/292 - 553s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 6/100
292/292 - 559s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 7/100
292/292 - 557s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 8/100
292/292 - 540s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 9/100
292/292 - 538s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 10/100
292/292 - 539s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 11/100
292/292 - 541s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 12/100
292/292 - 538s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 13/100
292/292 - 541s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 14/100
292/292 - 539s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 15/100
292/292 - 539s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 16/100
292/292 - 535s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 17/100
292/292 - 532s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 18/100
292/292 - 536s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 19/100
292/292 - 536s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 20/100
292/292 - 537s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Epoch 21/100
292/292 - 538s - 2s/step - auc-prc: 0.6303 - loss: 9.8587 - val_auc-prc: 0.6274 - val_loss: 9.8603
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 14s - 415ms/step
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       403
           1       0.61      1.00      0.76       635

    accuracy                           0.61      1038
   macro avg       0.31      0.50      0.38      1038
weighted avg       0.37      0.61      0.46      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.47      0.41       403
           1       0.59      0.49      0.54       635

    accuracy                           0.48      1038
   macro avg       0.48      0.48      0.48      1038
weighted avg       0.51      0.48      0.49      1038

______________________________________________________
fold 1
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 2772, 6, 3)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 2772, 6, 32)    │         1,760 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (None, 2772, 6, 64)    │        36,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 2772, 1, 64)    │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_1 (Lambda)               │ (None, 2772, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 2772, 64),     │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_1                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 2772)]             │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 76,322 (298.13 KB)
 Trainable params: 76,322 (298.13 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 536s - 2s/step - auc-prc: 0.3949 - loss: 0.7326 - val_auc-prc: 0.3623 - val_loss: 0.4061
Epoch 2/100
292/292 - 531s - 2s/step - auc-prc: 0.4405 - loss: 1.3011 - val_auc-prc: 0.4703 - val_loss: 0.7526
Epoch 3/100
292/292 - 532s - 2s/step - auc-prc: 0.4439 - loss: 0.6316 - val_auc-prc: 0.4165 - val_loss: 0.6868
Epoch 4/100
292/292 - 528s - 2s/step - auc-prc: 0.4096 - loss: 0.6999 - val_auc-prc: 0.4118 - val_loss: 0.7901
Epoch 5/100
292/292 - 529s - 2s/step - auc-prc: 0.4166 - loss: 0.6101 - val_auc-prc: 0.4178 - val_loss: 0.3941
Epoch 6/100
slurmstepd: error: *** JOB 31253863 ON nc31140 CANCELLED AT 2024-07-04T23:08:43 DUE TO TIME LIMIT ***
