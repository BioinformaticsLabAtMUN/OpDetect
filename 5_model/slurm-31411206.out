
The following have been reloaded with a version change:
  1) python/3.10.13 => python/3.11.5

fold 0
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 18s - 62ms/step - acc: 0.2957 - auc-prc: 0.4112 - auc-roc: 0.3950 - loss: 4.8548 - val_acc: 0.3073 - val_auc-prc: 0.5000 - val_auc-roc: 0.5000 - val_loss: 0.5648
Epoch 2/100
292/292 - 13s - 43ms/step - acc: 0.1603 - auc-prc: 0.4223 - auc-roc: 0.4168 - loss: 0.6336 - val_acc: 0.1349 - val_auc-prc: 0.4177 - val_auc-roc: 0.4084 - val_loss: 0.3135
Epoch 3/100
292/292 - 12s - 39ms/step - acc: 0.1681 - auc-prc: 0.4191 - auc-roc: 0.4112 - loss: 0.5529 - val_acc: 0.3208 - val_auc-prc: 0.4740 - val_auc-roc: 0.4841 - val_loss: 0.7967
Epoch 4/100
292/292 - 12s - 40ms/step - acc: 0.2719 - auc-prc: 0.4854 - auc-roc: 0.4902 - loss: 0.8492 - val_acc: 0.2890 - val_auc-prc: 0.5041 - val_auc-roc: 0.5048 - val_loss: 0.7051
Epoch 5/100
292/292 - 12s - 39ms/step - acc: 0.3005 - auc-prc: 0.5006 - auc-roc: 0.5009 - loss: 0.6279 - val_acc: 0.3776 - val_auc-prc: 0.5084 - val_auc-roc: 0.5071 - val_loss: 0.6646
Epoch 6/100
292/292 - 12s - 40ms/step - acc: 0.2853 - auc-prc: 0.4991 - auc-roc: 0.4982 - loss: 0.6022 - val_acc: 0.2283 - val_auc-prc: 0.4800 - val_auc-roc: 0.4758 - val_loss: 0.5255
Epoch 7/100
292/292 - 12s - 40ms/step - acc: 0.3060 - auc-prc: 0.5048 - auc-roc: 0.5003 - loss: 0.6898 - val_acc: 0.1782 - val_auc-prc: 0.4992 - val_auc-roc: 0.4991 - val_loss: 0.5633
Epoch 8/100
292/292 - 12s - 40ms/step - acc: 0.2296 - auc-prc: 0.4972 - auc-roc: 0.4965 - loss: 0.6382 - val_acc: 0.3882 - val_auc-prc: 0.4537 - val_auc-roc: 0.4208 - val_loss: 2.3883
Epoch 9/100
292/292 - 12s - 40ms/step - acc: 0.7536 - auc-prc: 0.5074 - auc-roc: 0.5146 - loss: 0.5530 - val_acc: 0.8266 - val_auc-prc: 0.5172 - val_auc-roc: 0.5332 - val_loss: 0.4239
Epoch 10/100
292/292 - 12s - 40ms/step - acc: 0.8496 - auc-prc: 0.5602 - auc-roc: 0.6070 - loss: 0.4137 - val_acc: 0.8690 - val_auc-prc: 0.5873 - val_auc-roc: 0.6484 - val_loss: 0.3286
Epoch 11/100
292/292 - 11s - 39ms/step - acc: 0.8699 - auc-prc: 0.6322 - auc-roc: 0.7080 - loss: 0.3749 - val_acc: 0.8661 - val_auc-prc: 0.6715 - val_auc-roc: 0.7545 - val_loss: 0.3184
Epoch 12/100
292/292 - 12s - 40ms/step - acc: 0.8679 - auc-prc: 0.6354 - auc-roc: 0.7122 - loss: 0.3460 - val_acc: 0.8719 - val_auc-prc: 0.6253 - val_auc-roc: 0.7001 - val_loss: 0.3056
Epoch 13/100
292/292 - 11s - 39ms/step - acc: 0.8376 - auc-prc: 0.5607 - auc-roc: 0.6082 - loss: 0.4436 - val_acc: 0.8738 - val_auc-prc: 0.5429 - val_auc-roc: 0.5790 - val_loss: 0.4037
Epoch 14/100
292/292 - 11s - 39ms/step - acc: 0.8683 - auc-prc: 0.5536 - auc-roc: 0.5967 - loss: 0.3628 - val_acc: 0.8690 - val_auc-prc: 0.5606 - val_auc-roc: 0.6080 - val_loss: 0.2952
Epoch 15/100
292/292 - 11s - 39ms/step - acc: 0.8719 - auc-prc: 0.5881 - auc-roc: 0.6495 - loss: 0.3213 - val_acc: 0.8757 - val_auc-prc: 0.5548 - val_auc-roc: 0.5988 - val_loss: 0.2831
Epoch 16/100
292/292 - 11s - 39ms/step - acc: 0.8768 - auc-prc: 0.5795 - auc-roc: 0.6370 - loss: 0.3242 - val_acc: 0.8825 - val_auc-prc: 0.5525 - val_auc-roc: 0.5950 - val_loss: 0.3541
Epoch 17/100
292/292 - 11s - 39ms/step - acc: 0.8764 - auc-prc: 0.5559 - auc-roc: 0.6006 - loss: 0.3352 - val_acc: 0.8863 - val_auc-prc: 0.5614 - val_auc-roc: 0.6093 - val_loss: 0.2829
Epoch 18/100
292/292 - 12s - 42ms/step - acc: 0.8798 - auc-prc: 0.5829 - auc-roc: 0.6420 - loss: 0.3100 - val_acc: 0.8940 - val_auc-prc: 0.5912 - val_auc-roc: 0.6542 - val_loss: 0.2698
Epoch 19/100
292/292 - 12s - 40ms/step - acc: 0.8790 - auc-prc: 0.5905 - auc-roc: 0.6529 - loss: 0.3110 - val_acc: 0.8902 - val_auc-prc: 0.5889 - val_auc-roc: 0.6508 - val_loss: 0.2693
Epoch 20/100
292/292 - 12s - 39ms/step - acc: 0.8697 - auc-prc: 0.5631 - auc-roc: 0.6119 - loss: 0.3221 - val_acc: 0.8854 - val_auc-prc: 0.5876 - val_auc-roc: 0.6490 - val_loss: 0.2762
Epoch 21/100
292/292 - 12s - 39ms/step - acc: 0.8723 - auc-prc: 0.5601 - auc-roc: 0.6072 - loss: 0.3684 - val_acc: 0.8873 - val_auc-prc: 0.5572 - val_auc-roc: 0.6026 - val_loss: 0.3248
******Evaluating TEST set*********
33/33 - 1s - 20ms/step
              precision    recall  f1-score   support

           0       0.86      0.78      0.82       403
           1       0.87      0.92      0.89       635

    accuracy                           0.87      1038
   macro avg       0.87      0.85      0.86      1038
weighted avg       0.87      0.87      0.86      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.47      0.41       403
           1       0.59      0.49      0.54       635

    accuracy                           0.48      1038
   macro avg       0.48      0.48      0.48      1038
weighted avg       0.51      0.48      0.49      1038

______________________________________________________
fold 1
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_1 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_1                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 14s - 46ms/step - acc: 0.1738 - auc-prc: 0.4175 - auc-roc: 0.4081 - loss: 1.1622 - val_acc: 0.1368 - val_auc-prc: 0.4044 - val_auc-roc: 0.3810 - val_loss: 0.2960
Epoch 2/100
292/292 - 11s - 39ms/step - acc: 0.1348 - auc-prc: 0.4030 - auc-roc: 0.3781 - loss: 0.6855 - val_acc: 0.1445 - val_auc-prc: 0.4304 - val_auc-roc: 0.4306 - val_loss: 0.3190
Epoch 3/100
292/292 - 11s - 39ms/step - acc: 0.1374 - auc-prc: 0.4166 - auc-roc: 0.4063 - loss: 0.3677 - val_acc: 0.1195 - val_auc-prc: 0.4903 - val_auc-roc: 0.4957 - val_loss: 0.3598
Epoch 4/100
292/292 - 11s - 39ms/step - acc: 0.1255 - auc-prc: 0.4222 - auc-roc: 0.4167 - loss: 0.3295 - val_acc: 0.1118 - val_auc-prc: 0.4178 - val_auc-roc: 0.4085 - val_loss: 0.2755
Epoch 5/100
292/292 - 11s - 39ms/step - acc: 0.1210 - auc-prc: 0.4135 - auc-roc: 0.4002 - loss: 0.3092 - val_acc: 0.1108 - val_auc-prc: 0.4165 - val_auc-roc: 0.4061 - val_loss: 0.2739
Epoch 6/100
292/292 - 11s - 39ms/step - acc: 0.1183 - auc-prc: 0.4145 - auc-roc: 0.4023 - loss: 0.3055 - val_acc: 0.1108 - val_auc-prc: 0.4163 - val_auc-roc: 0.4056 - val_loss: 0.2700
Epoch 7/100
292/292 - 11s - 39ms/step - acc: 0.1179 - auc-prc: 0.4246 - auc-roc: 0.4209 - loss: 0.3144 - val_acc: 0.1040 - val_auc-prc: 0.4153 - val_auc-roc: 0.4037 - val_loss: 0.2689
Epoch 8/100
292/292 - 11s - 39ms/step - acc: 0.1191 - auc-prc: 0.4145 - auc-roc: 0.4022 - loss: 0.3191 - val_acc: 0.1108 - val_auc-prc: 0.4180 - val_auc-roc: 0.4090 - val_loss: 0.2698
Epoch 9/100
292/292 - 11s - 39ms/step - acc: 0.1142 - auc-prc: 0.4161 - auc-roc: 0.4054 - loss: 0.2940 - val_acc: 0.1079 - val_auc-prc: 0.4170 - val_auc-roc: 0.4070 - val_loss: 0.2658
Epoch 10/100
292/292 - 11s - 39ms/step - acc: 0.1165 - auc-prc: 0.4166 - auc-roc: 0.4064 - loss: 0.2973 - val_acc: 0.1050 - val_auc-prc: 0.4163 - val_auc-roc: 0.4056 - val_loss: 0.2663
Epoch 11/100
292/292 - 11s - 39ms/step - acc: 0.1170 - auc-prc: 0.4172 - auc-roc: 0.4074 - loss: 0.3321 - val_acc: 0.1079 - val_auc-prc: 0.4261 - val_auc-roc: 0.4234 - val_loss: 0.2745
Epoch 12/100
292/292 - 11s - 39ms/step - acc: 0.1130 - auc-prc: 0.4149 - auc-roc: 0.4031 - loss: 0.3009 - val_acc: 0.1079 - val_auc-prc: 0.4153 - val_auc-roc: 0.4037 - val_loss: 0.2637
Epoch 13/100
292/292 - 11s - 39ms/step - acc: 0.1102 - auc-prc: 0.4107 - auc-roc: 0.3946 - loss: 0.4639 - val_acc: 0.1031 - val_auc-prc: 0.4138 - val_auc-roc: 0.4007 - val_loss: 0.3858
******Evaluating TEST set*********
33/33 - 1s - 19ms/step
              precision    recall  f1-score   support

           0       0.14      0.24      0.17       403
           1       0.09      0.05      0.06       635

    accuracy                           0.12      1038
   macro avg       0.11      0.14      0.12      1038
weighted avg       0.11      0.12      0.10      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.52      0.44       403
           1       0.60      0.47      0.53       635

    accuracy                           0.49      1038
   macro avg       0.49      0.49      0.48      1038
weighted avg       0.52      0.49      0.49      1038

______________________________________________________
fold 2
Model: "functional_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_2 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_2                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 14s - 46ms/step - acc: 0.1581 - auc-prc: 0.4077 - auc-roc: 0.3886 - loss: 1.2705 - val_acc: 0.1291 - val_auc-prc: 0.4554 - val_auc-roc: 0.4653 - val_loss: 0.3522
Epoch 2/100
292/292 - 11s - 39ms/step - acc: 0.1950 - auc-prc: 0.4361 - auc-roc: 0.4397 - loss: 0.4267 - val_acc: 0.1349 - val_auc-prc: 0.5000 - val_auc-roc: 0.5000 - val_loss: 0.5087
Epoch 3/100
292/292 - 11s - 39ms/step - acc: 0.1434 - auc-prc: 0.4788 - auc-roc: 0.4879 - loss: 0.4680 - val_acc: 0.1291 - val_auc-prc: 0.5000 - val_auc-roc: 0.5000 - val_loss: 0.4106
Epoch 4/100
292/292 - 11s - 39ms/step - acc: 0.1308 - auc-prc: 0.4785 - auc-roc: 0.4877 - loss: 0.3898 - val_acc: 0.1301 - val_auc-prc: 0.4735 - val_auc-roc: 0.4836 - val_loss: 0.3231
Epoch 5/100
292/292 - 11s - 39ms/step - acc: 0.1277 - auc-prc: 0.4511 - auc-roc: 0.4602 - loss: 0.3671 - val_acc: 0.1329 - val_auc-prc: 0.4856 - val_auc-roc: 0.4928 - val_loss: 0.3326
Epoch 6/100
292/292 - 12s - 40ms/step - acc: 0.1282 - auc-prc: 0.4743 - auc-roc: 0.4843 - loss: 0.3319 - val_acc: 0.1204 - val_auc-prc: 0.4692 - val_auc-roc: 0.4798 - val_loss: 0.3732
Epoch 7/100
292/292 - 11s - 39ms/step - acc: 0.1217 - auc-prc: 0.4462 - auc-roc: 0.4539 - loss: 0.3144 - val_acc: 0.1204 - val_auc-prc: 0.4412 - val_auc-roc: 0.4470 - val_loss: 0.2911
Epoch 8/100
292/292 - 11s - 39ms/step - acc: 0.1195 - auc-prc: 0.4250 - auc-roc: 0.4217 - loss: 0.3146 - val_acc: 0.1175 - val_auc-prc: 0.4252 - val_auc-roc: 0.4220 - val_loss: 0.3086
Epoch 9/100
292/292 - 11s - 39ms/step - acc: 0.1201 - auc-prc: 0.4224 - auc-roc: 0.4169 - loss: 0.3689 - val_acc: 0.1175 - val_auc-prc: 0.4236 - val_auc-roc: 0.4191 - val_loss: 0.3343
Epoch 10/100
292/292 - 11s - 39ms/step - acc: 0.1180 - auc-prc: 0.4161 - auc-roc: 0.4054 - loss: 0.3486 - val_acc: 0.1137 - val_auc-prc: 0.4201 - val_auc-roc: 0.4128 - val_loss: 0.3339
Epoch 11/100
292/292 - 12s - 40ms/step - acc: 0.1166 - auc-prc: 0.4203 - auc-roc: 0.4132 - loss: 0.3077 - val_acc: 0.1098 - val_auc-prc: 0.4252 - val_auc-roc: 0.4219 - val_loss: 0.2927
Epoch 12/100
292/292 - 11s - 39ms/step - acc: 0.1145 - auc-prc: 0.4173 - auc-roc: 0.4076 - loss: 0.3145 - val_acc: 0.1108 - val_auc-prc: 0.4165 - val_auc-roc: 0.4061 - val_loss: 0.2957
******Evaluating TEST set*********
33/33 - 1s - 20ms/step
              precision    recall  f1-score   support

           0       0.13      0.21      0.16       403
           1       0.15      0.09      0.11       635

    accuracy                           0.13      1038
   macro avg       0.14      0.15      0.13      1038
weighted avg       0.14      0.13      0.13      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.49      0.43       403
           1       0.61      0.50      0.55       635

    accuracy                           0.50      1038
   macro avg       0.50      0.50      0.49      1038
weighted avg       0.52      0.50      0.50      1038

______________________________________________________
fold 3
Model: "functional_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_3 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_3                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 14s - 47ms/step - acc: 0.1789 - auc-prc: 0.4259 - auc-roc: 0.4232 - loss: 0.4763 - val_acc: 0.1127 - val_auc-prc: 0.3643 - val_auc-roc: 0.2714 - val_loss: 0.4206
Epoch 2/100
292/292 - 11s - 39ms/step - acc: 0.1383 - auc-prc: 0.4026 - auc-roc: 0.3773 - loss: 0.3758 - val_acc: 0.1089 - val_auc-prc: 0.3976 - val_auc-roc: 0.3659 - val_loss: 0.3297
Epoch 3/100
292/292 - 12s - 40ms/step - acc: 0.1360 - auc-prc: 0.4041 - auc-roc: 0.3806 - loss: 0.4409 - val_acc: 0.1175 - val_auc-prc: 0.3778 - val_auc-roc: 0.3136 - val_loss: 0.3518
Epoch 4/100
292/292 - 12s - 39ms/step - acc: 0.1273 - auc-prc: 0.4003 - auc-roc: 0.3720 - loss: 0.6618 - val_acc: 0.1021 - val_auc-prc: 0.4064 - val_auc-roc: 0.3855 - val_loss: 1.7072
Epoch 5/100
292/292 - 12s - 39ms/step - acc: 0.1373 - auc-prc: 0.4289 - auc-roc: 0.4282 - loss: 0.4253 - val_acc: 0.1118 - val_auc-prc: 0.4472 - val_auc-roc: 0.4552 - val_loss: 0.2885
Epoch 6/100
292/292 - 12s - 40ms/step - acc: 0.1218 - auc-prc: 0.4203 - auc-roc: 0.4132 - loss: 0.3154 - val_acc: 0.1031 - val_auc-prc: 0.4097 - val_auc-roc: 0.3925 - val_loss: 0.2688
Epoch 7/100
292/292 - 11s - 39ms/step - acc: 0.1217 - auc-prc: 0.4181 - auc-roc: 0.4092 - loss: 0.3040 - val_acc: 0.1079 - val_auc-prc: 0.4429 - val_auc-roc: 0.4494 - val_loss: 0.2881
Epoch 8/100
292/292 - 12s - 40ms/step - acc: 0.1509 - auc-prc: 0.4360 - auc-roc: 0.4391 - loss: 0.4727 - val_acc: 0.1580 - val_auc-prc: 0.4824 - val_auc-roc: 0.4853 - val_loss: 0.8478
Epoch 9/100
292/292 - 12s - 40ms/step - acc: 0.2038 - auc-prc: 0.4751 - auc-roc: 0.4800 - loss: 0.8241 - val_acc: 0.3728 - val_auc-prc: 0.5150 - val_auc-roc: 0.5130 - val_loss: 0.7309
Epoch 10/100
292/292 - 12s - 40ms/step - acc: 0.2162 - auc-prc: 0.4692 - auc-roc: 0.4710 - loss: 1.0396 - val_acc: 0.2495 - val_auc-prc: 0.5388 - val_auc-roc: 0.5121 - val_loss: 0.4774
Epoch 11/100
292/292 - 12s - 40ms/step - acc: 0.2301 - auc-prc: 0.4835 - auc-roc: 0.4883 - loss: 0.7148 - val_acc: 0.1069 - val_auc-prc: 0.4132 - val_auc-roc: 0.3996 - val_loss: 0.7251
Epoch 12/100
292/292 - 12s - 40ms/step - acc: 0.1241 - auc-prc: 0.4259 - auc-roc: 0.4233 - loss: 0.6176 - val_acc: 0.1012 - val_auc-prc: 0.4111 - val_auc-roc: 0.3954 - val_loss: 0.8685
Epoch 13/100
292/292 - 12s - 40ms/step - acc: 0.1206 - auc-prc: 0.4178 - auc-roc: 0.4085 - loss: 0.7400 - val_acc: 0.1012 - val_auc-prc: 0.4125 - val_auc-roc: 0.3982 - val_loss: 0.8211
Epoch 14/100
292/292 - 12s - 40ms/step - acc: 0.1206 - auc-prc: 0.4166 - auc-roc: 0.4063 - loss: 0.7158 - val_acc: 0.1040 - val_auc-prc: 0.4121 - val_auc-roc: 0.3974 - val_loss: 0.8117
Epoch 15/100
292/292 - 12s - 40ms/step - acc: 0.1263 - auc-prc: 0.4186 - auc-roc: 0.4100 - loss: 0.7184 - val_acc: 0.1301 - val_auc-prc: 0.4526 - val_auc-roc: 0.4619 - val_loss: 0.3916
Epoch 16/100
292/292 - 11s - 39ms/step - acc: 0.1205 - auc-prc: 0.4189 - auc-roc: 0.4107 - loss: 0.6523 - val_acc: 0.0992 - val_auc-prc: 0.4078 - val_auc-roc: 0.3886 - val_loss: 0.8202
Epoch 17/100
292/292 - 11s - 39ms/step - acc: 0.1254 - auc-prc: 0.4167 - auc-roc: 0.4064 - loss: 0.7717 - val_acc: 0.1127 - val_auc-prc: 0.4284 - val_auc-roc: 0.4273 - val_loss: 0.3716
Epoch 18/100
292/292 - 11s - 39ms/step - acc: 0.1195 - auc-prc: 0.4216 - auc-roc: 0.4156 - loss: 0.4547 - val_acc: 0.0954 - val_auc-prc: 0.4155 - val_auc-roc: 0.4041 - val_loss: 0.4270
Epoch 19/100
292/292 - 11s - 39ms/step - acc: 0.1166 - auc-prc: 0.4182 - auc-roc: 0.4094 - loss: 0.4420 - val_acc: 0.0934 - val_auc-prc: 0.4298 - val_auc-roc: 0.4297 - val_loss: 0.3439
******Evaluating TEST set*********
33/33 - 1s - 19ms/step
              precision    recall  f1-score   support

           0       0.38      0.96      0.54       403
           1       0.10      0.00      0.01       635

    accuracy                           0.37      1038
   macro avg       0.24      0.48      0.27      1038
weighted avg       0.21      0.37      0.21      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.46      0.42       403
           1       0.60      0.52      0.56       635

    accuracy                           0.50      1038
   macro avg       0.49      0.49      0.49      1038
weighted avg       0.52      0.50      0.50      1038

______________________________________________________
fold 4
Model: "functional_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_4 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_4                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_4 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 14s - 49ms/step - acc: 0.1657 - auc-prc: 0.4131 - auc-roc: 0.3996 - loss: 1.1925 - val_acc: 0.1936 - val_auc-prc: 0.4418 - val_auc-roc: 0.4479 - val_loss: 0.4624
Epoch 2/100
292/292 - 11s - 39ms/step - acc: 0.2799 - auc-prc: 0.4901 - auc-roc: 0.4894 - loss: 0.7752 - val_acc: 0.3882 - val_auc-prc: 0.5250 - val_auc-roc: 0.5229 - val_loss: 0.9680
Epoch 3/100
292/292 - 20s - 70ms/step - acc: 0.2523 - auc-prc: 0.4894 - auc-roc: 0.4917 - loss: 0.8382 - val_acc: 0.3083 - val_auc-prc: 0.5010 - val_auc-roc: 0.4993 - val_loss: 0.7297
Epoch 4/100
292/292 - 12s - 42ms/step - acc: 0.2663 - auc-prc: 0.5003 - auc-roc: 0.4968 - loss: 0.8132 - val_acc: 0.2380 - val_auc-prc: 0.5110 - val_auc-roc: 0.5017 - val_loss: 0.5980
Epoch 5/100
292/292 - 12s - 42ms/step - acc: 0.1835 - auc-prc: 0.4515 - auc-roc: 0.4564 - loss: 0.7294 - val_acc: 0.2707 - val_auc-prc: 0.5659 - val_auc-roc: 0.5205 - val_loss: 0.5436
Epoch 6/100
292/292 - 13s - 44ms/step - acc: 0.2140 - auc-prc: 0.4837 - auc-roc: 0.4832 - loss: 0.6446 - val_acc: 0.1320 - val_auc-prc: 0.4179 - val_auc-roc: 0.4089 - val_loss: 0.5598
Epoch 7/100
292/292 - 12s - 43ms/step - acc: 0.2803 - auc-prc: 0.4561 - auc-roc: 0.4662 - loss: 0.7012 - val_acc: 0.3882 - val_auc-prc: 0.5000 - val_auc-roc: 0.5000 - val_loss: 0.6545
Epoch 8/100
292/292 - 13s - 43ms/step - acc: 0.3844 - auc-prc: 0.5003 - auc-roc: 0.5001 - loss: 0.6089 - val_acc: 0.3796 - val_auc-prc: 0.5000 - val_auc-roc: 0.5000 - val_loss: 0.5642
Epoch 9/100
292/292 - 13s - 46ms/step - acc: 0.3426 - auc-prc: 0.4945 - auc-roc: 0.4979 - loss: 0.5336 - val_acc: 0.2775 - val_auc-prc: 0.4911 - val_auc-roc: 0.4961 - val_loss: 0.4990
Epoch 10/100
292/292 - 13s - 44ms/step - acc: 0.1989 - auc-prc: 0.4782 - auc-roc: 0.4875 - loss: 0.5074 - val_acc: 0.1445 - val_auc-prc: 0.4662 - val_auc-roc: 0.4769 - val_loss: 0.4892
Epoch 11/100
292/292 - 14s - 47ms/step - acc: 0.1373 - auc-prc: 0.4397 - auc-roc: 0.4449 - loss: 0.6658 - val_acc: 0.1320 - val_auc-prc: 0.4321 - val_auc-roc: 0.4334 - val_loss: 0.5362
Epoch 12/100
292/292 - 13s - 45ms/step - acc: 0.1337 - auc-prc: 0.4304 - auc-roc: 0.4307 - loss: 0.6402 - val_acc: 0.1281 - val_auc-prc: 0.4266 - val_auc-roc: 0.4244 - val_loss: 0.4744
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

           0       0.39      1.00      0.56       403
           1       0.00      0.00      0.00       635

    accuracy                           0.39      1038
   macro avg       0.19      0.50      0.28      1038
weighted avg       0.15      0.39      0.22      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.51      0.43       403
           1       0.60      0.47      0.53       635

    accuracy                           0.49      1038
   macro avg       0.49      0.49      0.48      1038
weighted avg       0.52      0.49      0.49      1038

______________________________________________________
fold 5
Model: "functional_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_5 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_5 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_5                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_5 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 15s - 52ms/step - acc: 0.6108 - auc-prc: 0.6596 - auc-roc: 0.6476 - loss: 9.7858 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 2/100
292/292 - 13s - 45ms/step - acc: 0.6116 - auc-prc: 0.6622 - auc-roc: 0.6479 - loss: 9.8145 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 3/100
292/292 - 13s - 44ms/step - acc: 0.6116 - auc-prc: 0.6610 - auc-roc: 0.6478 - loss: 9.8041 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 4/100
292/292 - 13s - 44ms/step - acc: 0.6116 - auc-prc: 0.6617 - auc-roc: 0.6481 - loss: 9.8265 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 5/100
292/292 - 13s - 45ms/step - acc: 0.6116 - auc-prc: 0.6565 - auc-roc: 0.6464 - loss: 9.7644 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 6/100
292/292 - 12s - 40ms/step - acc: 0.6116 - auc-prc: 0.6611 - auc-roc: 0.6478 - loss: 9.8058 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 7/100
292/292 - 13s - 44ms/step - acc: 0.6116 - auc-prc: 0.6601 - auc-roc: 0.6472 - loss: 9.8076 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 8/100
292/292 - 13s - 44ms/step - acc: 0.6116 - auc-prc: 0.6618 - auc-roc: 0.6480 - loss: 9.7955 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 9/100
292/292 - 12s - 42ms/step - acc: 0.6116 - auc-prc: 0.6589 - auc-roc: 0.6469 - loss: 9.8145 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 10/100
292/292 - 13s - 45ms/step - acc: 0.6116 - auc-prc: 0.6614 - auc-roc: 0.6473 - loss: 9.8179 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
Epoch 11/100
292/292 - 13s - 45ms/step - acc: 0.6116 - auc-prc: 0.6611 - auc-roc: 0.6483 - loss: 9.8404 - val_acc: 0.6114 - val_auc-prc: 0.6550 - val_auc-roc: 0.6472 - val_loss: 9.8543
******Evaluating TEST set*********
33/33 - 1s - 21ms/step
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       403
           1       0.61      1.00      0.76       634

    accuracy                           0.61      1037
   macro avg       0.31      0.50      0.38      1037
weighted avg       0.37      0.61      0.46      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.50      0.43       403
           1       0.60      0.48      0.53       634

    accuracy                           0.48      1037
   macro avg       0.49      0.49      0.48      1037
weighted avg       0.51      0.48      0.49      1037

______________________________________________________
fold 6
Model: "functional_13"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_6 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_6 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_6 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_6                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_6 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.3882 - auc-prc: 0.4980 - auc-roc: 0.4155 - loss: 4.9794 - val_acc: 0.3886 - val_auc-prc: 0.5122 - val_auc-roc: 0.4090 - val_loss: 5.2224
Epoch 2/100
292/292 - 13s - 44ms/step - acc: 0.3884 - auc-prc: 0.4810 - auc-roc: 0.4040 - loss: 4.8831 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 3/100
292/292 - 12s - 41ms/step - acc: 0.3884 - auc-prc: 0.4745 - auc-roc: 0.3997 - loss: 4.8365 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 4/100
292/292 - 12s - 42ms/step - acc: 0.3884 - auc-prc: 0.4768 - auc-roc: 0.3999 - loss: 4.8503 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 5/100
292/292 - 12s - 42ms/step - acc: 0.3884 - auc-prc: 0.4739 - auc-roc: 0.3984 - loss: 4.8537 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 6/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.4741 - auc-roc: 0.3991 - loss: 4.8485 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 7/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.4752 - auc-roc: 0.4004 - loss: 4.8434 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 8/100
292/292 - 13s - 45ms/step - acc: 0.3884 - auc-prc: 0.4755 - auc-roc: 0.4002 - loss: 4.8416 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 9/100
292/292 - 13s - 44ms/step - acc: 0.3884 - auc-prc: 0.4749 - auc-roc: 0.3993 - loss: 4.8399 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 10/100
292/292 - 13s - 44ms/step - acc: 0.3884 - auc-prc: 0.4740 - auc-roc: 0.3992 - loss: 4.8278 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
Epoch 11/100
292/292 - 13s - 45ms/step - acc: 0.3884 - auc-prc: 0.4756 - auc-roc: 0.3998 - loss: 4.8434 - val_acc: 0.3886 - val_auc-prc: 0.4924 - val_auc-roc: 0.3982 - val_loss: 5.0670
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

           0       0.39      1.00      0.56       403
           1       0.00      0.00      0.00       634

    accuracy                           0.39      1037
   macro avg       0.19      0.50      0.28      1037
weighted avg       0.15      0.39      0.22      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.54      0.48       403
           1       0.65      0.53      0.58       634

    accuracy                           0.53      1037
   macro avg       0.53      0.54      0.53      1037
weighted avg       0.56      0.53      0.54      1037

______________________________________________________
fold 7
Model: "functional_15"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_7 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_7 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_7 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_7                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_7 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 53ms/step - acc: 0.8383 - auc-prc: 0.7966 - auc-roc: 0.8417 - loss: 0.5949 - val_acc: 0.8611 - val_auc-prc: 0.8173 - val_auc-roc: 0.8799 - val_loss: 0.5134
Epoch 2/100
292/292 - 13s - 46ms/step - acc: 0.8627 - auc-prc: 0.7175 - auc-roc: 0.7982 - loss: 0.6433 - val_acc: 0.8631 - val_auc-prc: 0.7346 - val_auc-roc: 0.8154 - val_loss: 0.3428
Epoch 3/100
292/292 - 13s - 45ms/step - acc: 0.8697 - auc-prc: 0.6972 - auc-roc: 0.7800 - loss: 0.5599 - val_acc: 0.8833 - val_auc-prc: 0.5625 - val_auc-roc: 0.6108 - val_loss: 0.4296
Epoch 4/100
292/292 - 12s - 41ms/step - acc: 0.8758 - auc-prc: 0.6921 - auc-roc: 0.7754 - loss: 0.3856 - val_acc: 0.8814 - val_auc-prc: 0.5796 - val_auc-roc: 0.6368 - val_loss: 0.3498
Epoch 5/100
292/292 - 12s - 39ms/step - acc: 0.8775 - auc-prc: 0.7129 - auc-roc: 0.7960 - loss: 0.3084 - val_acc: 0.8891 - val_auc-prc: 0.5583 - val_auc-roc: 0.6042 - val_loss: 0.3715
Epoch 6/100
292/292 - 12s - 43ms/step - acc: 0.8723 - auc-prc: 0.6627 - auc-roc: 0.7439 - loss: 0.3122 - val_acc: 0.8910 - val_auc-prc: 0.7131 - val_auc-roc: 0.7967 - val_loss: 0.3110
Epoch 7/100
292/292 - 13s - 45ms/step - acc: 0.8828 - auc-prc: 0.7104 - auc-roc: 0.7941 - loss: 0.2917 - val_acc: 0.8968 - val_auc-prc: 0.7350 - val_auc-roc: 0.8167 - val_loss: 0.3246
Epoch 8/100
292/292 - 12s - 41ms/step - acc: 0.8847 - auc-prc: 0.6982 - auc-roc: 0.7820 - loss: 0.2938 - val_acc: 0.8930 - val_auc-prc: 0.7265 - val_auc-roc: 0.8088 - val_loss: 0.3303
Epoch 9/100
292/292 - 13s - 43ms/step - acc: 0.8758 - auc-prc: 0.5882 - auc-roc: 0.6496 - loss: 0.3287 - val_acc: 0.8737 - val_auc-prc: 0.6547 - val_auc-roc: 0.7352 - val_loss: 0.3079
Epoch 10/100
292/292 - 14s - 46ms/step - acc: 0.8831 - auc-prc: 0.6355 - auc-roc: 0.7124 - loss: 0.2966 - val_acc: 0.8987 - val_auc-prc: 0.6906 - val_auc-roc: 0.7738 - val_loss: 0.3083
Epoch 11/100
292/292 - 12s - 40ms/step - acc: 0.8874 - auc-prc: 0.6601 - auc-roc: 0.7416 - loss: 0.2875 - val_acc: 0.9007 - val_auc-prc: 0.6744 - val_auc-roc: 0.7568 - val_loss: 0.3249
******Evaluating TEST set*********
33/33 - 1s - 21ms/step
              precision    recall  f1-score   support

           0       0.90      0.72      0.80       403
           1       0.84      0.95      0.89       634

    accuracy                           0.86      1037
   macro avg       0.87      0.84      0.85      1037
weighted avg       0.87      0.86      0.86      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.51      0.45       403
           1       0.63      0.53      0.58       634

    accuracy                           0.52      1037
   macro avg       0.52      0.52      0.51      1037
weighted avg       0.54      0.52      0.53      1037

______________________________________________________
fold 8
Model: "functional_17"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_8 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_8 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_8 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_8                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_8 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 14s - 47ms/step - acc: 0.3888 - auc-prc: 0.3866 - auc-roc: 0.3369 - loss: 6.2046 - val_acc: 0.3886 - val_auc-prc: 0.3820 - val_auc-roc: 0.3278 - val_loss: 6.2638
Epoch 2/100
292/292 - 11s - 39ms/step - acc: 0.3884 - auc-prc: 0.3854 - auc-roc: 0.3344 - loss: 6.2208 - val_acc: 0.3886 - val_auc-prc: 0.3822 - val_auc-roc: 0.3249 - val_loss: 6.2483
Epoch 3/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3847 - auc-roc: 0.3297 - loss: 6.2501 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 4/100
292/292 - 12s - 39ms/step - acc: 0.3884 - auc-prc: 0.3847 - auc-roc: 0.3293 - loss: 6.2260 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 5/100
292/292 - 12s - 42ms/step - acc: 0.3884 - auc-prc: 0.3852 - auc-roc: 0.3303 - loss: 6.2363 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 6/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3852 - auc-roc: 0.3301 - loss: 6.2242 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 7/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3851 - auc-roc: 0.3300 - loss: 6.2225 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 8/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3853 - auc-roc: 0.3301 - loss: 6.2311 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 9/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3845 - auc-roc: 0.3293 - loss: 6.2329 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 10/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3849 - auc-roc: 0.3298 - loss: 6.2501 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
Epoch 11/100
292/292 - 12s - 40ms/step - acc: 0.3884 - auc-prc: 0.3852 - auc-roc: 0.3302 - loss: 6.2605 - val_acc: 0.3886 - val_auc-prc: 0.3826 - val_auc-roc: 0.3253 - val_loss: 6.2483
******Evaluating TEST set*********
33/33 - 1s - 20ms/step
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/lustre06/project/6003138/rezvank/5_model/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
              precision    recall  f1-score   support

           0       0.39      1.00      0.56       403
           1       0.00      0.00      0.00       634

    accuracy                           0.39      1037
   macro avg       0.19      0.50      0.28      1037
weighted avg       0.15      0.39      0.22      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.53      0.45       403
           1       0.62      0.48      0.54       634

    accuracy                           0.50      1037
   macro avg       0.51      0.51      0.50      1037
weighted avg       0.53      0.50      0.51      1037

______________________________________________________
fold 9
Model: "functional_19"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_9 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_9 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_9 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_9                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 15s - 52ms/step - acc: 0.8414 - auc-prc: 0.7906 - auc-roc: 0.8368 - loss: 0.4746 - val_acc: 0.8660 - val_auc-prc: 0.5660 - val_auc-roc: 0.6163 - val_loss: 0.4736
Epoch 2/100
292/292 - 12s - 40ms/step - acc: 0.8572 - auc-prc: 0.7132 - auc-roc: 0.7951 - loss: 0.3937 - val_acc: 0.8785 - val_auc-prc: 0.7720 - val_auc-roc: 0.8482 - val_loss: 0.3646
Epoch 3/100
292/292 - 13s - 44ms/step - acc: 0.8686 - auc-prc: 0.7483 - auc-roc: 0.8278 - loss: 0.3193 - val_acc: 0.8727 - val_auc-prc: 0.7443 - val_auc-roc: 0.8258 - val_loss: 0.3060
Epoch 4/100
292/292 - 13s - 45ms/step - acc: 0.8718 - auc-prc: 0.6291 - auc-roc: 0.7043 - loss: 0.6667 - val_acc: 0.8727 - val_auc-prc: 0.7457 - val_auc-roc: 0.8271 - val_loss: 0.3099
Epoch 5/100
292/292 - 13s - 45ms/step - acc: 0.8402 - auc-prc: 0.5756 - auc-roc: 0.6309 - loss: 0.4119 - val_acc: 0.8756 - val_auc-prc: 0.5589 - val_auc-roc: 0.6052 - val_loss: 0.4212
Epoch 6/100
292/292 - 13s - 46ms/step - acc: 0.8705 - auc-prc: 0.5630 - auc-roc: 0.6118 - loss: 0.3950 - val_acc: 0.8785 - val_auc-prc: 0.5863 - val_auc-roc: 0.6471 - val_loss: 0.2997
Epoch 7/100
292/292 - 13s - 45ms/step - acc: 0.8812 - auc-prc: 0.6292 - auc-roc: 0.7046 - loss: 0.3828 - val_acc: 0.8717 - val_auc-prc: 0.7168 - val_auc-roc: 0.8007 - val_loss: 0.3502
Epoch 8/100
292/292 - 13s - 45ms/step - acc: 0.8850 - auc-prc: 0.6237 - auc-roc: 0.6976 - loss: 0.3250 - val_acc: 0.8737 - val_auc-prc: 0.7048 - val_auc-roc: 0.7893 - val_loss: 0.2880
Epoch 9/100
292/292 - 13s - 45ms/step - acc: 0.8840 - auc-prc: 0.6164 - auc-roc: 0.6883 - loss: 0.3039 - val_acc: 0.8717 - val_auc-prc: 0.6988 - val_auc-roc: 0.7832 - val_loss: 0.2852
Epoch 10/100
292/292 - 13s - 45ms/step - acc: 0.8881 - auc-prc: 0.6145 - auc-roc: 0.6859 - loss: 0.2951 - val_acc: 0.8717 - val_auc-prc: 0.7119 - val_auc-roc: 0.7962 - val_loss: 0.2967
Epoch 11/100
292/292 - 13s - 45ms/step - acc: 0.8872 - auc-prc: 0.6213 - auc-roc: 0.6947 - loss: 0.2926 - val_acc: 0.8766 - val_auc-prc: 0.6917 - val_auc-roc: 0.7764 - val_loss: 0.2817
Epoch 12/100
292/292 - 15s - 52ms/step - acc: 0.8876 - auc-prc: 0.6311 - auc-roc: 0.7070 - loss: 0.3015 - val_acc: 0.8746 - val_auc-prc: 0.6773 - val_auc-roc: 0.7609 - val_loss: 0.2907
******Evaluating TEST set*********
33/33 - 1s - 23ms/step
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       403
           1       0.88      0.92      0.90       634

    accuracy                           0.88      1037
   macro avg       0.88      0.87      0.87      1037
weighted avg       0.88      0.88      0.88      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.46      0.42       403
           1       0.60      0.53      0.56       634

    accuracy                           0.50      1037
   macro avg       0.49      0.49      0.49      1037
weighted avg       0.52      0.50      0.51      1037

______________________________________________________
Model: "functional_19"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_9 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_9 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_9 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_9                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 130,376 (509.29 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 86,918 (339.53 KB)
None
Mean AUC_ROC[0.5318] IC [0.3807, 0.6830]
Mean Accuracy[0.5010] IC [0.3334, 0.6685]
Mean Recall[0.5318] IC [0.3807, 0.6830]
Mean F1[0.4317] IC [0.2556, 0.6077]
Median AUC_ROC[0.5000]
Median Accuracy[0.3886]
Median Recall[0.5000]
Median F1[0.2799]
