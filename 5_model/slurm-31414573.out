
The following have been reloaded with a version change:
  1) python/3.10.13 => python/3.11.5

fold 0
Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 56ms/step - acc: 0.8090 - auc_prc: 0.7861 - auc_roc: 0.8098 - loss: 1.8790 - val_acc: 0.8536 - val_auc_prc: 0.8665 - val_auc_roc: 0.9053 - val_loss: 1.3207
Epoch 2/100
292/292 - 13s - 46ms/step - acc: 0.8170 - auc_prc: 0.6716 - auc_roc: 0.7487 - loss: 0.6786 - val_acc: 0.8651 - val_auc_prc: 0.7614 - val_auc_roc: 0.8384 - val_loss: 0.3473
Epoch 3/100
292/292 - 14s - 47ms/step - acc: 0.8621 - auc_prc: 0.7288 - auc_roc: 0.8092 - loss: 0.4720 - val_acc: 0.8690 - val_auc_prc: 0.7797 - val_auc_roc: 0.8534 - val_loss: 0.4403
Epoch 4/100
292/292 - 14s - 48ms/step - acc: 0.8553 - auc_prc: 0.6476 - auc_roc: 0.7261 - loss: 0.4980 - val_acc: 0.8728 - val_auc_prc: 0.6063 - val_auc_roc: 0.6743 - val_loss: 0.5827
Epoch 5/100
292/292 - 14s - 47ms/step - acc: 0.8632 - auc_prc: 0.5784 - auc_roc: 0.6354 - loss: 0.6591 - val_acc: 0.8757 - val_auc_prc: 0.5857 - val_auc_roc: 0.6460 - val_loss: 0.5210
Epoch 6/100
292/292 - 14s - 47ms/step - acc: 0.8712 - auc_prc: 0.6669 - auc_roc: 0.7486 - loss: 0.3803 - val_acc: 0.8805 - val_auc_prc: 0.7205 - val_auc_roc: 0.8037 - val_loss: 0.3099
Epoch 7/100
292/292 - 14s - 47ms/step - acc: 0.8772 - auc_prc: 0.6771 - auc_roc: 0.7598 - loss: 0.3131 - val_acc: 0.8854 - val_auc_prc: 0.7309 - val_auc_roc: 0.8131 - val_loss: 0.3460
Epoch 8/100
292/292 - 13s - 46ms/step - acc: 0.8063 - auc_prc: 0.5756 - auc_roc: 0.6308 - loss: 0.4258 - val_acc: 0.8256 - val_auc_prc: 0.5422 - val_auc_roc: 0.5776 - val_loss: 0.4138
Epoch 9/100
292/292 - 14s - 46ms/step - acc: 0.8238 - auc_prc: 0.5161 - auc_roc: 0.5312 - loss: 0.5046 - val_acc: 0.8661 - val_auc_prc: 0.5000 - val_auc_roc: 0.5000 - val_loss: 0.4543
Epoch 10/100
292/292 - 13s - 45ms/step - acc: 0.8660 - auc_prc: 0.5231 - auc_roc: 0.5442 - loss: 0.3721 - val_acc: 0.8709 - val_auc_prc: 0.6746 - val_auc_roc: 0.7568 - val_loss: 0.3054
Epoch 11/100
292/292 - 13s - 46ms/step - acc: 0.8728 - auc_prc: 0.6826 - auc_roc: 0.7655 - loss: 0.3044 - val_acc: 0.8825 - val_auc_prc: 0.7192 - val_auc_roc: 0.8025 - val_loss: 0.2888
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
              precision    recall  f1-score   support

           0       0.93      0.67      0.78       403
           1       0.82      0.97      0.89       635

    accuracy                           0.85      1038
   macro avg       0.88      0.82      0.84      1038
weighted avg       0.86      0.85      0.85      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.35      0.45      0.39       403
           1       0.58      0.48      0.52       635

    accuracy                           0.47      1038
   macro avg       0.46      0.46      0.46      1038
weighted avg       0.49      0.47      0.47      1038

______________________________________________________
fold 1
Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_1 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_1 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_1                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 15s - 53ms/step - acc: 0.1545 - auc_prc: 0.4118 - auc_roc: 0.3970 - loss: 2.5447 - val_acc: 0.2187 - val_auc_prc: 0.4073 - val_auc_roc: 0.3877 - val_loss: 3.3944
Epoch 2/100
292/292 - 13s - 45ms/step - acc: 0.2215 - auc_prc: 0.4627 - auc_roc: 0.4700 - loss: 1.5176 - val_acc: 0.3776 - val_auc_prc: 0.5119 - val_auc_roc: 0.5089 - val_loss: 0.6354
Epoch 3/100
292/292 - 14s - 47ms/step - acc: 0.3263 - auc_prc: 0.5078 - auc_roc: 0.5066 - loss: 0.7751 - val_acc: 0.4383 - val_auc_prc: 0.5061 - val_auc_roc: 0.5078 - val_loss: 0.5902
Epoch 4/100
292/292 - 14s - 47ms/step - acc: 0.4422 - auc_prc: 0.5121 - auc_roc: 0.5151 - loss: 0.4974 - val_acc: 0.4846 - val_auc_prc: 0.5045 - val_auc_roc: 0.5049 - val_loss: 0.4381
Epoch 5/100
292/292 - 14s - 47ms/step - acc: 0.5514 - auc_prc: 0.5364 - auc_roc: 0.5505 - loss: 0.4616 - val_acc: 0.6464 - val_auc_prc: 0.5567 - val_auc_roc: 0.5864 - val_loss: 0.4171
Epoch 6/100
292/292 - 13s - 46ms/step - acc: 0.4293 - auc_prc: 0.5468 - auc_roc: 0.5508 - loss: 0.4970 - val_acc: 0.4229 - val_auc_prc: 0.5668 - val_auc_roc: 0.5739 - val_loss: 0.4281
Epoch 7/100
292/292 - 13s - 46ms/step - acc: 0.4142 - auc_prc: 0.5393 - auc_roc: 0.5426 - loss: 0.4923 - val_acc: 0.3882 - val_auc_prc: 0.5827 - val_auc_roc: 0.5617 - val_loss: 0.4603
Epoch 8/100
292/292 - 13s - 46ms/step - acc: 0.3828 - auc_prc: 0.5947 - auc_roc: 0.5695 - loss: 0.5363 - val_acc: 0.3892 - val_auc_prc: 0.6601 - val_auc_roc: 0.5949 - val_loss: 0.4854
Epoch 9/100
292/292 - 13s - 46ms/step - acc: 0.3702 - auc_prc: 0.6334 - auc_roc: 0.5846 - loss: 0.5696 - val_acc: 0.3815 - val_auc_prc: 0.6560 - val_auc_roc: 0.5901 - val_loss: 0.5801
Epoch 10/100
292/292 - 14s - 47ms/step - acc: 0.3450 - auc_prc: 0.6276 - auc_roc: 0.5768 - loss: 0.7284 - val_acc: 0.2881 - val_auc_prc: 0.5494 - val_auc_roc: 0.5274 - val_loss: 0.8501
Epoch 11/100
292/292 - 13s - 46ms/step - acc: 0.2980 - auc_prc: 0.5663 - auc_roc: 0.5398 - loss: 1.3655 - val_acc: 0.1927 - val_auc_prc: 0.4357 - val_auc_roc: 0.4373 - val_loss: 1.9786
Epoch 12/100
292/292 - 14s - 47ms/step - acc: 0.2530 - auc_prc: 0.5007 - auc_roc: 0.4986 - loss: 2.1109 - val_acc: 0.2119 - val_auc_prc: 0.4475 - val_auc_roc: 0.4524 - val_loss: 1.9439
Epoch 13/100
292/292 - 13s - 46ms/step - acc: 0.1900 - auc_prc: 0.4324 - auc_roc: 0.4329 - loss: 2.2424 - val_acc: 0.1696 - val_auc_prc: 0.4206 - val_auc_roc: 0.4138 - val_loss: 1.7256
Epoch 14/100
292/292 - 13s - 45ms/step - acc: 0.1497 - auc_prc: 0.4152 - auc_roc: 0.4037 - loss: 1.7561 - val_acc: 0.1590 - val_auc_prc: 0.4250 - val_auc_roc: 0.4215 - val_loss: 1.3286
Epoch 15/100
292/292 - 13s - 45ms/step - acc: 0.1824 - auc_prc: 0.4243 - auc_roc: 0.4205 - loss: 1.4022 - val_acc: 0.3468 - val_auc_prc: 0.5000 - val_auc_roc: 0.5000 - val_loss: 0.6218
Epoch 16/100
292/292 - 13s - 46ms/step - acc: 0.2177 - auc_prc: 0.4515 - auc_roc: 0.4606 - loss: 0.5630 - val_acc: 0.1484 - val_auc_prc: 0.4284 - val_auc_roc: 0.4273 - val_loss: 1.0870
Epoch 17/100
292/292 - 13s - 45ms/step - acc: 0.2021 - auc_prc: 0.4441 - auc_roc: 0.4511 - loss: 0.7446 - val_acc: 0.2071 - val_auc_prc: 0.4502 - val_auc_roc: 0.4591 - val_loss: 0.4570
Epoch 18/100
292/292 - 13s - 46ms/step - acc: 0.1601 - auc_prc: 0.4260 - auc_roc: 0.4234 - loss: 0.6356 - val_acc: 0.1570 - val_auc_prc: 0.4238 - val_auc_roc: 0.4196 - val_loss: 0.8754
******Evaluating TEST set*********
33/33 - 1s - 21ms/step
              precision    recall  f1-score   support

           0       0.39      1.00      0.56       403
           1       1.00      0.00      0.00       635

    accuracy                           0.39      1038
   macro avg       0.69      0.50      0.28      1038
weighted avg       0.76      0.39      0.22      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.51      0.43       403
           1       0.60      0.46      0.52       635

    accuracy                           0.48      1038
   macro avg       0.49      0.49      0.48      1038
weighted avg       0.51      0.48      0.49      1038

______________________________________________________
fold 2
Model: "functional_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_2 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_2 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_2 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_2                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.1713 - auc_prc: 0.4167 - auc_roc: 0.4065 - loss: 1.4817 - val_acc: 0.1243 - val_auc_prc: 0.4175 - val_auc_roc: 0.4080 - val_loss: 0.9506
Epoch 2/100
292/292 - 14s - 47ms/step - acc: 0.4416 - auc_prc: 0.4853 - auc_roc: 0.4726 - loss: 0.9442 - val_acc: 0.6118 - val_auc_prc: 0.5000 - val_auc_roc: 0.5000 - val_loss: 0.6616
Epoch 3/100
292/292 - 13s - 46ms/step - acc: 0.6663 - auc_prc: 0.5074 - auc_roc: 0.5145 - loss: 0.6012 - val_acc: 0.7418 - val_auc_prc: 0.5000 - val_auc_roc: 0.5000 - val_loss: 0.5226
Epoch 4/100
292/292 - 14s - 46ms/step - acc: 0.8457 - auc_prc: 0.5562 - auc_roc: 0.6008 - loss: 0.3867 - val_acc: 0.8767 - val_auc_prc: 0.5699 - val_auc_roc: 0.6226 - val_loss: 0.3197
Epoch 5/100
292/292 - 14s - 47ms/step - acc: 0.8664 - auc_prc: 0.6328 - auc_roc: 0.7091 - loss: 0.3208 - val_acc: 0.8834 - val_auc_prc: 0.6328 - val_auc_roc: 0.7090 - val_loss: 0.3038
Epoch 6/100
292/292 - 14s - 47ms/step - acc: 0.8700 - auc_prc: 0.5726 - auc_roc: 0.6266 - loss: 0.3447 - val_acc: 0.8266 - val_auc_prc: 0.5027 - val_auc_roc: 0.5053 - val_loss: 0.3865
Epoch 7/100
292/292 - 14s - 48ms/step - acc: 0.8719 - auc_prc: 0.5910 - auc_roc: 0.6536 - loss: 0.3126 - val_acc: 0.8911 - val_auc_prc: 0.6021 - val_auc_roc: 0.6693 - val_loss: 0.2884
Epoch 8/100
292/292 - 14s - 49ms/step - acc: 0.8776 - auc_prc: 0.6183 - auc_roc: 0.6907 - loss: 0.3009 - val_acc: 0.8882 - val_auc_prc: 0.5986 - val_auc_roc: 0.6644 - val_loss: 0.2868
Epoch 9/100
292/292 - 14s - 47ms/step - acc: 0.8808 - auc_prc: 0.6066 - auc_roc: 0.6753 - loss: 0.3004 - val_acc: 0.8882 - val_auc_prc: 0.5768 - val_auc_roc: 0.6330 - val_loss: 0.2852
Epoch 10/100
292/292 - 14s - 48ms/step - acc: 0.8836 - auc_prc: 0.6192 - auc_roc: 0.6920 - loss: 0.2949 - val_acc: 0.8882 - val_auc_prc: 0.6278 - val_auc_roc: 0.7028 - val_loss: 0.2870
Epoch 11/100
292/292 - 14s - 48ms/step - acc: 0.8850 - auc_prc: 0.6095 - auc_roc: 0.6792 - loss: 0.2963 - val_acc: 0.8882 - val_auc_prc: 0.6173 - val_auc_roc: 0.6896 - val_loss: 0.2824
Epoch 12/100
292/292 - 14s - 49ms/step - acc: 0.8782 - auc_prc: 0.5841 - auc_roc: 0.6437 - loss: 0.3202 - val_acc: 0.8767 - val_auc_prc: 0.5329 - val_auc_roc: 0.5617 - val_loss: 0.2983
Epoch 13/100
292/292 - 14s - 48ms/step - acc: 0.8836 - auc_prc: 0.5950 - auc_roc: 0.6593 - loss: 0.2926 - val_acc: 0.8863 - val_auc_prc: 0.5495 - val_auc_roc: 0.5901 - val_loss: 0.2985
Epoch 14/100
292/292 - 14s - 48ms/step - acc: 0.8865 - auc_prc: 0.6058 - auc_roc: 0.6743 - loss: 0.2931 - val_acc: 0.8892 - val_auc_prc: 0.6105 - val_auc_roc: 0.6806 - val_loss: 0.2763
Epoch 15/100
292/292 - 14s - 48ms/step - acc: 0.8882 - auc_prc: 0.6181 - auc_roc: 0.6906 - loss: 0.2903 - val_acc: 0.8911 - val_auc_prc: 0.6332 - val_auc_roc: 0.7098 - val_loss: 0.2771
Epoch 16/100
292/292 - 13s - 45ms/step - acc: 0.8857 - auc_prc: 0.5929 - auc_roc: 0.6564 - loss: 0.3060 - val_acc: 0.8902 - val_auc_prc: 0.5829 - val_auc_roc: 0.6422 - val_loss: 0.2773
Epoch 17/100
292/292 - 14s - 47ms/step - acc: 0.8892 - auc_prc: 0.5844 - auc_roc: 0.6442 - loss: 0.2867 - val_acc: 0.8921 - val_auc_prc: 0.5849 - val_auc_roc: 0.6451 - val_loss: 0.2738
Epoch 18/100
292/292 - 13s - 45ms/step - acc: 0.8915 - auc_prc: 0.5930 - auc_roc: 0.6567 - loss: 0.2936 - val_acc: 0.8863 - val_auc_prc: 0.5572 - val_auc_roc: 0.6026 - val_loss: 0.3395
Epoch 19/100
292/292 - 14s - 46ms/step - acc: 0.8921 - auc_prc: 0.5635 - auc_roc: 0.6126 - loss: 0.2957 - val_acc: 0.8940 - val_auc_prc: 0.5693 - val_auc_roc: 0.6216 - val_loss: 0.2737
Epoch 20/100
292/292 - 13s - 46ms/step - acc: 0.8926 - auc_prc: 0.5766 - auc_roc: 0.6327 - loss: 0.2848 - val_acc: 0.8940 - val_auc_prc: 0.5572 - val_auc_roc: 0.6026 - val_loss: 0.2802
Epoch 21/100
292/292 - 13s - 45ms/step - acc: 0.8921 - auc_prc: 0.5675 - auc_roc: 0.6188 - loss: 0.2857 - val_acc: 0.9008 - val_auc_prc: 0.5572 - val_auc_roc: 0.6026 - val_loss: 0.2703
Epoch 22/100
292/292 - 13s - 45ms/step - acc: 0.8905 - auc_prc: 0.5805 - auc_roc: 0.6385 - loss: 0.2846 - val_acc: 0.9017 - val_auc_prc: 0.5566 - val_auc_roc: 0.6016 - val_loss: 0.2683
Epoch 23/100
292/292 - 13s - 46ms/step - acc: 0.8926 - auc_prc: 0.5798 - auc_roc: 0.6376 - loss: 0.2692 - val_acc: 0.8950 - val_auc_prc: 0.5686 - val_auc_roc: 0.6205 - val_loss: 0.2773
Epoch 24/100
292/292 - 13s - 46ms/step - acc: 0.8895 - auc_prc: 0.5651 - auc_roc: 0.6151 - loss: 0.2852 - val_acc: 0.8960 - val_auc_prc: 0.5542 - val_auc_roc: 0.5978 - val_loss: 0.2616
Epoch 25/100
292/292 - 13s - 46ms/step - acc: 0.8917 - auc_prc: 0.5939 - auc_roc: 0.6579 - loss: 0.2803 - val_acc: 0.8969 - val_auc_prc: 0.5807 - val_auc_roc: 0.6388 - val_loss: 0.2607
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
              precision    recall  f1-score   support

           0       0.91      0.79      0.85       403
           1       0.88      0.95      0.91       635

    accuracy                           0.89      1038
   macro avg       0.90      0.87      0.88      1038
weighted avg       0.89      0.89      0.89      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.48      0.42       403
           1       0.60      0.49      0.54       635

    accuracy                           0.49      1038
   macro avg       0.49      0.49      0.48      1038
weighted avg       0.51      0.49      0.49      1038

______________________________________________________
fold 3
Model: "functional_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_3 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_3 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_3 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_3                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 53ms/step - acc: 0.8126 - auc_prc: 0.6468 - auc_roc: 0.7097 - loss: 1.1840 - val_acc: 0.6118 - val_auc_prc: 0.4834 - val_auc_roc: 0.4688 - val_loss: 1.0800
Epoch 2/100
292/292 - 13s - 44ms/step - acc: 0.7254 - auc_prc: 0.5086 - auc_roc: 0.5162 - loss: 0.9219 - val_acc: 0.8767 - val_auc_prc: 0.5420 - val_auc_roc: 0.5764 - val_loss: 0.8692
Epoch 3/100
292/292 - 13s - 46ms/step - acc: 0.3171 - auc_prc: 0.4719 - auc_roc: 0.4644 - loss: 0.5593 - val_acc: 0.1493 - val_auc_prc: 0.4160 - val_auc_roc: 0.4051 - val_loss: 0.3254
Epoch 4/100
292/292 - 13s - 45ms/step - acc: 0.1548 - auc_prc: 0.4170 - auc_roc: 0.4072 - loss: 0.3837 - val_acc: 0.1416 - val_auc_prc: 0.4149 - val_auc_roc: 0.4031 - val_loss: 0.3257
Epoch 5/100
292/292 - 13s - 46ms/step - acc: 0.1492 - auc_prc: 0.4205 - auc_roc: 0.4137 - loss: 0.3899 - val_acc: 0.1358 - val_auc_prc: 0.4159 - val_auc_roc: 0.4050 - val_loss: 0.3196
Epoch 6/100
292/292 - 13s - 45ms/step - acc: 0.1361 - auc_prc: 0.4163 - auc_roc: 0.4058 - loss: 0.3563 - val_acc: 0.1272 - val_auc_prc: 0.4157 - val_auc_roc: 0.4046 - val_loss: 0.3322
Epoch 7/100
292/292 - 13s - 45ms/step - acc: 0.1313 - auc_prc: 0.4126 - auc_roc: 0.3985 - loss: 0.4376 - val_acc: 0.1252 - val_auc_prc: 0.4140 - val_auc_roc: 0.4012 - val_loss: 0.3027
Epoch 8/100
292/292 - 13s - 45ms/step - acc: 0.1333 - auc_prc: 0.4162 - auc_roc: 0.4055 - loss: 0.3343 - val_acc: 0.1204 - val_auc_prc: 0.4155 - val_auc_roc: 0.4042 - val_loss: 0.2823
Epoch 9/100
292/292 - 13s - 45ms/step - acc: 0.1352 - auc_prc: 0.4191 - auc_roc: 0.4111 - loss: 0.3425 - val_acc: 0.1166 - val_auc_prc: 0.4130 - val_auc_roc: 0.3993 - val_loss: 0.2761
Epoch 10/100
292/292 - 13s - 45ms/step - acc: 0.1441 - auc_prc: 0.4278 - auc_roc: 0.4263 - loss: 0.3438 - val_acc: 0.1175 - val_auc_prc: 0.4185 - val_auc_roc: 0.4099 - val_loss: 0.2798
Epoch 11/100
292/292 - 13s - 45ms/step - acc: 0.1251 - auc_prc: 0.4159 - auc_roc: 0.4050 - loss: 0.3146 - val_acc: 0.1079 - val_auc_prc: 0.4116 - val_auc_roc: 0.3964 - val_loss: 0.2687
Epoch 12/100
292/292 - 13s - 45ms/step - acc: 0.1813 - auc_prc: 0.4394 - auc_roc: 0.4445 - loss: 0.3886 - val_acc: 0.1474 - val_auc_prc: 0.4758 - val_auc_roc: 0.4855 - val_loss: 0.3385
******Evaluating TEST set*********
33/33 - 1s - 20ms/step
              precision    recall  f1-score   support

           0       0.88      0.79      0.83       403
           1       0.87      0.93      0.90       635

    accuracy                           0.88      1038
   macro avg       0.88      0.86      0.87      1038
weighted avg       0.88      0.88      0.88      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.46      0.42       403
           1       0.60      0.52      0.56       635

    accuracy                           0.50      1038
   macro avg       0.49      0.49      0.49      1038
weighted avg       0.52      0.50      0.50      1038

______________________________________________________
fold 4
Model: "functional_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_4 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_4 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_4 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_4                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_4 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.1816 - auc_prc: 0.4180 - auc_roc: 0.4091 - loss: 1.7293 - val_acc: 0.1532 - val_auc_prc: 0.4310 - val_auc_roc: 0.4315 - val_loss: 0.5590
Epoch 2/100
292/292 - 13s - 46ms/step - acc: 0.1675 - auc_prc: 0.4409 - auc_roc: 0.4466 - loss: 0.4502 - val_acc: 0.1252 - val_auc_prc: 0.4275 - val_auc_roc: 0.4258 - val_loss: 0.2993
Epoch 3/100
292/292 - 13s - 46ms/step - acc: 0.1333 - auc_prc: 0.4179 - auc_roc: 0.4087 - loss: 0.5018 - val_acc: 0.1224 - val_auc_prc: 0.4331 - val_auc_roc: 0.4350 - val_loss: 0.2907
Epoch 4/100
292/292 - 13s - 45ms/step - acc: 0.1268 - auc_prc: 0.4147 - auc_roc: 0.4027 - loss: 0.6389 - val_acc: 0.1243 - val_auc_prc: 0.4116 - val_auc_roc: 0.3964 - val_loss: 0.8459
Epoch 5/100
292/292 - 13s - 45ms/step - acc: 0.1211 - auc_prc: 0.4111 - auc_roc: 0.3955 - loss: 0.5071 - val_acc: 0.1156 - val_auc_prc: 0.4138 - val_auc_roc: 0.4008 - val_loss: 0.4534
Epoch 6/100
292/292 - 13s - 45ms/step - acc: 0.1206 - auc_prc: 0.4199 - auc_roc: 0.4125 - loss: 0.4073 - val_acc: 0.1146 - val_auc_prc: 0.4230 - val_auc_roc: 0.4181 - val_loss: 0.2782
Epoch 7/100
292/292 - 13s - 46ms/step - acc: 0.1149 - auc_prc: 0.4136 - auc_roc: 0.4006 - loss: 0.3057 - val_acc: 0.1175 - val_auc_prc: 0.4162 - val_auc_roc: 0.4055 - val_loss: 0.2917
Epoch 8/100
292/292 - 13s - 46ms/step - acc: 0.1167 - auc_prc: 0.4146 - auc_roc: 0.4025 - loss: 0.3053 - val_acc: 0.1146 - val_auc_prc: 0.4196 - val_auc_roc: 0.4119 - val_loss: 0.2753
Epoch 9/100
292/292 - 13s - 46ms/step - acc: 0.1150 - auc_prc: 0.4174 - auc_roc: 0.4077 - loss: 0.2894 - val_acc: 0.1262 - val_auc_prc: 0.4244 - val_auc_roc: 0.4205 - val_loss: 0.2913
Epoch 10/100
292/292 - 13s - 46ms/step - acc: 0.1232 - auc_prc: 0.4127 - auc_roc: 0.3986 - loss: 0.3201 - val_acc: 0.1127 - val_auc_prc: 0.4167 - val_auc_roc: 0.4064 - val_loss: 0.2874
Epoch 11/100
292/292 - 14s - 47ms/step - acc: 0.1141 - auc_prc: 0.4119 - auc_roc: 0.3970 - loss: 0.3039 - val_acc: 0.1108 - val_auc_prc: 0.4185 - val_auc_roc: 0.4098 - val_loss: 0.2740
Epoch 12/100
292/292 - 14s - 47ms/step - acc: 0.1142 - auc_prc: 0.4119 - auc_roc: 0.3970 - loss: 0.2909 - val_acc: 0.1079 - val_auc_prc: 0.4169 - val_auc_roc: 0.4069 - val_loss: 0.2819
Epoch 13/100
292/292 - 13s - 46ms/step - acc: 0.1129 - auc_prc: 0.4128 - auc_roc: 0.3989 - loss: 0.3019 - val_acc: 0.1021 - val_auc_prc: 0.4190 - val_auc_roc: 0.4108 - val_loss: 0.2677
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
              precision    recall  f1-score   support

           0       0.14      0.24      0.17       403
           1       0.09      0.05      0.07       635

    accuracy                           0.12      1038
   macro avg       0.12      0.14      0.12      1038
weighted avg       0.11      0.12      0.11      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.52      0.44       403
           1       0.61      0.48      0.54       635

    accuracy                           0.50      1038
   macro avg       0.50      0.50      0.49      1038
weighted avg       0.53      0.50      0.50      1038

______________________________________________________
fold 5
Model: "functional_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_5 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_5 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_5 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_5                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_5 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.8364 - auc_prc: 0.8152 - auc_roc: 0.8472 - loss: 0.9204 - val_acc: 0.8650 - val_auc_prc: 0.7999 - val_auc_roc: 0.8685 - val_loss: 0.3055
Epoch 2/100
292/292 - 14s - 46ms/step - acc: 0.8581 - auc_prc: 0.7278 - auc_roc: 0.8061 - loss: 1.3808 - val_acc: 0.8592 - val_auc_prc: 0.7448 - val_auc_roc: 0.8240 - val_loss: 1.7603
Epoch 3/100
292/292 - 14s - 46ms/step - acc: 0.8718 - auc_prc: 0.7047 - auc_roc: 0.7863 - loss: 1.8326 - val_acc: 0.8640 - val_auc_prc: 0.7483 - val_auc_roc: 0.8267 - val_loss: 1.7547
Epoch 4/100
292/292 - 14s - 47ms/step - acc: 0.8647 - auc_prc: 0.7117 - auc_roc: 0.7935 - loss: 1.2670 - val_acc: 0.8698 - val_auc_prc: 0.7035 - val_auc_roc: 0.7868 - val_loss: 0.7866
Epoch 5/100
292/292 - 13s - 46ms/step - acc: 0.8777 - auc_prc: 0.7102 - auc_roc: 0.7927 - loss: 0.9366 - val_acc: 0.8766 - val_auc_prc: 0.7304 - val_auc_roc: 0.8125 - val_loss: 0.5519
Epoch 6/100
292/292 - 13s - 46ms/step - acc: 0.8699 - auc_prc: 0.6329 - auc_roc: 0.7087 - loss: 1.0782 - val_acc: 0.8785 - val_auc_prc: 0.7167 - val_auc_roc: 0.8008 - val_loss: 0.2944
Epoch 7/100
292/292 - 14s - 46ms/step - acc: 0.8837 - auc_prc: 0.7260 - auc_roc: 0.8080 - loss: 0.3778 - val_acc: 0.8766 - val_auc_prc: 0.7248 - val_auc_roc: 0.8087 - val_loss: 0.2739
Epoch 8/100
292/292 - 14s - 46ms/step - acc: 0.8854 - auc_prc: 0.6805 - auc_roc: 0.7633 - loss: 0.3404 - val_acc: 0.8737 - val_auc_prc: 0.7103 - val_auc_roc: 0.7944 - val_loss: 0.3058
Epoch 9/100
292/292 - 14s - 46ms/step - acc: 0.8859 - auc_prc: 0.7174 - auc_roc: 0.8002 - loss: 0.3047 - val_acc: 0.8833 - val_auc_prc: 0.6970 - val_auc_roc: 0.7812 - val_loss: 0.2841
Epoch 10/100
292/292 - 13s - 45ms/step - acc: 0.8854 - auc_prc: 0.6416 - auc_roc: 0.7196 - loss: 0.3056 - val_acc: 0.8717 - val_auc_prc: 0.5359 - val_auc_roc: 0.5670 - val_loss: 0.3074
Epoch 11/100
292/292 - 13s - 46ms/step - acc: 0.8867 - auc_prc: 0.6677 - auc_roc: 0.7496 - loss: 0.2977 - val_acc: 0.8843 - val_auc_prc: 0.7059 - val_auc_roc: 0.7910 - val_loss: 0.2621
******Evaluating TEST set*********
33/33 - 1s - 21ms/step
              precision    recall  f1-score   support

           0       0.88      0.75      0.81       403
           1       0.86      0.94      0.89       634

    accuracy                           0.86      1037
   macro avg       0.87      0.84      0.85      1037
weighted avg       0.87      0.86      0.86      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.51      0.44       403
           1       0.61      0.48      0.54       634

    accuracy                           0.49      1037
   macro avg       0.50      0.50      0.49      1037
weighted avg       0.52      0.49      0.50      1037

______________________________________________________
fold 6
Model: "functional_13"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_6 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_6 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_6 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_6                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_6 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.8127 - auc_prc: 0.8150 - auc_roc: 0.8477 - loss: 0.5216 - val_acc: 0.7927 - val_auc_prc: 0.5796 - val_auc_roc: 0.6357 - val_loss: 0.6056
Epoch 2/100
292/292 - 14s - 46ms/step - acc: 0.8642 - auc_prc: 0.7728 - auc_roc: 0.8451 - loss: 1.0049 - val_acc: 0.8621 - val_auc_prc: 0.7972 - val_auc_roc: 0.8661 - val_loss: 0.7288
Epoch 3/100
292/292 - 13s - 46ms/step - acc: 0.8402 - auc_prc: 0.6582 - auc_roc: 0.7301 - loss: 0.9381 - val_acc: 0.6258 - val_auc_prc: 0.4989 - val_auc_roc: 0.4979 - val_loss: 0.6231
Epoch 4/100
292/292 - 14s - 47ms/step - acc: 0.7265 - auc_prc: 0.5032 - auc_roc: 0.5056 - loss: 0.6616 - val_acc: 0.8476 - val_auc_prc: 0.5160 - val_auc_roc: 0.5302 - val_loss: 0.6292
Epoch 5/100
292/292 - 13s - 46ms/step - acc: 0.5395 - auc_prc: 0.5101 - auc_roc: 0.5068 - loss: 0.5970 - val_acc: 0.1311 - val_auc_prc: 0.4100 - val_auc_roc: 0.3932 - val_loss: 0.3818
Epoch 6/100
292/292 - 13s - 46ms/step - acc: 0.1313 - auc_prc: 0.4014 - auc_roc: 0.3746 - loss: 0.3642 - val_acc: 0.1311 - val_auc_prc: 0.4004 - val_auc_roc: 0.3723 - val_loss: 0.3258
Epoch 7/100
292/292 - 13s - 45ms/step - acc: 0.1279 - auc_prc: 0.3962 - auc_roc: 0.3626 - loss: 0.3626 - val_acc: 0.1321 - val_auc_prc: 0.4169 - val_auc_roc: 0.4070 - val_loss: 0.3203
Epoch 8/100
292/292 - 13s - 45ms/step - acc: 0.1257 - auc_prc: 0.4052 - auc_roc: 0.3831 - loss: 0.3557 - val_acc: 0.1283 - val_auc_prc: 0.4130 - val_auc_roc: 0.3992 - val_loss: 0.3273
Epoch 9/100
292/292 - 13s - 45ms/step - acc: 0.1687 - auc_prc: 0.4513 - auc_roc: 0.4604 - loss: 0.3785 - val_acc: 0.1389 - val_auc_prc: 0.4886 - val_auc_roc: 0.4947 - val_loss: 0.3486
Epoch 10/100
292/292 - 13s - 46ms/step - acc: 0.1277 - auc_prc: 0.4235 - auc_roc: 0.4190 - loss: 0.3302 - val_acc: 0.1283 - val_auc_prc: 0.4162 - val_auc_roc: 0.4055 - val_loss: 0.3236
Epoch 11/100
292/292 - 14s - 46ms/step - acc: 0.1260 - auc_prc: 0.4140 - auc_roc: 0.4012 - loss: 0.3124 - val_acc: 0.1292 - val_auc_prc: 0.4232 - val_auc_roc: 0.4185 - val_loss: 0.3153
Epoch 12/100
292/292 - 14s - 46ms/step - acc: 0.1207 - auc_prc: 0.4131 - auc_roc: 0.3994 - loss: 0.3147 - val_acc: 0.1254 - val_auc_prc: 0.4149 - val_auc_roc: 0.4031 - val_loss: 0.3068
******Evaluating TEST set*********
33/33 - 1s - 21ms/step
              precision    recall  f1-score   support

           0       0.86      0.77      0.81       403
           1       0.86      0.92      0.89       634

    accuracy                           0.86      1037
   macro avg       0.86      0.85      0.85      1037
weighted avg       0.86      0.86      0.86      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.51      0.44       403
           1       0.62      0.50      0.56       634

    accuracy                           0.51      1037
   macro avg       0.51      0.51      0.50      1037
weighted avg       0.53      0.51      0.51      1037

______________________________________________________
fold 7
Model: "functional_15"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_7 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_7 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_7 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_7                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_7 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.8022 - auc_prc: 0.5949 - auc_roc: 0.6480 - loss: 1.0506 - val_acc: 0.6249 - val_auc_prc: 0.4924 - val_auc_roc: 0.4860 - val_loss: 0.9052
Epoch 2/100
292/292 - 13s - 45ms/step - acc: 0.6761 - auc_prc: 0.4937 - auc_roc: 0.4879 - loss: 0.8747 - val_acc: 0.8322 - val_auc_prc: 0.5181 - val_auc_roc: 0.5341 - val_loss: 0.8409
Epoch 3/100
292/292 - 13s - 46ms/step - acc: 0.7291 - auc_prc: 0.5026 - auc_roc: 0.5026 - loss: 0.7447 - val_acc: 0.6114 - val_auc_prc: 0.4592 - val_auc_roc: 0.4143 - val_loss: 0.8759
Epoch 4/100
292/292 - 13s - 45ms/step - acc: 0.5369 - auc_prc: 0.4885 - auc_roc: 0.4740 - loss: 1.1391 - val_acc: 0.1398 - val_auc_prc: 0.4114 - val_auc_roc: 0.3963 - val_loss: 2.0850
Epoch 5/100
292/292 - 13s - 46ms/step - acc: 0.1462 - auc_prc: 0.4072 - auc_roc: 0.3874 - loss: 2.3639 - val_acc: 0.1263 - val_auc_prc: 0.4037 - val_auc_roc: 0.3799 - val_loss: 2.4255
Epoch 6/100
292/292 - 14s - 47ms/step - acc: 0.1426 - auc_prc: 0.4043 - auc_roc: 0.3812 - loss: 2.4182 - val_acc: 0.1591 - val_auc_prc: 0.4157 - val_auc_roc: 0.4045 - val_loss: 1.4895
Epoch 7/100
292/292 - 14s - 47ms/step - acc: 0.1648 - auc_prc: 0.4169 - auc_roc: 0.4070 - loss: 2.0521 - val_acc: 0.1244 - val_auc_prc: 0.4059 - val_auc_roc: 0.3846 - val_loss: 3.4465
Epoch 8/100
292/292 - 13s - 46ms/step - acc: 0.1402 - auc_prc: 0.4021 - auc_roc: 0.3764 - loss: 2.8551 - val_acc: 0.1495 - val_auc_prc: 0.4174 - val_auc_roc: 0.4079 - val_loss: 1.4857
Epoch 9/100
292/292 - 13s - 46ms/step - acc: 0.1519 - auc_prc: 0.4159 - auc_roc: 0.4055 - loss: 2.0638 - val_acc: 0.1823 - val_auc_prc: 0.5007 - val_auc_roc: 0.5023 - val_loss: 0.7487
Epoch 10/100
292/292 - 14s - 47ms/step - acc: 0.2857 - auc_prc: 0.5039 - auc_roc: 0.5034 - loss: 0.8644 - val_acc: 0.3886 - val_auc_prc: 0.5306 - val_auc_roc: 0.5136 - val_loss: 0.8028
Epoch 11/100
292/292 - 14s - 46ms/step - acc: 0.2812 - auc_prc: 0.4934 - auc_roc: 0.4900 - loss: 0.9746 - val_acc: 0.7927 - val_auc_prc: 0.5162 - val_auc_roc: 0.5295 - val_loss: 0.5110
Epoch 12/100
292/292 - 14s - 47ms/step - acc: 0.3013 - auc_prc: 0.5215 - auc_roc: 0.5123 - loss: 0.9380 - val_acc: 0.2420 - val_auc_prc: 0.5167 - val_auc_roc: 0.5087 - val_loss: 1.0645
Epoch 13/100
292/292 - 13s - 46ms/step - acc: 0.3299 - auc_prc: 0.6083 - auc_roc: 0.5687 - loss: 1.1803 - val_acc: 0.2025 - val_auc_prc: 0.4497 - val_auc_roc: 0.4580 - val_loss: 0.9728
Epoch 14/100
292/292 - 13s - 46ms/step - acc: 0.4983 - auc_prc: 0.5080 - auc_roc: 0.5092 - loss: 0.7569 - val_acc: 0.8910 - val_auc_prc: 0.5499 - val_auc_roc: 0.5906 - val_loss: 0.3750
Epoch 15/100
292/292 - 13s - 46ms/step - acc: 0.8571 - auc_prc: 0.5793 - auc_roc: 0.6366 - loss: 0.3588 - val_acc: 0.8843 - val_auc_prc: 0.5672 - val_auc_roc: 0.6182 - val_loss: 0.3101
Epoch 16/100
292/292 - 13s - 46ms/step - acc: 0.8582 - auc_prc: 0.5643 - auc_roc: 0.6138 - loss: 0.3490 - val_acc: 0.8910 - val_auc_prc: 0.5940 - val_auc_roc: 0.6578 - val_loss: 0.3213
Epoch 17/100
292/292 - 13s - 45ms/step - acc: 0.8284 - auc_prc: 0.5670 - auc_roc: 0.6178 - loss: 0.3982 - val_acc: 0.8023 - val_auc_prc: 0.5206 - val_auc_roc: 0.5395 - val_loss: 0.4251
Epoch 18/100
292/292 - 13s - 46ms/step - acc: 0.8508 - auc_prc: 0.5737 - auc_roc: 0.6281 - loss: 0.4151 - val_acc: 0.8968 - val_auc_prc: 0.6064 - val_auc_roc: 0.6750 - val_loss: 0.3362
Epoch 19/100
292/292 - 13s - 45ms/step - acc: 0.8683 - auc_prc: 0.5742 - auc_roc: 0.6290 - loss: 0.4015 - val_acc: 0.8968 - val_auc_prc: 0.5570 - val_auc_roc: 0.6022 - val_loss: 0.3827
Epoch 20/100
292/292 - 13s - 45ms/step - acc: 0.8684 - auc_prc: 0.5633 - auc_roc: 0.6122 - loss: 0.5060 - val_acc: 0.8930 - val_auc_prc: 0.5607 - val_auc_roc: 0.6082 - val_loss: 0.3172
Epoch 21/100
292/292 - 13s - 45ms/step - acc: 0.8675 - auc_prc: 0.5744 - auc_roc: 0.6292 - loss: 0.3751 - val_acc: 0.8997 - val_auc_prc: 0.5700 - val_auc_roc: 0.6227 - val_loss: 0.3000
Epoch 22/100
292/292 - 13s - 45ms/step - acc: 0.8713 - auc_prc: 0.5963 - auc_roc: 0.6612 - loss: 0.3300 - val_acc: 0.8987 - val_auc_prc: 0.5768 - val_auc_roc: 0.6330 - val_loss: 0.2927
Epoch 23/100
292/292 - 13s - 45ms/step - acc: 0.8755 - auc_prc: 0.6113 - auc_roc: 0.6816 - loss: 0.3377 - val_acc: 0.8978 - val_auc_prc: 0.6253 - val_auc_roc: 0.6998 - val_loss: 0.2891
Epoch 24/100
292/292 - 13s - 46ms/step - acc: 0.8740 - auc_prc: 0.5985 - auc_roc: 0.6641 - loss: 0.3380 - val_acc: 0.8891 - val_auc_prc: 0.5974 - val_auc_roc: 0.6626 - val_loss: 0.2983
Epoch 25/100
292/292 - 13s - 45ms/step - acc: 0.8718 - auc_prc: 0.6033 - auc_roc: 0.6708 - loss: 0.3190 - val_acc: 0.8949 - val_auc_prc: 0.6282 - val_auc_roc: 0.7035 - val_loss: 0.2843
Epoch 26/100
292/292 - 14s - 47ms/step - acc: 0.8340 - auc_prc: 0.5361 - auc_roc: 0.5673 - loss: 0.3850 - val_acc: 0.9055 - val_auc_prc: 0.5816 - val_auc_roc: 0.6402 - val_loss: 0.2842
Epoch 27/100
292/292 - 14s - 47ms/step - acc: 0.8763 - auc_prc: 0.5799 - auc_roc: 0.6375 - loss: 0.3579 - val_acc: 0.9016 - val_auc_prc: 0.5615 - val_auc_roc: 0.6094 - val_loss: 0.3031
Epoch 28/100
292/292 - 14s - 47ms/step - acc: 0.8606 - auc_prc: 0.5512 - auc_roc: 0.5927 - loss: 0.3318 - val_acc: 0.8997 - val_auc_prc: 0.5766 - val_auc_roc: 0.6327 - val_loss: 0.2819
Epoch 29/100
292/292 - 14s - 47ms/step - acc: 0.8779 - auc_prc: 0.5803 - auc_roc: 0.6381 - loss: 0.3106 - val_acc: 0.8987 - val_auc_prc: 0.6332 - val_auc_roc: 0.7098 - val_loss: 0.2767
Epoch 30/100
292/292 - 14s - 48ms/step - acc: 0.8789 - auc_prc: 0.5792 - auc_roc: 0.6365 - loss: 0.3017 - val_acc: 0.8968 - val_auc_prc: 0.5967 - val_auc_roc: 0.6618 - val_loss: 0.2803
Epoch 31/100
292/292 - 14s - 48ms/step - acc: 0.8809 - auc_prc: 0.5942 - auc_roc: 0.6583 - loss: 0.2976 - val_acc: 0.8949 - val_auc_prc: 0.5570 - val_auc_roc: 0.6023 - val_loss: 0.2763
Epoch 32/100
292/292 - 14s - 47ms/step - acc: 0.8792 - auc_prc: 0.5797 - auc_roc: 0.6373 - loss: 0.2934 - val_acc: 0.8978 - val_auc_prc: 0.6028 - val_auc_roc: 0.6702 - val_loss: 0.2738
Epoch 33/100
292/292 - 14s - 46ms/step - acc: 0.8831 - auc_prc: 0.5855 - auc_roc: 0.6458 - loss: 0.2938 - val_acc: 0.9016 - val_auc_prc: 0.5564 - val_auc_roc: 0.6013 - val_loss: 0.2787
Epoch 34/100
292/292 - 14s - 47ms/step - acc: 0.8855 - auc_prc: 0.5815 - auc_roc: 0.6399 - loss: 0.2950 - val_acc: 0.8997 - val_auc_prc: 0.5914 - val_auc_roc: 0.6542 - val_loss: 0.2808
Epoch 35/100
292/292 - 13s - 46ms/step - acc: 0.8831 - auc_prc: 0.5766 - auc_roc: 0.6327 - loss: 0.2990 - val_acc: 0.8939 - val_auc_prc: 0.5878 - val_auc_roc: 0.6491 - val_loss: 0.2746
Epoch 36/100
292/292 - 13s - 46ms/step - acc: 0.8857 - auc_prc: 0.5884 - auc_roc: 0.6500 - loss: 0.2984 - val_acc: 0.8930 - val_auc_prc: 0.5768 - val_auc_roc: 0.6330 - val_loss: 0.2837
Epoch 37/100
292/292 - 13s - 46ms/step - acc: 0.8881 - auc_prc: 0.5623 - auc_roc: 0.6107 - loss: 0.3156 - val_acc: 0.8978 - val_auc_prc: 0.5713 - val_auc_roc: 0.6246 - val_loss: 0.2710
Epoch 38/100
292/292 - 13s - 45ms/step - acc: 0.8861 - auc_prc: 0.5624 - auc_roc: 0.6108 - loss: 0.2960 - val_acc: 0.8930 - val_auc_prc: 0.5804 - val_auc_roc: 0.6383 - val_loss: 0.2824
Epoch 39/100
292/292 - 13s - 46ms/step - acc: 0.8874 - auc_prc: 0.5654 - auc_roc: 0.6156 - loss: 0.2850 - val_acc: 0.9026 - val_auc_prc: 0.5552 - val_auc_roc: 0.5994 - val_loss: 0.2676
******Evaluating TEST set*********
33/33 - 1s - 21ms/step
              precision    recall  f1-score   support

           0       0.89      0.84      0.87       403
           1       0.90      0.94      0.92       634

    accuracy                           0.90      1037
   macro avg       0.90      0.89      0.89      1037
weighted avg       0.90      0.90      0.90      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.48      0.42       403
           1       0.61      0.51      0.55       634

    accuracy                           0.50      1037
   macro avg       0.49      0.49      0.49      1037
weighted avg       0.52      0.50      0.50      1037

______________________________________________________
fold 8
Model: "functional_17"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_8 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_8 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_8 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_8                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_8 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 54ms/step - acc: 0.8058 - auc_prc: 0.6630 - auc_roc: 0.7338 - loss: 1.1431 - val_acc: 0.8206 - val_auc_prc: 0.5021 - val_auc_roc: 0.5048 - val_loss: 1.1355
Epoch 2/100
292/292 - 14s - 47ms/step - acc: 0.7065 - auc_prc: 0.5112 - auc_roc: 0.5216 - loss: 1.1252 - val_acc: 0.8428 - val_auc_prc: 0.5594 - val_auc_roc: 0.6062 - val_loss: 3.2724
Epoch 3/100
292/292 - 13s - 45ms/step - acc: 0.8628 - auc_prc: 0.5952 - auc_roc: 0.6589 - loss: 3.0831 - val_acc: 0.8525 - val_auc_prc: 0.5709 - val_auc_roc: 0.6238 - val_loss: 3.2430
Epoch 4/100
292/292 - 13s - 46ms/step - acc: 0.8671 - auc_prc: 0.6332 - auc_roc: 0.7090 - loss: 1.6635 - val_acc: 0.8621 - val_auc_prc: 0.6757 - val_auc_roc: 0.7582 - val_loss: 0.7722
Epoch 5/100
292/292 - 14s - 47ms/step - acc: 0.8358 - auc_prc: 0.5921 - auc_roc: 0.6550 - loss: 0.4695 - val_acc: 0.8563 - val_auc_prc: 0.5625 - val_auc_roc: 0.6111 - val_loss: 0.3961
Epoch 6/100
292/292 - 14s - 47ms/step - acc: 0.8365 - auc_prc: 0.5991 - auc_roc: 0.6648 - loss: 0.4287 - val_acc: 0.8419 - val_auc_prc: 0.5235 - val_auc_roc: 0.5448 - val_loss: 0.3686
Epoch 7/100
292/292 - 13s - 46ms/step - acc: 0.8654 - auc_prc: 0.6627 - auc_roc: 0.7437 - loss: 0.3336 - val_acc: 0.8602 - val_auc_prc: 0.6806 - val_auc_roc: 0.7643 - val_loss: 0.3084
Epoch 8/100
292/292 - 13s - 46ms/step - acc: 0.8625 - auc_prc: 0.6090 - auc_roc: 0.6782 - loss: 0.3415 - val_acc: 0.8457 - val_auc_prc: 0.5159 - val_auc_roc: 0.5309 - val_loss: 0.3803
Epoch 9/100
292/292 - 13s - 46ms/step - acc: 0.8656 - auc_prc: 0.5569 - auc_roc: 0.6021 - loss: 0.3354 - val_acc: 0.8717 - val_auc_prc: 0.6315 - val_auc_roc: 0.7082 - val_loss: 0.3073
Epoch 10/100
292/292 - 13s - 45ms/step - acc: 0.8824 - auc_prc: 0.6583 - auc_roc: 0.7393 - loss: 0.3463 - val_acc: 0.8660 - val_auc_prc: 0.6178 - val_auc_roc: 0.6906 - val_loss: 0.3342
Epoch 11/100
292/292 - 13s - 46ms/step - acc: 0.8856 - auc_prc: 0.6708 - auc_roc: 0.7531 - loss: 0.3378 - val_acc: 0.8737 - val_auc_prc: 0.6853 - val_auc_roc: 0.7692 - val_loss: 0.3879
Epoch 12/100
292/292 - 13s - 46ms/step - acc: 0.8876 - auc_prc: 0.6890 - auc_roc: 0.7724 - loss: 0.3653 - val_acc: 0.8727 - val_auc_prc: 0.6802 - val_auc_roc: 0.7641 - val_loss: 0.3226
Epoch 13/100
292/292 - 14s - 47ms/step - acc: 0.8843 - auc_prc: 0.6647 - auc_roc: 0.7465 - loss: 0.3575 - val_acc: 0.8399 - val_auc_prc: 0.5134 - val_auc_roc: 0.5260 - val_loss: 0.4570
Epoch 14/100
292/292 - 13s - 45ms/step - acc: 0.8832 - auc_prc: 0.5502 - auc_roc: 0.5912 - loss: 0.8417 - val_acc: 0.8689 - val_auc_prc: 0.5586 - val_auc_roc: 0.6048 - val_loss: 0.7847
Epoch 15/100
292/292 - 13s - 46ms/step - acc: 0.8887 - auc_prc: 0.5703 - auc_roc: 0.6230 - loss: 0.7500 - val_acc: 0.8679 - val_auc_prc: 0.5640 - val_auc_roc: 0.6134 - val_loss: 0.5460
Epoch 16/100
292/292 - 13s - 45ms/step - acc: 0.8894 - auc_prc: 0.5904 - auc_roc: 0.6527 - loss: 0.5628 - val_acc: 0.8804 - val_auc_prc: 0.6030 - val_auc_roc: 0.6705 - val_loss: 0.5280
Epoch 17/100
292/292 - 14s - 46ms/step - acc: 0.8881 - auc_prc: 0.5960 - auc_roc: 0.6607 - loss: 0.4283 - val_acc: 0.8804 - val_auc_prc: 0.5624 - val_auc_roc: 0.6109 - val_loss: 0.5203
Epoch 18/100
292/292 - 14s - 46ms/step - acc: 0.8888 - auc_prc: 0.6140 - auc_roc: 0.6850 - loss: 0.4395 - val_acc: 0.8756 - val_auc_prc: 0.5724 - val_auc_roc: 0.6264 - val_loss: 0.4859
Epoch 19/100
292/292 - 13s - 46ms/step - acc: 0.8874 - auc_prc: 0.5997 - auc_roc: 0.6659 - loss: 0.3404 - val_acc: 0.8804 - val_auc_prc: 0.5969 - val_auc_roc: 0.6620 - val_loss: 0.3330
Epoch 20/100
292/292 - 13s - 46ms/step - acc: 0.8912 - auc_prc: 0.6261 - auc_roc: 0.7007 - loss: 0.3270 - val_acc: 0.8611 - val_auc_prc: 0.5639 - val_auc_roc: 0.6133 - val_loss: 0.3253
Epoch 21/100
292/292 - 13s - 45ms/step - acc: 0.8919 - auc_prc: 0.6092 - auc_roc: 0.6789 - loss: 0.2913 - val_acc: 0.8795 - val_auc_prc: 0.6039 - val_auc_roc: 0.6716 - val_loss: 0.3325
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
              precision    recall  f1-score   support

           0       0.88      0.78      0.83       403
           1       0.87      0.93      0.90       634

    accuracy                           0.87      1037
   macro avg       0.88      0.86      0.86      1037
weighted avg       0.87      0.87      0.87      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.55      0.47       403
           1       0.63      0.49      0.55       634

    accuracy                           0.51      1037
   macro avg       0.52      0.52      0.51      1037
weighted avg       0.54      0.51      0.52      1037

______________________________________________________
fold 9
Model: "functional_19"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_9 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_9 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_9 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_9                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/100
292/292 - 16s - 53ms/step - acc: 0.1610 - auc_prc: 0.4026 - auc_roc: 0.3777 - loss: 1.1971 - val_acc: 0.2777 - val_auc_prc: 0.4782 - val_auc_roc: 0.4875 - val_loss: 0.5385
Epoch 2/100
292/292 - 13s - 45ms/step - acc: 0.1408 - auc_prc: 0.4026 - auc_roc: 0.3775 - loss: 0.4278 - val_acc: 0.1360 - val_auc_prc: 0.4226 - val_auc_roc: 0.4175 - val_loss: 0.4227
Epoch 3/100
292/292 - 13s - 45ms/step - acc: 0.1316 - auc_prc: 0.4143 - auc_roc: 0.4019 - loss: 1.2412 - val_acc: 0.1610 - val_auc_prc: 0.4494 - val_auc_roc: 0.4580 - val_loss: 0.3724
Epoch 4/100
292/292 - 13s - 46ms/step - acc: 0.2000 - auc_prc: 0.4467 - auc_roc: 0.4513 - loss: 0.8313 - val_acc: 0.1533 - val_auc_prc: 0.4333 - val_auc_roc: 0.4354 - val_loss: 1.0238
Epoch 5/100
292/292 - 13s - 45ms/step - acc: 0.1253 - auc_prc: 0.4169 - auc_roc: 0.4069 - loss: 1.4198 - val_acc: 0.1398 - val_auc_prc: 0.4257 - val_auc_roc: 0.4229 - val_loss: 1.1071
Epoch 6/100
292/292 - 13s - 45ms/step - acc: 0.1199 - auc_prc: 0.4124 - auc_roc: 0.3981 - loss: 1.2256 - val_acc: 0.1302 - val_auc_prc: 0.4175 - val_auc_roc: 0.4082 - val_loss: 1.0935
Epoch 7/100
292/292 - 13s - 45ms/step - acc: 0.1172 - auc_prc: 0.4143 - auc_roc: 0.4019 - loss: 1.2251 - val_acc: 0.1311 - val_auc_prc: 0.4168 - val_auc_roc: 0.4068 - val_loss: 1.3188
Epoch 8/100
292/292 - 13s - 45ms/step - acc: 0.1152 - auc_prc: 0.4115 - auc_roc: 0.3963 - loss: 1.5584 - val_acc: 0.1283 - val_auc_prc: 0.4145 - val_auc_roc: 0.4024 - val_loss: 1.4165
Epoch 9/100
292/292 - 13s - 45ms/step - acc: 0.1374 - auc_prc: 0.4252 - auc_roc: 0.4219 - loss: 0.8993 - val_acc: 0.1283 - val_auc_prc: 0.4192 - val_auc_roc: 0.4113 - val_loss: 0.4306
Epoch 10/100
292/292 - 13s - 46ms/step - acc: 0.1150 - auc_prc: 0.4125 - auc_roc: 0.3983 - loss: 0.4180 - val_acc: 0.1263 - val_auc_prc: 0.4194 - val_auc_roc: 0.4118 - val_loss: 0.3336
Epoch 11/100
292/292 - 13s - 46ms/step - acc: 0.1136 - auc_prc: 0.4149 - auc_roc: 0.4031 - loss: 0.3247 - val_acc: 0.1263 - val_auc_prc: 0.4202 - val_auc_roc: 0.4131 - val_loss: 0.3334
******Evaluating TEST set*********
33/33 - 1s - 22ms/step
              precision    recall  f1-score   support

           0       0.31      0.71      0.43       403
           1       0.02      0.00      0.01       634

    accuracy                           0.28      1037
   macro avg       0.16      0.36      0.22      1037
weighted avg       0.13      0.28      0.17      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.45      0.41       403
           1       0.60      0.52      0.56       634

    accuracy                           0.49      1037
   macro avg       0.49      0.49      0.48      1037
weighted avg       0.51      0.49      0.50      1037

______________________________________________________
Model: "functional_19"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer_9 (InputLayer)      │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_9 (Conv2D)               │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda_9 (Lambda)               │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention_9                │ [(None, 1024), (None,  │         2,560 │
│ (SelfAttention)                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (Dense)                 │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 130,376 (509.29 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 86,918 (339.53 KB)
None
Mean AUC_ROC[0.6990] IC [0.5443, 0.8536]
Mean Accuracy[0.6910] IC [0.5158, 0.8662]
Mean Recall[0.6990] IC [0.5443, 0.8536]
Mean F1[0.6667] IC [0.4810, 0.8523]
Median AUC_ROC[0.8452]
Median Accuracy[0.8635]
Median Recall[0.8452]
Median F1[0.8528]
