fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 22s - loss: 0.3176 - acc: 0.8623 - auc-prc: 0.9373 - auc-roc: 0.9383 - val_loss: 0.2900 - val_acc: 0.8804 - val_auc-prc: 0.9477 - val_auc-roc: 0.9493 - 22s/epoch - 84ms/step
Epoch 2/100
268/268 - 16s - loss: 0.2842 - acc: 0.8834 - auc-prc: 0.9488 - auc-roc: 0.9502 - val_loss: 0.2801 - val_acc: 0.8909 - val_auc-prc: 0.9515 - val_auc-roc: 0.9529 - 16s/epoch - 58ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2697 - acc: 0.8936 - auc-prc: 0.9534 - auc-roc: 0.9547 - val_loss: 0.2797 - val_acc: 0.8835 - val_auc-prc: 0.9511 - val_auc-roc: 0.9526 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2684 - acc: 0.8922 - auc-prc: 0.9543 - auc-roc: 0.9552 - val_loss: 0.2845 - val_acc: 0.8898 - val_auc-prc: 0.9516 - val_auc-roc: 0.9532 - 15s/epoch - 56ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2641 - acc: 0.8954 - auc-prc: 0.9556 - auc-roc: 0.9567 - val_loss: 0.2776 - val_acc: 0.8993 - val_auc-prc: 0.9517 - val_auc-roc: 0.9528 - 15s/epoch - 57ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2612 - acc: 0.8991 - auc-prc: 0.9564 - auc-roc: 0.9572 - val_loss: 0.2742 - val_acc: 0.8919 - val_auc-prc: 0.9530 - val_auc-roc: 0.9544 - 15s/epoch - 57ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2596 - acc: 0.8951 - auc-prc: 0.9574 - auc-roc: 0.9582 - val_loss: 0.2771 - val_acc: 0.8898 - val_auc-prc: 0.9524 - val_auc-roc: 0.9536 - 15s/epoch - 57ms/step
Epoch 8/100
268/268 - 16s - loss: 0.2546 - acc: 0.9000 - auc-prc: 0.9590 - auc-roc: 0.9600 - val_loss: 0.2934 - val_acc: 0.8846 - val_auc-prc: 0.9499 - val_auc-roc: 0.9508 - 16s/epoch - 60ms/step
Epoch 9/100
268/268 - 16s - loss: 0.2531 - acc: 0.9000 - auc-prc: 0.9596 - auc-roc: 0.9602 - val_loss: 0.2899 - val_acc: 0.8772 - val_auc-prc: 0.9486 - val_auc-roc: 0.9498 - 16s/epoch - 58ms/step
Epoch 10/100
268/268 - 16s - loss: 0.2518 - acc: 0.9014 - auc-prc: 0.9592 - auc-roc: 0.9605 - val_loss: 0.2776 - val_acc: 0.8793 - val_auc-prc: 0.9518 - val_auc-roc: 0.9525 - 16s/epoch - 61ms/step
Epoch 11/100
268/268 - 16s - loss: 0.2481 - acc: 0.8995 - auc-prc: 0.9610 - auc-roc: 0.9618 - val_loss: 0.2743 - val_acc: 0.8888 - val_auc-prc: 0.9532 - val_auc-roc: 0.9544 - 16s/epoch - 60ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2473 - acc: 0.9013 - auc-prc: 0.9613 - auc-roc: 0.9620 - val_loss: 0.2929 - val_acc: 0.8762 - val_auc-prc: 0.9484 - val_auc-roc: 0.9493 - 15s/epoch - 58ms/step
Epoch 13/100
268/268 - 16s - loss: 0.2484 - acc: 0.9015 - auc-prc: 0.9614 - auc-roc: 0.9620 - val_loss: 0.2736 - val_acc: 0.8846 - val_auc-prc: 0.9538 - val_auc-roc: 0.9542 - 16s/epoch - 59ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2477 - acc: 0.9014 - auc-prc: 0.9610 - auc-roc: 0.9618 - val_loss: 0.2779 - val_acc: 0.8856 - val_auc-prc: 0.9529 - val_auc-roc: 0.9544 - 15s/epoch - 55ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2426 - acc: 0.9015 - auc-prc: 0.9631 - auc-roc: 0.9635 - val_loss: 0.2732 - val_acc: 0.8825 - val_auc-prc: 0.9546 - val_auc-roc: 0.9554 - 15s/epoch - 55ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2403 - acc: 0.9013 - auc-prc: 0.9636 - auc-roc: 0.9641 - val_loss: 0.2729 - val_acc: 0.8867 - val_auc-prc: 0.9530 - val_auc-roc: 0.9541 - 15s/epoch - 55ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2357 - acc: 0.9034 - auc-prc: 0.9656 - auc-roc: 0.9656 - val_loss: 0.2799 - val_acc: 0.8877 - val_auc-prc: 0.9537 - val_auc-roc: 0.9545 - 15s/epoch - 55ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2335 - acc: 0.9068 - auc-prc: 0.9662 - auc-roc: 0.9663 - val_loss: 0.2950 - val_acc: 0.8877 - val_auc-prc: 0.9515 - val_auc-roc: 0.9539 - 15s/epoch - 55ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2317 - acc: 0.9074 - auc-prc: 0.9665 - auc-roc: 0.9667 - val_loss: 0.2860 - val_acc: 0.8846 - val_auc-prc: 0.9490 - val_auc-roc: 0.9499 - 15s/epoch - 55ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2327 - acc: 0.9056 - auc-prc: 0.9665 - auc-roc: 0.9665 - val_loss: 0.2786 - val_acc: 0.8835 - val_auc-prc: 0.9530 - val_auc-roc: 0.9539 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2271 - acc: 0.9075 - auc-prc: 0.9683 - auc-roc: 0.9683 - val_loss: 0.2724 - val_acc: 0.8888 - val_auc-prc: 0.9541 - val_auc-roc: 0.9553 - 15s/epoch - 56ms/step
Epoch 22/100
268/268 - 15s - loss: 0.2255 - acc: 0.9075 - auc-prc: 0.9684 - auc-roc: 0.9685 - val_loss: 0.2768 - val_acc: 0.8888 - val_auc-prc: 0.9521 - val_auc-roc: 0.9524 - 15s/epoch - 56ms/step
Epoch 23/100
268/268 - 15s - loss: 0.2210 - acc: 0.9127 - auc-prc: 0.9698 - auc-roc: 0.9697 - val_loss: 0.2752 - val_acc: 0.8888 - val_auc-prc: 0.9560 - val_auc-roc: 0.9566 - 15s/epoch - 57ms/step
Epoch 24/100
268/268 - 15s - loss: 0.2209 - acc: 0.9116 - auc-prc: 0.9694 - auc-roc: 0.9697 - val_loss: 0.2774 - val_acc: 0.8793 - val_auc-prc: 0.9536 - val_auc-roc: 0.9531 - 15s/epoch - 56ms/step
Epoch 25/100
268/268 - 15s - loss: 0.2190 - acc: 0.9142 - auc-prc: 0.9698 - auc-roc: 0.9701 - val_loss: 0.2717 - val_acc: 0.8888 - val_auc-prc: 0.9563 - val_auc-roc: 0.9570 - 15s/epoch - 56ms/step
Epoch 26/100
268/268 - 15s - loss: 0.2150 - acc: 0.9146 - auc-prc: 0.9716 - auc-roc: 0.9715 - val_loss: 0.2790 - val_acc: 0.8835 - val_auc-prc: 0.9535 - val_auc-roc: 0.9536 - 15s/epoch - 58ms/step
Epoch 27/100
268/268 - 16s - loss: 0.2096 - acc: 0.9163 - auc-prc: 0.9727 - auc-roc: 0.9729 - val_loss: 0.2716 - val_acc: 0.8898 - val_auc-prc: 0.9564 - val_auc-roc: 0.9564 - 16s/epoch - 59ms/step
Epoch 28/100
268/268 - 16s - loss: 0.2044 - acc: 0.9187 - auc-prc: 0.9741 - auc-roc: 0.9741 - val_loss: 0.2801 - val_acc: 0.8835 - val_auc-prc: 0.9541 - val_auc-roc: 0.9536 - 16s/epoch - 59ms/step
Epoch 29/100
268/268 - 16s - loss: 0.1993 - acc: 0.9215 - auc-prc: 0.9753 - auc-roc: 0.9753 - val_loss: 0.2953 - val_acc: 0.8814 - val_auc-prc: 0.9483 - val_auc-roc: 0.9510 - 16s/epoch - 59ms/step
Epoch 30/100
268/268 - 15s - loss: 0.1977 - acc: 0.9221 - auc-prc: 0.9752 - auc-roc: 0.9756 - val_loss: 0.2805 - val_acc: 0.8877 - val_auc-prc: 0.9556 - val_auc-roc: 0.9576 - 15s/epoch - 58ms/step
Epoch 31/100
268/268 - 15s - loss: 0.1898 - acc: 0.9272 - auc-prc: 0.9774 - auc-roc: 0.9775 - val_loss: 0.2855 - val_acc: 0.8814 - val_auc-prc: 0.9512 - val_auc-roc: 0.9509 - 15s/epoch - 56ms/step
Epoch 32/100
268/268 - 15s - loss: 0.1843 - acc: 0.9284 - auc-prc: 0.9787 - auc-roc: 0.9788 - val_loss: 0.2888 - val_acc: 0.8804 - val_auc-prc: 0.9510 - val_auc-roc: 0.9524 - 15s/epoch - 55ms/step
Early stopping epoch: 31
******Evaluating TEST set*********
30/30 - 1s - 787ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.90      0.81      0.85       383
           1       0.88      0.94      0.91       570

    accuracy                           0.89       953
   macro avg       0.89      0.88      0.88       953
weighted avg       0.89      0.89      0.89       953

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.49      0.44       383
           1       0.60      0.50      0.55       570

    accuracy                           0.50       953
   macro avg       0.50      0.50      0.49       953
weighted avg       0.52      0.50      0.50       953

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3227 - acc: 0.8635 - auc-prc: 0.9346 - auc-roc: 0.9362 - val_loss: 0.2902 - val_acc: 0.8783 - val_auc-prc: 0.9467 - val_auc-roc: 0.9480 - 18s/epoch - 66ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2841 - acc: 0.8827 - auc-prc: 0.9489 - auc-roc: 0.9502 - val_loss: 0.2861 - val_acc: 0.8919 - val_auc-prc: 0.9478 - val_auc-roc: 0.9499 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2723 - acc: 0.8902 - auc-prc: 0.9525 - auc-roc: 0.9541 - val_loss: 0.2785 - val_acc: 0.8940 - val_auc-prc: 0.9502 - val_auc-roc: 0.9519 - 15s/epoch - 55ms/step
Epoch 4/100
268/268 - 14s - loss: 0.2671 - acc: 0.8923 - auc-prc: 0.9548 - auc-roc: 0.9558 - val_loss: 0.2738 - val_acc: 0.8951 - val_auc-prc: 0.9533 - val_auc-roc: 0.9540 - 14s/epoch - 54ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2645 - acc: 0.8968 - auc-prc: 0.9553 - auc-roc: 0.9567 - val_loss: 0.2648 - val_acc: 0.9024 - val_auc-prc: 0.9564 - val_auc-roc: 0.9569 - 14s/epoch - 54ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2620 - acc: 0.8957 - auc-prc: 0.9561 - auc-roc: 0.9573 - val_loss: 0.2705 - val_acc: 0.8961 - val_auc-prc: 0.9545 - val_auc-roc: 0.9559 - 15s/epoch - 54ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2601 - acc: 0.8949 - auc-prc: 0.9566 - auc-roc: 0.9578 - val_loss: 0.2636 - val_acc: 0.8972 - val_auc-prc: 0.9566 - val_auc-roc: 0.9569 - 15s/epoch - 55ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2550 - acc: 0.8974 - auc-prc: 0.9587 - auc-roc: 0.9596 - val_loss: 0.2611 - val_acc: 0.8982 - val_auc-prc: 0.9583 - val_auc-roc: 0.9593 - 15s/epoch - 57ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2568 - acc: 0.8960 - auc-prc: 0.9582 - auc-roc: 0.9591 - val_loss: 0.2495 - val_acc: 0.9003 - val_auc-prc: 0.9606 - val_auc-roc: 0.9609 - 15s/epoch - 55ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2525 - acc: 0.8992 - auc-prc: 0.9594 - auc-roc: 0.9605 - val_loss: 0.2541 - val_acc: 0.9014 - val_auc-prc: 0.9593 - val_auc-roc: 0.9596 - 15s/epoch - 54ms/step
Epoch 11/100
268/268 - 14s - loss: 0.2517 - acc: 0.8992 - auc-prc: 0.9602 - auc-roc: 0.9611 - val_loss: 0.2852 - val_acc: 0.8877 - val_auc-prc: 0.9490 - val_auc-roc: 0.9498 - 14s/epoch - 53ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2474 - acc: 0.9032 - auc-prc: 0.9613 - auc-roc: 0.9621 - val_loss: 0.2520 - val_acc: 0.8961 - val_auc-prc: 0.9601 - val_auc-roc: 0.9603 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2465 - acc: 0.9009 - auc-prc: 0.9618 - auc-roc: 0.9625 - val_loss: 0.2548 - val_acc: 0.8951 - val_auc-prc: 0.9600 - val_auc-roc: 0.9602 - 15s/epoch - 57ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2448 - acc: 0.9047 - auc-prc: 0.9626 - auc-roc: 0.9631 - val_loss: 0.2523 - val_acc: 0.8951 - val_auc-prc: 0.9612 - val_auc-roc: 0.9609 - 15s/epoch - 56ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2448 - acc: 0.9030 - auc-prc: 0.9622 - auc-roc: 0.9631 - val_loss: 0.2537 - val_acc: 0.8982 - val_auc-prc: 0.9609 - val_auc-roc: 0.9607 - 15s/epoch - 56ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2391 - acc: 0.9025 - auc-prc: 0.9643 - auc-roc: 0.9648 - val_loss: 0.2997 - val_acc: 0.8846 - val_auc-prc: 0.9462 - val_auc-roc: 0.9484 - 15s/epoch - 55ms/step
Epoch 17/100
268/268 - 14s - loss: 0.2382 - acc: 0.9039 - auc-prc: 0.9647 - auc-roc: 0.9651 - val_loss: 0.2548 - val_acc: 0.8993 - val_auc-prc: 0.9592 - val_auc-roc: 0.9594 - 14s/epoch - 53ms/step
Epoch 18/100
268/268 - 14s - loss: 0.2336 - acc: 0.9062 - auc-prc: 0.9656 - auc-roc: 0.9662 - val_loss: 0.2553 - val_acc: 0.8930 - val_auc-prc: 0.9601 - val_auc-roc: 0.9598 - 14s/epoch - 53ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2318 - acc: 0.9086 - auc-prc: 0.9663 - auc-roc: 0.9666 - val_loss: 0.2648 - val_acc: 0.8930 - val_auc-prc: 0.9581 - val_auc-roc: 0.9579 - 14s/epoch - 53ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2312 - acc: 0.9056 - auc-prc: 0.9670 - auc-roc: 0.9671 - val_loss: 0.2565 - val_acc: 0.8909 - val_auc-prc: 0.9603 - val_auc-roc: 0.9598 - 15s/epoch - 56ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2289 - acc: 0.9083 - auc-prc: 0.9675 - auc-roc: 0.9677 - val_loss: 0.2558 - val_acc: 0.8961 - val_auc-prc: 0.9590 - val_auc-roc: 0.9598 - 15s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 727ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.87      0.87      0.87       383
           1       0.91      0.91      0.91       570

    accuracy                           0.90       953
   macro avg       0.89      0.89      0.89       953
weighted avg       0.89      0.90      0.90       953

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.52      0.46       383
           1       0.61      0.49      0.54       570

    accuracy                           0.50       953
   macro avg       0.51      0.51      0.50       953
weighted avg       0.53      0.50      0.51       953

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3203 - acc: 0.8630 - auc-prc: 0.9361 - auc-roc: 0.9374 - val_loss: 0.2849 - val_acc: 0.8867 - val_auc-prc: 0.9456 - val_auc-roc: 0.9480 - 17s/epoch - 65ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2866 - acc: 0.8830 - auc-prc: 0.9479 - auc-roc: 0.9496 - val_loss: 0.2901 - val_acc: 0.8888 - val_auc-prc: 0.9430 - val_auc-roc: 0.9454 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2776 - acc: 0.8897 - auc-prc: 0.9504 - auc-roc: 0.9524 - val_loss: 0.2670 - val_acc: 0.8940 - val_auc-prc: 0.9557 - val_auc-roc: 0.9563 - 15s/epoch - 55ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2692 - acc: 0.8928 - auc-prc: 0.9534 - auc-roc: 0.9551 - val_loss: 0.2854 - val_acc: 0.8846 - val_auc-prc: 0.9485 - val_auc-roc: 0.9499 - 15s/epoch - 58ms/step
Epoch 5/100
268/268 - 16s - loss: 0.2668 - acc: 0.8942 - auc-prc: 0.9548 - auc-roc: 0.9558 - val_loss: 0.2633 - val_acc: 0.8951 - val_auc-prc: 0.9578 - val_auc-roc: 0.9578 - 16s/epoch - 59ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2633 - acc: 0.8945 - auc-prc: 0.9558 - auc-roc: 0.9570 - val_loss: 0.2628 - val_acc: 0.8982 - val_auc-prc: 0.9574 - val_auc-roc: 0.9572 - 15s/epoch - 55ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2605 - acc: 0.8950 - auc-prc: 0.9571 - auc-roc: 0.9581 - val_loss: 0.2549 - val_acc: 0.8961 - val_auc-prc: 0.9595 - val_auc-roc: 0.9597 - 15s/epoch - 55ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2572 - acc: 0.8971 - auc-prc: 0.9580 - auc-roc: 0.9590 - val_loss: 0.2590 - val_acc: 0.8951 - val_auc-prc: 0.9598 - val_auc-roc: 0.9597 - 15s/epoch - 55ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2550 - acc: 0.8967 - auc-prc: 0.9587 - auc-roc: 0.9598 - val_loss: 0.2487 - val_acc: 0.9003 - val_auc-prc: 0.9629 - val_auc-roc: 0.9627 - 15s/epoch - 55ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2542 - acc: 0.8992 - auc-prc: 0.9592 - auc-roc: 0.9600 - val_loss: 0.2578 - val_acc: 0.8993 - val_auc-prc: 0.9575 - val_auc-roc: 0.9588 - 15s/epoch - 55ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2527 - acc: 0.8995 - auc-prc: 0.9597 - auc-roc: 0.9605 - val_loss: 0.2462 - val_acc: 0.8993 - val_auc-prc: 0.9613 - val_auc-roc: 0.9618 - 15s/epoch - 57ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2518 - acc: 0.8994 - auc-prc: 0.9602 - auc-roc: 0.9607 - val_loss: 0.2652 - val_acc: 0.8930 - val_auc-prc: 0.9577 - val_auc-roc: 0.9579 - 15s/epoch - 58ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2481 - acc: 0.9012 - auc-prc: 0.9611 - auc-roc: 0.9620 - val_loss: 0.2508 - val_acc: 0.8993 - val_auc-prc: 0.9617 - val_auc-roc: 0.9619 - 15s/epoch - 54ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2481 - acc: 0.9000 - auc-prc: 0.9613 - auc-roc: 0.9621 - val_loss: 0.2579 - val_acc: 0.8993 - val_auc-prc: 0.9575 - val_auc-roc: 0.9586 - 15s/epoch - 54ms/step
Epoch 15/100
268/268 - 14s - loss: 0.2463 - acc: 0.9008 - auc-prc: 0.9620 - auc-roc: 0.9623 - val_loss: 0.2506 - val_acc: 0.9024 - val_auc-prc: 0.9620 - val_auc-roc: 0.9625 - 14s/epoch - 54ms/step
Epoch 16/100
268/268 - 14s - loss: 0.2446 - acc: 0.9008 - auc-prc: 0.9626 - auc-roc: 0.9630 - val_loss: 0.2458 - val_acc: 0.9014 - val_auc-prc: 0.9614 - val_auc-roc: 0.9627 - 14s/epoch - 54ms/step
Epoch 17/100
268/268 - 14s - loss: 0.2423 - acc: 0.9026 - auc-prc: 0.9630 - auc-roc: 0.9636 - val_loss: 0.2488 - val_acc: 0.9035 - val_auc-prc: 0.9622 - val_auc-roc: 0.9624 - 14s/epoch - 54ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2409 - acc: 0.9036 - auc-prc: 0.9640 - auc-roc: 0.9643 - val_loss: 0.2444 - val_acc: 0.8972 - val_auc-prc: 0.9629 - val_auc-roc: 0.9631 - 15s/epoch - 55ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2374 - acc: 0.9035 - auc-prc: 0.9648 - auc-roc: 0.9652 - val_loss: 0.2405 - val_acc: 0.9066 - val_auc-prc: 0.9637 - val_auc-roc: 0.9648 - 15s/epoch - 55ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2338 - acc: 0.9065 - auc-prc: 0.9661 - auc-roc: 0.9662 - val_loss: 0.2403 - val_acc: 0.9035 - val_auc-prc: 0.9645 - val_auc-roc: 0.9653 - 15s/epoch - 55ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2338 - acc: 0.9046 - auc-prc: 0.9662 - auc-roc: 0.9664 - val_loss: 0.2354 - val_acc: 0.9066 - val_auc-prc: 0.9654 - val_auc-roc: 0.9664 - 15s/epoch - 55ms/step
Epoch 22/100
268/268 - 15s - loss: 0.2312 - acc: 0.9076 - auc-prc: 0.9670 - auc-roc: 0.9672 - val_loss: 0.2492 - val_acc: 0.9035 - val_auc-prc: 0.9621 - val_auc-roc: 0.9627 - 15s/epoch - 54ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
30/30 - 1s - 704ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.92      0.84      0.88       382
           1       0.90      0.95      0.92       571

    accuracy                           0.91       953
   macro avg       0.91      0.89      0.90       953
weighted avg       0.91      0.91      0.91       953

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.50      0.44       382
           1       0.60      0.49      0.54       571

    accuracy                           0.50       953
   macro avg       0.50      0.50      0.49       953
weighted avg       0.52      0.50      0.50       953

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3143 - acc: 0.8665 - auc-prc: 0.9378 - auc-roc: 0.9395 - val_loss: 0.3181 - val_acc: 0.8803 - val_auc-prc: 0.9450 - val_auc-roc: 0.9465 - 18s/epoch - 67ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2808 - acc: 0.8890 - auc-prc: 0.9496 - auc-roc: 0.9513 - val_loss: 0.2590 - val_acc: 0.8992 - val_auc-prc: 0.9590 - val_auc-roc: 0.9590 - 15s/epoch - 56ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2736 - acc: 0.8903 - auc-prc: 0.9520 - auc-roc: 0.9534 - val_loss: 0.2549 - val_acc: 0.8960 - val_auc-prc: 0.9611 - val_auc-roc: 0.9609 - 15s/epoch - 57ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2663 - acc: 0.8921 - auc-prc: 0.9551 - auc-roc: 0.9562 - val_loss: 0.2534 - val_acc: 0.8981 - val_auc-prc: 0.9616 - val_auc-roc: 0.9616 - 15s/epoch - 54ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2635 - acc: 0.8963 - auc-prc: 0.9552 - auc-roc: 0.9568 - val_loss: 0.2595 - val_acc: 0.8939 - val_auc-prc: 0.9594 - val_auc-roc: 0.9589 - 15s/epoch - 54ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2639 - acc: 0.8962 - auc-prc: 0.9556 - auc-roc: 0.9568 - val_loss: 0.2756 - val_acc: 0.8876 - val_auc-prc: 0.9532 - val_auc-roc: 0.9543 - 14s/epoch - 54ms/step
Epoch 7/100
268/268 - 14s - loss: 0.2623 - acc: 0.8945 - auc-prc: 0.9565 - auc-roc: 0.9573 - val_loss: 0.2578 - val_acc: 0.8971 - val_auc-prc: 0.9589 - val_auc-roc: 0.9589 - 14s/epoch - 54ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2588 - acc: 0.8969 - auc-prc: 0.9578 - auc-roc: 0.9585 - val_loss: 0.2474 - val_acc: 0.8971 - val_auc-prc: 0.9624 - val_auc-roc: 0.9631 - 15s/epoch - 55ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2544 - acc: 0.8977 - auc-prc: 0.9589 - auc-roc: 0.9598 - val_loss: 0.2470 - val_acc: 0.8971 - val_auc-prc: 0.9644 - val_auc-roc: 0.9639 - 15s/epoch - 55ms/step
Epoch 10/100
268/268 - 14s - loss: 0.2520 - acc: 0.8963 - auc-prc: 0.9601 - auc-roc: 0.9609 - val_loss: 0.2505 - val_acc: 0.8992 - val_auc-prc: 0.9623 - val_auc-roc: 0.9623 - 14s/epoch - 53ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2564 - acc: 0.8999 - auc-prc: 0.9584 - auc-roc: 0.9592 - val_loss: 0.2406 - val_acc: 0.8981 - val_auc-prc: 0.9651 - val_auc-roc: 0.9648 - 15s/epoch - 55ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2516 - acc: 0.8983 - auc-prc: 0.9606 - auc-roc: 0.9612 - val_loss: 0.2422 - val_acc: 0.9023 - val_auc-prc: 0.9652 - val_auc-roc: 0.9646 - 15s/epoch - 55ms/step
Epoch 13/100
268/268 - 14s - loss: 0.2483 - acc: 0.9005 - auc-prc: 0.9615 - auc-roc: 0.9619 - val_loss: 0.2559 - val_acc: 0.9023 - val_auc-prc: 0.9599 - val_auc-roc: 0.9604 - 14s/epoch - 54ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2461 - acc: 0.9008 - auc-prc: 0.9623 - auc-roc: 0.9625 - val_loss: 0.2550 - val_acc: 0.8950 - val_auc-prc: 0.9620 - val_auc-roc: 0.9617 - 15s/epoch - 56ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2432 - acc: 0.9022 - auc-prc: 0.9630 - auc-roc: 0.9635 - val_loss: 0.2437 - val_acc: 0.9023 - val_auc-prc: 0.9632 - val_auc-roc: 0.9640 - 15s/epoch - 55ms/step
Epoch 16/100
268/268 - 14s - loss: 0.2457 - acc: 0.8976 - auc-prc: 0.9628 - auc-roc: 0.9630 - val_loss: 0.2538 - val_acc: 0.9002 - val_auc-prc: 0.9611 - val_auc-roc: 0.9610 - 14s/epoch - 54ms/step
Epoch 17/100
268/268 - 14s - loss: 0.2388 - acc: 0.9035 - auc-prc: 0.9646 - auc-roc: 0.9648 - val_loss: 0.2450 - val_acc: 0.9044 - val_auc-prc: 0.9642 - val_auc-roc: 0.9638 - 14s/epoch - 54ms/step
Epoch 18/100
268/268 - 14s - loss: 0.2375 - acc: 0.9056 - auc-prc: 0.9646 - auc-roc: 0.9649 - val_loss: 0.2522 - val_acc: 0.9013 - val_auc-prc: 0.9613 - val_auc-roc: 0.9610 - 14s/epoch - 54ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2336 - acc: 0.9058 - auc-prc: 0.9660 - auc-roc: 0.9664 - val_loss: 0.2404 - val_acc: 0.9034 - val_auc-prc: 0.9646 - val_auc-roc: 0.9644 - 14s/epoch - 54ms/step
Epoch 20/100
268/268 - 14s - loss: 0.2311 - acc: 0.9096 - auc-prc: 0.9670 - auc-roc: 0.9670 - val_loss: 0.2635 - val_acc: 0.8960 - val_auc-prc: 0.9570 - val_auc-roc: 0.9575 - 14s/epoch - 54ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2289 - acc: 0.9079 - auc-prc: 0.9680 - auc-roc: 0.9677 - val_loss: 0.2397 - val_acc: 0.9002 - val_auc-prc: 0.9650 - val_auc-roc: 0.9648 - 15s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 709ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       382
           1       0.91      0.92      0.92       570

    accuracy                           0.90       952
   macro avg       0.90      0.89      0.90       952
weighted avg       0.90      0.90      0.90       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.48      0.43       382
           1       0.59      0.51      0.55       570

    accuracy                           0.50       952
   macro avg       0.50      0.50      0.49       952
weighted avg       0.51      0.50      0.50       952

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3152 - acc: 0.8644 - auc-prc: 0.9385 - auc-roc: 0.9390 - val_loss: 0.2737 - val_acc: 0.8929 - val_auc-prc: 0.9536 - val_auc-roc: 0.9556 - 18s/epoch - 67ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2851 - acc: 0.8851 - auc-prc: 0.9478 - auc-roc: 0.9496 - val_loss: 0.2565 - val_acc: 0.8908 - val_auc-prc: 0.9574 - val_auc-roc: 0.9591 - 15s/epoch - 58ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2757 - acc: 0.8902 - auc-prc: 0.9513 - auc-roc: 0.9528 - val_loss: 0.2543 - val_acc: 0.8929 - val_auc-prc: 0.9608 - val_auc-roc: 0.9614 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 16s - loss: 0.2719 - acc: 0.8894 - auc-prc: 0.9529 - auc-roc: 0.9541 - val_loss: 0.2590 - val_acc: 0.8908 - val_auc-prc: 0.9607 - val_auc-roc: 0.9603 - 16s/epoch - 58ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2650 - acc: 0.8921 - auc-prc: 0.9551 - auc-roc: 0.9566 - val_loss: 0.2473 - val_acc: 0.8845 - val_auc-prc: 0.9624 - val_auc-roc: 0.9631 - 15s/epoch - 57ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2629 - acc: 0.8943 - auc-prc: 0.9558 - auc-roc: 0.9571 - val_loss: 0.2487 - val_acc: 0.8981 - val_auc-prc: 0.9628 - val_auc-roc: 0.9628 - 14s/epoch - 53ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2564 - acc: 0.8984 - auc-prc: 0.9580 - auc-roc: 0.9591 - val_loss: 0.2441 - val_acc: 0.8981 - val_auc-prc: 0.9642 - val_auc-roc: 0.9642 - 15s/epoch - 55ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2567 - acc: 0.8972 - auc-prc: 0.9584 - auc-roc: 0.9592 - val_loss: 0.2465 - val_acc: 0.8971 - val_auc-prc: 0.9625 - val_auc-roc: 0.9638 - 15s/epoch - 56ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2542 - acc: 0.8969 - auc-prc: 0.9593 - auc-roc: 0.9600 - val_loss: 0.2412 - val_acc: 0.9065 - val_auc-prc: 0.9648 - val_auc-roc: 0.9653 - 15s/epoch - 55ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2541 - acc: 0.8974 - auc-prc: 0.9590 - auc-roc: 0.9599 - val_loss: 0.2439 - val_acc: 0.9055 - val_auc-prc: 0.9614 - val_auc-roc: 0.9631 - 15s/epoch - 56ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2509 - acc: 0.8998 - auc-prc: 0.9599 - auc-roc: 0.9611 - val_loss: 0.2401 - val_acc: 0.9055 - val_auc-prc: 0.9636 - val_auc-roc: 0.9645 - 15s/epoch - 55ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2470 - acc: 0.9001 - auc-prc: 0.9613 - auc-roc: 0.9623 - val_loss: 0.2577 - val_acc: 0.8876 - val_auc-prc: 0.9610 - val_auc-roc: 0.9610 - 15s/epoch - 55ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2487 - acc: 0.8993 - auc-prc: 0.9611 - auc-roc: 0.9620 - val_loss: 0.2379 - val_acc: 0.8971 - val_auc-prc: 0.9668 - val_auc-roc: 0.9660 - 15s/epoch - 56ms/step
Epoch 14/100
268/268 - 14s - loss: 0.2444 - acc: 0.9005 - auc-prc: 0.9627 - auc-roc: 0.9633 - val_loss: 0.2383 - val_acc: 0.9034 - val_auc-prc: 0.9645 - val_auc-roc: 0.9653 - 14s/epoch - 54ms/step
Epoch 15/100
268/268 - 14s - loss: 0.2402 - acc: 0.9019 - auc-prc: 0.9638 - auc-roc: 0.9642 - val_loss: 0.2383 - val_acc: 0.9044 - val_auc-prc: 0.9642 - val_auc-roc: 0.9649 - 14s/epoch - 54ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2394 - acc: 0.9033 - auc-prc: 0.9643 - auc-roc: 0.9646 - val_loss: 0.2492 - val_acc: 0.9065 - val_auc-prc: 0.9602 - val_auc-roc: 0.9616 - 15s/epoch - 55ms/step
Epoch 17/100
268/268 - 16s - loss: 0.2387 - acc: 0.9034 - auc-prc: 0.9646 - auc-roc: 0.9649 - val_loss: 0.2620 - val_acc: 0.8897 - val_auc-prc: 0.9627 - val_auc-roc: 0.9622 - 16s/epoch - 58ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2376 - acc: 0.9014 - auc-prc: 0.9654 - auc-roc: 0.9653 - val_loss: 0.2406 - val_acc: 0.8939 - val_auc-prc: 0.9649 - val_auc-roc: 0.9648 - 15s/epoch - 57ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2345 - acc: 0.9056 - auc-prc: 0.9659 - auc-roc: 0.9660 - val_loss: 0.2414 - val_acc: 0.9118 - val_auc-prc: 0.9616 - val_auc-roc: 0.9634 - 15s/epoch - 57ms/step
Epoch 20/100
268/268 - 16s - loss: 0.2313 - acc: 0.9056 - auc-prc: 0.9675 - auc-roc: 0.9674 - val_loss: 0.2600 - val_acc: 0.8845 - val_auc-prc: 0.9589 - val_auc-roc: 0.9599 - 16s/epoch - 60ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2274 - acc: 0.9071 - auc-prc: 0.9677 - auc-roc: 0.9682 - val_loss: 0.2466 - val_acc: 0.8950 - val_auc-prc: 0.9643 - val_auc-roc: 0.9638 - 15s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 735ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       382
           1       0.91      0.92      0.91       570

    accuracy                           0.90       952
   macro avg       0.89      0.89      0.89       952
weighted avg       0.90      0.90      0.90       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.47      0.42       382
           1       0.57      0.48      0.52       570

    accuracy                           0.47       952
   macro avg       0.47      0.47      0.47       952
weighted avg       0.49      0.47      0.48       952

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3181 - acc: 0.8655 - auc-prc: 0.9366 - auc-roc: 0.9379 - val_loss: 0.3095 - val_acc: 0.8729 - val_auc-prc: 0.9410 - val_auc-roc: 0.9442 - 18s/epoch - 68ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2798 - acc: 0.8875 - auc-prc: 0.9500 - auc-roc: 0.9513 - val_loss: 0.2922 - val_acc: 0.8813 - val_auc-prc: 0.9446 - val_auc-roc: 0.9481 - 15s/epoch - 56ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2733 - acc: 0.8910 - auc-prc: 0.9532 - auc-roc: 0.9538 - val_loss: 0.2891 - val_acc: 0.8960 - val_auc-prc: 0.9493 - val_auc-roc: 0.9518 - 15s/epoch - 55ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2662 - acc: 0.8962 - auc-prc: 0.9549 - auc-roc: 0.9560 - val_loss: 0.2741 - val_acc: 0.8918 - val_auc-prc: 0.9501 - val_auc-roc: 0.9533 - 15s/epoch - 54ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2596 - acc: 0.8955 - auc-prc: 0.9577 - auc-roc: 0.9583 - val_loss: 0.3051 - val_acc: 0.8792 - val_auc-prc: 0.9417 - val_auc-roc: 0.9437 - 14s/epoch - 54ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2603 - acc: 0.8959 - auc-prc: 0.9577 - auc-roc: 0.9581 - val_loss: 0.2773 - val_acc: 0.8876 - val_auc-prc: 0.9498 - val_auc-roc: 0.9531 - 15s/epoch - 55ms/step
Epoch 7/100
268/268 - 16s - loss: 0.2573 - acc: 0.8959 - auc-prc: 0.9579 - auc-roc: 0.9589 - val_loss: 0.2772 - val_acc: 0.8950 - val_auc-prc: 0.9501 - val_auc-roc: 0.9529 - 16s/epoch - 58ms/step
Epoch 8/100
268/268 - 16s - loss: 0.2546 - acc: 0.9000 - auc-prc: 0.9591 - auc-roc: 0.9600 - val_loss: 0.2794 - val_acc: 0.8918 - val_auc-prc: 0.9494 - val_auc-roc: 0.9530 - 16s/epoch - 59ms/step
Epoch 9/100
268/268 - 16s - loss: 0.2521 - acc: 0.9002 - auc-prc: 0.9599 - auc-roc: 0.9607 - val_loss: 0.2742 - val_acc: 0.8929 - val_auc-prc: 0.9524 - val_auc-roc: 0.9538 - 16s/epoch - 58ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2481 - acc: 0.9011 - auc-prc: 0.9615 - auc-roc: 0.9621 - val_loss: 0.2920 - val_acc: 0.8887 - val_auc-prc: 0.9485 - val_auc-roc: 0.9503 - 15s/epoch - 58ms/step
Epoch 11/100
268/268 - 16s - loss: 0.2477 - acc: 0.9009 - auc-prc: 0.9616 - auc-roc: 0.9621 - val_loss: 0.2753 - val_acc: 0.8960 - val_auc-prc: 0.9505 - val_auc-roc: 0.9532 - 16s/epoch - 59ms/step
Epoch 12/100
268/268 - 16s - loss: 0.2468 - acc: 0.9014 - auc-prc: 0.9615 - auc-roc: 0.9624 - val_loss: 0.2857 - val_acc: 0.8855 - val_auc-prc: 0.9497 - val_auc-roc: 0.9517 - 16s/epoch - 58ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2456 - acc: 0.9008 - auc-prc: 0.9622 - auc-roc: 0.9628 - val_loss: 0.2841 - val_acc: 0.8908 - val_auc-prc: 0.9487 - val_auc-roc: 0.9512 - 15s/epoch - 55ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2435 - acc: 0.9033 - auc-prc: 0.9626 - auc-roc: 0.9633 - val_loss: 0.2785 - val_acc: 0.8855 - val_auc-prc: 0.9518 - val_auc-roc: 0.9543 - 15s/epoch - 55ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2373 - acc: 0.9047 - auc-prc: 0.9645 - auc-roc: 0.9652 - val_loss: 0.2858 - val_acc: 0.8866 - val_auc-prc: 0.9474 - val_auc-roc: 0.9493 - 15s/epoch - 55ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2393 - acc: 0.9048 - auc-prc: 0.9636 - auc-roc: 0.9644 - val_loss: 0.2835 - val_acc: 0.8887 - val_auc-prc: 0.9516 - val_auc-roc: 0.9537 - 15s/epoch - 55ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2334 - acc: 0.9054 - auc-prc: 0.9653 - auc-roc: 0.9662 - val_loss: 0.2746 - val_acc: 0.8887 - val_auc-prc: 0.9517 - val_auc-roc: 0.9543 - 15s/epoch - 56ms/step
Epoch 18/100
268/268 - 14s - loss: 0.2305 - acc: 0.9102 - auc-prc: 0.9661 - auc-roc: 0.9670 - val_loss: 0.2782 - val_acc: 0.8866 - val_auc-prc: 0.9511 - val_auc-roc: 0.9529 - 14s/epoch - 54ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2300 - acc: 0.9107 - auc-prc: 0.9667 - auc-roc: 0.9672 - val_loss: 0.2824 - val_acc: 0.8761 - val_auc-prc: 0.9505 - val_auc-roc: 0.9517 - 14s/epoch - 53ms/step
Epoch 20/100
268/268 - 14s - loss: 0.2260 - acc: 0.9079 - auc-prc: 0.9679 - auc-roc: 0.9685 - val_loss: 0.3077 - val_acc: 0.8803 - val_auc-prc: 0.9501 - val_auc-roc: 0.9532 - 14s/epoch - 54ms/step
Epoch 21/100
268/268 - 16s - loss: 0.2266 - acc: 0.9118 - auc-prc: 0.9674 - auc-roc: 0.9682 - val_loss: 0.2961 - val_acc: 0.8855 - val_auc-prc: 0.9503 - val_auc-roc: 0.9517 - 16s/epoch - 58ms/step
Epoch 22/100
268/268 - 14s - loss: 0.2203 - acc: 0.9106 - auc-prc: 0.9698 - auc-roc: 0.9701 - val_loss: 0.2873 - val_acc: 0.8845 - val_auc-prc: 0.9499 - val_auc-roc: 0.9511 - 14s/epoch - 53ms/step
Epoch 23/100
268/268 - 15s - loss: 0.2210 - acc: 0.9120 - auc-prc: 0.9689 - auc-roc: 0.9697 - val_loss: 0.3001 - val_acc: 0.8855 - val_auc-prc: 0.9475 - val_auc-roc: 0.9479 - 15s/epoch - 56ms/step
Epoch 24/100
268/268 - 15s - loss: 0.2201 - acc: 0.9113 - auc-prc: 0.9698 - auc-roc: 0.9701 - val_loss: 0.2971 - val_acc: 0.8782 - val_auc-prc: 0.9487 - val_auc-roc: 0.9509 - 15s/epoch - 55ms/step
Epoch 25/100
268/268 - 15s - loss: 0.2123 - acc: 0.9147 - auc-prc: 0.9719 - auc-roc: 0.9721 - val_loss: 0.2910 - val_acc: 0.8782 - val_auc-prc: 0.9481 - val_auc-roc: 0.9488 - 15s/epoch - 57ms/step
Early stopping epoch: 24
******Evaluating TEST set*********
30/30 - 1s - 706ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.87      0.84      0.85       382
           1       0.89      0.92      0.91       570

    accuracy                           0.89       952
   macro avg       0.88      0.88      0.88       952
weighted avg       0.89      0.89      0.89       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.51      0.45       382
           1       0.60      0.49      0.54       570

    accuracy                           0.50       952
   macro avg       0.50      0.50      0.49       952
weighted avg       0.52      0.50      0.50       952

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3184 - acc: 0.8613 - auc-prc: 0.9363 - auc-roc: 0.9380 - val_loss: 0.2763 - val_acc: 0.8792 - val_auc-prc: 0.9533 - val_auc-roc: 0.9534 - 18s/epoch - 66ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2866 - acc: 0.8847 - auc-prc: 0.9479 - auc-roc: 0.9494 - val_loss: 0.2488 - val_acc: 0.9149 - val_auc-prc: 0.9634 - val_auc-roc: 0.9639 - 15s/epoch - 56ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2752 - acc: 0.8893 - auc-prc: 0.9519 - auc-roc: 0.9533 - val_loss: 0.2591 - val_acc: 0.8992 - val_auc-prc: 0.9582 - val_auc-roc: 0.9589 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2724 - acc: 0.8896 - auc-prc: 0.9526 - auc-roc: 0.9540 - val_loss: 0.2444 - val_acc: 0.9002 - val_auc-prc: 0.9637 - val_auc-roc: 0.9640 - 15s/epoch - 57ms/step
Epoch 5/100
268/268 - 16s - loss: 0.2668 - acc: 0.8925 - auc-prc: 0.9553 - auc-roc: 0.9562 - val_loss: 0.2433 - val_acc: 0.9055 - val_auc-prc: 0.9639 - val_auc-roc: 0.9644 - 16s/epoch - 59ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2646 - acc: 0.8937 - auc-prc: 0.9554 - auc-roc: 0.9567 - val_loss: 0.2558 - val_acc: 0.8992 - val_auc-prc: 0.9594 - val_auc-roc: 0.9603 - 15s/epoch - 55ms/step
Epoch 7/100
268/268 - 16s - loss: 0.2618 - acc: 0.8932 - auc-prc: 0.9570 - auc-roc: 0.9577 - val_loss: 0.2304 - val_acc: 0.9128 - val_auc-prc: 0.9666 - val_auc-roc: 0.9672 - 16s/epoch - 58ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2575 - acc: 0.8952 - auc-prc: 0.9581 - auc-roc: 0.9591 - val_loss: 0.2361 - val_acc: 0.9034 - val_auc-prc: 0.9648 - val_auc-roc: 0.9657 - 15s/epoch - 57ms/step
Epoch 9/100
268/268 - 16s - loss: 0.2564 - acc: 0.8985 - auc-prc: 0.9582 - auc-roc: 0.9594 - val_loss: 0.2386 - val_acc: 0.8981 - val_auc-prc: 0.9645 - val_auc-roc: 0.9649 - 16s/epoch - 58ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2532 - acc: 0.8980 - auc-prc: 0.9598 - auc-roc: 0.9605 - val_loss: 0.2451 - val_acc: 0.9013 - val_auc-prc: 0.9613 - val_auc-roc: 0.9629 - 15s/epoch - 56ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2547 - acc: 0.8973 - auc-prc: 0.9594 - auc-roc: 0.9601 - val_loss: 0.2443 - val_acc: 0.9034 - val_auc-prc: 0.9652 - val_auc-roc: 0.9653 - 15s/epoch - 58ms/step
Epoch 12/100
268/268 - 16s - loss: 0.2530 - acc: 0.8960 - auc-prc: 0.9601 - auc-roc: 0.9608 - val_loss: 0.2295 - val_acc: 0.9076 - val_auc-prc: 0.9673 - val_auc-roc: 0.9675 - 16s/epoch - 59ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2470 - acc: 0.9004 - auc-prc: 0.9623 - auc-roc: 0.9624 - val_loss: 0.2367 - val_acc: 0.8981 - val_auc-prc: 0.9653 - val_auc-roc: 0.9654 - 15s/epoch - 58ms/step
Epoch 14/100
268/268 - 16s - loss: 0.2459 - acc: 0.8992 - auc-prc: 0.9622 - auc-roc: 0.9628 - val_loss: 0.2427 - val_acc: 0.8971 - val_auc-prc: 0.9641 - val_auc-roc: 0.9641 - 16s/epoch - 58ms/step
Epoch 15/100
268/268 - 16s - loss: 0.2443 - acc: 0.8986 - auc-prc: 0.9633 - auc-roc: 0.9635 - val_loss: 0.2394 - val_acc: 0.9013 - val_auc-prc: 0.9659 - val_auc-roc: 0.9657 - 16s/epoch - 58ms/step
Epoch 16/100
268/268 - 16s - loss: 0.2399 - acc: 0.9032 - auc-prc: 0.9644 - auc-roc: 0.9645 - val_loss: 0.2392 - val_acc: 0.8971 - val_auc-prc: 0.9658 - val_auc-roc: 0.9653 - 16s/epoch - 58ms/step
Epoch 17/100
268/268 - 16s - loss: 0.2365 - acc: 0.9028 - auc-prc: 0.9656 - auc-roc: 0.9657 - val_loss: 0.2330 - val_acc: 0.9065 - val_auc-prc: 0.9678 - val_auc-roc: 0.9674 - 16s/epoch - 58ms/step
Epoch 18/100
268/268 - 16s - loss: 0.2376 - acc: 0.9049 - auc-prc: 0.9650 - auc-roc: 0.9654 - val_loss: 0.2282 - val_acc: 0.9055 - val_auc-prc: 0.9680 - val_auc-roc: 0.9678 - 16s/epoch - 58ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2318 - acc: 0.9043 - auc-prc: 0.9666 - auc-roc: 0.9669 - val_loss: 0.2355 - val_acc: 0.9055 - val_auc-prc: 0.9663 - val_auc-roc: 0.9660 - 15s/epoch - 57ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2301 - acc: 0.9067 - auc-prc: 0.9671 - auc-roc: 0.9675 - val_loss: 0.2320 - val_acc: 0.9034 - val_auc-prc: 0.9668 - val_auc-roc: 0.9669 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2282 - acc: 0.9071 - auc-prc: 0.9675 - auc-roc: 0.9679 - val_loss: 0.2426 - val_acc: 0.8971 - val_auc-prc: 0.9648 - val_auc-roc: 0.9643 - 15s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 754ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.89      0.87      0.88       382
           1       0.92      0.93      0.92       570

    accuracy                           0.91       952
   macro avg       0.90      0.90      0.90       952
weighted avg       0.91      0.91      0.91       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.55      0.48       382
           1       0.62      0.48      0.54       570

    accuracy                           0.51       952
   macro avg       0.52      0.52      0.51       952
weighted avg       0.54      0.51      0.52       952

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3118 - acc: 0.8658 - auc-prc: 0.9391 - auc-roc: 0.9404 - val_loss: 0.3338 - val_acc: 0.8561 - val_auc-prc: 0.9296 - val_auc-roc: 0.9321 - 18s/epoch - 69ms/step
Epoch 2/100
268/268 - 16s - loss: 0.2854 - acc: 0.8862 - auc-prc: 0.9482 - auc-roc: 0.9499 - val_loss: 0.2993 - val_acc: 0.8761 - val_auc-prc: 0.9419 - val_auc-roc: 0.9440 - 16s/epoch - 58ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2723 - acc: 0.8901 - auc-prc: 0.9525 - auc-roc: 0.9541 - val_loss: 0.2926 - val_acc: 0.8803 - val_auc-prc: 0.9455 - val_auc-roc: 0.9469 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2656 - acc: 0.8946 - auc-prc: 0.9553 - auc-roc: 0.9564 - val_loss: 0.2873 - val_acc: 0.8803 - val_auc-prc: 0.9467 - val_auc-roc: 0.9491 - 15s/epoch - 55ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2626 - acc: 0.8939 - auc-prc: 0.9564 - auc-roc: 0.9574 - val_loss: 0.2836 - val_acc: 0.8855 - val_auc-prc: 0.9477 - val_auc-roc: 0.9498 - 15s/epoch - 56ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2615 - acc: 0.8970 - auc-prc: 0.9569 - auc-roc: 0.9577 - val_loss: 0.2881 - val_acc: 0.8824 - val_auc-prc: 0.9474 - val_auc-roc: 0.9495 - 15s/epoch - 55ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2569 - acc: 0.8972 - auc-prc: 0.9585 - auc-roc: 0.9594 - val_loss: 0.2839 - val_acc: 0.8908 - val_auc-prc: 0.9484 - val_auc-roc: 0.9506 - 15s/epoch - 55ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2548 - acc: 0.8967 - auc-prc: 0.9594 - auc-roc: 0.9600 - val_loss: 0.2809 - val_acc: 0.8887 - val_auc-prc: 0.9498 - val_auc-roc: 0.9510 - 15s/epoch - 55ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2517 - acc: 0.8984 - auc-prc: 0.9604 - auc-roc: 0.9611 - val_loss: 0.2839 - val_acc: 0.8887 - val_auc-prc: 0.9495 - val_auc-roc: 0.9507 - 15s/epoch - 55ms/step
Epoch 10/100
268/268 - 14s - loss: 0.2489 - acc: 0.8987 - auc-prc: 0.9609 - auc-roc: 0.9620 - val_loss: 0.2881 - val_acc: 0.8866 - val_auc-prc: 0.9498 - val_auc-roc: 0.9508 - 14s/epoch - 54ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2510 - acc: 0.8997 - auc-prc: 0.9608 - auc-roc: 0.9614 - val_loss: 0.2822 - val_acc: 0.8918 - val_auc-prc: 0.9502 - val_auc-roc: 0.9513 - 15s/epoch - 55ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2459 - acc: 0.8999 - auc-prc: 0.9622 - auc-roc: 0.9629 - val_loss: 0.2850 - val_acc: 0.8782 - val_auc-prc: 0.9494 - val_auc-roc: 0.9503 - 15s/epoch - 56ms/step
Epoch 13/100
268/268 - 14s - loss: 0.2420 - acc: 0.9022 - auc-prc: 0.9633 - auc-roc: 0.9640 - val_loss: 0.2837 - val_acc: 0.8792 - val_auc-prc: 0.9500 - val_auc-roc: 0.9502 - 14s/epoch - 53ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2416 - acc: 0.9041 - auc-prc: 0.9639 - auc-roc: 0.9640 - val_loss: 0.2766 - val_acc: 0.8918 - val_auc-prc: 0.9513 - val_auc-roc: 0.9531 - 15s/epoch - 55ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2400 - acc: 0.9022 - auc-prc: 0.9644 - auc-roc: 0.9647 - val_loss: 0.2823 - val_acc: 0.8834 - val_auc-prc: 0.9504 - val_auc-roc: 0.9508 - 15s/epoch - 58ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2368 - acc: 0.9069 - auc-prc: 0.9649 - auc-roc: 0.9654 - val_loss: 0.2926 - val_acc: 0.8803 - val_auc-prc: 0.9492 - val_auc-roc: 0.9491 - 15s/epoch - 56ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2352 - acc: 0.9040 - auc-prc: 0.9656 - auc-roc: 0.9659 - val_loss: 0.2784 - val_acc: 0.8981 - val_auc-prc: 0.9519 - val_auc-roc: 0.9530 - 15s/epoch - 55ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2312 - acc: 0.9067 - auc-prc: 0.9666 - auc-roc: 0.9671 - val_loss: 0.2863 - val_acc: 0.8813 - val_auc-prc: 0.9518 - val_auc-roc: 0.9532 - 15s/epoch - 58ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2363 - acc: 0.9051 - auc-prc: 0.9656 - auc-roc: 0.9657 - val_loss: 0.3215 - val_acc: 0.8561 - val_auc-prc: 0.9363 - val_auc-roc: 0.9379 - 15s/epoch - 56ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2331 - acc: 0.9060 - auc-prc: 0.9660 - auc-roc: 0.9664 - val_loss: 0.2843 - val_acc: 0.8834 - val_auc-prc: 0.9512 - val_auc-roc: 0.9518 - 15s/epoch - 54ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2294 - acc: 0.9082 - auc-prc: 0.9677 - auc-roc: 0.9677 - val_loss: 0.2792 - val_acc: 0.8824 - val_auc-prc: 0.9520 - val_auc-roc: 0.9524 - 15s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 742ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.89      0.80      0.84       382
           1       0.88      0.93      0.90       570

    accuracy                           0.88       952
   macro avg       0.88      0.87      0.87       952
weighted avg       0.88      0.88      0.88       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.44      0.54      0.49       382
           1       0.64      0.55      0.59       570

    accuracy                           0.55       952
   macro avg       0.54      0.54      0.54       952
weighted avg       0.56      0.55      0.55       952

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3183 - acc: 0.8687 - auc-prc: 0.9358 - auc-roc: 0.9376 - val_loss: 0.2971 - val_acc: 0.8761 - val_auc-prc: 0.9452 - val_auc-roc: 0.9468 - 17s/epoch - 63ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2839 - acc: 0.8858 - auc-prc: 0.9484 - auc-roc: 0.9504 - val_loss: 0.2747 - val_acc: 0.8845 - val_auc-prc: 0.9519 - val_auc-roc: 0.9537 - 15s/epoch - 56ms/step
Epoch 3/100
268/268 - 14s - loss: 0.2730 - acc: 0.8903 - auc-prc: 0.9523 - auc-roc: 0.9537 - val_loss: 0.2734 - val_acc: 0.8855 - val_auc-prc: 0.9528 - val_auc-roc: 0.9542 - 14s/epoch - 54ms/step
Epoch 4/100
268/268 - 14s - loss: 0.2679 - acc: 0.8955 - auc-prc: 0.9544 - auc-roc: 0.9554 - val_loss: 0.2773 - val_acc: 0.8739 - val_auc-prc: 0.9526 - val_auc-roc: 0.9535 - 14s/epoch - 51ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2654 - acc: 0.8942 - auc-prc: 0.9553 - auc-roc: 0.9563 - val_loss: 0.2737 - val_acc: 0.8813 - val_auc-prc: 0.9538 - val_auc-roc: 0.9552 - 14s/epoch - 52ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2632 - acc: 0.8957 - auc-prc: 0.9562 - auc-roc: 0.9571 - val_loss: 0.2858 - val_acc: 0.8792 - val_auc-prc: 0.9509 - val_auc-roc: 0.9521 - 14s/epoch - 52ms/step
Epoch 7/100
268/268 - 14s - loss: 0.2587 - acc: 0.8980 - auc-prc: 0.9576 - auc-roc: 0.9585 - val_loss: 0.2738 - val_acc: 0.8782 - val_auc-prc: 0.9535 - val_auc-roc: 0.9545 - 14s/epoch - 51ms/step
Epoch 8/100
268/268 - 14s - loss: 0.2587 - acc: 0.8959 - auc-prc: 0.9574 - auc-roc: 0.9584 - val_loss: 0.2575 - val_acc: 0.8908 - val_auc-prc: 0.9583 - val_auc-roc: 0.9596 - 14s/epoch - 52ms/step
Epoch 9/100
268/268 - 14s - loss: 0.2558 - acc: 0.8994 - auc-prc: 0.9592 - auc-roc: 0.9596 - val_loss: 0.2610 - val_acc: 0.8866 - val_auc-prc: 0.9579 - val_auc-roc: 0.9587 - 14s/epoch - 53ms/step
Epoch 10/100
268/268 - 14s - loss: 0.2536 - acc: 0.9004 - auc-prc: 0.9586 - auc-roc: 0.9601 - val_loss: 0.2550 - val_acc: 0.8929 - val_auc-prc: 0.9593 - val_auc-roc: 0.9606 - 14s/epoch - 53ms/step
Epoch 11/100
268/268 - 14s - loss: 0.2511 - acc: 0.9009 - auc-prc: 0.9599 - auc-roc: 0.9609 - val_loss: 0.2662 - val_acc: 0.8876 - val_auc-prc: 0.9565 - val_auc-roc: 0.9569 - 14s/epoch - 51ms/step
Epoch 12/100
268/268 - 14s - loss: 0.2466 - acc: 0.8987 - auc-prc: 0.9621 - auc-roc: 0.9625 - val_loss: 0.2656 - val_acc: 0.8897 - val_auc-prc: 0.9569 - val_auc-roc: 0.9577 - 14s/epoch - 52ms/step
Epoch 13/100
268/268 - 14s - loss: 0.2464 - acc: 0.8998 - auc-prc: 0.9620 - auc-roc: 0.9627 - val_loss: 0.2830 - val_acc: 0.8929 - val_auc-prc: 0.9512 - val_auc-roc: 0.9525 - 14s/epoch - 52ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2500 - acc: 0.8992 - auc-prc: 0.9611 - auc-roc: 0.9615 - val_loss: 0.2534 - val_acc: 0.8939 - val_auc-prc: 0.9606 - val_auc-roc: 0.9611 - 15s/epoch - 55ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2433 - acc: 0.9030 - auc-prc: 0.9629 - auc-roc: 0.9636 - val_loss: 0.2510 - val_acc: 0.8971 - val_auc-prc: 0.9610 - val_auc-roc: 0.9617 - 15s/epoch - 54ms/step
Epoch 16/100
268/268 - 14s - loss: 0.2379 - acc: 0.9032 - auc-prc: 0.9647 - auc-roc: 0.9652 - val_loss: 0.2714 - val_acc: 0.8803 - val_auc-prc: 0.9554 - val_auc-roc: 0.9563 - 14s/epoch - 54ms/step
Epoch 17/100
268/268 - 14s - loss: 0.2380 - acc: 0.9028 - auc-prc: 0.9648 - auc-roc: 0.9652 - val_loss: 0.2543 - val_acc: 0.8981 - val_auc-prc: 0.9604 - val_auc-roc: 0.9609 - 14s/epoch - 54ms/step
Epoch 18/100
268/268 - 14s - loss: 0.2382 - acc: 0.9037 - auc-prc: 0.9646 - auc-roc: 0.9651 - val_loss: 0.2532 - val_acc: 0.8960 - val_auc-prc: 0.9594 - val_auc-roc: 0.9602 - 14s/epoch - 54ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2332 - acc: 0.9074 - auc-prc: 0.9660 - auc-roc: 0.9664 - val_loss: 0.2582 - val_acc: 0.8971 - val_auc-prc: 0.9588 - val_auc-roc: 0.9589 - 14s/epoch - 54ms/step
Epoch 20/100
268/268 - 14s - loss: 0.2270 - acc: 0.9105 - auc-prc: 0.9673 - auc-roc: 0.9681 - val_loss: 0.2799 - val_acc: 0.8803 - val_auc-prc: 0.9526 - val_auc-roc: 0.9550 - 14s/epoch - 54ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2253 - acc: 0.9088 - auc-prc: 0.9684 - auc-roc: 0.9687 - val_loss: 0.2525 - val_acc: 0.9002 - val_auc-prc: 0.9592 - val_auc-roc: 0.9611 - 15s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 717ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.91      0.83      0.87       382
           1       0.89      0.94      0.92       570

    accuracy                           0.90       952
   macro avg       0.90      0.89      0.89       952
weighted avg       0.90      0.90      0.90       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.48      0.43       382
           1       0.59      0.51      0.54       570

    accuracy                           0.49       952
   macro avg       0.49      0.49      0.49       952
weighted avg       0.51      0.49      0.50       952

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3241 - acc: 0.8572 - auc-prc: 0.9342 - auc-roc: 0.9358 - val_loss: 0.2972 - val_acc: 0.8708 - val_auc-prc: 0.9455 - val_auc-roc: 0.9461 - 18s/epoch - 68ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2884 - acc: 0.8823 - auc-prc: 0.9467 - auc-roc: 0.9486 - val_loss: 0.2602 - val_acc: 0.8992 - val_auc-prc: 0.9562 - val_auc-roc: 0.9577 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2773 - acc: 0.8879 - auc-prc: 0.9511 - auc-roc: 0.9525 - val_loss: 0.2531 - val_acc: 0.9013 - val_auc-prc: 0.9595 - val_auc-roc: 0.9598 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2700 - acc: 0.8921 - auc-prc: 0.9534 - auc-roc: 0.9545 - val_loss: 0.2775 - val_acc: 0.8897 - val_auc-prc: 0.9540 - val_auc-roc: 0.9542 - 15s/epoch - 55ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2682 - acc: 0.8931 - auc-prc: 0.9540 - auc-roc: 0.9552 - val_loss: 0.2628 - val_acc: 0.8960 - val_auc-prc: 0.9582 - val_auc-roc: 0.9586 - 15s/epoch - 57ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2654 - acc: 0.8911 - auc-prc: 0.9550 - auc-roc: 0.9561 - val_loss: 0.2482 - val_acc: 0.9076 - val_auc-prc: 0.9608 - val_auc-roc: 0.9613 - 15s/epoch - 56ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2596 - acc: 0.8964 - auc-prc: 0.9570 - auc-roc: 0.9580 - val_loss: 0.2620 - val_acc: 0.8971 - val_auc-prc: 0.9578 - val_auc-roc: 0.9581 - 15s/epoch - 57ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2585 - acc: 0.8955 - auc-prc: 0.9579 - auc-roc: 0.9587 - val_loss: 0.2450 - val_acc: 0.9086 - val_auc-prc: 0.9628 - val_auc-roc: 0.9628 - 15s/epoch - 58ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2552 - acc: 0.8964 - auc-prc: 0.9589 - auc-roc: 0.9596 - val_loss: 0.2523 - val_acc: 0.9002 - val_auc-prc: 0.9612 - val_auc-roc: 0.9611 - 15s/epoch - 56ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2560 - acc: 0.8978 - auc-prc: 0.9585 - auc-roc: 0.9594 - val_loss: 0.2479 - val_acc: 0.9055 - val_auc-prc: 0.9612 - val_auc-roc: 0.9626 - 15s/epoch - 55ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2516 - acc: 0.8994 - auc-prc: 0.9601 - auc-roc: 0.9608 - val_loss: 0.2450 - val_acc: 0.9076 - val_auc-prc: 0.9632 - val_auc-roc: 0.9629 - 15s/epoch - 55ms/step
Epoch 12/100
268/268 - 14s - loss: 0.2512 - acc: 0.8991 - auc-prc: 0.9606 - auc-roc: 0.9611 - val_loss: 0.2387 - val_acc: 0.9097 - val_auc-prc: 0.9656 - val_auc-roc: 0.9654 - 14s/epoch - 54ms/step
Epoch 13/100
268/268 - 14s - loss: 0.2489 - acc: 0.8995 - auc-prc: 0.9616 - auc-roc: 0.9618 - val_loss: 0.2409 - val_acc: 0.9055 - val_auc-prc: 0.9651 - val_auc-roc: 0.9649 - 14s/epoch - 53ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2483 - acc: 0.9008 - auc-prc: 0.9615 - auc-roc: 0.9621 - val_loss: 0.2483 - val_acc: 0.9034 - val_auc-prc: 0.9628 - val_auc-roc: 0.9624 - 15s/epoch - 57ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2420 - acc: 0.9036 - auc-prc: 0.9635 - auc-roc: 0.9639 - val_loss: 0.2602 - val_acc: 0.8981 - val_auc-prc: 0.9581 - val_auc-roc: 0.9581 - 15s/epoch - 57ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2411 - acc: 0.9056 - auc-prc: 0.9629 - auc-roc: 0.9639 - val_loss: 0.2354 - val_acc: 0.9055 - val_auc-prc: 0.9661 - val_auc-roc: 0.9660 - 15s/epoch - 57ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2378 - acc: 0.9034 - auc-prc: 0.9641 - auc-roc: 0.9649 - val_loss: 0.2415 - val_acc: 0.9034 - val_auc-prc: 0.9646 - val_auc-roc: 0.9644 - 15s/epoch - 56ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2383 - acc: 0.9055 - auc-prc: 0.9646 - auc-roc: 0.9648 - val_loss: 0.2439 - val_acc: 0.9065 - val_auc-prc: 0.9637 - val_auc-roc: 0.9645 - 15s/epoch - 58ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2333 - acc: 0.9074 - auc-prc: 0.9652 - auc-roc: 0.9662 - val_loss: 0.2450 - val_acc: 0.9023 - val_auc-prc: 0.9636 - val_auc-roc: 0.9635 - 15s/epoch - 57ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2362 - acc: 0.9050 - auc-prc: 0.9653 - auc-roc: 0.9657 - val_loss: 0.2429 - val_acc: 0.8992 - val_auc-prc: 0.9638 - val_auc-roc: 0.9641 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2316 - acc: 0.9078 - auc-prc: 0.9666 - auc-roc: 0.9668 - val_loss: 0.2438 - val_acc: 0.8971 - val_auc-prc: 0.9646 - val_auc-roc: 0.9644 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 707ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.91      0.85      0.88       382
           1       0.90      0.94      0.92       570

    accuracy                           0.91       952
   macro avg       0.91      0.90      0.90       952
weighted avg       0.91      0.91      0.90       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.51      0.44       382
           1       0.59      0.47      0.53       570

    accuracy                           0.49       952
   macro avg       0.49      0.49      0.48       952
weighted avg       0.51      0.49      0.49       952

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8875] IC [0.8815, 0.8935]
Mean Accuracy[0.8961] IC [0.8910, 0.9013]
Mean Recall[0.8875] IC [0.8815, 0.8935]
Mean F1[0.8909] IC [0.8854, 0.8964]
Median AUC_ROC[0.8908]
Median Accuracy[0.8971]
Median Recall[0.8908]
Median F1[0.8919]
********************txid224308********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.75      0.75      0.75       208
           1       0.92      0.92      0.92       644

    accuracy                           0.88       852
   macro avg       0.84      0.84      0.84       852
weighted avg       0.88      0.88      0.88       852

Predicted  0.0  1.0  All
True                    
0          157   51  208
1           51  593  644
All        208  644  852
**************************************************
fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 15s - loss: 0.2987 - acc: 0.8683 - auc-prc: 0.9447 - auc-roc: 0.9458 - val_loss: 0.2507 - val_acc: 0.9039 - val_auc-prc: 0.9571 - val_auc-roc: 0.9610 - 15s/epoch - 66ms/step
Epoch 2/100
229/229 - 12s - loss: 0.2621 - acc: 0.8901 - auc-prc: 0.9559 - auc-roc: 0.9578 - val_loss: 0.2370 - val_acc: 0.9126 - val_auc-prc: 0.9604 - val_auc-roc: 0.9639 - 12s/epoch - 54ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2504 - acc: 0.8976 - auc-prc: 0.9598 - auc-roc: 0.9612 - val_loss: 0.2312 - val_acc: 0.9150 - val_auc-prc: 0.9643 - val_auc-roc: 0.9661 - 13s/epoch - 58ms/step
Epoch 4/100
229/229 - 13s - loss: 0.2446 - acc: 0.8992 - auc-prc: 0.9613 - auc-roc: 0.9632 - val_loss: 0.2384 - val_acc: 0.9027 - val_auc-prc: 0.9626 - val_auc-roc: 0.9639 - 13s/epoch - 55ms/step
Epoch 5/100
229/229 - 12s - loss: 0.2429 - acc: 0.8999 - auc-prc: 0.9613 - auc-roc: 0.9635 - val_loss: 0.2292 - val_acc: 0.9113 - val_auc-prc: 0.9635 - val_auc-roc: 0.9663 - 12s/epoch - 54ms/step
Epoch 6/100
229/229 - 12s - loss: 0.2396 - acc: 0.9032 - auc-prc: 0.9624 - auc-roc: 0.9643 - val_loss: 0.2303 - val_acc: 0.9113 - val_auc-prc: 0.9654 - val_auc-roc: 0.9668 - 12s/epoch - 54ms/step
Epoch 7/100
229/229 - 12s - loss: 0.2363 - acc: 0.9042 - auc-prc: 0.9642 - auc-roc: 0.9653 - val_loss: 0.2310 - val_acc: 0.9089 - val_auc-prc: 0.9671 - val_auc-roc: 0.9679 - 12s/epoch - 53ms/step
Epoch 8/100
229/229 - 12s - loss: 0.2364 - acc: 0.9029 - auc-prc: 0.9645 - auc-roc: 0.9654 - val_loss: 0.2304 - val_acc: 0.9150 - val_auc-prc: 0.9628 - val_auc-roc: 0.9659 - 12s/epoch - 52ms/step
Epoch 9/100
229/229 - 12s - loss: 0.2330 - acc: 0.9054 - auc-prc: 0.9651 - auc-roc: 0.9663 - val_loss: 0.2325 - val_acc: 0.9015 - val_auc-prc: 0.9638 - val_auc-roc: 0.9659 - 12s/epoch - 52ms/step
Epoch 10/100
229/229 - 12s - loss: 0.2316 - acc: 0.9033 - auc-prc: 0.9657 - auc-roc: 0.9668 - val_loss: 0.2291 - val_acc: 0.9126 - val_auc-prc: 0.9634 - val_auc-roc: 0.9667 - 12s/epoch - 53ms/step
Epoch 11/100
229/229 - 12s - loss: 0.2297 - acc: 0.9065 - auc-prc: 0.9661 - auc-roc: 0.9671 - val_loss: 0.2347 - val_acc: 0.9052 - val_auc-prc: 0.9641 - val_auc-roc: 0.9658 - 12s/epoch - 53ms/step
Epoch 12/100
229/229 - 12s - loss: 0.2272 - acc: 0.9074 - auc-prc: 0.9676 - auc-roc: 0.9681 - val_loss: 0.2327 - val_acc: 0.9089 - val_auc-prc: 0.9638 - val_auc-roc: 0.9659 - 12s/epoch - 53ms/step
Epoch 13/100
229/229 - 12s - loss: 0.2263 - acc: 0.9066 - auc-prc: 0.9675 - auc-roc: 0.9681 - val_loss: 0.2267 - val_acc: 0.9138 - val_auc-prc: 0.9653 - val_auc-roc: 0.9668 - 12s/epoch - 54ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2242 - acc: 0.9083 - auc-prc: 0.9683 - auc-roc: 0.9689 - val_loss: 0.2358 - val_acc: 0.9076 - val_auc-prc: 0.9622 - val_auc-roc: 0.9650 - 13s/epoch - 55ms/step
Epoch 15/100
229/229 - 12s - loss: 0.2237 - acc: 0.9095 - auc-prc: 0.9677 - auc-roc: 0.9688 - val_loss: 0.2314 - val_acc: 0.9076 - val_auc-prc: 0.9660 - val_auc-roc: 0.9666 - 12s/epoch - 53ms/step
Epoch 16/100
229/229 - 12s - loss: 0.2233 - acc: 0.9099 - auc-prc: 0.9676 - auc-roc: 0.9688 - val_loss: 0.2288 - val_acc: 0.9101 - val_auc-prc: 0.9639 - val_auc-roc: 0.9663 - 12s/epoch - 53ms/step
Epoch 17/100
229/229 - 12s - loss: 0.2183 - acc: 0.9121 - auc-prc: 0.9699 - auc-roc: 0.9704 - val_loss: 0.2413 - val_acc: 0.9113 - val_auc-prc: 0.9611 - val_auc-roc: 0.9635 - 12s/epoch - 53ms/step
Epoch 18/100
229/229 - 12s - loss: 0.2170 - acc: 0.9125 - auc-prc: 0.9698 - auc-roc: 0.9707 - val_loss: 0.2346 - val_acc: 0.9015 - val_auc-prc: 0.9640 - val_auc-roc: 0.9660 - 12s/epoch - 53ms/step
Epoch 19/100
229/229 - 12s - loss: 0.2171 - acc: 0.9114 - auc-prc: 0.9703 - auc-roc: 0.9709 - val_loss: 0.2299 - val_acc: 0.9200 - val_auc-prc: 0.9655 - val_auc-roc: 0.9672 - 12s/epoch - 52ms/step
Epoch 20/100
229/229 - 12s - loss: 0.2129 - acc: 0.9120 - auc-prc: 0.9714 - auc-roc: 0.9717 - val_loss: 0.2315 - val_acc: 0.9150 - val_auc-prc: 0.9637 - val_auc-roc: 0.9660 - 12s/epoch - 52ms/step
Epoch 21/100
229/229 - 12s - loss: 0.2119 - acc: 0.9125 - auc-prc: 0.9717 - auc-roc: 0.9722 - val_loss: 0.2466 - val_acc: 0.9039 - val_auc-prc: 0.9629 - val_auc-roc: 0.9652 - 12s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
26/26 - 1s - 629ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.90      0.84      0.87       285
           1       0.91      0.95      0.93       527

    accuracy                           0.91       812
   macro avg       0.91      0.89      0.90       812
weighted avg       0.91      0.91      0.91       812

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.51      0.43       285
           1       0.67      0.53      0.59       527

    accuracy                           0.52       812
   macro avg       0.52      0.52      0.51       812
weighted avg       0.56      0.52      0.54       812

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 14s - loss: 0.2975 - acc: 0.8709 - auc-prc: 0.9444 - auc-roc: 0.9459 - val_loss: 0.2564 - val_acc: 0.8904 - val_auc-prc: 0.9596 - val_auc-roc: 0.9607 - 14s/epoch - 62ms/step
Epoch 2/100
229/229 - 12s - loss: 0.2626 - acc: 0.8907 - auc-prc: 0.9553 - auc-roc: 0.9577 - val_loss: 0.2426 - val_acc: 0.9027 - val_auc-prc: 0.9636 - val_auc-roc: 0.9651 - 12s/epoch - 52ms/step
Epoch 3/100
229/229 - 12s - loss: 0.2529 - acc: 0.8962 - auc-prc: 0.9583 - auc-roc: 0.9604 - val_loss: 0.2355 - val_acc: 0.9052 - val_auc-prc: 0.9653 - val_auc-roc: 0.9668 - 12s/epoch - 53ms/step
Epoch 4/100
229/229 - 12s - loss: 0.2463 - acc: 0.9003 - auc-prc: 0.9601 - auc-roc: 0.9622 - val_loss: 0.2319 - val_acc: 0.9126 - val_auc-prc: 0.9664 - val_auc-roc: 0.9681 - 12s/epoch - 53ms/step
Epoch 5/100
229/229 - 13s - loss: 0.2433 - acc: 0.8998 - auc-prc: 0.9616 - auc-roc: 0.9631 - val_loss: 0.2450 - val_acc: 0.8929 - val_auc-prc: 0.9648 - val_auc-roc: 0.9644 - 13s/epoch - 57ms/step
Epoch 6/100
229/229 - 14s - loss: 0.2443 - acc: 0.9009 - auc-prc: 0.9615 - auc-roc: 0.9630 - val_loss: 0.2198 - val_acc: 0.9150 - val_auc-prc: 0.9702 - val_auc-roc: 0.9706 - 14s/epoch - 59ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2408 - acc: 0.9014 - auc-prc: 0.9627 - auc-roc: 0.9639 - val_loss: 0.2316 - val_acc: 0.9089 - val_auc-prc: 0.9672 - val_auc-roc: 0.9682 - 13s/epoch - 57ms/step
Epoch 8/100
229/229 - 12s - loss: 0.2394 - acc: 0.9036 - auc-prc: 0.9628 - auc-roc: 0.9642 - val_loss: 0.2226 - val_acc: 0.9163 - val_auc-prc: 0.9714 - val_auc-roc: 0.9717 - 12s/epoch - 54ms/step
Epoch 9/100
229/229 - 12s - loss: 0.2359 - acc: 0.9040 - auc-prc: 0.9644 - auc-roc: 0.9654 - val_loss: 0.2322 - val_acc: 0.9002 - val_auc-prc: 0.9690 - val_auc-roc: 0.9686 - 12s/epoch - 54ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2381 - acc: 0.9051 - auc-prc: 0.9637 - auc-roc: 0.9646 - val_loss: 0.2139 - val_acc: 0.9200 - val_auc-prc: 0.9723 - val_auc-roc: 0.9722 - 13s/epoch - 58ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2327 - acc: 0.9055 - auc-prc: 0.9652 - auc-roc: 0.9664 - val_loss: 0.2253 - val_acc: 0.9064 - val_auc-prc: 0.9697 - val_auc-roc: 0.9694 - 13s/epoch - 55ms/step
Epoch 12/100
229/229 - 12s - loss: 0.2297 - acc: 0.9068 - auc-prc: 0.9660 - auc-roc: 0.9671 - val_loss: 0.2122 - val_acc: 0.9261 - val_auc-prc: 0.9718 - val_auc-roc: 0.9722 - 12s/epoch - 52ms/step
Epoch 13/100
229/229 - 12s - loss: 0.2314 - acc: 0.9064 - auc-prc: 0.9657 - auc-roc: 0.9667 - val_loss: 0.2414 - val_acc: 0.9015 - val_auc-prc: 0.9658 - val_auc-roc: 0.9654 - 12s/epoch - 53ms/step
Epoch 14/100
229/229 - 12s - loss: 0.2278 - acc: 0.9064 - auc-prc: 0.9675 - auc-roc: 0.9679 - val_loss: 0.2164 - val_acc: 0.9187 - val_auc-prc: 0.9721 - val_auc-roc: 0.9720 - 12s/epoch - 53ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2266 - acc: 0.9072 - auc-prc: 0.9672 - auc-roc: 0.9680 - val_loss: 0.2109 - val_acc: 0.9236 - val_auc-prc: 0.9742 - val_auc-roc: 0.9737 - 13s/epoch - 58ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2252 - acc: 0.9083 - auc-prc: 0.9680 - auc-roc: 0.9685 - val_loss: 0.2282 - val_acc: 0.9052 - val_auc-prc: 0.9703 - val_auc-roc: 0.9697 - 13s/epoch - 57ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2227 - acc: 0.9080 - auc-prc: 0.9681 - auc-roc: 0.9690 - val_loss: 0.2132 - val_acc: 0.9076 - val_auc-prc: 0.9736 - val_auc-roc: 0.9730 - 13s/epoch - 57ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2204 - acc: 0.9107 - auc-prc: 0.9696 - auc-roc: 0.9699 - val_loss: 0.2271 - val_acc: 0.9150 - val_auc-prc: 0.9719 - val_auc-roc: 0.9712 - 13s/epoch - 57ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2201 - acc: 0.9085 - auc-prc: 0.9697 - auc-roc: 0.9699 - val_loss: 0.2167 - val_acc: 0.9200 - val_auc-prc: 0.9721 - val_auc-roc: 0.9716 - 13s/epoch - 57ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2167 - acc: 0.9121 - auc-prc: 0.9702 - auc-roc: 0.9707 - val_loss: 0.2178 - val_acc: 0.9126 - val_auc-prc: 0.9728 - val_auc-roc: 0.9721 - 13s/epoch - 56ms/step
Epoch 21/100
229/229 - 12s - loss: 0.2150 - acc: 0.9135 - auc-prc: 0.9708 - auc-roc: 0.9713 - val_loss: 0.2141 - val_acc: 0.9175 - val_auc-prc: 0.9724 - val_auc-roc: 0.9721 - 12s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
26/26 - 1s - 705ms/epoch - 27ms/step
              precision    recall  f1-score   support

           0       0.91      0.87      0.89       285
           1       0.93      0.95      0.94       527

    accuracy                           0.92       812
   macro avg       0.92      0.91      0.92       812
weighted avg       0.92      0.92      0.92       812

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.36      0.53      0.43       285
           1       0.66      0.49      0.56       527

    accuracy                           0.50       812
   macro avg       0.51      0.51      0.49       812
weighted avg       0.55      0.50      0.51       812

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 16s - loss: 0.2956 - acc: 0.8736 - auc-prc: 0.9451 - auc-roc: 0.9468 - val_loss: 0.2785 - val_acc: 0.8830 - val_auc-prc: 0.9510 - val_auc-roc: 0.9522 - 16s/epoch - 68ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2585 - acc: 0.8950 - auc-prc: 0.9563 - auc-roc: 0.9589 - val_loss: 0.2671 - val_acc: 0.8879 - val_auc-prc: 0.9561 - val_auc-roc: 0.9562 - 13s/epoch - 58ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2470 - acc: 0.9036 - auc-prc: 0.9597 - auc-roc: 0.9621 - val_loss: 0.2641 - val_acc: 0.8818 - val_auc-prc: 0.9575 - val_auc-roc: 0.9576 - 13s/epoch - 58ms/step
Epoch 4/100
229/229 - 13s - loss: 0.2444 - acc: 0.9006 - auc-prc: 0.9609 - auc-roc: 0.9628 - val_loss: 0.2746 - val_acc: 0.8867 - val_auc-prc: 0.9563 - val_auc-roc: 0.9554 - 13s/epoch - 57ms/step
Epoch 5/100
229/229 - 12s - loss: 0.2431 - acc: 0.9005 - auc-prc: 0.9620 - auc-roc: 0.9634 - val_loss: 0.2664 - val_acc: 0.8818 - val_auc-prc: 0.9578 - val_auc-roc: 0.9566 - 12s/epoch - 53ms/step
Epoch 6/100
229/229 - 12s - loss: 0.2386 - acc: 0.9033 - auc-prc: 0.9633 - auc-roc: 0.9645 - val_loss: 0.2574 - val_acc: 0.8842 - val_auc-prc: 0.9616 - val_auc-roc: 0.9603 - 12s/epoch - 55ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2385 - acc: 0.9044 - auc-prc: 0.9629 - auc-roc: 0.9643 - val_loss: 0.2459 - val_acc: 0.8929 - val_auc-prc: 0.9638 - val_auc-roc: 0.9632 - 13s/epoch - 55ms/step
Epoch 8/100
229/229 - 12s - loss: 0.2363 - acc: 0.9029 - auc-prc: 0.9637 - auc-roc: 0.9652 - val_loss: 0.2553 - val_acc: 0.8966 - val_auc-prc: 0.9599 - val_auc-roc: 0.9605 - 12s/epoch - 54ms/step
Epoch 9/100
229/229 - 12s - loss: 0.2299 - acc: 0.9092 - auc-prc: 0.9653 - auc-roc: 0.9669 - val_loss: 0.2521 - val_acc: 0.8966 - val_auc-prc: 0.9619 - val_auc-roc: 0.9616 - 12s/epoch - 54ms/step
Epoch 10/100
229/229 - 12s - loss: 0.2313 - acc: 0.9098 - auc-prc: 0.9655 - auc-roc: 0.9668 - val_loss: 0.2448 - val_acc: 0.8904 - val_auc-prc: 0.9637 - val_auc-roc: 0.9631 - 12s/epoch - 54ms/step
Epoch 11/100
229/229 - 12s - loss: 0.2277 - acc: 0.9070 - auc-prc: 0.9663 - auc-roc: 0.9675 - val_loss: 0.2555 - val_acc: 0.8879 - val_auc-prc: 0.9620 - val_auc-roc: 0.9610 - 12s/epoch - 54ms/step
Epoch 12/100
229/229 - 12s - loss: 0.2267 - acc: 0.9079 - auc-prc: 0.9663 - auc-roc: 0.9679 - val_loss: 0.2466 - val_acc: 0.9015 - val_auc-prc: 0.9637 - val_auc-roc: 0.9631 - 12s/epoch - 54ms/step
Epoch 13/100
229/229 - 12s - loss: 0.2270 - acc: 0.9058 - auc-prc: 0.9667 - auc-roc: 0.9678 - val_loss: 0.2453 - val_acc: 0.8904 - val_auc-prc: 0.9645 - val_auc-roc: 0.9634 - 12s/epoch - 53ms/step
Epoch 14/100
229/229 - 12s - loss: 0.2234 - acc: 0.9095 - auc-prc: 0.9680 - auc-roc: 0.9689 - val_loss: 0.2474 - val_acc: 0.8990 - val_auc-prc: 0.9644 - val_auc-roc: 0.9636 - 12s/epoch - 53ms/step
Epoch 15/100
229/229 - 12s - loss: 0.2257 - acc: 0.9079 - auc-prc: 0.9678 - auc-roc: 0.9684 - val_loss: 0.2716 - val_acc: 0.8929 - val_auc-prc: 0.9604 - val_auc-roc: 0.9595 - 12s/epoch - 53ms/step
Epoch 16/100
229/229 - 12s - loss: 0.2242 - acc: 0.9073 - auc-prc: 0.9688 - auc-roc: 0.9691 - val_loss: 0.2552 - val_acc: 0.8966 - val_auc-prc: 0.9623 - val_auc-roc: 0.9614 - 12s/epoch - 53ms/step
Epoch 17/100
229/229 - 12s - loss: 0.2213 - acc: 0.9094 - auc-prc: 0.9689 - auc-roc: 0.9695 - val_loss: 0.2533 - val_acc: 0.8916 - val_auc-prc: 0.9620 - val_auc-roc: 0.9613 - 12s/epoch - 53ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2195 - acc: 0.9105 - auc-prc: 0.9691 - auc-roc: 0.9700 - val_loss: 0.2483 - val_acc: 0.8941 - val_auc-prc: 0.9634 - val_auc-roc: 0.9626 - 13s/epoch - 55ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2180 - acc: 0.9100 - auc-prc: 0.9698 - auc-roc: 0.9703 - val_loss: 0.2431 - val_acc: 0.8978 - val_auc-prc: 0.9646 - val_auc-roc: 0.9641 - 13s/epoch - 57ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2134 - acc: 0.9142 - auc-prc: 0.9708 - auc-roc: 0.9714 - val_loss: 0.2446 - val_acc: 0.9002 - val_auc-prc: 0.9639 - val_auc-roc: 0.9635 - 13s/epoch - 57ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2154 - acc: 0.9158 - auc-prc: 0.9705 - auc-roc: 0.9712 - val_loss: 0.2540 - val_acc: 0.9002 - val_auc-prc: 0.9619 - val_auc-roc: 0.9613 - 13s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
26/26 - 1s - 645ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.85      0.86      0.86       285
           1       0.92      0.92      0.92       527

    accuracy                           0.90       812
   macro avg       0.89      0.89      0.89       812
weighted avg       0.90      0.90      0.90       812

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.35      0.53      0.42       285
           1       0.65      0.47      0.55       527

    accuracy                           0.49       812
   macro avg       0.50      0.50      0.48       812
weighted avg       0.54      0.49      0.50       812

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 15s - loss: 0.2964 - acc: 0.8769 - auc-prc: 0.9447 - auc-roc: 0.9465 - val_loss: 0.2646 - val_acc: 0.8818 - val_auc-prc: 0.9538 - val_auc-roc: 0.9571 - 15s/epoch - 65ms/step
Epoch 2/100
229/229 - 12s - loss: 0.2580 - acc: 0.8959 - auc-prc: 0.9560 - auc-roc: 0.9589 - val_loss: 0.2571 - val_acc: 0.8830 - val_auc-prc: 0.9569 - val_auc-roc: 0.9598 - 12s/epoch - 53ms/step
Epoch 3/100
229/229 - 12s - loss: 0.2527 - acc: 0.8972 - auc-prc: 0.9588 - auc-roc: 0.9604 - val_loss: 0.2850 - val_acc: 0.8707 - val_auc-prc: 0.9462 - val_auc-roc: 0.9499 - 12s/epoch - 52ms/step
Epoch 4/100
229/229 - 15s - loss: 0.2428 - acc: 0.9029 - auc-prc: 0.9617 - auc-roc: 0.9634 - val_loss: 0.2722 - val_acc: 0.8855 - val_auc-prc: 0.9540 - val_auc-roc: 0.9559 - 15s/epoch - 67ms/step
Epoch 5/100
229/229 - 12s - loss: 0.2395 - acc: 0.9027 - auc-prc: 0.9636 - auc-roc: 0.9646 - val_loss: 0.2582 - val_acc: 0.8867 - val_auc-prc: 0.9575 - val_auc-roc: 0.9601 - 12s/epoch - 55ms/step
Epoch 6/100
229/229 - 12s - loss: 0.2375 - acc: 0.9038 - auc-prc: 0.9635 - auc-roc: 0.9648 - val_loss: 0.2563 - val_acc: 0.8941 - val_auc-prc: 0.9561 - val_auc-roc: 0.9594 - 12s/epoch - 54ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2325 - acc: 0.9048 - auc-prc: 0.9653 - auc-roc: 0.9665 - val_loss: 0.2542 - val_acc: 0.8892 - val_auc-prc: 0.9577 - val_auc-roc: 0.9608 - 13s/epoch - 55ms/step
Epoch 8/100
229/229 - 12s - loss: 0.2325 - acc: 0.9043 - auc-prc: 0.9657 - auc-roc: 0.9665 - val_loss: 0.2613 - val_acc: 0.8953 - val_auc-prc: 0.9552 - val_auc-roc: 0.9594 - 12s/epoch - 53ms/step
Epoch 9/100
229/229 - 12s - loss: 0.2298 - acc: 0.9106 - auc-prc: 0.9658 - auc-roc: 0.9668 - val_loss: 0.2619 - val_acc: 0.8892 - val_auc-prc: 0.9570 - val_auc-roc: 0.9595 - 12s/epoch - 53ms/step
Epoch 10/100
229/229 - 12s - loss: 0.2304 - acc: 0.9032 - auc-prc: 0.9668 - auc-roc: 0.9673 - val_loss: 0.2690 - val_acc: 0.8855 - val_auc-prc: 0.9555 - val_auc-roc: 0.9569 - 12s/epoch - 53ms/step
Epoch 11/100
229/229 - 12s - loss: 0.2282 - acc: 0.9091 - auc-prc: 0.9672 - auc-roc: 0.9678 - val_loss: 0.2594 - val_acc: 0.8892 - val_auc-prc: 0.9576 - val_auc-roc: 0.9612 - 12s/epoch - 53ms/step
Epoch 12/100
229/229 - 12s - loss: 0.2270 - acc: 0.9092 - auc-prc: 0.9665 - auc-roc: 0.9679 - val_loss: 0.2524 - val_acc: 0.8929 - val_auc-prc: 0.9599 - val_auc-roc: 0.9613 - 12s/epoch - 52ms/step
Epoch 13/100
229/229 - 12s - loss: 0.2256 - acc: 0.9116 - auc-prc: 0.9676 - auc-roc: 0.9684 - val_loss: 0.2724 - val_acc: 0.8855 - val_auc-prc: 0.9553 - val_auc-roc: 0.9591 - 12s/epoch - 50ms/step
Epoch 14/100
229/229 - 12s - loss: 0.2230 - acc: 0.9072 - auc-prc: 0.9681 - auc-roc: 0.9691 - val_loss: 0.2543 - val_acc: 0.8904 - val_auc-prc: 0.9603 - val_auc-roc: 0.9621 - 12s/epoch - 53ms/step
Epoch 15/100
229/229 - 12s - loss: 0.2256 - acc: 0.9098 - auc-prc: 0.9673 - auc-roc: 0.9683 - val_loss: 0.2620 - val_acc: 0.8929 - val_auc-prc: 0.9592 - val_auc-roc: 0.9599 - 12s/epoch - 54ms/step
Epoch 16/100
229/229 - 12s - loss: 0.2216 - acc: 0.9116 - auc-prc: 0.9688 - auc-roc: 0.9695 - val_loss: 0.2639 - val_acc: 0.8892 - val_auc-prc: 0.9593 - val_auc-roc: 0.9612 - 12s/epoch - 53ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2178 - acc: 0.9133 - auc-prc: 0.9699 - auc-roc: 0.9704 - val_loss: 0.2500 - val_acc: 0.8892 - val_auc-prc: 0.9616 - val_auc-roc: 0.9629 - 13s/epoch - 57ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2181 - acc: 0.9114 - auc-prc: 0.9701 - auc-roc: 0.9705 - val_loss: 0.2545 - val_acc: 0.8904 - val_auc-prc: 0.9586 - val_auc-roc: 0.9611 - 13s/epoch - 56ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2141 - acc: 0.9114 - auc-prc: 0.9709 - auc-roc: 0.9714 - val_loss: 0.2603 - val_acc: 0.8892 - val_auc-prc: 0.9559 - val_auc-roc: 0.9605 - 13s/epoch - 56ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2128 - acc: 0.9159 - auc-prc: 0.9710 - auc-roc: 0.9717 - val_loss: 0.2787 - val_acc: 0.8805 - val_auc-prc: 0.9521 - val_auc-roc: 0.9561 - 13s/epoch - 56ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2112 - acc: 0.9135 - auc-prc: 0.9718 - auc-roc: 0.9723 - val_loss: 0.2526 - val_acc: 0.8842 - val_auc-prc: 0.9622 - val_auc-roc: 0.9625 - 13s/epoch - 57ms/step
Epoch 22/100
229/229 - 13s - loss: 0.2093 - acc: 0.9169 - auc-prc: 0.9724 - auc-roc: 0.9726 - val_loss: 0.2635 - val_acc: 0.8867 - val_auc-prc: 0.9572 - val_auc-roc: 0.9591 - 13s/epoch - 57ms/step
Epoch 23/100
229/229 - 13s - loss: 0.2074 - acc: 0.9168 - auc-prc: 0.9727 - auc-roc: 0.9732 - val_loss: 0.2663 - val_acc: 0.8904 - val_auc-prc: 0.9555 - val_auc-roc: 0.9584 - 13s/epoch - 57ms/step
Early stopping epoch: 22
******Evaluating TEST set*********
26/26 - 1s - 1s/epoch - 54ms/step
              precision    recall  f1-score   support

           0       0.86      0.81      0.84       285
           1       0.90      0.93      0.92       527

    accuracy                           0.89       812
   macro avg       0.88      0.87      0.88       812
weighted avg       0.89      0.89      0.89       812

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.35      0.48      0.41       285
           1       0.65      0.52      0.58       527

    accuracy                           0.50       812
   macro avg       0.50      0.50      0.49       812
weighted avg       0.54      0.50      0.52       812

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 16s - loss: 0.2982 - acc: 0.8719 - auc-prc: 0.9437 - auc-roc: 0.9458 - val_loss: 0.2469 - val_acc: 0.9052 - val_auc-prc: 0.9594 - val_auc-roc: 0.9626 - 16s/epoch - 70ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2595 - acc: 0.8928 - auc-prc: 0.9563 - auc-roc: 0.9587 - val_loss: 0.2454 - val_acc: 0.9089 - val_auc-prc: 0.9621 - val_auc-roc: 0.9634 - 13s/epoch - 57ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2508 - acc: 0.8966 - auc-prc: 0.9592 - auc-roc: 0.9610 - val_loss: 0.2357 - val_acc: 0.9101 - val_auc-prc: 0.9633 - val_auc-roc: 0.9656 - 13s/epoch - 57ms/step
Epoch 4/100
229/229 - 13s - loss: 0.2456 - acc: 0.8984 - auc-prc: 0.9615 - auc-roc: 0.9626 - val_loss: 0.2340 - val_acc: 0.8941 - val_auc-prc: 0.9650 - val_auc-roc: 0.9668 - 13s/epoch - 57ms/step
Epoch 5/100
229/229 - 13s - loss: 0.2461 - acc: 0.9022 - auc-prc: 0.9608 - auc-roc: 0.9624 - val_loss: 0.2323 - val_acc: 0.9150 - val_auc-prc: 0.9669 - val_auc-roc: 0.9674 - 13s/epoch - 56ms/step
Epoch 6/100
229/229 - 13s - loss: 0.2396 - acc: 0.9058 - auc-prc: 0.9633 - auc-roc: 0.9644 - val_loss: 0.2402 - val_acc: 0.9150 - val_auc-prc: 0.9664 - val_auc-roc: 0.9662 - 13s/epoch - 57ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2363 - acc: 0.9054 - auc-prc: 0.9646 - auc-roc: 0.9654 - val_loss: 0.2256 - val_acc: 0.9138 - val_auc-prc: 0.9688 - val_auc-roc: 0.9687 - 13s/epoch - 57ms/step
Epoch 8/100
229/229 - 13s - loss: 0.2377 - acc: 0.9032 - auc-prc: 0.9638 - auc-roc: 0.9649 - val_loss: 0.2236 - val_acc: 0.9163 - val_auc-prc: 0.9699 - val_auc-roc: 0.9696 - 13s/epoch - 58ms/step
Epoch 9/100
229/229 - 13s - loss: 0.2309 - acc: 0.9048 - auc-prc: 0.9660 - auc-roc: 0.9667 - val_loss: 0.2399 - val_acc: 0.8929 - val_auc-prc: 0.9627 - val_auc-roc: 0.9639 - 13s/epoch - 57ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2328 - acc: 0.9055 - auc-prc: 0.9655 - auc-roc: 0.9665 - val_loss: 0.2258 - val_acc: 0.9126 - val_auc-prc: 0.9683 - val_auc-roc: 0.9686 - 13s/epoch - 56ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2305 - acc: 0.9038 - auc-prc: 0.9656 - auc-roc: 0.9668 - val_loss: 0.2241 - val_acc: 0.9138 - val_auc-prc: 0.9693 - val_auc-roc: 0.9692 - 13s/epoch - 56ms/step
Epoch 12/100
229/229 - 13s - loss: 0.2291 - acc: 0.9068 - auc-prc: 0.9666 - auc-roc: 0.9673 - val_loss: 0.2275 - val_acc: 0.9076 - val_auc-prc: 0.9674 - val_auc-roc: 0.9679 - 13s/epoch - 56ms/step
Epoch 13/100
229/229 - 13s - loss: 0.2252 - acc: 0.9072 - auc-prc: 0.9679 - auc-roc: 0.9685 - val_loss: 0.2275 - val_acc: 0.9052 - val_auc-prc: 0.9685 - val_auc-roc: 0.9681 - 13s/epoch - 56ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2257 - acc: 0.9109 - auc-prc: 0.9671 - auc-roc: 0.9681 - val_loss: 0.2303 - val_acc: 0.9113 - val_auc-prc: 0.9673 - val_auc-roc: 0.9673 - 13s/epoch - 56ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2241 - acc: 0.9064 - auc-prc: 0.9684 - auc-roc: 0.9689 - val_loss: 0.2294 - val_acc: 0.9015 - val_auc-prc: 0.9660 - val_auc-roc: 0.9668 - 13s/epoch - 57ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2209 - acc: 0.9106 - auc-prc: 0.9691 - auc-roc: 0.9697 - val_loss: 0.2261 - val_acc: 0.9052 - val_auc-prc: 0.9685 - val_auc-roc: 0.9688 - 13s/epoch - 56ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2228 - acc: 0.9103 - auc-prc: 0.9684 - auc-roc: 0.9693 - val_loss: 0.2254 - val_acc: 0.9064 - val_auc-prc: 0.9692 - val_auc-roc: 0.9689 - 13s/epoch - 57ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2170 - acc: 0.9127 - auc-prc: 0.9703 - auc-roc: 0.9708 - val_loss: 0.2254 - val_acc: 0.9064 - val_auc-prc: 0.9680 - val_auc-roc: 0.9686 - 13s/epoch - 56ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2138 - acc: 0.9137 - auc-prc: 0.9709 - auc-roc: 0.9713 - val_loss: 0.2311 - val_acc: 0.9027 - val_auc-prc: 0.9658 - val_auc-roc: 0.9675 - 13s/epoch - 57ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2137 - acc: 0.9121 - auc-prc: 0.9709 - auc-roc: 0.9716 - val_loss: 0.2382 - val_acc: 0.9150 - val_auc-prc: 0.9656 - val_auc-roc: 0.9665 - 13s/epoch - 56ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2117 - acc: 0.9110 - auc-prc: 0.9720 - auc-roc: 0.9723 - val_loss: 0.2315 - val_acc: 0.9076 - val_auc-prc: 0.9644 - val_auc-roc: 0.9661 - 13s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
26/26 - 1s - 688ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.88      0.89      0.88       285
           1       0.94      0.93      0.94       527

    accuracy                           0.92       812
   macro avg       0.91      0.91      0.91       812
weighted avg       0.92      0.92      0.92       812

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.49      0.42       285
           1       0.66      0.54      0.59       527

    accuracy                           0.52       812
   macro avg       0.52      0.52      0.51       812
weighted avg       0.56      0.52      0.53       812

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 15s - loss: 0.2977 - acc: 0.8739 - auc-prc: 0.9444 - auc-roc: 0.9460 - val_loss: 0.2552 - val_acc: 0.8916 - val_auc-prc: 0.9570 - val_auc-roc: 0.9592 - 15s/epoch - 67ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2626 - acc: 0.8923 - auc-prc: 0.9557 - auc-roc: 0.9577 - val_loss: 0.2526 - val_acc: 0.9027 - val_auc-prc: 0.9531 - val_auc-roc: 0.9595 - 13s/epoch - 56ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2561 - acc: 0.8935 - auc-prc: 0.9582 - auc-roc: 0.9597 - val_loss: 0.2459 - val_acc: 0.9027 - val_auc-prc: 0.9596 - val_auc-roc: 0.9619 - 13s/epoch - 57ms/step
Epoch 4/100
229/229 - 13s - loss: 0.2473 - acc: 0.8998 - auc-prc: 0.9597 - auc-roc: 0.9620 - val_loss: 0.2388 - val_acc: 0.9039 - val_auc-prc: 0.9591 - val_auc-roc: 0.9642 - 13s/epoch - 57ms/step
Epoch 5/100
229/229 - 13s - loss: 0.2436 - acc: 0.9038 - auc-prc: 0.9611 - auc-roc: 0.9630 - val_loss: 0.2334 - val_acc: 0.9076 - val_auc-prc: 0.9641 - val_auc-roc: 0.9655 - 13s/epoch - 56ms/step
Epoch 6/100
229/229 - 13s - loss: 0.2441 - acc: 0.9001 - auc-prc: 0.9616 - auc-roc: 0.9630 - val_loss: 0.2391 - val_acc: 0.9089 - val_auc-prc: 0.9642 - val_auc-roc: 0.9649 - 13s/epoch - 56ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2373 - acc: 0.9005 - auc-prc: 0.9641 - auc-roc: 0.9651 - val_loss: 0.2271 - val_acc: 0.9076 - val_auc-prc: 0.9649 - val_auc-roc: 0.9667 - 13s/epoch - 57ms/step
Epoch 8/100
229/229 - 13s - loss: 0.2340 - acc: 0.9047 - auc-prc: 0.9653 - auc-roc: 0.9661 - val_loss: 0.2256 - val_acc: 0.9076 - val_auc-prc: 0.9647 - val_auc-roc: 0.9675 - 13s/epoch - 57ms/step
Epoch 9/100
229/229 - 13s - loss: 0.2347 - acc: 0.9079 - auc-prc: 0.9651 - auc-roc: 0.9659 - val_loss: 0.2300 - val_acc: 0.9089 - val_auc-prc: 0.9650 - val_auc-roc: 0.9663 - 13s/epoch - 56ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2329 - acc: 0.9068 - auc-prc: 0.9655 - auc-roc: 0.9664 - val_loss: 0.2272 - val_acc: 0.9076 - val_auc-prc: 0.9654 - val_auc-roc: 0.9682 - 13s/epoch - 57ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2343 - acc: 0.9042 - auc-prc: 0.9652 - auc-roc: 0.9661 - val_loss: 0.2284 - val_acc: 0.9138 - val_auc-prc: 0.9620 - val_auc-roc: 0.9666 - 13s/epoch - 57ms/step
Epoch 12/100
229/229 - 13s - loss: 0.2283 - acc: 0.9087 - auc-prc: 0.9670 - auc-roc: 0.9677 - val_loss: 0.2339 - val_acc: 0.9076 - val_auc-prc: 0.9650 - val_auc-roc: 0.9658 - 13s/epoch - 56ms/step
Epoch 13/100
229/229 - 13s - loss: 0.2306 - acc: 0.9081 - auc-prc: 0.9659 - auc-roc: 0.9669 - val_loss: 0.2239 - val_acc: 0.9163 - val_auc-prc: 0.9659 - val_auc-roc: 0.9681 - 13s/epoch - 56ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2278 - acc: 0.9066 - auc-prc: 0.9673 - auc-roc: 0.9680 - val_loss: 0.2391 - val_acc: 0.9039 - val_auc-prc: 0.9662 - val_auc-roc: 0.9676 - 13s/epoch - 57ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2267 - acc: 0.9076 - auc-prc: 0.9680 - auc-roc: 0.9683 - val_loss: 0.2320 - val_acc: 0.9101 - val_auc-prc: 0.9636 - val_auc-roc: 0.9654 - 13s/epoch - 57ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2254 - acc: 0.9061 - auc-prc: 0.9684 - auc-roc: 0.9686 - val_loss: 0.2363 - val_acc: 0.9064 - val_auc-prc: 0.9656 - val_auc-roc: 0.9660 - 13s/epoch - 56ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2241 - acc: 0.9073 - auc-prc: 0.9682 - auc-roc: 0.9689 - val_loss: 0.2371 - val_acc: 0.9027 - val_auc-prc: 0.9646 - val_auc-roc: 0.9650 - 13s/epoch - 56ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2217 - acc: 0.9110 - auc-prc: 0.9687 - auc-roc: 0.9695 - val_loss: 0.2236 - val_acc: 0.9076 - val_auc-prc: 0.9677 - val_auc-roc: 0.9682 - 13s/epoch - 56ms/step
Epoch 19/100
229/229 - 12s - loss: 0.2203 - acc: 0.9100 - auc-prc: 0.9696 - auc-roc: 0.9701 - val_loss: 0.2250 - val_acc: 0.9113 - val_auc-prc: 0.9656 - val_auc-roc: 0.9679 - 12s/epoch - 52ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2168 - acc: 0.9114 - auc-prc: 0.9702 - auc-roc: 0.9708 - val_loss: 0.2290 - val_acc: 0.9064 - val_auc-prc: 0.9659 - val_auc-roc: 0.9670 - 13s/epoch - 56ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2145 - acc: 0.9127 - auc-prc: 0.9710 - auc-roc: 0.9716 - val_loss: 0.2312 - val_acc: 0.9089 - val_auc-prc: 0.9644 - val_auc-roc: 0.9665 - 13s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
26/26 - 1s - 662ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       285
           1       0.92      0.93      0.93       527

    accuracy                           0.91       812
   macro avg       0.90      0.90      0.90       812
weighted avg       0.91      0.91      0.91       812

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.34      0.49      0.40       285
           1       0.64      0.48      0.55       527

    accuracy                           0.48       812
   macro avg       0.49      0.49      0.47       812
weighted avg       0.53      0.48      0.50       812

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 15s - loss: 0.2976 - acc: 0.8695 - auc-prc: 0.9442 - auc-roc: 0.9458 - val_loss: 0.2707 - val_acc: 0.8940 - val_auc-prc: 0.9509 - val_auc-roc: 0.9551 - 15s/epoch - 65ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2597 - acc: 0.8942 - auc-prc: 0.9566 - auc-roc: 0.9586 - val_loss: 0.2618 - val_acc: 0.9026 - val_auc-prc: 0.9549 - val_auc-roc: 0.9580 - 13s/epoch - 58ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2520 - acc: 0.8980 - auc-prc: 0.9586 - auc-roc: 0.9607 - val_loss: 0.2641 - val_acc: 0.9051 - val_auc-prc: 0.9509 - val_auc-roc: 0.9565 - 13s/epoch - 56ms/step
Epoch 4/100
229/229 - 12s - loss: 0.2450 - acc: 0.8976 - auc-prc: 0.9607 - auc-roc: 0.9629 - val_loss: 0.2599 - val_acc: 0.9063 - val_auc-prc: 0.9544 - val_auc-roc: 0.9576 - 12s/epoch - 54ms/step
Epoch 5/100
229/229 - 12s - loss: 0.2412 - acc: 0.9014 - auc-prc: 0.9615 - auc-roc: 0.9637 - val_loss: 0.2673 - val_acc: 0.8927 - val_auc-prc: 0.9497 - val_auc-roc: 0.9545 - 12s/epoch - 53ms/step
Epoch 6/100
229/229 - 12s - loss: 0.2389 - acc: 0.9010 - auc-prc: 0.9637 - auc-roc: 0.9646 - val_loss: 0.2941 - val_acc: 0.8866 - val_auc-prc: 0.9426 - val_auc-roc: 0.9460 - 12s/epoch - 53ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2335 - acc: 0.9029 - auc-prc: 0.9653 - auc-roc: 0.9663 - val_loss: 0.2517 - val_acc: 0.9014 - val_auc-prc: 0.9558 - val_auc-roc: 0.9600 - 13s/epoch - 58ms/step
Epoch 8/100
229/229 - 13s - loss: 0.2332 - acc: 0.9046 - auc-prc: 0.9656 - auc-roc: 0.9663 - val_loss: 0.2717 - val_acc: 0.8940 - val_auc-prc: 0.9532 - val_auc-roc: 0.9574 - 13s/epoch - 57ms/step
Epoch 9/100
229/229 - 13s - loss: 0.2309 - acc: 0.9068 - auc-prc: 0.9660 - auc-roc: 0.9669 - val_loss: 0.2594 - val_acc: 0.9038 - val_auc-prc: 0.9561 - val_auc-roc: 0.9599 - 13s/epoch - 56ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2288 - acc: 0.9072 - auc-prc: 0.9669 - auc-roc: 0.9675 - val_loss: 0.2663 - val_acc: 0.9051 - val_auc-prc: 0.9535 - val_auc-roc: 0.9591 - 13s/epoch - 56ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2263 - acc: 0.9054 - auc-prc: 0.9676 - auc-roc: 0.9683 - val_loss: 0.2597 - val_acc: 0.9014 - val_auc-prc: 0.9546 - val_auc-roc: 0.9588 - 13s/epoch - 57ms/step
Epoch 12/100
229/229 - 13s - loss: 0.2297 - acc: 0.9031 - auc-prc: 0.9666 - auc-roc: 0.9674 - val_loss: 0.2481 - val_acc: 0.9075 - val_auc-prc: 0.9587 - val_auc-roc: 0.9612 - 13s/epoch - 57ms/step
Epoch 13/100
229/229 - 13s - loss: 0.2241 - acc: 0.9046 - auc-prc: 0.9688 - auc-roc: 0.9691 - val_loss: 0.2605 - val_acc: 0.9051 - val_auc-prc: 0.9584 - val_auc-roc: 0.9610 - 13s/epoch - 57ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2234 - acc: 0.9080 - auc-prc: 0.9685 - auc-roc: 0.9691 - val_loss: 0.2605 - val_acc: 0.9014 - val_auc-prc: 0.9569 - val_auc-roc: 0.9585 - 13s/epoch - 56ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2221 - acc: 0.9097 - auc-prc: 0.9686 - auc-roc: 0.9693 - val_loss: 0.2515 - val_acc: 0.9088 - val_auc-prc: 0.9565 - val_auc-roc: 0.9599 - 13s/epoch - 57ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2206 - acc: 0.9092 - auc-prc: 0.9689 - auc-roc: 0.9699 - val_loss: 0.2465 - val_acc: 0.9063 - val_auc-prc: 0.9594 - val_auc-roc: 0.9616 - 13s/epoch - 57ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2180 - acc: 0.9127 - auc-prc: 0.9693 - auc-roc: 0.9703 - val_loss: 0.2474 - val_acc: 0.9001 - val_auc-prc: 0.9602 - val_auc-roc: 0.9616 - 13s/epoch - 58ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2174 - acc: 0.9101 - auc-prc: 0.9699 - auc-roc: 0.9706 - val_loss: 0.2612 - val_acc: 0.9014 - val_auc-prc: 0.9544 - val_auc-roc: 0.9576 - 13s/epoch - 57ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2122 - acc: 0.9132 - auc-prc: 0.9713 - auc-roc: 0.9720 - val_loss: 0.2623 - val_acc: 0.9026 - val_auc-prc: 0.9558 - val_auc-roc: 0.9582 - 13s/epoch - 55ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2149 - acc: 0.9127 - auc-prc: 0.9700 - auc-roc: 0.9711 - val_loss: 0.2538 - val_acc: 0.9026 - val_auc-prc: 0.9581 - val_auc-roc: 0.9598 - 13s/epoch - 57ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2084 - acc: 0.9168 - auc-prc: 0.9718 - auc-roc: 0.9728 - val_loss: 0.2900 - val_acc: 0.8952 - val_auc-prc: 0.9502 - val_auc-roc: 0.9543 - 13s/epoch - 57ms/step
Epoch 22/100
229/229 - 13s - loss: 0.2084 - acc: 0.9164 - auc-prc: 0.9729 - auc-roc: 0.9730 - val_loss: 0.2991 - val_acc: 0.8866 - val_auc-prc: 0.9502 - val_auc-roc: 0.9531 - 13s/epoch - 57ms/step
Epoch 23/100
229/229 - 13s - loss: 0.2064 - acc: 0.9151 - auc-prc: 0.9732 - auc-roc: 0.9735 - val_loss: 0.2644 - val_acc: 0.8940 - val_auc-prc: 0.9549 - val_auc-roc: 0.9568 - 13s/epoch - 57ms/step
Epoch 24/100
229/229 - 13s - loss: 0.2059 - acc: 0.9161 - auc-prc: 0.9729 - auc-roc: 0.9734 - val_loss: 0.2489 - val_acc: 0.8977 - val_auc-prc: 0.9613 - val_auc-roc: 0.9620 - 13s/epoch - 57ms/step
Epoch 25/100
229/229 - 13s - loss: 0.1997 - acc: 0.9218 - auc-prc: 0.9749 - auc-roc: 0.9753 - val_loss: 0.2690 - val_acc: 0.8952 - val_auc-prc: 0.9540 - val_auc-roc: 0.9555 - 13s/epoch - 57ms/step
Epoch 26/100
229/229 - 13s - loss: 0.1970 - acc: 0.9221 - auc-prc: 0.9745 - auc-roc: 0.9756 - val_loss: 0.2685 - val_acc: 0.8927 - val_auc-prc: 0.9558 - val_auc-roc: 0.9572 - 13s/epoch - 56ms/step
Early stopping epoch: 25
******Evaluating TEST set*********
26/26 - 1s - 679ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.87      0.83      0.85       284
           1       0.91      0.93      0.92       527

    accuracy                           0.90       811
   macro avg       0.89      0.88      0.89       811
weighted avg       0.90      0.90      0.90       811

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.36      0.52      0.43       284
           1       0.66      0.50      0.57       527

    accuracy                           0.51       811
   macro avg       0.51      0.51      0.50       811
weighted avg       0.56      0.51      0.52       811

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 16s - loss: 0.3027 - acc: 0.8682 - auc-prc: 0.9426 - auc-roc: 0.9440 - val_loss: 0.2657 - val_acc: 0.8878 - val_auc-prc: 0.9557 - val_auc-roc: 0.9568 - 16s/epoch - 69ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2612 - acc: 0.8935 - auc-prc: 0.9550 - auc-roc: 0.9579 - val_loss: 0.2822 - val_acc: 0.8668 - val_auc-prc: 0.9508 - val_auc-roc: 0.9519 - 13s/epoch - 57ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2514 - acc: 0.8961 - auc-prc: 0.9584 - auc-roc: 0.9607 - val_loss: 0.2406 - val_acc: 0.9001 - val_auc-prc: 0.9628 - val_auc-roc: 0.9644 - 13s/epoch - 55ms/step
Epoch 4/100
229/229 - 12s - loss: 0.2472 - acc: 0.9014 - auc-prc: 0.9600 - auc-roc: 0.9622 - val_loss: 0.2301 - val_acc: 0.8977 - val_auc-prc: 0.9680 - val_auc-roc: 0.9686 - 12s/epoch - 53ms/step
Epoch 5/100
229/229 - 13s - loss: 0.2497 - acc: 0.9017 - auc-prc: 0.9598 - auc-roc: 0.9613 - val_loss: 0.2435 - val_acc: 0.8903 - val_auc-prc: 0.9645 - val_auc-roc: 0.9640 - 13s/epoch - 55ms/step
Epoch 6/100
229/229 - 13s - loss: 0.2436 - acc: 0.9013 - auc-prc: 0.9617 - auc-roc: 0.9631 - val_loss: 0.2272 - val_acc: 0.8977 - val_auc-prc: 0.9697 - val_auc-roc: 0.9692 - 13s/epoch - 55ms/step
Epoch 7/100
229/229 - 12s - loss: 0.2401 - acc: 0.9031 - auc-prc: 0.9622 - auc-roc: 0.9642 - val_loss: 0.2358 - val_acc: 0.8915 - val_auc-prc: 0.9673 - val_auc-roc: 0.9667 - 12s/epoch - 54ms/step
Epoch 8/100
229/229 - 13s - loss: 0.2376 - acc: 0.9043 - auc-prc: 0.9634 - auc-roc: 0.9646 - val_loss: 0.2264 - val_acc: 0.8964 - val_auc-prc: 0.9702 - val_auc-roc: 0.9705 - 13s/epoch - 55ms/step
Epoch 9/100
229/229 - 13s - loss: 0.2339 - acc: 0.9054 - auc-prc: 0.9637 - auc-roc: 0.9658 - val_loss: 0.2180 - val_acc: 0.9026 - val_auc-prc: 0.9713 - val_auc-roc: 0.9710 - 13s/epoch - 57ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2345 - acc: 0.9054 - auc-prc: 0.9640 - auc-roc: 0.9658 - val_loss: 0.2221 - val_acc: 0.9001 - val_auc-prc: 0.9703 - val_auc-roc: 0.9699 - 13s/epoch - 57ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2328 - acc: 0.9047 - auc-prc: 0.9649 - auc-roc: 0.9661 - val_loss: 0.2209 - val_acc: 0.9026 - val_auc-prc: 0.9713 - val_auc-roc: 0.9707 - 13s/epoch - 57ms/step
Epoch 12/100
229/229 - 13s - loss: 0.2315 - acc: 0.9075 - auc-prc: 0.9656 - auc-roc: 0.9665 - val_loss: 0.2170 - val_acc: 0.8977 - val_auc-prc: 0.9723 - val_auc-roc: 0.9723 - 13s/epoch - 57ms/step
Epoch 13/100
229/229 - 13s - loss: 0.2285 - acc: 0.9090 - auc-prc: 0.9661 - auc-roc: 0.9673 - val_loss: 0.2158 - val_acc: 0.8964 - val_auc-prc: 0.9728 - val_auc-roc: 0.9719 - 13s/epoch - 57ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2287 - acc: 0.9090 - auc-prc: 0.9661 - auc-roc: 0.9673 - val_loss: 0.2259 - val_acc: 0.8952 - val_auc-prc: 0.9703 - val_auc-roc: 0.9694 - 13s/epoch - 57ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2282 - acc: 0.9072 - auc-prc: 0.9674 - auc-roc: 0.9677 - val_loss: 0.2179 - val_acc: 0.9014 - val_auc-prc: 0.9719 - val_auc-roc: 0.9711 - 13s/epoch - 57ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2265 - acc: 0.9097 - auc-prc: 0.9675 - auc-roc: 0.9682 - val_loss: 0.2203 - val_acc: 0.9014 - val_auc-prc: 0.9720 - val_auc-roc: 0.9711 - 13s/epoch - 57ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2286 - acc: 0.9069 - auc-prc: 0.9655 - auc-roc: 0.9675 - val_loss: 0.2172 - val_acc: 0.9014 - val_auc-prc: 0.9727 - val_auc-roc: 0.9720 - 13s/epoch - 57ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2213 - acc: 0.9117 - auc-prc: 0.9680 - auc-roc: 0.9694 - val_loss: 0.2202 - val_acc: 0.8940 - val_auc-prc: 0.9709 - val_auc-roc: 0.9705 - 13s/epoch - 55ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2202 - acc: 0.9107 - auc-prc: 0.9689 - auc-roc: 0.9699 - val_loss: 0.2274 - val_acc: 0.8952 - val_auc-prc: 0.9701 - val_auc-roc: 0.9693 - 13s/epoch - 56ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2187 - acc: 0.9140 - auc-prc: 0.9692 - auc-roc: 0.9700 - val_loss: 0.2210 - val_acc: 0.9125 - val_auc-prc: 0.9716 - val_auc-roc: 0.9709 - 13s/epoch - 56ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2188 - acc: 0.9131 - auc-prc: 0.9693 - auc-roc: 0.9701 - val_loss: 0.2163 - val_acc: 0.9063 - val_auc-prc: 0.9729 - val_auc-roc: 0.9722 - 13s/epoch - 56ms/step
Epoch 22/100
229/229 - 13s - loss: 0.2172 - acc: 0.9142 - auc-prc: 0.9698 - auc-roc: 0.9707 - val_loss: 0.2054 - val_acc: 0.9137 - val_auc-prc: 0.9746 - val_auc-roc: 0.9744 - 13s/epoch - 57ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
26/26 - 1s - 687ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.89      0.86      0.87       284
           1       0.93      0.94      0.93       527

    accuracy                           0.91       811
   macro avg       0.91      0.90      0.90       811
weighted avg       0.91      0.91      0.91       811

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.34      0.51      0.41       284
           1       0.64      0.46      0.54       527

    accuracy                           0.48       811
   macro avg       0.49      0.49      0.47       811
weighted avg       0.53      0.48      0.49       811

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 16s - loss: 0.3035 - acc: 0.8660 - auc-prc: 0.9421 - auc-roc: 0.9439 - val_loss: 0.2419 - val_acc: 0.9051 - val_auc-prc: 0.9628 - val_auc-roc: 0.9638 - 16s/epoch - 68ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2565 - acc: 0.8961 - auc-prc: 0.9567 - auc-roc: 0.9592 - val_loss: 0.2413 - val_acc: 0.9063 - val_auc-prc: 0.9646 - val_auc-roc: 0.9649 - 13s/epoch - 57ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2557 - acc: 0.8984 - auc-prc: 0.9576 - auc-roc: 0.9596 - val_loss: 0.2770 - val_acc: 0.8792 - val_auc-prc: 0.9516 - val_auc-roc: 0.9532 - 13s/epoch - 55ms/step
Epoch 4/100
229/229 - 13s - loss: 0.2483 - acc: 0.8999 - auc-prc: 0.9601 - auc-roc: 0.9617 - val_loss: 0.2453 - val_acc: 0.9100 - val_auc-prc: 0.9631 - val_auc-roc: 0.9647 - 13s/epoch - 57ms/step
Epoch 5/100
229/229 - 13s - loss: 0.2441 - acc: 0.9005 - auc-prc: 0.9614 - auc-roc: 0.9629 - val_loss: 0.2493 - val_acc: 0.9100 - val_auc-prc: 0.9620 - val_auc-roc: 0.9630 - 13s/epoch - 56ms/step
Epoch 6/100
229/229 - 13s - loss: 0.2403 - acc: 0.9029 - auc-prc: 0.9625 - auc-roc: 0.9640 - val_loss: 0.2571 - val_acc: 0.8853 - val_auc-prc: 0.9576 - val_auc-roc: 0.9592 - 13s/epoch - 56ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2403 - acc: 0.9028 - auc-prc: 0.9629 - auc-roc: 0.9640 - val_loss: 0.2300 - val_acc: 0.9100 - val_auc-prc: 0.9653 - val_auc-roc: 0.9665 - 13s/epoch - 57ms/step
Epoch 8/100
229/229 - 13s - loss: 0.2377 - acc: 0.9042 - auc-prc: 0.9632 - auc-roc: 0.9647 - val_loss: 0.2466 - val_acc: 0.8964 - val_auc-prc: 0.9616 - val_auc-roc: 0.9624 - 13s/epoch - 56ms/step
Epoch 9/100
229/229 - 13s - loss: 0.2333 - acc: 0.9025 - auc-prc: 0.9653 - auc-roc: 0.9662 - val_loss: 0.2297 - val_acc: 0.9112 - val_auc-prc: 0.9657 - val_auc-roc: 0.9666 - 13s/epoch - 57ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2358 - acc: 0.9031 - auc-prc: 0.9642 - auc-roc: 0.9654 - val_loss: 0.2322 - val_acc: 0.9137 - val_auc-prc: 0.9652 - val_auc-roc: 0.9669 - 13s/epoch - 57ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2305 - acc: 0.9077 - auc-prc: 0.9661 - auc-roc: 0.9669 - val_loss: 0.2252 - val_acc: 0.9112 - val_auc-prc: 0.9663 - val_auc-roc: 0.9675 - 13s/epoch - 57ms/step
Epoch 12/100
229/229 - 13s - loss: 0.2306 - acc: 0.9061 - auc-prc: 0.9660 - auc-roc: 0.9670 - val_loss: 0.2323 - val_acc: 0.9088 - val_auc-prc: 0.9640 - val_auc-roc: 0.9669 - 13s/epoch - 56ms/step
Epoch 13/100
229/229 - 13s - loss: 0.2302 - acc: 0.9047 - auc-prc: 0.9661 - auc-roc: 0.9670 - val_loss: 0.2286 - val_acc: 0.9088 - val_auc-prc: 0.9667 - val_auc-roc: 0.9673 - 13s/epoch - 57ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2245 - acc: 0.9099 - auc-prc: 0.9680 - auc-roc: 0.9685 - val_loss: 0.2303 - val_acc: 0.9125 - val_auc-prc: 0.9661 - val_auc-roc: 0.9669 - 13s/epoch - 57ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2256 - acc: 0.9084 - auc-prc: 0.9679 - auc-roc: 0.9686 - val_loss: 0.2358 - val_acc: 0.9125 - val_auc-prc: 0.9630 - val_auc-roc: 0.9650 - 13s/epoch - 56ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2227 - acc: 0.9091 - auc-prc: 0.9689 - auc-roc: 0.9693 - val_loss: 0.2314 - val_acc: 0.9162 - val_auc-prc: 0.9677 - val_auc-roc: 0.9686 - 13s/epoch - 57ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2205 - acc: 0.9123 - auc-prc: 0.9692 - auc-roc: 0.9698 - val_loss: 0.2447 - val_acc: 0.8989 - val_auc-prc: 0.9620 - val_auc-roc: 0.9629 - 13s/epoch - 56ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2186 - acc: 0.9121 - auc-prc: 0.9699 - auc-roc: 0.9702 - val_loss: 0.2371 - val_acc: 0.9026 - val_auc-prc: 0.9634 - val_auc-roc: 0.9644 - 13s/epoch - 57ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2167 - acc: 0.9124 - auc-prc: 0.9703 - auc-roc: 0.9708 - val_loss: 0.2302 - val_acc: 0.9088 - val_auc-prc: 0.9666 - val_auc-roc: 0.9680 - 13s/epoch - 56ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2178 - acc: 0.9127 - auc-prc: 0.9702 - auc-roc: 0.9705 - val_loss: 0.2522 - val_acc: 0.8927 - val_auc-prc: 0.9571 - val_auc-roc: 0.9607 - 13s/epoch - 56ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2128 - acc: 0.9147 - auc-prc: 0.9714 - auc-roc: 0.9718 - val_loss: 0.2382 - val_acc: 0.9075 - val_auc-prc: 0.9636 - val_auc-roc: 0.9655 - 13s/epoch - 56ms/step
Epoch 22/100
229/229 - 13s - loss: 0.2107 - acc: 0.9177 - auc-prc: 0.9726 - auc-roc: 0.9727 - val_loss: 0.2289 - val_acc: 0.9162 - val_auc-prc: 0.9663 - val_auc-roc: 0.9671 - 13s/epoch - 56ms/step
Epoch 23/100
229/229 - 13s - loss: 0.2090 - acc: 0.9153 - auc-prc: 0.9729 - auc-roc: 0.9730 - val_loss: 0.2327 - val_acc: 0.9125 - val_auc-prc: 0.9639 - val_auc-roc: 0.9661 - 13s/epoch - 56ms/step
Early stopping epoch: 22
******Evaluating TEST set*********
26/26 - 1s - 680ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.93      0.83      0.87       285
           1       0.91      0.96      0.94       526

    accuracy                           0.92       811
   macro avg       0.92      0.90      0.91       811
weighted avg       0.92      0.92      0.91       811

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.34      0.48      0.40       285
           1       0.64      0.49      0.56       526

    accuracy                           0.49       811
   macro avg       0.49      0.49      0.48       811
weighted avg       0.53      0.49      0.50       811

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
229/229 - 16s - loss: 0.2975 - acc: 0.8734 - auc-prc: 0.9438 - auc-roc: 0.9461 - val_loss: 0.2803 - val_acc: 0.8903 - val_auc-prc: 0.9524 - val_auc-roc: 0.9529 - 16s/epoch - 68ms/step
Epoch 2/100
229/229 - 13s - loss: 0.2581 - acc: 0.8919 - auc-prc: 0.9562 - auc-roc: 0.9585 - val_loss: 0.2968 - val_acc: 0.8767 - val_auc-prc: 0.9492 - val_auc-roc: 0.9496 - 13s/epoch - 56ms/step
Epoch 3/100
229/229 - 13s - loss: 0.2528 - acc: 0.8957 - auc-prc: 0.9580 - auc-roc: 0.9602 - val_loss: 0.2706 - val_acc: 0.8940 - val_auc-prc: 0.9558 - val_auc-roc: 0.9559 - 13s/epoch - 56ms/step
Epoch 4/100
229/229 - 13s - loss: 0.2458 - acc: 0.8979 - auc-prc: 0.9608 - auc-roc: 0.9622 - val_loss: 0.2538 - val_acc: 0.8940 - val_auc-prc: 0.9600 - val_auc-roc: 0.9606 - 13s/epoch - 55ms/step
Epoch 5/100
229/229 - 13s - loss: 0.2446 - acc: 0.8987 - auc-prc: 0.9607 - auc-roc: 0.9626 - val_loss: 0.2613 - val_acc: 0.8927 - val_auc-prc: 0.9577 - val_auc-roc: 0.9580 - 13s/epoch - 56ms/step
Epoch 6/100
229/229 - 13s - loss: 0.2386 - acc: 0.9044 - auc-prc: 0.9620 - auc-roc: 0.9644 - val_loss: 0.2582 - val_acc: 0.8915 - val_auc-prc: 0.9579 - val_auc-roc: 0.9588 - 13s/epoch - 57ms/step
Epoch 7/100
229/229 - 13s - loss: 0.2355 - acc: 0.9064 - auc-prc: 0.9640 - auc-roc: 0.9652 - val_loss: 0.2603 - val_acc: 0.8940 - val_auc-prc: 0.9582 - val_auc-roc: 0.9588 - 13s/epoch - 56ms/step
Epoch 8/100
229/229 - 13s - loss: 0.2328 - acc: 0.9062 - auc-prc: 0.9647 - auc-roc: 0.9660 - val_loss: 0.2486 - val_acc: 0.8989 - val_auc-prc: 0.9618 - val_auc-roc: 0.9621 - 13s/epoch - 57ms/step
Epoch 9/100
229/229 - 13s - loss: 0.2339 - acc: 0.9070 - auc-prc: 0.9643 - auc-roc: 0.9656 - val_loss: 0.2547 - val_acc: 0.8940 - val_auc-prc: 0.9599 - val_auc-roc: 0.9603 - 13s/epoch - 57ms/step
Epoch 10/100
229/229 - 13s - loss: 0.2260 - acc: 0.9075 - auc-prc: 0.9669 - auc-roc: 0.9679 - val_loss: 0.2487 - val_acc: 0.8977 - val_auc-prc: 0.9624 - val_auc-roc: 0.9628 - 13s/epoch - 57ms/step
Epoch 11/100
229/229 - 13s - loss: 0.2297 - acc: 0.9066 - auc-prc: 0.9660 - auc-roc: 0.9670 - val_loss: 0.2541 - val_acc: 0.8927 - val_auc-prc: 0.9607 - val_auc-roc: 0.9610 - 13s/epoch - 57ms/step
Epoch 12/100
229/229 - 13s - loss: 0.2254 - acc: 0.9098 - auc-prc: 0.9667 - auc-roc: 0.9681 - val_loss: 0.2723 - val_acc: 0.8890 - val_auc-prc: 0.9577 - val_auc-roc: 0.9588 - 13s/epoch - 56ms/step
Epoch 13/100
229/229 - 13s - loss: 0.2253 - acc: 0.9081 - auc-prc: 0.9671 - auc-roc: 0.9683 - val_loss: 0.2571 - val_acc: 0.8927 - val_auc-prc: 0.9614 - val_auc-roc: 0.9616 - 13s/epoch - 56ms/step
Epoch 14/100
229/229 - 13s - loss: 0.2262 - acc: 0.9088 - auc-prc: 0.9674 - auc-roc: 0.9681 - val_loss: 0.2483 - val_acc: 0.8927 - val_auc-prc: 0.9621 - val_auc-roc: 0.9625 - 13s/epoch - 56ms/step
Epoch 15/100
229/229 - 13s - loss: 0.2212 - acc: 0.9120 - auc-prc: 0.9690 - auc-roc: 0.9695 - val_loss: 0.2570 - val_acc: 0.8927 - val_auc-prc: 0.9598 - val_auc-roc: 0.9600 - 13s/epoch - 56ms/step
Epoch 16/100
229/229 - 13s - loss: 0.2189 - acc: 0.9101 - auc-prc: 0.9703 - auc-roc: 0.9704 - val_loss: 0.2529 - val_acc: 0.8964 - val_auc-prc: 0.9620 - val_auc-roc: 0.9619 - 13s/epoch - 56ms/step
Epoch 17/100
229/229 - 13s - loss: 0.2162 - acc: 0.9144 - auc-prc: 0.9700 - auc-roc: 0.9707 - val_loss: 0.2524 - val_acc: 0.8816 - val_auc-prc: 0.9617 - val_auc-roc: 0.9620 - 13s/epoch - 57ms/step
Epoch 18/100
229/229 - 13s - loss: 0.2161 - acc: 0.9144 - auc-prc: 0.9707 - auc-roc: 0.9710 - val_loss: 0.2527 - val_acc: 0.8915 - val_auc-prc: 0.9634 - val_auc-roc: 0.9634 - 13s/epoch - 57ms/step
Epoch 19/100
229/229 - 13s - loss: 0.2134 - acc: 0.9125 - auc-prc: 0.9705 - auc-roc: 0.9714 - val_loss: 0.2649 - val_acc: 0.8829 - val_auc-prc: 0.9587 - val_auc-roc: 0.9588 - 13s/epoch - 56ms/step
Epoch 20/100
229/229 - 13s - loss: 0.2112 - acc: 0.9133 - auc-prc: 0.9721 - auc-roc: 0.9723 - val_loss: 0.2704 - val_acc: 0.8853 - val_auc-prc: 0.9569 - val_auc-roc: 0.9568 - 13s/epoch - 57ms/step
Epoch 21/100
229/229 - 13s - loss: 0.2122 - acc: 0.9147 - auc-prc: 0.9713 - auc-roc: 0.9719 - val_loss: 0.2522 - val_acc: 0.8952 - val_auc-prc: 0.9622 - val_auc-roc: 0.9627 - 13s/epoch - 57ms/step
Epoch 22/100
229/229 - 13s - loss: 0.2052 - acc: 0.9161 - auc-prc: 0.9736 - auc-roc: 0.9739 - val_loss: 0.2544 - val_acc: 0.8878 - val_auc-prc: 0.9615 - val_auc-roc: 0.9617 - 13s/epoch - 56ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
26/26 - 1s - 630ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       285
           1       0.90      0.94      0.92       526

    accuracy                           0.89       811
   macro avg       0.89      0.87      0.88       811
weighted avg       0.89      0.89      0.89       811

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.35      0.50      0.42       285
           1       0.65      0.51      0.57       526

    accuracy                           0.50       811
   macro avg       0.50      0.50      0.49       811
weighted avg       0.55      0.50      0.52       811

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8924] IC [0.8844, 0.9004]
Mean Accuracy[0.9062] IC [0.8995, 0.9130]
Mean Recall[0.8924] IC [0.8844, 0.9004]
Mean F1[0.8960] IC [0.8885, 0.9036]
Median AUC_ROC[0.8940]
Median Accuracy[0.9083]
Median Recall[0.8940]
Median F1[0.8982]
********************txid196627********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.93      0.81      0.87      1182
           1       0.82      0.93      0.87      1077

    accuracy                           0.87      2259
   macro avg       0.87      0.87      0.87      2259
weighted avg       0.87      0.87      0.87      2259

Predicted   0.0   1.0   All
True                       
0           959   223  1182
1            76  1001  1077
All        1035  1224  2259
**************************************************
fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3192 - acc: 0.8663 - auc-prc: 0.9351 - auc-roc: 0.9367 - val_loss: 0.2657 - val_acc: 0.9009 - val_auc-prc: 0.9541 - val_auc-roc: 0.9564 - 13s/epoch - 71ms/step
Epoch 2/100
185/185 - 10s - loss: 0.2827 - acc: 0.8826 - auc-prc: 0.9498 - auc-roc: 0.9506 - val_loss: 0.2532 - val_acc: 0.9162 - val_auc-prc: 0.9578 - val_auc-roc: 0.9599 - 10s/epoch - 55ms/step
Epoch 3/100
185/185 - 10s - loss: 0.2683 - acc: 0.8941 - auc-prc: 0.9540 - auc-roc: 0.9551 - val_loss: 0.2710 - val_acc: 0.9040 - val_auc-prc: 0.9523 - val_auc-roc: 0.9581 - 10s/epoch - 54ms/step
Epoch 4/100
185/185 - 10s - loss: 0.2624 - acc: 0.8965 - auc-prc: 0.9564 - auc-roc: 0.9571 - val_loss: 0.2434 - val_acc: 0.9146 - val_auc-prc: 0.9599 - val_auc-roc: 0.9615 - 10s/epoch - 56ms/step
Epoch 5/100
185/185 - 10s - loss: 0.2572 - acc: 0.8989 - auc-prc: 0.9573 - auc-roc: 0.9587 - val_loss: 0.2416 - val_acc: 0.9162 - val_auc-prc: 0.9628 - val_auc-roc: 0.9639 - 10s/epoch - 56ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2552 - acc: 0.8974 - auc-prc: 0.9589 - auc-roc: 0.9596 - val_loss: 0.2313 - val_acc: 0.9207 - val_auc-prc: 0.9641 - val_auc-roc: 0.9655 - 10s/epoch - 56ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2515 - acc: 0.9008 - auc-prc: 0.9602 - auc-roc: 0.9612 - val_loss: 0.2288 - val_acc: 0.9207 - val_auc-prc: 0.9651 - val_auc-roc: 0.9664 - 10s/epoch - 56ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2454 - acc: 0.9036 - auc-prc: 0.9616 - auc-roc: 0.9630 - val_loss: 0.2276 - val_acc: 0.9238 - val_auc-prc: 0.9633 - val_auc-roc: 0.9664 - 10s/epoch - 55ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2431 - acc: 0.9043 - auc-prc: 0.9624 - auc-roc: 0.9635 - val_loss: 0.2318 - val_acc: 0.9192 - val_auc-prc: 0.9629 - val_auc-roc: 0.9650 - 10s/epoch - 56ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2413 - acc: 0.9050 - auc-prc: 0.9631 - auc-roc: 0.9641 - val_loss: 0.2295 - val_acc: 0.9223 - val_auc-prc: 0.9647 - val_auc-roc: 0.9663 - 10s/epoch - 56ms/step
Epoch 11/100
185/185 - 10s - loss: 0.2409 - acc: 0.9025 - auc-prc: 0.9633 - auc-roc: 0.9644 - val_loss: 0.2265 - val_acc: 0.9238 - val_auc-prc: 0.9658 - val_auc-roc: 0.9674 - 10s/epoch - 56ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2381 - acc: 0.9031 - auc-prc: 0.9643 - auc-roc: 0.9652 - val_loss: 0.2423 - val_acc: 0.9116 - val_auc-prc: 0.9610 - val_auc-roc: 0.9643 - 10s/epoch - 56ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2326 - acc: 0.9086 - auc-prc: 0.9659 - auc-roc: 0.9666 - val_loss: 0.2361 - val_acc: 0.9131 - val_auc-prc: 0.9631 - val_auc-roc: 0.9641 - 10s/epoch - 56ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2340 - acc: 0.9067 - auc-prc: 0.9655 - auc-roc: 0.9663 - val_loss: 0.2372 - val_acc: 0.9116 - val_auc-prc: 0.9649 - val_auc-roc: 0.9658 - 10s/epoch - 56ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2272 - acc: 0.9092 - auc-prc: 0.9673 - auc-roc: 0.9682 - val_loss: 0.2349 - val_acc: 0.9101 - val_auc-prc: 0.9646 - val_auc-roc: 0.9651 - 10s/epoch - 56ms/step
Epoch 16/100
185/185 - 10s - loss: 0.2253 - acc: 0.9109 - auc-prc: 0.9682 - auc-roc: 0.9687 - val_loss: 0.2232 - val_acc: 0.9207 - val_auc-prc: 0.9661 - val_auc-roc: 0.9681 - 10s/epoch - 56ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2236 - acc: 0.9098 - auc-prc: 0.9684 - auc-roc: 0.9691 - val_loss: 0.2382 - val_acc: 0.9101 - val_auc-prc: 0.9650 - val_auc-roc: 0.9658 - 10s/epoch - 55ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2229 - acc: 0.9098 - auc-prc: 0.9690 - auc-roc: 0.9695 - val_loss: 0.2227 - val_acc: 0.9238 - val_auc-prc: 0.9660 - val_auc-roc: 0.9679 - 10s/epoch - 56ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2197 - acc: 0.9098 - auc-prc: 0.9699 - auc-roc: 0.9702 - val_loss: 0.2257 - val_acc: 0.9085 - val_auc-prc: 0.9667 - val_auc-roc: 0.9674 - 10s/epoch - 56ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2161 - acc: 0.9155 - auc-prc: 0.9706 - auc-roc: 0.9711 - val_loss: 0.2193 - val_acc: 0.9207 - val_auc-prc: 0.9674 - val_auc-roc: 0.9686 - 10s/epoch - 57ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2101 - acc: 0.9174 - auc-prc: 0.9724 - auc-roc: 0.9727 - val_loss: 0.2440 - val_acc: 0.9055 - val_auc-prc: 0.9630 - val_auc-roc: 0.9632 - 10s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 615ms/epoch - 29ms/step
              precision    recall  f1-score   support

           0       0.90      0.82      0.86       194
           1       0.93      0.96      0.94       462

    accuracy                           0.92       656
   macro avg       0.92      0.89      0.90       656
weighted avg       0.92      0.92      0.92       656

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.31      0.50      0.38       194
           1       0.71      0.53      0.61       462

    accuracy                           0.52       656
   macro avg       0.51      0.51      0.49       656
weighted avg       0.59      0.52      0.54       656

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3078 - acc: 0.8752 - auc-prc: 0.9393 - auc-roc: 0.9414 - val_loss: 0.3451 - val_acc: 0.8702 - val_auc-prc: 0.9323 - val_auc-roc: 0.9370 - 13s/epoch - 69ms/step
Epoch 2/100
185/185 - 11s - loss: 0.2781 - acc: 0.8909 - auc-prc: 0.9494 - auc-roc: 0.9513 - val_loss: 0.3006 - val_acc: 0.8748 - val_auc-prc: 0.9433 - val_auc-roc: 0.9452 - 11s/epoch - 57ms/step
Epoch 3/100
185/185 - 10s - loss: 0.2643 - acc: 0.8993 - auc-prc: 0.9545 - auc-roc: 0.9562 - val_loss: 0.3302 - val_acc: 0.8458 - val_auc-prc: 0.9339 - val_auc-roc: 0.9343 - 10s/epoch - 56ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2633 - acc: 0.8960 - auc-prc: 0.9554 - auc-roc: 0.9568 - val_loss: 0.3027 - val_acc: 0.8718 - val_auc-prc: 0.9450 - val_auc-roc: 0.9461 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 11s - loss: 0.2573 - acc: 0.8996 - auc-prc: 0.9574 - auc-roc: 0.9585 - val_loss: 0.2826 - val_acc: 0.8870 - val_auc-prc: 0.9509 - val_auc-roc: 0.9517 - 11s/epoch - 57ms/step
Epoch 6/100
185/185 - 11s - loss: 0.2532 - acc: 0.9001 - auc-prc: 0.9592 - auc-roc: 0.9601 - val_loss: 0.2737 - val_acc: 0.8840 - val_auc-prc: 0.9540 - val_auc-roc: 0.9551 - 11s/epoch - 58ms/step
Epoch 7/100
185/185 - 11s - loss: 0.2471 - acc: 0.9035 - auc-prc: 0.9612 - auc-roc: 0.9621 - val_loss: 0.2874 - val_acc: 0.8885 - val_auc-prc: 0.9542 - val_auc-roc: 0.9553 - 11s/epoch - 58ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2461 - acc: 0.9020 - auc-prc: 0.9619 - auc-roc: 0.9624 - val_loss: 0.2722 - val_acc: 0.8901 - val_auc-prc: 0.9558 - val_auc-roc: 0.9567 - 10s/epoch - 57ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2415 - acc: 0.9076 - auc-prc: 0.9628 - auc-roc: 0.9637 - val_loss: 0.2628 - val_acc: 0.8870 - val_auc-prc: 0.9565 - val_auc-roc: 0.9583 - 10s/epoch - 52ms/step
Epoch 10/100
185/185 - 9s - loss: 0.2410 - acc: 0.9050 - auc-prc: 0.9635 - auc-roc: 0.9640 - val_loss: 0.2650 - val_acc: 0.8916 - val_auc-prc: 0.9568 - val_auc-roc: 0.9580 - 9s/epoch - 51ms/step
Epoch 11/100
185/185 - 10s - loss: 0.2381 - acc: 0.9054 - auc-prc: 0.9639 - auc-roc: 0.9649 - val_loss: 0.2732 - val_acc: 0.8855 - val_auc-prc: 0.9569 - val_auc-roc: 0.9587 - 10s/epoch - 52ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2415 - acc: 0.9040 - auc-prc: 0.9632 - auc-roc: 0.9641 - val_loss: 0.2771 - val_acc: 0.8870 - val_auc-prc: 0.9498 - val_auc-roc: 0.9544 - 10s/epoch - 52ms/step
Epoch 13/100
185/185 - 9s - loss: 0.2319 - acc: 0.9064 - auc-prc: 0.9661 - auc-roc: 0.9668 - val_loss: 0.2659 - val_acc: 0.8840 - val_auc-prc: 0.9562 - val_auc-roc: 0.9576 - 9s/epoch - 51ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2311 - acc: 0.9082 - auc-prc: 0.9658 - auc-roc: 0.9666 - val_loss: 0.2732 - val_acc: 0.8870 - val_auc-prc: 0.9543 - val_auc-roc: 0.9573 - 10s/epoch - 53ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2272 - acc: 0.9081 - auc-prc: 0.9680 - auc-roc: 0.9685 - val_loss: 0.2589 - val_acc: 0.8901 - val_auc-prc: 0.9565 - val_auc-roc: 0.9592 - 10s/epoch - 51ms/step
Epoch 16/100
185/185 - 10s - loss: 0.2240 - acc: 0.9123 - auc-prc: 0.9683 - auc-roc: 0.9686 - val_loss: 0.2843 - val_acc: 0.8824 - val_auc-prc: 0.9496 - val_auc-roc: 0.9526 - 10s/epoch - 52ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2240 - acc: 0.9145 - auc-prc: 0.9682 - auc-roc: 0.9688 - val_loss: 0.2695 - val_acc: 0.8931 - val_auc-prc: 0.9554 - val_auc-roc: 0.9569 - 10s/epoch - 53ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2195 - acc: 0.9113 - auc-prc: 0.9699 - auc-roc: 0.9703 - val_loss: 0.2711 - val_acc: 0.8901 - val_auc-prc: 0.9523 - val_auc-roc: 0.9567 - 10s/epoch - 53ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2187 - acc: 0.9142 - auc-prc: 0.9705 - auc-roc: 0.9706 - val_loss: 0.2729 - val_acc: 0.8779 - val_auc-prc: 0.9552 - val_auc-roc: 0.9573 - 10s/epoch - 53ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2118 - acc: 0.9191 - auc-prc: 0.9717 - auc-roc: 0.9721 - val_loss: 0.2743 - val_acc: 0.8916 - val_auc-prc: 0.9550 - val_auc-roc: 0.9568 - 10s/epoch - 53ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2072 - acc: 0.9179 - auc-prc: 0.9733 - auc-roc: 0.9735 - val_loss: 0.2829 - val_acc: 0.8824 - val_auc-prc: 0.9535 - val_auc-roc: 0.9561 - 10s/epoch - 53ms/step
Epoch 22/100
185/185 - 10s - loss: 0.2070 - acc: 0.9198 - auc-prc: 0.9731 - auc-roc: 0.9733 - val_loss: 0.2854 - val_acc: 0.8901 - val_auc-prc: 0.9535 - val_auc-roc: 0.9550 - 10s/epoch - 53ms/step
Epoch 23/100
185/185 - 10s - loss: 0.1988 - acc: 0.9208 - auc-prc: 0.9754 - auc-roc: 0.9754 - val_loss: 0.2945 - val_acc: 0.8763 - val_auc-prc: 0.9490 - val_auc-roc: 0.9503 - 10s/epoch - 53ms/step
Early stopping epoch: 22
******Evaluating TEST set*********
21/21 - 1s - 566ms/epoch - 27ms/step
              precision    recall  f1-score   support

           0       0.85      0.76      0.80       193
           1       0.90      0.94      0.92       462

    accuracy                           0.89       655
   macro avg       0.88      0.85      0.86       655
weighted avg       0.89      0.89      0.89       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.26      0.46      0.33       193
           1       0.66      0.45      0.53       462

    accuracy                           0.45       655
   macro avg       0.46      0.45      0.43       655
weighted avg       0.54      0.45      0.47       655

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3161 - acc: 0.8731 - auc-prc: 0.9363 - auc-roc: 0.9381 - val_loss: 0.3509 - val_acc: 0.8733 - val_auc-prc: 0.9367 - val_auc-roc: 0.9389 - 13s/epoch - 71ms/step
Epoch 2/100
185/185 - 11s - loss: 0.2752 - acc: 0.8879 - auc-prc: 0.9517 - auc-roc: 0.9529 - val_loss: 0.2981 - val_acc: 0.8885 - val_auc-prc: 0.9448 - val_auc-roc: 0.9465 - 11s/epoch - 58ms/step
Epoch 3/100
185/185 - 11s - loss: 0.2669 - acc: 0.8960 - auc-prc: 0.9543 - auc-roc: 0.9556 - val_loss: 0.2688 - val_acc: 0.9023 - val_auc-prc: 0.9544 - val_auc-roc: 0.9550 - 11s/epoch - 58ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2575 - acc: 0.8982 - auc-prc: 0.9576 - auc-roc: 0.9588 - val_loss: 0.2719 - val_acc: 0.8855 - val_auc-prc: 0.9546 - val_auc-roc: 0.9551 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 10s - loss: 0.2526 - acc: 0.9030 - auc-prc: 0.9595 - auc-roc: 0.9603 - val_loss: 0.2662 - val_acc: 0.8916 - val_auc-prc: 0.9556 - val_auc-roc: 0.9560 - 10s/epoch - 53ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2532 - acc: 0.9016 - auc-prc: 0.9591 - auc-roc: 0.9600 - val_loss: 0.2932 - val_acc: 0.8702 - val_auc-prc: 0.9487 - val_auc-roc: 0.9483 - 10s/epoch - 53ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2479 - acc: 0.9021 - auc-prc: 0.9612 - auc-roc: 0.9619 - val_loss: 0.2736 - val_acc: 0.8870 - val_auc-prc: 0.9555 - val_auc-roc: 0.9558 - 10s/epoch - 53ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2401 - acc: 0.9054 - auc-prc: 0.9634 - auc-roc: 0.9643 - val_loss: 0.2691 - val_acc: 0.8824 - val_auc-prc: 0.9554 - val_auc-roc: 0.9558 - 10s/epoch - 53ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2391 - acc: 0.9069 - auc-prc: 0.9637 - auc-roc: 0.9648 - val_loss: 0.2706 - val_acc: 0.8977 - val_auc-prc: 0.9545 - val_auc-roc: 0.9558 - 10s/epoch - 52ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2390 - acc: 0.9055 - auc-prc: 0.9641 - auc-roc: 0.9649 - val_loss: 0.2672 - val_acc: 0.8977 - val_auc-prc: 0.9577 - val_auc-roc: 0.9578 - 10s/epoch - 53ms/step
Epoch 11/100
185/185 - 10s - loss: 0.2378 - acc: 0.9050 - auc-prc: 0.9644 - auc-roc: 0.9651 - val_loss: 0.2688 - val_acc: 0.9023 - val_auc-prc: 0.9556 - val_auc-roc: 0.9567 - 10s/epoch - 53ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2330 - acc: 0.9067 - auc-prc: 0.9656 - auc-roc: 0.9664 - val_loss: 0.2660 - val_acc: 0.8901 - val_auc-prc: 0.9542 - val_auc-roc: 0.9569 - 10s/epoch - 51ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2341 - acc: 0.9060 - auc-prc: 0.9656 - auc-roc: 0.9662 - val_loss: 0.2710 - val_acc: 0.8855 - val_auc-prc: 0.9553 - val_auc-roc: 0.9554 - 10s/epoch - 53ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2314 - acc: 0.9057 - auc-prc: 0.9665 - auc-roc: 0.9670 - val_loss: 0.2801 - val_acc: 0.8947 - val_auc-prc: 0.9552 - val_auc-roc: 0.9568 - 10s/epoch - 52ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2303 - acc: 0.9108 - auc-prc: 0.9664 - auc-roc: 0.9674 - val_loss: 0.2706 - val_acc: 0.8855 - val_auc-prc: 0.9547 - val_auc-roc: 0.9558 - 10s/epoch - 57ms/step
Epoch 16/100
185/185 - 11s - loss: 0.2307 - acc: 0.9099 - auc-prc: 0.9668 - auc-roc: 0.9672 - val_loss: 0.2774 - val_acc: 0.8840 - val_auc-prc: 0.9545 - val_auc-roc: 0.9542 - 11s/epoch - 57ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2234 - acc: 0.9104 - auc-prc: 0.9689 - auc-roc: 0.9692 - val_loss: 0.2722 - val_acc: 0.8947 - val_auc-prc: 0.9544 - val_auc-roc: 0.9554 - 10s/epoch - 54ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2191 - acc: 0.9130 - auc-prc: 0.9689 - auc-roc: 0.9702 - val_loss: 0.2765 - val_acc: 0.8947 - val_auc-prc: 0.9550 - val_auc-roc: 0.9556 - 10s/epoch - 53ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2213 - acc: 0.9130 - auc-prc: 0.9687 - auc-roc: 0.9695 - val_loss: 0.2687 - val_acc: 0.8885 - val_auc-prc: 0.9535 - val_auc-roc: 0.9554 - 10s/epoch - 53ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2183 - acc: 0.9125 - auc-prc: 0.9703 - auc-roc: 0.9705 - val_loss: 0.2590 - val_acc: 0.8947 - val_auc-prc: 0.9545 - val_auc-roc: 0.9580 - 10s/epoch - 53ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2172 - acc: 0.9113 - auc-prc: 0.9706 - auc-roc: 0.9709 - val_loss: 0.2794 - val_acc: 0.8824 - val_auc-prc: 0.9534 - val_auc-roc: 0.9557 - 10s/epoch - 52ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 590ms/epoch - 28ms/step
              precision    recall  f1-score   support

           0       0.86      0.77      0.81       193
           1       0.91      0.95      0.93       462

    accuracy                           0.89       655
   macro avg       0.88      0.86      0.87       655
weighted avg       0.89      0.89      0.89       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.29      0.50      0.36       193
           1       0.70      0.48      0.57       462

    accuracy                           0.49       655
   macro avg       0.49      0.49      0.47       655
weighted avg       0.58      0.49      0.51       655

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3153 - acc: 0.8716 - auc-prc: 0.9365 - auc-roc: 0.9383 - val_loss: 0.2881 - val_acc: 0.8763 - val_auc-prc: 0.9504 - val_auc-roc: 0.9508 - 13s/epoch - 71ms/step
Epoch 2/100
185/185 - 11s - loss: 0.2834 - acc: 0.8911 - auc-prc: 0.9472 - auc-roc: 0.9492 - val_loss: 0.2717 - val_acc: 0.8840 - val_auc-prc: 0.9555 - val_auc-roc: 0.9554 - 11s/epoch - 58ms/step
Epoch 3/100
185/185 - 11s - loss: 0.2700 - acc: 0.8989 - auc-prc: 0.9524 - auc-roc: 0.9538 - val_loss: 0.2506 - val_acc: 0.8977 - val_auc-prc: 0.9606 - val_auc-roc: 0.9615 - 11s/epoch - 58ms/step
Epoch 4/100
185/185 - 10s - loss: 0.2620 - acc: 0.8989 - auc-prc: 0.9557 - auc-roc: 0.9572 - val_loss: 0.2470 - val_acc: 0.8931 - val_auc-prc: 0.9620 - val_auc-roc: 0.9630 - 10s/epoch - 56ms/step
Epoch 5/100
185/185 - 10s - loss: 0.2605 - acc: 0.8976 - auc-prc: 0.9563 - auc-roc: 0.9574 - val_loss: 0.2461 - val_acc: 0.9038 - val_auc-prc: 0.9646 - val_auc-roc: 0.9643 - 10s/epoch - 54ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2538 - acc: 0.8994 - auc-prc: 0.9590 - auc-roc: 0.9601 - val_loss: 0.2382 - val_acc: 0.8992 - val_auc-prc: 0.9657 - val_auc-roc: 0.9659 - 10s/epoch - 53ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2512 - acc: 0.8994 - auc-prc: 0.9604 - auc-roc: 0.9610 - val_loss: 0.2384 - val_acc: 0.9038 - val_auc-prc: 0.9660 - val_auc-roc: 0.9663 - 10s/epoch - 53ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2491 - acc: 0.9023 - auc-prc: 0.9610 - auc-roc: 0.9616 - val_loss: 0.2368 - val_acc: 0.9038 - val_auc-prc: 0.9657 - val_auc-roc: 0.9660 - 10s/epoch - 52ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2461 - acc: 0.9026 - auc-prc: 0.9615 - auc-roc: 0.9624 - val_loss: 0.2438 - val_acc: 0.9053 - val_auc-prc: 0.9662 - val_auc-roc: 0.9660 - 10s/epoch - 53ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2419 - acc: 0.9040 - auc-prc: 0.9632 - auc-roc: 0.9638 - val_loss: 0.2371 - val_acc: 0.8977 - val_auc-prc: 0.9661 - val_auc-roc: 0.9663 - 10s/epoch - 54ms/step
Epoch 11/100
185/185 - 10s - loss: 0.2402 - acc: 0.9069 - auc-prc: 0.9635 - auc-roc: 0.9644 - val_loss: 0.2374 - val_acc: 0.9084 - val_auc-prc: 0.9667 - val_auc-roc: 0.9669 - 10s/epoch - 53ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2353 - acc: 0.9047 - auc-prc: 0.9655 - auc-roc: 0.9659 - val_loss: 0.2365 - val_acc: 0.9069 - val_auc-prc: 0.9662 - val_auc-roc: 0.9665 - 10s/epoch - 53ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2386 - acc: 0.9091 - auc-prc: 0.9633 - auc-roc: 0.9646 - val_loss: 0.2431 - val_acc: 0.8992 - val_auc-prc: 0.9636 - val_auc-roc: 0.9638 - 10s/epoch - 53ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2360 - acc: 0.9082 - auc-prc: 0.9650 - auc-roc: 0.9656 - val_loss: 0.2320 - val_acc: 0.9038 - val_auc-prc: 0.9664 - val_auc-roc: 0.9665 - 10s/epoch - 52ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2322 - acc: 0.9088 - auc-prc: 0.9666 - auc-roc: 0.9668 - val_loss: 0.2207 - val_acc: 0.9053 - val_auc-prc: 0.9700 - val_auc-roc: 0.9701 - 10s/epoch - 51ms/step
Epoch 16/100
185/185 - 10s - loss: 0.2293 - acc: 0.9111 - auc-prc: 0.9667 - auc-roc: 0.9675 - val_loss: 0.2231 - val_acc: 0.9145 - val_auc-prc: 0.9701 - val_auc-roc: 0.9702 - 10s/epoch - 53ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2310 - acc: 0.9091 - auc-prc: 0.9666 - auc-roc: 0.9671 - val_loss: 0.2319 - val_acc: 0.9038 - val_auc-prc: 0.9669 - val_auc-roc: 0.9670 - 10s/epoch - 53ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2231 - acc: 0.9130 - auc-prc: 0.9687 - auc-roc: 0.9693 - val_loss: 0.2306 - val_acc: 0.9069 - val_auc-prc: 0.9655 - val_auc-roc: 0.9665 - 10s/epoch - 53ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2256 - acc: 0.9133 - auc-prc: 0.9675 - auc-roc: 0.9685 - val_loss: 0.2619 - val_acc: 0.8824 - val_auc-prc: 0.9593 - val_auc-roc: 0.9583 - 10s/epoch - 55ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2233 - acc: 0.9108 - auc-prc: 0.9690 - auc-roc: 0.9693 - val_loss: 0.2215 - val_acc: 0.9115 - val_auc-prc: 0.9699 - val_auc-roc: 0.9700 - 10s/epoch - 53ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2238 - acc: 0.9145 - auc-prc: 0.9689 - auc-roc: 0.9692 - val_loss: 0.2612 - val_acc: 0.8885 - val_auc-prc: 0.9612 - val_auc-roc: 0.9615 - 10s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 593ms/epoch - 28ms/step
              precision    recall  f1-score   support

           0       0.90      0.80      0.85       193
           1       0.92      0.96      0.94       462

    accuracy                           0.91       655
   macro avg       0.91      0.88      0.89       655
weighted avg       0.91      0.91      0.91       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.28      0.48      0.35       193
           1       0.69      0.48      0.56       462

    accuracy                           0.48       655
   macro avg       0.48      0.48      0.46       655
weighted avg       0.57      0.48      0.50       655

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3228 - acc: 0.8680 - auc-prc: 0.9334 - auc-roc: 0.9353 - val_loss: 0.2579 - val_acc: 0.8977 - val_auc-prc: 0.9609 - val_auc-roc: 0.9611 - 13s/epoch - 72ms/step
Epoch 2/100
185/185 - 10s - loss: 0.2841 - acc: 0.8867 - auc-prc: 0.9484 - auc-roc: 0.9497 - val_loss: 0.2379 - val_acc: 0.9023 - val_auc-prc: 0.9639 - val_auc-roc: 0.9648 - 10s/epoch - 56ms/step
Epoch 3/100
185/185 - 10s - loss: 0.2759 - acc: 0.8909 - auc-prc: 0.9516 - auc-roc: 0.9527 - val_loss: 0.2347 - val_acc: 0.9084 - val_auc-prc: 0.9648 - val_auc-roc: 0.9655 - 10s/epoch - 55ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2638 - acc: 0.8943 - auc-prc: 0.9552 - auc-roc: 0.9567 - val_loss: 0.2378 - val_acc: 0.9084 - val_auc-prc: 0.9662 - val_auc-roc: 0.9660 - 11s/epoch - 62ms/step
Epoch 5/100
185/185 - 11s - loss: 0.2613 - acc: 0.8993 - auc-prc: 0.9567 - auc-roc: 0.9578 - val_loss: 0.2449 - val_acc: 0.9053 - val_auc-prc: 0.9662 - val_auc-roc: 0.9656 - 11s/epoch - 61ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2596 - acc: 0.8981 - auc-prc: 0.9570 - auc-roc: 0.9583 - val_loss: 0.2341 - val_acc: 0.9069 - val_auc-prc: 0.9660 - val_auc-roc: 0.9659 - 10s/epoch - 55ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2536 - acc: 0.9003 - auc-prc: 0.9591 - auc-roc: 0.9602 - val_loss: 0.2321 - val_acc: 0.9145 - val_auc-prc: 0.9681 - val_auc-roc: 0.9675 - 10s/epoch - 57ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2509 - acc: 0.9015 - auc-prc: 0.9592 - auc-roc: 0.9606 - val_loss: 0.2302 - val_acc: 0.9145 - val_auc-prc: 0.9691 - val_auc-roc: 0.9686 - 10s/epoch - 57ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2461 - acc: 0.9040 - auc-prc: 0.9609 - auc-roc: 0.9624 - val_loss: 0.2319 - val_acc: 0.9130 - val_auc-prc: 0.9687 - val_auc-roc: 0.9682 - 10s/epoch - 56ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2414 - acc: 0.9035 - auc-prc: 0.9627 - auc-roc: 0.9640 - val_loss: 0.2343 - val_acc: 0.9130 - val_auc-prc: 0.9669 - val_auc-roc: 0.9666 - 10s/epoch - 56ms/step
Epoch 11/100
185/185 - 10s - loss: 0.2461 - acc: 0.9049 - auc-prc: 0.9619 - auc-roc: 0.9624 - val_loss: 0.2407 - val_acc: 0.9023 - val_auc-prc: 0.9664 - val_auc-roc: 0.9654 - 10s/epoch - 55ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2381 - acc: 0.9079 - auc-prc: 0.9634 - auc-roc: 0.9647 - val_loss: 0.2305 - val_acc: 0.9084 - val_auc-prc: 0.9694 - val_auc-roc: 0.9687 - 10s/epoch - 57ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2344 - acc: 0.9069 - auc-prc: 0.9652 - auc-roc: 0.9660 - val_loss: 0.2303 - val_acc: 0.9099 - val_auc-prc: 0.9686 - val_auc-roc: 0.9679 - 10s/epoch - 56ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2342 - acc: 0.9108 - auc-prc: 0.9654 - auc-roc: 0.9661 - val_loss: 0.2315 - val_acc: 0.9084 - val_auc-prc: 0.9680 - val_auc-roc: 0.9677 - 10s/epoch - 56ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2289 - acc: 0.9103 - auc-prc: 0.9670 - auc-roc: 0.9675 - val_loss: 0.2373 - val_acc: 0.9008 - val_auc-prc: 0.9660 - val_auc-roc: 0.9659 - 10s/epoch - 54ms/step
Epoch 16/100
185/185 - 11s - loss: 0.2265 - acc: 0.9094 - auc-prc: 0.9668 - auc-roc: 0.9680 - val_loss: 0.2282 - val_acc: 0.9084 - val_auc-prc: 0.9680 - val_auc-roc: 0.9687 - 11s/epoch - 57ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2270 - acc: 0.9089 - auc-prc: 0.9672 - auc-roc: 0.9681 - val_loss: 0.2395 - val_acc: 0.8870 - val_auc-prc: 0.9657 - val_auc-roc: 0.9652 - 10s/epoch - 56ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2236 - acc: 0.9125 - auc-prc: 0.9677 - auc-roc: 0.9687 - val_loss: 0.2479 - val_acc: 0.8901 - val_auc-prc: 0.9637 - val_auc-roc: 0.9630 - 10s/epoch - 56ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2203 - acc: 0.9140 - auc-prc: 0.9685 - auc-roc: 0.9695 - val_loss: 0.2346 - val_acc: 0.8916 - val_auc-prc: 0.9680 - val_auc-roc: 0.9673 - 10s/epoch - 56ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2217 - acc: 0.9140 - auc-prc: 0.9684 - auc-roc: 0.9695 - val_loss: 0.2366 - val_acc: 0.9069 - val_auc-prc: 0.9683 - val_auc-roc: 0.9679 - 10s/epoch - 55ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2119 - acc: 0.9130 - auc-prc: 0.9718 - auc-roc: 0.9722 - val_loss: 0.2506 - val_acc: 0.8931 - val_auc-prc: 0.9635 - val_auc-roc: 0.9625 - 10s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 611ms/epoch - 29ms/step
              precision    recall  f1-score   support

           0       0.87      0.81      0.84       193
           1       0.92      0.95      0.94       462

    accuracy                           0.91       655
   macro avg       0.90      0.88      0.89       655
weighted avg       0.91      0.91      0.91       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.27      0.45      0.34       193
           1       0.68      0.49      0.57       462

    accuracy                           0.48       655
   macro avg       0.48      0.47      0.46       655
weighted avg       0.56      0.48      0.50       655

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3185 - acc: 0.8669 - auc-prc: 0.9342 - auc-roc: 0.9368 - val_loss: 0.2721 - val_acc: 0.8992 - val_auc-prc: 0.9530 - val_auc-roc: 0.9542 - 13s/epoch - 68ms/step
Epoch 2/100
185/185 - 11s - loss: 0.2850 - acc: 0.8872 - auc-prc: 0.9469 - auc-roc: 0.9495 - val_loss: 0.2559 - val_acc: 0.9053 - val_auc-prc: 0.9564 - val_auc-roc: 0.9586 - 11s/epoch - 57ms/step
Epoch 3/100
185/185 - 10s - loss: 0.2689 - acc: 0.8908 - auc-prc: 0.9540 - auc-roc: 0.9552 - val_loss: 0.2709 - val_acc: 0.8824 - val_auc-prc: 0.9542 - val_auc-roc: 0.9548 - 10s/epoch - 56ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2668 - acc: 0.8945 - auc-prc: 0.9546 - auc-roc: 0.9559 - val_loss: 0.2482 - val_acc: 0.9084 - val_auc-prc: 0.9608 - val_auc-roc: 0.9622 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 11s - loss: 0.2566 - acc: 0.9008 - auc-prc: 0.9579 - auc-roc: 0.9589 - val_loss: 0.2375 - val_acc: 0.9053 - val_auc-prc: 0.9626 - val_auc-roc: 0.9638 - 11s/epoch - 57ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2563 - acc: 0.8989 - auc-prc: 0.9592 - auc-roc: 0.9595 - val_loss: 0.2421 - val_acc: 0.9023 - val_auc-prc: 0.9635 - val_auc-roc: 0.9639 - 10s/epoch - 57ms/step
Epoch 7/100
185/185 - 11s - loss: 0.2483 - acc: 0.9015 - auc-prc: 0.9610 - auc-roc: 0.9619 - val_loss: 0.2399 - val_acc: 0.9038 - val_auc-prc: 0.9648 - val_auc-roc: 0.9646 - 11s/epoch - 57ms/step
Epoch 8/100
185/185 - 11s - loss: 0.2478 - acc: 0.9025 - auc-prc: 0.9611 - auc-roc: 0.9621 - val_loss: 0.2370 - val_acc: 0.9145 - val_auc-prc: 0.9659 - val_auc-roc: 0.9659 - 11s/epoch - 57ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2446 - acc: 0.9033 - auc-prc: 0.9621 - auc-roc: 0.9630 - val_loss: 0.2443 - val_acc: 0.9053 - val_auc-prc: 0.9632 - val_auc-roc: 0.9633 - 10s/epoch - 56ms/step
Epoch 10/100
185/185 - 11s - loss: 0.2498 - acc: 0.9018 - auc-prc: 0.9598 - auc-roc: 0.9613 - val_loss: 0.2301 - val_acc: 0.9145 - val_auc-prc: 0.9665 - val_auc-roc: 0.9667 - 11s/epoch - 58ms/step
Epoch 11/100
185/185 - 11s - loss: 0.2392 - acc: 0.9059 - auc-prc: 0.9635 - auc-roc: 0.9646 - val_loss: 0.2269 - val_acc: 0.9160 - val_auc-prc: 0.9685 - val_auc-roc: 0.9680 - 11s/epoch - 59ms/step
Epoch 12/100
185/185 - 11s - loss: 0.2434 - acc: 0.9016 - auc-prc: 0.9624 - auc-roc: 0.9636 - val_loss: 0.2257 - val_acc: 0.9130 - val_auc-prc: 0.9673 - val_auc-roc: 0.9679 - 11s/epoch - 58ms/step
Epoch 13/100
185/185 - 11s - loss: 0.2413 - acc: 0.9035 - auc-prc: 0.9634 - auc-roc: 0.9641 - val_loss: 0.2245 - val_acc: 0.9206 - val_auc-prc: 0.9687 - val_auc-roc: 0.9689 - 11s/epoch - 58ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2364 - acc: 0.9072 - auc-prc: 0.9649 - auc-roc: 0.9655 - val_loss: 0.2166 - val_acc: 0.9145 - val_auc-prc: 0.9712 - val_auc-roc: 0.9708 - 10s/epoch - 55ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2365 - acc: 0.9067 - auc-prc: 0.9648 - auc-roc: 0.9653 - val_loss: 0.2259 - val_acc: 0.9206 - val_auc-prc: 0.9694 - val_auc-roc: 0.9693 - 10s/epoch - 53ms/step
Epoch 16/100
185/185 - 10s - loss: 0.2301 - acc: 0.9084 - auc-prc: 0.9671 - auc-roc: 0.9674 - val_loss: 0.2167 - val_acc: 0.9176 - val_auc-prc: 0.9707 - val_auc-roc: 0.9706 - 10s/epoch - 57ms/step
Epoch 17/100
185/185 - 11s - loss: 0.2334 - acc: 0.9045 - auc-prc: 0.9660 - auc-roc: 0.9665 - val_loss: 0.2225 - val_acc: 0.9099 - val_auc-prc: 0.9692 - val_auc-roc: 0.9690 - 11s/epoch - 57ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2301 - acc: 0.9084 - auc-prc: 0.9669 - auc-roc: 0.9673 - val_loss: 0.2199 - val_acc: 0.9206 - val_auc-prc: 0.9708 - val_auc-roc: 0.9703 - 10s/epoch - 56ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2253 - acc: 0.9098 - auc-prc: 0.9679 - auc-roc: 0.9686 - val_loss: 0.2250 - val_acc: 0.9099 - val_auc-prc: 0.9694 - val_auc-roc: 0.9688 - 10s/epoch - 55ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2251 - acc: 0.9106 - auc-prc: 0.9680 - auc-roc: 0.9688 - val_loss: 0.2263 - val_acc: 0.9191 - val_auc-prc: 0.9688 - val_auc-roc: 0.9683 - 10s/epoch - 56ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2201 - acc: 0.9101 - auc-prc: 0.9697 - auc-roc: 0.9702 - val_loss: 0.2214 - val_acc: 0.9115 - val_auc-prc: 0.9706 - val_auc-roc: 0.9700 - 10s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 614ms/epoch - 29ms/step
              precision    recall  f1-score   support

           0       0.91      0.79      0.85       193
           1       0.92      0.97      0.94       462

    accuracy                           0.91       655
   macro avg       0.91      0.88      0.89       655
weighted avg       0.91      0.91      0.91       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.27      0.44      0.34       193
           1       0.69      0.51      0.58       462

    accuracy                           0.49       655
   macro avg       0.48      0.47      0.46       655
weighted avg       0.56      0.49      0.51       655

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3174 - acc: 0.8701 - auc-prc: 0.9363 - auc-roc: 0.9375 - val_loss: 0.2614 - val_acc: 0.8931 - val_auc-prc: 0.9589 - val_auc-roc: 0.9586 - 13s/epoch - 69ms/step
Epoch 2/100
185/185 - 10s - loss: 0.2753 - acc: 0.8908 - auc-prc: 0.9515 - auc-roc: 0.9529 - val_loss: 0.2564 - val_acc: 0.9023 - val_auc-prc: 0.9597 - val_auc-roc: 0.9597 - 10s/epoch - 55ms/step
Epoch 3/100
185/185 - 10s - loss: 0.2666 - acc: 0.8931 - auc-prc: 0.9542 - auc-roc: 0.9558 - val_loss: 0.2467 - val_acc: 0.9099 - val_auc-prc: 0.9611 - val_auc-roc: 0.9617 - 10s/epoch - 56ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2644 - acc: 0.8996 - auc-prc: 0.9555 - auc-roc: 0.9564 - val_loss: 0.2476 - val_acc: 0.9130 - val_auc-prc: 0.9614 - val_auc-roc: 0.9619 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 11s - loss: 0.2556 - acc: 0.8986 - auc-prc: 0.9582 - auc-roc: 0.9593 - val_loss: 0.2667 - val_acc: 0.8931 - val_auc-prc: 0.9550 - val_auc-roc: 0.9564 - 11s/epoch - 57ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2586 - acc: 0.8964 - auc-prc: 0.9577 - auc-roc: 0.9586 - val_loss: 0.2510 - val_acc: 0.9145 - val_auc-prc: 0.9614 - val_auc-roc: 0.9615 - 10s/epoch - 56ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2514 - acc: 0.8987 - auc-prc: 0.9611 - auc-roc: 0.9612 - val_loss: 0.2404 - val_acc: 0.9069 - val_auc-prc: 0.9632 - val_auc-roc: 0.9639 - 10s/epoch - 52ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2480 - acc: 0.9009 - auc-prc: 0.9610 - auc-roc: 0.9620 - val_loss: 0.2472 - val_acc: 0.8992 - val_auc-prc: 0.9620 - val_auc-roc: 0.9621 - 10s/epoch - 55ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2441 - acc: 0.9042 - auc-prc: 0.9623 - auc-roc: 0.9631 - val_loss: 0.2491 - val_acc: 0.9084 - val_auc-prc: 0.9617 - val_auc-roc: 0.9616 - 10s/epoch - 56ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2425 - acc: 0.9030 - auc-prc: 0.9632 - auc-roc: 0.9637 - val_loss: 0.2462 - val_acc: 0.9099 - val_auc-prc: 0.9634 - val_auc-roc: 0.9634 - 10s/epoch - 57ms/step
Epoch 11/100
185/185 - 11s - loss: 0.2403 - acc: 0.9064 - auc-prc: 0.9640 - auc-roc: 0.9644 - val_loss: 0.2358 - val_acc: 0.8992 - val_auc-prc: 0.9664 - val_auc-roc: 0.9660 - 11s/epoch - 57ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2361 - acc: 0.9093 - auc-prc: 0.9647 - auc-roc: 0.9654 - val_loss: 0.2352 - val_acc: 0.9084 - val_auc-prc: 0.9654 - val_auc-roc: 0.9656 - 10s/epoch - 56ms/step
Epoch 13/100
185/185 - 11s - loss: 0.2368 - acc: 0.9081 - auc-prc: 0.9654 - auc-roc: 0.9655 - val_loss: 0.2326 - val_acc: 0.9069 - val_auc-prc: 0.9676 - val_auc-roc: 0.9676 - 11s/epoch - 57ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2316 - acc: 0.9110 - auc-prc: 0.9661 - auc-roc: 0.9666 - val_loss: 0.2478 - val_acc: 0.9023 - val_auc-prc: 0.9628 - val_auc-roc: 0.9631 - 10s/epoch - 55ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2341 - acc: 0.9086 - auc-prc: 0.9655 - auc-roc: 0.9660 - val_loss: 0.2371 - val_acc: 0.9069 - val_auc-prc: 0.9655 - val_auc-roc: 0.9660 - 10s/epoch - 56ms/step
Epoch 16/100
185/185 - 10s - loss: 0.2313 - acc: 0.9099 - auc-prc: 0.9661 - auc-roc: 0.9669 - val_loss: 0.2465 - val_acc: 0.9008 - val_auc-prc: 0.9632 - val_auc-roc: 0.9637 - 10s/epoch - 55ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2269 - acc: 0.9138 - auc-prc: 0.9675 - auc-roc: 0.9679 - val_loss: 0.2456 - val_acc: 0.9053 - val_auc-prc: 0.9630 - val_auc-roc: 0.9635 - 10s/epoch - 56ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2239 - acc: 0.9137 - auc-prc: 0.9680 - auc-roc: 0.9688 - val_loss: 0.2451 - val_acc: 0.9038 - val_auc-prc: 0.9646 - val_auc-roc: 0.9649 - 10s/epoch - 57ms/step
Epoch 19/100
185/185 - 11s - loss: 0.2280 - acc: 0.9088 - auc-prc: 0.9680 - auc-roc: 0.9679 - val_loss: 0.2307 - val_acc: 0.9084 - val_auc-prc: 0.9685 - val_auc-roc: 0.9683 - 11s/epoch - 57ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2242 - acc: 0.9121 - auc-prc: 0.9690 - auc-roc: 0.9689 - val_loss: 0.2482 - val_acc: 0.9053 - val_auc-prc: 0.9649 - val_auc-roc: 0.9646 - 10s/epoch - 57ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2173 - acc: 0.9167 - auc-prc: 0.9700 - auc-roc: 0.9704 - val_loss: 0.2732 - val_acc: 0.8992 - val_auc-prc: 0.9551 - val_auc-roc: 0.9571 - 10s/epoch - 55ms/step
Epoch 22/100
185/185 - 11s - loss: 0.2168 - acc: 0.9167 - auc-prc: 0.9703 - auc-roc: 0.9707 - val_loss: 0.2435 - val_acc: 0.8977 - val_auc-prc: 0.9638 - val_auc-roc: 0.9653 - 11s/epoch - 57ms/step
Epoch 23/100
185/185 - 11s - loss: 0.2133 - acc: 0.9162 - auc-prc: 0.9713 - auc-roc: 0.9717 - val_loss: 0.2428 - val_acc: 0.8931 - val_auc-prc: 0.9653 - val_auc-roc: 0.9651 - 11s/epoch - 57ms/step
Epoch 24/100
185/185 - 11s - loss: 0.2092 - acc: 0.9225 - auc-prc: 0.9724 - auc-roc: 0.9726 - val_loss: 0.2331 - val_acc: 0.8992 - val_auc-prc: 0.9669 - val_auc-roc: 0.9669 - 11s/epoch - 57ms/step
Epoch 25/100
185/185 - 10s - loss: 0.2046 - acc: 0.9215 - auc-prc: 0.9734 - auc-roc: 0.9738 - val_loss: 0.2418 - val_acc: 0.9008 - val_auc-prc: 0.9661 - val_auc-roc: 0.9669 - 10s/epoch - 57ms/step
Early stopping epoch: 24
******Evaluating TEST set*********
21/21 - 1s - 605ms/epoch - 29ms/step
              precision    recall  f1-score   support

           0       0.90      0.78      0.83       193
           1       0.91      0.96      0.94       462

    accuracy                           0.91       655
   macro avg       0.91      0.87      0.89       655
weighted avg       0.91      0.91      0.91       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.28      0.46      0.35       193
           1       0.69      0.51      0.58       462

    accuracy                           0.49       655
   macro avg       0.49      0.48      0.47       655
weighted avg       0.57      0.49      0.52       655

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3141 - acc: 0.8714 - auc-prc: 0.9372 - auc-roc: 0.9391 - val_loss: 0.2988 - val_acc: 0.8824 - val_auc-prc: 0.9452 - val_auc-roc: 0.9450 - 13s/epoch - 71ms/step
Epoch 2/100
185/185 - 11s - loss: 0.2774 - acc: 0.8894 - auc-prc: 0.9507 - auc-roc: 0.9522 - val_loss: 0.2715 - val_acc: 0.8870 - val_auc-prc: 0.9560 - val_auc-roc: 0.9559 - 11s/epoch - 57ms/step
Epoch 3/100
185/185 - 11s - loss: 0.2736 - acc: 0.8908 - auc-prc: 0.9512 - auc-roc: 0.9531 - val_loss: 0.2662 - val_acc: 0.8947 - val_auc-prc: 0.9569 - val_auc-roc: 0.9566 - 11s/epoch - 57ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2662 - acc: 0.8962 - auc-prc: 0.9541 - auc-roc: 0.9552 - val_loss: 0.2529 - val_acc: 0.8931 - val_auc-prc: 0.9602 - val_auc-roc: 0.9609 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 10s - loss: 0.2591 - acc: 0.8993 - auc-prc: 0.9566 - auc-roc: 0.9579 - val_loss: 0.2635 - val_acc: 0.8870 - val_auc-prc: 0.9598 - val_auc-roc: 0.9607 - 10s/epoch - 56ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2583 - acc: 0.8989 - auc-prc: 0.9573 - auc-roc: 0.9585 - val_loss: 0.2776 - val_acc: 0.8916 - val_auc-prc: 0.9521 - val_auc-roc: 0.9538 - 10s/epoch - 52ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2539 - acc: 0.8993 - auc-prc: 0.9587 - auc-roc: 0.9598 - val_loss: 0.2543 - val_acc: 0.9023 - val_auc-prc: 0.9586 - val_auc-roc: 0.9598 - 10s/epoch - 56ms/step
Epoch 8/100
185/185 - 11s - loss: 0.2491 - acc: 0.9021 - auc-prc: 0.9604 - auc-roc: 0.9615 - val_loss: 0.2499 - val_acc: 0.9069 - val_auc-prc: 0.9600 - val_auc-roc: 0.9614 - 11s/epoch - 57ms/step
Epoch 9/100
185/185 - 11s - loss: 0.2442 - acc: 0.9054 - auc-prc: 0.9624 - auc-roc: 0.9630 - val_loss: 0.2510 - val_acc: 0.8885 - val_auc-prc: 0.9639 - val_auc-roc: 0.9655 - 11s/epoch - 57ms/step
Epoch 10/100
185/185 - 11s - loss: 0.2434 - acc: 0.9021 - auc-prc: 0.9634 - auc-roc: 0.9635 - val_loss: 0.2359 - val_acc: 0.8977 - val_auc-prc: 0.9656 - val_auc-roc: 0.9665 - 11s/epoch - 57ms/step
Epoch 11/100
185/185 - 10s - loss: 0.2390 - acc: 0.9062 - auc-prc: 0.9638 - auc-roc: 0.9647 - val_loss: 0.2474 - val_acc: 0.9038 - val_auc-prc: 0.9613 - val_auc-roc: 0.9622 - 10s/epoch - 57ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2356 - acc: 0.9064 - auc-prc: 0.9659 - auc-roc: 0.9659 - val_loss: 0.2418 - val_acc: 0.8901 - val_auc-prc: 0.9644 - val_auc-roc: 0.9648 - 10s/epoch - 56ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2373 - acc: 0.9098 - auc-prc: 0.9639 - auc-roc: 0.9649 - val_loss: 0.2633 - val_acc: 0.8809 - val_auc-prc: 0.9573 - val_auc-roc: 0.9601 - 10s/epoch - 56ms/step
Epoch 14/100
185/185 - 11s - loss: 0.2324 - acc: 0.9106 - auc-prc: 0.9662 - auc-roc: 0.9666 - val_loss: 0.2861 - val_acc: 0.8794 - val_auc-prc: 0.9571 - val_auc-roc: 0.9590 - 11s/epoch - 57ms/step
Epoch 15/100
185/185 - 14s - loss: 0.2317 - acc: 0.9082 - auc-prc: 0.9670 - auc-roc: 0.9672 - val_loss: 0.2335 - val_acc: 0.9069 - val_auc-prc: 0.9659 - val_auc-roc: 0.9665 - 14s/epoch - 77ms/step
Epoch 16/100
185/185 - 11s - loss: 0.2294 - acc: 0.9082 - auc-prc: 0.9674 - auc-roc: 0.9675 - val_loss: 0.2469 - val_acc: 0.8855 - val_auc-prc: 0.9622 - val_auc-roc: 0.9642 - 11s/epoch - 58ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2287 - acc: 0.9086 - auc-prc: 0.9675 - auc-roc: 0.9678 - val_loss: 0.2355 - val_acc: 0.9038 - val_auc-prc: 0.9641 - val_auc-roc: 0.9661 - 10s/epoch - 55ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2262 - acc: 0.9142 - auc-prc: 0.9678 - auc-roc: 0.9682 - val_loss: 0.2317 - val_acc: 0.9069 - val_auc-prc: 0.9665 - val_auc-roc: 0.9669 - 10s/epoch - 56ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2211 - acc: 0.9110 - auc-prc: 0.9695 - auc-roc: 0.9698 - val_loss: 0.2348 - val_acc: 0.9038 - val_auc-prc: 0.9665 - val_auc-roc: 0.9665 - 10s/epoch - 55ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2206 - acc: 0.9121 - auc-prc: 0.9704 - auc-roc: 0.9701 - val_loss: 0.2547 - val_acc: 0.8885 - val_auc-prc: 0.9614 - val_auc-roc: 0.9615 - 10s/epoch - 54ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2176 - acc: 0.9164 - auc-prc: 0.9705 - auc-roc: 0.9707 - val_loss: 0.2475 - val_acc: 0.8901 - val_auc-prc: 0.9654 - val_auc-roc: 0.9666 - 10s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 1s/epoch - 63ms/step
              precision    recall  f1-score   support

           0       0.88      0.79      0.83       193
           1       0.92      0.96      0.94       462

    accuracy                           0.91       655
   macro avg       0.90      0.87      0.88       655
weighted avg       0.91      0.91      0.91       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.30      0.54      0.38       193
           1       0.71      0.47      0.57       462

    accuracy                           0.49       655
   macro avg       0.50      0.51      0.48       655
weighted avg       0.59      0.49      0.51       655

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3119 - acc: 0.8713 - auc-prc: 0.9383 - auc-roc: 0.9394 - val_loss: 0.3258 - val_acc: 0.8611 - val_auc-prc: 0.9307 - val_auc-roc: 0.9348 - 13s/epoch - 68ms/step
Epoch 2/100
185/185 - 10s - loss: 0.2785 - acc: 0.8908 - auc-prc: 0.9499 - auc-roc: 0.9514 - val_loss: 0.3183 - val_acc: 0.8763 - val_auc-prc: 0.9357 - val_auc-roc: 0.9389 - 10s/epoch - 54ms/step
Epoch 3/100
185/185 - 10s - loss: 0.2673 - acc: 0.8940 - auc-prc: 0.9539 - auc-roc: 0.9551 - val_loss: 0.3163 - val_acc: 0.8779 - val_auc-prc: 0.9384 - val_auc-roc: 0.9417 - 10s/epoch - 57ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2588 - acc: 0.8972 - auc-prc: 0.9578 - auc-roc: 0.9585 - val_loss: 0.3103 - val_acc: 0.8748 - val_auc-prc: 0.9410 - val_auc-roc: 0.9427 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 10s - loss: 0.2507 - acc: 0.9021 - auc-prc: 0.9595 - auc-roc: 0.9606 - val_loss: 0.2993 - val_acc: 0.8855 - val_auc-prc: 0.9427 - val_auc-roc: 0.9459 - 10s/epoch - 57ms/step
Epoch 6/100
185/185 - 10s - loss: 0.2513 - acc: 0.9047 - auc-prc: 0.9595 - auc-roc: 0.9604 - val_loss: 0.3107 - val_acc: 0.8855 - val_auc-prc: 0.9410 - val_auc-roc: 0.9434 - 10s/epoch - 56ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2443 - acc: 0.9030 - auc-prc: 0.9628 - auc-roc: 0.9632 - val_loss: 0.3198 - val_acc: 0.8794 - val_auc-prc: 0.9401 - val_auc-roc: 0.9424 - 10s/epoch - 56ms/step
Epoch 8/100
185/185 - 10s - loss: 0.2417 - acc: 0.9030 - auc-prc: 0.9637 - auc-roc: 0.9641 - val_loss: 0.2986 - val_acc: 0.8824 - val_auc-prc: 0.9411 - val_auc-roc: 0.9448 - 10s/epoch - 55ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2398 - acc: 0.9060 - auc-prc: 0.9636 - auc-roc: 0.9641 - val_loss: 0.3332 - val_acc: 0.8718 - val_auc-prc: 0.9386 - val_auc-roc: 0.9403 - 10s/epoch - 56ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2345 - acc: 0.9074 - auc-prc: 0.9652 - auc-roc: 0.9660 - val_loss: 0.2955 - val_acc: 0.8870 - val_auc-prc: 0.9421 - val_auc-roc: 0.9457 - 10s/epoch - 56ms/step
Epoch 11/100
185/185 - 11s - loss: 0.2351 - acc: 0.9071 - auc-prc: 0.9652 - auc-roc: 0.9657 - val_loss: 0.2926 - val_acc: 0.8855 - val_auc-prc: 0.9455 - val_auc-roc: 0.9482 - 11s/epoch - 57ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2323 - acc: 0.9081 - auc-prc: 0.9664 - auc-roc: 0.9668 - val_loss: 0.2936 - val_acc: 0.8824 - val_auc-prc: 0.9419 - val_auc-roc: 0.9460 - 10s/epoch - 57ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2384 - acc: 0.9057 - auc-prc: 0.9643 - auc-roc: 0.9649 - val_loss: 0.2960 - val_acc: 0.8840 - val_auc-prc: 0.9476 - val_auc-roc: 0.9473 - 10s/epoch - 56ms/step
Epoch 14/100
185/185 - 11s - loss: 0.2478 - acc: 0.9021 - auc-prc: 0.9609 - auc-roc: 0.9621 - val_loss: 0.2932 - val_acc: 0.8855 - val_auc-prc: 0.9476 - val_auc-roc: 0.9484 - 11s/epoch - 57ms/step
Epoch 15/100
185/185 - 11s - loss: 0.2370 - acc: 0.9055 - auc-prc: 0.9646 - auc-roc: 0.9651 - val_loss: 0.2974 - val_acc: 0.8992 - val_auc-prc: 0.9475 - val_auc-roc: 0.9496 - 11s/epoch - 57ms/step
Epoch 16/100
185/185 - 11s - loss: 0.2282 - acc: 0.9094 - auc-prc: 0.9673 - auc-roc: 0.9678 - val_loss: 0.2857 - val_acc: 0.8824 - val_auc-prc: 0.9499 - val_auc-roc: 0.9509 - 11s/epoch - 57ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2322 - acc: 0.9059 - auc-prc: 0.9661 - auc-roc: 0.9667 - val_loss: 0.2822 - val_acc: 0.8916 - val_auc-prc: 0.9487 - val_auc-roc: 0.9505 - 10s/epoch - 56ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2258 - acc: 0.9089 - auc-prc: 0.9682 - auc-roc: 0.9686 - val_loss: 0.3022 - val_acc: 0.8947 - val_auc-prc: 0.9439 - val_auc-roc: 0.9469 - 10s/epoch - 57ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2219 - acc: 0.9121 - auc-prc: 0.9698 - auc-roc: 0.9698 - val_loss: 0.2962 - val_acc: 0.8931 - val_auc-prc: 0.9454 - val_auc-roc: 0.9493 - 10s/epoch - 56ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2215 - acc: 0.9147 - auc-prc: 0.9691 - auc-roc: 0.9695 - val_loss: 0.3082 - val_acc: 0.8916 - val_auc-prc: 0.9422 - val_auc-roc: 0.9455 - 10s/epoch - 57ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2165 - acc: 0.9132 - auc-prc: 0.9706 - auc-roc: 0.9710 - val_loss: 0.3404 - val_acc: 0.8840 - val_auc-prc: 0.9403 - val_auc-roc: 0.9441 - 10s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
21/21 - 1s - 603ms/epoch - 29ms/step
              precision    recall  f1-score   support

           0       0.87      0.70      0.78       193
           1       0.89      0.96      0.92       462

    accuracy                           0.88       655
   macro avg       0.88      0.83      0.85       655
weighted avg       0.88      0.88      0.88       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.26      0.46      0.34       193
           1       0.67      0.47      0.55       462

    accuracy                           0.46       655
   macro avg       0.47      0.46      0.44       655
weighted avg       0.55      0.46      0.49       655

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
185/185 - 13s - loss: 0.3174 - acc: 0.8703 - auc-prc: 0.9346 - auc-roc: 0.9372 - val_loss: 0.2564 - val_acc: 0.8947 - val_auc-prc: 0.9621 - val_auc-roc: 0.9624 - 13s/epoch - 72ms/step
Epoch 2/100
185/185 - 11s - loss: 0.2804 - acc: 0.8881 - auc-prc: 0.9492 - auc-roc: 0.9510 - val_loss: 0.2567 - val_acc: 0.8962 - val_auc-prc: 0.9621 - val_auc-roc: 0.9626 - 11s/epoch - 57ms/step
Epoch 3/100
185/185 - 11s - loss: 0.2748 - acc: 0.8915 - auc-prc: 0.9502 - auc-roc: 0.9523 - val_loss: 0.2452 - val_acc: 0.8916 - val_auc-prc: 0.9664 - val_auc-roc: 0.9658 - 11s/epoch - 57ms/step
Epoch 4/100
185/185 - 11s - loss: 0.2646 - acc: 0.8954 - auc-prc: 0.9542 - auc-roc: 0.9558 - val_loss: 0.2412 - val_acc: 0.9008 - val_auc-prc: 0.9665 - val_auc-roc: 0.9663 - 11s/epoch - 57ms/step
Epoch 5/100
185/185 - 11s - loss: 0.2564 - acc: 0.9016 - auc-prc: 0.9584 - auc-roc: 0.9592 - val_loss: 0.2390 - val_acc: 0.9008 - val_auc-prc: 0.9656 - val_auc-roc: 0.9658 - 11s/epoch - 57ms/step
Epoch 6/100
185/185 - 11s - loss: 0.2606 - acc: 0.8970 - auc-prc: 0.9568 - auc-roc: 0.9576 - val_loss: 0.2539 - val_acc: 0.8977 - val_auc-prc: 0.9601 - val_auc-roc: 0.9610 - 11s/epoch - 57ms/step
Epoch 7/100
185/185 - 10s - loss: 0.2530 - acc: 0.9006 - auc-prc: 0.9596 - auc-roc: 0.9604 - val_loss: 0.2437 - val_acc: 0.9008 - val_auc-prc: 0.9632 - val_auc-roc: 0.9640 - 10s/epoch - 57ms/step
Epoch 8/100
185/185 - 11s - loss: 0.2508 - acc: 0.9020 - auc-prc: 0.9596 - auc-roc: 0.9608 - val_loss: 0.2368 - val_acc: 0.9008 - val_auc-prc: 0.9688 - val_auc-roc: 0.9687 - 11s/epoch - 57ms/step
Epoch 9/100
185/185 - 10s - loss: 0.2474 - acc: 0.9018 - auc-prc: 0.9612 - auc-roc: 0.9619 - val_loss: 0.2394 - val_acc: 0.8962 - val_auc-prc: 0.9649 - val_auc-roc: 0.9654 - 10s/epoch - 55ms/step
Epoch 10/100
185/185 - 10s - loss: 0.2424 - acc: 0.9043 - auc-prc: 0.9633 - auc-roc: 0.9637 - val_loss: 0.2334 - val_acc: 0.9023 - val_auc-prc: 0.9665 - val_auc-roc: 0.9671 - 10s/epoch - 56ms/step
Epoch 11/100
185/185 - 11s - loss: 0.2413 - acc: 0.9043 - auc-prc: 0.9637 - auc-roc: 0.9641 - val_loss: 0.2257 - val_acc: 0.9084 - val_auc-prc: 0.9692 - val_auc-roc: 0.9705 - 11s/epoch - 57ms/step
Epoch 12/100
185/185 - 10s - loss: 0.2413 - acc: 0.9042 - auc-prc: 0.9634 - auc-roc: 0.9640 - val_loss: 0.2374 - val_acc: 0.8977 - val_auc-prc: 0.9648 - val_auc-roc: 0.9664 - 10s/epoch - 56ms/step
Epoch 13/100
185/185 - 10s - loss: 0.2403 - acc: 0.9045 - auc-prc: 0.9634 - auc-roc: 0.9642 - val_loss: 0.2252 - val_acc: 0.9053 - val_auc-prc: 0.9695 - val_auc-roc: 0.9708 - 10s/epoch - 56ms/step
Epoch 14/100
185/185 - 10s - loss: 0.2361 - acc: 0.9067 - auc-prc: 0.9650 - auc-roc: 0.9656 - val_loss: 0.2265 - val_acc: 0.8992 - val_auc-prc: 0.9707 - val_auc-roc: 0.9706 - 10s/epoch - 56ms/step
Epoch 15/100
185/185 - 10s - loss: 0.2364 - acc: 0.9038 - auc-prc: 0.9654 - auc-roc: 0.9657 - val_loss: 0.2281 - val_acc: 0.9069 - val_auc-prc: 0.9671 - val_auc-roc: 0.9695 - 10s/epoch - 57ms/step
Epoch 16/100
185/185 - 10s - loss: 0.2332 - acc: 0.9079 - auc-prc: 0.9659 - auc-roc: 0.9664 - val_loss: 0.2185 - val_acc: 0.9038 - val_auc-prc: 0.9710 - val_auc-roc: 0.9720 - 10s/epoch - 57ms/step
Epoch 17/100
185/185 - 10s - loss: 0.2314 - acc: 0.9062 - auc-prc: 0.9671 - auc-roc: 0.9671 - val_loss: 0.2156 - val_acc: 0.9069 - val_auc-prc: 0.9708 - val_auc-roc: 0.9719 - 10s/epoch - 56ms/step
Epoch 18/100
185/185 - 10s - loss: 0.2314 - acc: 0.9096 - auc-prc: 0.9669 - auc-roc: 0.9669 - val_loss: 0.2195 - val_acc: 0.9069 - val_auc-prc: 0.9713 - val_auc-roc: 0.9712 - 10s/epoch - 56ms/step
Epoch 19/100
185/185 - 10s - loss: 0.2242 - acc: 0.9098 - auc-prc: 0.9688 - auc-roc: 0.9689 - val_loss: 0.2218 - val_acc: 0.9115 - val_auc-prc: 0.9710 - val_auc-roc: 0.9710 - 10s/epoch - 56ms/step
Epoch 20/100
185/185 - 10s - loss: 0.2260 - acc: 0.9104 - auc-prc: 0.9684 - auc-roc: 0.9685 - val_loss: 0.2212 - val_acc: 0.9084 - val_auc-prc: 0.9715 - val_auc-roc: 0.9712 - 10s/epoch - 56ms/step
Epoch 21/100
185/185 - 10s - loss: 0.2204 - acc: 0.9128 - auc-prc: 0.9694 - auc-roc: 0.9699 - val_loss: 0.2192 - val_acc: 0.9084 - val_auc-prc: 0.9709 - val_auc-roc: 0.9717 - 10s/epoch - 56ms/step
Epoch 22/100
185/185 - 10s - loss: 0.2169 - acc: 0.9143 - auc-prc: 0.9707 - auc-roc: 0.9709 - val_loss: 0.2259 - val_acc: 0.8992 - val_auc-prc: 0.9683 - val_auc-roc: 0.9695 - 10s/epoch - 56ms/step
Epoch 23/100
185/185 - 10s - loss: 0.2183 - acc: 0.9167 - auc-prc: 0.9697 - auc-roc: 0.9702 - val_loss: 0.2262 - val_acc: 0.9130 - val_auc-prc: 0.9665 - val_auc-roc: 0.9692 - 10s/epoch - 56ms/step
Epoch 24/100
185/185 - 10s - loss: 0.2168 - acc: 0.9142 - auc-prc: 0.9713 - auc-roc: 0.9711 - val_loss: 0.2199 - val_acc: 0.9053 - val_auc-prc: 0.9706 - val_auc-roc: 0.9711 - 10s/epoch - 55ms/step
Epoch 25/100
185/185 - 10s - loss: 0.2108 - acc: 0.9166 - auc-prc: 0.9728 - auc-roc: 0.9726 - val_loss: 0.2387 - val_acc: 0.9084 - val_auc-prc: 0.9722 - val_auc-roc: 0.9724 - 10s/epoch - 54ms/step
Epoch 26/100
185/185 - 10s - loss: 0.2128 - acc: 0.9174 - auc-prc: 0.9718 - auc-roc: 0.9718 - val_loss: 0.2333 - val_acc: 0.9069 - val_auc-prc: 0.9680 - val_auc-roc: 0.9676 - 10s/epoch - 53ms/step
Early stopping epoch: 25
******Evaluating TEST set*********
21/21 - 1s - 533ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.91      0.77      0.83       194
           1       0.91      0.97      0.94       461

    accuracy                           0.91       655
   macro avg       0.91      0.87      0.88       655
weighted avg       0.91      0.91      0.91       655

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.27      0.49      0.35       194
           1       0.68      0.45      0.54       461

    accuracy                           0.46       655
   macro avg       0.48      0.47      0.45       655
weighted avg       0.56      0.46      0.49       655

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8684] IC [0.8583, 0.8785]
Mean Accuracy[0.9049] IC [0.8979, 0.9119]
Mean Recall[0.8684] IC [0.8583, 0.8785]
Mean F1[0.8813] IC [0.8721, 0.8905]
Median AUC_ROC[0.8712]
Median Accuracy[0.9084]
Median Recall[0.8712]
Median F1[0.8849]
********************txid511145********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.94      0.78      0.85      2098
           1       0.78      0.94      0.85      1726

    accuracy                           0.85      3824
   macro avg       0.86      0.86      0.85      3824
weighted avg       0.87      0.85      0.85      3824

Predicted   0.0   1.0   All
True                       
0          1644   454  2098
1           109  1617  1726
All        1753  2071  3824
**************************************************
fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3315 - acc: 0.8573 - auc-prc: 0.9312 - auc-roc: 0.9323 - val_loss: 0.2911 - val_acc: 0.8708 - val_auc-prc: 0.9473 - val_auc-roc: 0.9483 - 18s/epoch - 65ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2957 - acc: 0.8793 - auc-prc: 0.9441 - auc-roc: 0.9458 - val_loss: 0.2889 - val_acc: 0.8761 - val_auc-prc: 0.9490 - val_auc-roc: 0.9495 - 15s/epoch - 55ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2826 - acc: 0.8874 - auc-prc: 0.9485 - auc-roc: 0.9501 - val_loss: 0.2803 - val_acc: 0.8908 - val_auc-prc: 0.9520 - val_auc-roc: 0.9525 - 15s/epoch - 57ms/step
Epoch 4/100
268/268 - 14s - loss: 0.2817 - acc: 0.8851 - auc-prc: 0.9494 - auc-roc: 0.9507 - val_loss: 0.2812 - val_acc: 0.8866 - val_auc-prc: 0.9517 - val_auc-roc: 0.9522 - 14s/epoch - 53ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2732 - acc: 0.8915 - auc-prc: 0.9523 - auc-roc: 0.9535 - val_loss: 0.2831 - val_acc: 0.8803 - val_auc-prc: 0.9517 - val_auc-roc: 0.9518 - 15s/epoch - 55ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2705 - acc: 0.8911 - auc-prc: 0.9533 - auc-roc: 0.9546 - val_loss: 0.2963 - val_acc: 0.8761 - val_auc-prc: 0.9454 - val_auc-roc: 0.9465 - 15s/epoch - 56ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2693 - acc: 0.8900 - auc-prc: 0.9542 - auc-roc: 0.9550 - val_loss: 0.2787 - val_acc: 0.8855 - val_auc-prc: 0.9518 - val_auc-roc: 0.9527 - 15s/epoch - 55ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2648 - acc: 0.8910 - auc-prc: 0.9557 - auc-roc: 0.9565 - val_loss: 0.2798 - val_acc: 0.8876 - val_auc-prc: 0.9512 - val_auc-roc: 0.9525 - 15s/epoch - 57ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2606 - acc: 0.8948 - auc-prc: 0.9573 - auc-roc: 0.9580 - val_loss: 0.2760 - val_acc: 0.8834 - val_auc-prc: 0.9536 - val_auc-roc: 0.9537 - 15s/epoch - 57ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2605 - acc: 0.8940 - auc-prc: 0.9569 - auc-roc: 0.9580 - val_loss: 0.2807 - val_acc: 0.8771 - val_auc-prc: 0.9522 - val_auc-roc: 0.9519 - 15s/epoch - 57ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2600 - acc: 0.8957 - auc-prc: 0.9574 - auc-roc: 0.9583 - val_loss: 0.2758 - val_acc: 0.8855 - val_auc-prc: 0.9549 - val_auc-roc: 0.9548 - 15s/epoch - 56ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2563 - acc: 0.8988 - auc-prc: 0.9593 - auc-roc: 0.9593 - val_loss: 0.2770 - val_acc: 0.8897 - val_auc-prc: 0.9551 - val_auc-roc: 0.9546 - 15s/epoch - 56ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2558 - acc: 0.8973 - auc-prc: 0.9592 - auc-roc: 0.9595 - val_loss: 0.2697 - val_acc: 0.8845 - val_auc-prc: 0.9559 - val_auc-roc: 0.9559 - 15s/epoch - 56ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2523 - acc: 0.8956 - auc-prc: 0.9609 - auc-roc: 0.9610 - val_loss: 0.2782 - val_acc: 0.8855 - val_auc-prc: 0.9538 - val_auc-roc: 0.9538 - 15s/epoch - 56ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2495 - acc: 0.9011 - auc-prc: 0.9616 - auc-roc: 0.9617 - val_loss: 0.2711 - val_acc: 0.8813 - val_auc-prc: 0.9551 - val_auc-roc: 0.9554 - 15s/epoch - 56ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2445 - acc: 0.8997 - auc-prc: 0.9630 - auc-roc: 0.9633 - val_loss: 0.2857 - val_acc: 0.8845 - val_auc-prc: 0.9532 - val_auc-roc: 0.9528 - 15s/epoch - 56ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2425 - acc: 0.9005 - auc-prc: 0.9640 - auc-roc: 0.9641 - val_loss: 0.2845 - val_acc: 0.8803 - val_auc-prc: 0.9509 - val_auc-roc: 0.9512 - 15s/epoch - 56ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2441 - acc: 0.8987 - auc-prc: 0.9634 - auc-roc: 0.9635 - val_loss: 0.2768 - val_acc: 0.8803 - val_auc-prc: 0.9526 - val_auc-roc: 0.9531 - 15s/epoch - 57ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2395 - acc: 0.9033 - auc-prc: 0.9647 - auc-roc: 0.9648 - val_loss: 0.2717 - val_acc: 0.8897 - val_auc-prc: 0.9551 - val_auc-roc: 0.9552 - 15s/epoch - 56ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2344 - acc: 0.9039 - auc-prc: 0.9663 - auc-roc: 0.9664 - val_loss: 0.2967 - val_acc: 0.8729 - val_auc-prc: 0.9515 - val_auc-roc: 0.9512 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2341 - acc: 0.9047 - auc-prc: 0.9660 - auc-roc: 0.9661 - val_loss: 0.2749 - val_acc: 0.8834 - val_auc-prc: 0.9536 - val_auc-roc: 0.9545 - 15s/epoch - 57ms/step
Epoch 22/100
268/268 - 15s - loss: 0.2302 - acc: 0.9094 - auc-prc: 0.9673 - auc-roc: 0.9672 - val_loss: 0.2819 - val_acc: 0.8855 - val_auc-prc: 0.9517 - val_auc-roc: 0.9531 - 15s/epoch - 57ms/step
Epoch 23/100
268/268 - 15s - loss: 0.2269 - acc: 0.9088 - auc-prc: 0.9686 - auc-roc: 0.9684 - val_loss: 0.3122 - val_acc: 0.8771 - val_auc-prc: 0.9469 - val_auc-roc: 0.9465 - 15s/epoch - 57ms/step
Epoch 24/100
268/268 - 15s - loss: 0.2229 - acc: 0.9130 - auc-prc: 0.9695 - auc-roc: 0.9694 - val_loss: 0.3014 - val_acc: 0.8739 - val_auc-prc: 0.9484 - val_auc-roc: 0.9475 - 15s/epoch - 58ms/step
Epoch 25/100
268/268 - 15s - loss: 0.2221 - acc: 0.9094 - auc-prc: 0.9700 - auc-roc: 0.9697 - val_loss: 0.2853 - val_acc: 0.8908 - val_auc-prc: 0.9551 - val_auc-roc: 0.9558 - 15s/epoch - 57ms/step
Epoch 26/100
268/268 - 15s - loss: 0.2208 - acc: 0.9083 - auc-prc: 0.9705 - auc-roc: 0.9702 - val_loss: 0.2963 - val_acc: 0.8813 - val_auc-prc: 0.9500 - val_auc-roc: 0.9502 - 15s/epoch - 55ms/step
Early stopping epoch: 25
******Evaluating TEST set*********
30/30 - 1s - 724ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.89      0.82      0.85       391
           1       0.88      0.93      0.90       561

    accuracy                           0.88       952
   macro avg       0.89      0.87      0.88       952
weighted avg       0.88      0.88      0.88       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.47      0.42       391
           1       0.57      0.49      0.52       561

    accuracy                           0.48       952
   macro avg       0.48      0.48      0.47       952
weighted avg       0.49      0.48      0.48       952

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3298 - acc: 0.8574 - auc-prc: 0.9319 - auc-roc: 0.9334 - val_loss: 0.3128 - val_acc: 0.8624 - val_auc-prc: 0.9401 - val_auc-roc: 0.9406 - 17s/epoch - 64ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2946 - acc: 0.8801 - auc-prc: 0.9448 - auc-roc: 0.9466 - val_loss: 0.2931 - val_acc: 0.8718 - val_auc-prc: 0.9464 - val_auc-roc: 0.9469 - 15s/epoch - 56ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2812 - acc: 0.8865 - auc-prc: 0.9494 - auc-roc: 0.9509 - val_loss: 0.2964 - val_acc: 0.8634 - val_auc-prc: 0.9464 - val_auc-roc: 0.9468 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 14s - loss: 0.2796 - acc: 0.8873 - auc-prc: 0.9501 - auc-roc: 0.9518 - val_loss: 0.3103 - val_acc: 0.8592 - val_auc-prc: 0.9431 - val_auc-roc: 0.9430 - 14s/epoch - 54ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2738 - acc: 0.8898 - auc-prc: 0.9526 - auc-roc: 0.9536 - val_loss: 0.2805 - val_acc: 0.8782 - val_auc-prc: 0.9528 - val_auc-roc: 0.9527 - 14s/epoch - 53ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2698 - acc: 0.8911 - auc-prc: 0.9539 - auc-roc: 0.9550 - val_loss: 0.2716 - val_acc: 0.8887 - val_auc-prc: 0.9543 - val_auc-roc: 0.9547 - 14s/epoch - 53ms/step
Epoch 7/100
268/268 - 14s - loss: 0.2676 - acc: 0.8938 - auc-prc: 0.9550 - auc-roc: 0.9558 - val_loss: 0.2712 - val_acc: 0.8845 - val_auc-prc: 0.9552 - val_auc-roc: 0.9555 - 14s/epoch - 53ms/step
Epoch 8/100
268/268 - 14s - loss: 0.2628 - acc: 0.8962 - auc-prc: 0.9569 - auc-roc: 0.9573 - val_loss: 0.2924 - val_acc: 0.8803 - val_auc-prc: 0.9520 - val_auc-roc: 0.9518 - 14s/epoch - 52ms/step
Epoch 9/100
268/268 - 14s - loss: 0.2675 - acc: 0.8910 - auc-prc: 0.9551 - auc-roc: 0.9560 - val_loss: 0.3099 - val_acc: 0.8750 - val_auc-prc: 0.9469 - val_auc-roc: 0.9462 - 14s/epoch - 53ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2611 - acc: 0.8959 - auc-prc: 0.9571 - auc-roc: 0.9579 - val_loss: 0.2708 - val_acc: 0.8845 - val_auc-prc: 0.9557 - val_auc-roc: 0.9559 - 15s/epoch - 56ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2581 - acc: 0.8953 - auc-prc: 0.9584 - auc-roc: 0.9590 - val_loss: 0.2713 - val_acc: 0.8855 - val_auc-prc: 0.9550 - val_auc-roc: 0.9552 - 15s/epoch - 56ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2575 - acc: 0.8962 - auc-prc: 0.9591 - auc-roc: 0.9593 - val_loss: 0.2650 - val_acc: 0.8866 - val_auc-prc: 0.9567 - val_auc-roc: 0.9573 - 15s/epoch - 56ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2498 - acc: 0.8983 - auc-prc: 0.9612 - auc-roc: 0.9616 - val_loss: 0.2714 - val_acc: 0.8981 - val_auc-prc: 0.9528 - val_auc-roc: 0.9542 - 15s/epoch - 56ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2486 - acc: 0.8962 - auc-prc: 0.9621 - auc-roc: 0.9621 - val_loss: 0.2645 - val_acc: 0.8929 - val_auc-prc: 0.9561 - val_auc-roc: 0.9573 - 15s/epoch - 56ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2445 - acc: 0.9006 - auc-prc: 0.9631 - auc-roc: 0.9632 - val_loss: 0.2940 - val_acc: 0.8739 - val_auc-prc: 0.9503 - val_auc-roc: 0.9507 - 15s/epoch - 56ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2430 - acc: 0.9004 - auc-prc: 0.9639 - auc-roc: 0.9638 - val_loss: 0.2699 - val_acc: 0.8897 - val_auc-prc: 0.9546 - val_auc-roc: 0.9553 - 15s/epoch - 56ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2411 - acc: 0.9041 - auc-prc: 0.9645 - auc-roc: 0.9644 - val_loss: 0.2725 - val_acc: 0.8887 - val_auc-prc: 0.9534 - val_auc-roc: 0.9547 - 15s/epoch - 56ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2386 - acc: 0.9023 - auc-prc: 0.9651 - auc-roc: 0.9652 - val_loss: 0.2655 - val_acc: 0.8918 - val_auc-prc: 0.9559 - val_auc-roc: 0.9570 - 15s/epoch - 56ms/step
Epoch 19/100
268/268 - 16s - loss: 0.2343 - acc: 0.9053 - auc-prc: 0.9667 - auc-roc: 0.9662 - val_loss: 0.2731 - val_acc: 0.8887 - val_auc-prc: 0.9547 - val_auc-roc: 0.9547 - 16s/epoch - 58ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2311 - acc: 0.9037 - auc-prc: 0.9675 - auc-roc: 0.9672 - val_loss: 0.2684 - val_acc: 0.8950 - val_auc-prc: 0.9555 - val_auc-roc: 0.9573 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2302 - acc: 0.9075 - auc-prc: 0.9677 - auc-roc: 0.9674 - val_loss: 0.2679 - val_acc: 0.8834 - val_auc-prc: 0.9575 - val_auc-roc: 0.9581 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 763ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.87      0.85      0.86       392
           1       0.89      0.91      0.90       560

    accuracy                           0.88       952
   macro avg       0.88      0.88      0.88       952
weighted avg       0.88      0.88      0.88       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.50      0.44       392
           1       0.57      0.47      0.52       560

    accuracy                           0.48       952
   macro avg       0.49      0.49      0.48       952
weighted avg       0.50      0.48      0.49       952

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3340 - acc: 0.8497 - auc-prc: 0.9310 - auc-roc: 0.9316 - val_loss: 0.2739 - val_acc: 0.8929 - val_auc-prc: 0.9491 - val_auc-roc: 0.9527 - 18s/epoch - 67ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2945 - acc: 0.8815 - auc-prc: 0.9446 - auc-roc: 0.9465 - val_loss: 0.2620 - val_acc: 0.8992 - val_auc-prc: 0.9541 - val_auc-roc: 0.9564 - 15s/epoch - 56ms/step
Epoch 3/100
268/268 - 14s - loss: 0.2849 - acc: 0.8845 - auc-prc: 0.9486 - auc-roc: 0.9499 - val_loss: 0.2548 - val_acc: 0.8939 - val_auc-prc: 0.9553 - val_auc-roc: 0.9589 - 14s/epoch - 54ms/step
Epoch 4/100
268/268 - 14s - loss: 0.2816 - acc: 0.8852 - auc-prc: 0.9496 - auc-roc: 0.9507 - val_loss: 0.2539 - val_acc: 0.9076 - val_auc-prc: 0.9595 - val_auc-roc: 0.9618 - 14s/epoch - 53ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2740 - acc: 0.8865 - auc-prc: 0.9525 - auc-roc: 0.9536 - val_loss: 0.2511 - val_acc: 0.8992 - val_auc-prc: 0.9562 - val_auc-roc: 0.9594 - 14s/epoch - 53ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2716 - acc: 0.8910 - auc-prc: 0.9532 - auc-roc: 0.9543 - val_loss: 0.2417 - val_acc: 0.9013 - val_auc-prc: 0.9595 - val_auc-roc: 0.9625 - 14s/epoch - 54ms/step
Epoch 7/100
268/268 - 14s - loss: 0.2708 - acc: 0.8896 - auc-prc: 0.9539 - auc-roc: 0.9547 - val_loss: 0.2476 - val_acc: 0.9086 - val_auc-prc: 0.9598 - val_auc-roc: 0.9623 - 14s/epoch - 53ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2705 - acc: 0.8935 - auc-prc: 0.9539 - auc-roc: 0.9548 - val_loss: 0.2402 - val_acc: 0.9055 - val_auc-prc: 0.9611 - val_auc-roc: 0.9636 - 15s/epoch - 55ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2637 - acc: 0.8905 - auc-prc: 0.9572 - auc-roc: 0.9573 - val_loss: 0.2386 - val_acc: 0.9086 - val_auc-prc: 0.9624 - val_auc-roc: 0.9643 - 15s/epoch - 56ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2645 - acc: 0.8928 - auc-prc: 0.9569 - auc-roc: 0.9569 - val_loss: 0.2394 - val_acc: 0.9055 - val_auc-prc: 0.9627 - val_auc-roc: 0.9643 - 15s/epoch - 57ms/step
Epoch 11/100
268/268 - 14s - loss: 0.2611 - acc: 0.8942 - auc-prc: 0.9579 - auc-roc: 0.9581 - val_loss: 0.2454 - val_acc: 0.9076 - val_auc-prc: 0.9621 - val_auc-roc: 0.9628 - 14s/epoch - 54ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2574 - acc: 0.8974 - auc-prc: 0.9593 - auc-roc: 0.9595 - val_loss: 0.2329 - val_acc: 0.9044 - val_auc-prc: 0.9644 - val_auc-roc: 0.9661 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2565 - acc: 0.8957 - auc-prc: 0.9594 - auc-roc: 0.9597 - val_loss: 0.2346 - val_acc: 0.9149 - val_auc-prc: 0.9654 - val_auc-roc: 0.9669 - 15s/epoch - 57ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2547 - acc: 0.8953 - auc-prc: 0.9599 - auc-roc: 0.9604 - val_loss: 0.2256 - val_acc: 0.9107 - val_auc-prc: 0.9679 - val_auc-roc: 0.9685 - 15s/epoch - 57ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2509 - acc: 0.8960 - auc-prc: 0.9612 - auc-roc: 0.9614 - val_loss: 0.2270 - val_acc: 0.9097 - val_auc-prc: 0.9681 - val_auc-roc: 0.9686 - 15s/epoch - 56ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2467 - acc: 0.8992 - auc-prc: 0.9625 - auc-roc: 0.9626 - val_loss: 0.2359 - val_acc: 0.9044 - val_auc-prc: 0.9654 - val_auc-roc: 0.9662 - 15s/epoch - 56ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2443 - acc: 0.8996 - auc-prc: 0.9634 - auc-roc: 0.9635 - val_loss: 0.2315 - val_acc: 0.9097 - val_auc-prc: 0.9665 - val_auc-roc: 0.9667 - 15s/epoch - 56ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2449 - acc: 0.8997 - auc-prc: 0.9631 - auc-roc: 0.9633 - val_loss: 0.2330 - val_acc: 0.9023 - val_auc-prc: 0.9641 - val_auc-roc: 0.9659 - 15s/epoch - 56ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2422 - acc: 0.9026 - auc-prc: 0.9641 - auc-roc: 0.9641 - val_loss: 0.2254 - val_acc: 0.9055 - val_auc-prc: 0.9670 - val_auc-roc: 0.9684 - 15s/epoch - 56ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2384 - acc: 0.9029 - auc-prc: 0.9648 - auc-roc: 0.9651 - val_loss: 0.2287 - val_acc: 0.9086 - val_auc-prc: 0.9672 - val_auc-roc: 0.9674 - 15s/epoch - 54ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2333 - acc: 0.9048 - auc-prc: 0.9666 - auc-roc: 0.9667 - val_loss: 0.2322 - val_acc: 0.9055 - val_auc-prc: 0.9660 - val_auc-roc: 0.9663 - 15s/epoch - 55ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 748ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.94      0.84      0.88       392
           1       0.89      0.96      0.93       560

    accuracy                           0.91       952
   macro avg       0.92      0.90      0.91       952
weighted avg       0.91      0.91      0.91       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.52      0.46       392
           1       0.60      0.50      0.55       560

    accuracy                           0.51       952
   macro avg       0.51      0.51      0.50       952
weighted avg       0.52      0.51      0.51       952

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3213 - acc: 0.8588 - auc-prc: 0.9351 - auc-roc: 0.9365 - val_loss: 0.3187 - val_acc: 0.8750 - val_auc-prc: 0.9330 - val_auc-roc: 0.9378 - 17s/epoch - 65ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2879 - acc: 0.8844 - auc-prc: 0.9481 - auc-roc: 0.9490 - val_loss: 0.3185 - val_acc: 0.8792 - val_auc-prc: 0.9355 - val_auc-roc: 0.9391 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2785 - acc: 0.8851 - auc-prc: 0.9507 - auc-roc: 0.9521 - val_loss: 0.3281 - val_acc: 0.8782 - val_auc-prc: 0.9359 - val_auc-roc: 0.9400 - 15s/epoch - 58ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2732 - acc: 0.8883 - auc-prc: 0.9530 - auc-roc: 0.9537 - val_loss: 0.3132 - val_acc: 0.8803 - val_auc-prc: 0.9350 - val_auc-roc: 0.9393 - 15s/epoch - 55ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2690 - acc: 0.8898 - auc-prc: 0.9545 - auc-roc: 0.9552 - val_loss: 0.3131 - val_acc: 0.8855 - val_auc-prc: 0.9370 - val_auc-roc: 0.9405 - 14s/epoch - 53ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2685 - acc: 0.8917 - auc-prc: 0.9548 - auc-roc: 0.9557 - val_loss: 0.3005 - val_acc: 0.8918 - val_auc-prc: 0.9411 - val_auc-roc: 0.9448 - 14s/epoch - 54ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2637 - acc: 0.8942 - auc-prc: 0.9567 - auc-roc: 0.9570 - val_loss: 0.3157 - val_acc: 0.8803 - val_auc-prc: 0.9368 - val_auc-roc: 0.9410 - 15s/epoch - 56ms/step
Epoch 8/100
268/268 - 14s - loss: 0.2651 - acc: 0.8924 - auc-prc: 0.9558 - auc-roc: 0.9567 - val_loss: 0.2984 - val_acc: 0.8876 - val_auc-prc: 0.9420 - val_auc-roc: 0.9459 - 14s/epoch - 54ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2611 - acc: 0.8919 - auc-prc: 0.9576 - auc-roc: 0.9580 - val_loss: 0.3020 - val_acc: 0.8834 - val_auc-prc: 0.9419 - val_auc-roc: 0.9454 - 15s/epoch - 57ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2559 - acc: 0.8978 - auc-prc: 0.9592 - auc-roc: 0.9596 - val_loss: 0.2940 - val_acc: 0.8918 - val_auc-prc: 0.9457 - val_auc-roc: 0.9474 - 15s/epoch - 57ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2564 - acc: 0.8943 - auc-prc: 0.9593 - auc-roc: 0.9595 - val_loss: 0.3009 - val_acc: 0.8897 - val_auc-prc: 0.9434 - val_auc-roc: 0.9472 - 15s/epoch - 57ms/step
Epoch 12/100
268/268 - 16s - loss: 0.2513 - acc: 0.8988 - auc-prc: 0.9613 - auc-roc: 0.9612 - val_loss: 0.2928 - val_acc: 0.8897 - val_auc-prc: 0.9447 - val_auc-roc: 0.9477 - 16s/epoch - 58ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2520 - acc: 0.8953 - auc-prc: 0.9607 - auc-roc: 0.9610 - val_loss: 0.3056 - val_acc: 0.8813 - val_auc-prc: 0.9409 - val_auc-roc: 0.9453 - 15s/epoch - 57ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2503 - acc: 0.8971 - auc-prc: 0.9614 - auc-roc: 0.9615 - val_loss: 0.2863 - val_acc: 0.8866 - val_auc-prc: 0.9478 - val_auc-roc: 0.9493 - 15s/epoch - 57ms/step
Epoch 15/100
268/268 - 16s - loss: 0.2484 - acc: 0.8967 - auc-prc: 0.9624 - auc-roc: 0.9623 - val_loss: 0.2957 - val_acc: 0.8855 - val_auc-prc: 0.9460 - val_auc-roc: 0.9490 - 16s/epoch - 60ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2442 - acc: 0.9013 - auc-prc: 0.9631 - auc-roc: 0.9633 - val_loss: 0.2953 - val_acc: 0.8803 - val_auc-prc: 0.9443 - val_auc-roc: 0.9472 - 15s/epoch - 57ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2451 - acc: 0.8973 - auc-prc: 0.9634 - auc-roc: 0.9633 - val_loss: 0.3049 - val_acc: 0.8771 - val_auc-prc: 0.9413 - val_auc-roc: 0.9433 - 15s/epoch - 54ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2409 - acc: 0.9017 - auc-prc: 0.9647 - auc-roc: 0.9645 - val_loss: 0.2963 - val_acc: 0.8876 - val_auc-prc: 0.9445 - val_auc-roc: 0.9478 - 15s/epoch - 55ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2364 - acc: 0.9022 - auc-prc: 0.9660 - auc-roc: 0.9658 - val_loss: 0.3027 - val_acc: 0.8739 - val_auc-prc: 0.9450 - val_auc-roc: 0.9471 - 14s/epoch - 54ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2341 - acc: 0.9061 - auc-prc: 0.9669 - auc-roc: 0.9664 - val_loss: 0.2916 - val_acc: 0.8876 - val_auc-prc: 0.9458 - val_auc-roc: 0.9486 - 15s/epoch - 55ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2318 - acc: 0.9061 - auc-prc: 0.9672 - auc-roc: 0.9671 - val_loss: 0.2869 - val_acc: 0.8824 - val_auc-prc: 0.9491 - val_auc-roc: 0.9503 - 15s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 691ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.86      0.85      0.86       392
           1       0.89      0.91      0.90       560

    accuracy                           0.88       952
   macro avg       0.88      0.88      0.88       952
weighted avg       0.88      0.88      0.88       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.49      0.45       392
           1       0.60      0.52      0.56       560

    accuracy                           0.51       952
   macro avg       0.51      0.51      0.51       952
weighted avg       0.52      0.51      0.51       952

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3374 - acc: 0.8492 - auc-prc: 0.9287 - auc-roc: 0.9302 - val_loss: 0.2601 - val_acc: 0.8908 - val_auc-prc: 0.9568 - val_auc-roc: 0.9585 - 18s/epoch - 66ms/step
Epoch 2/100
268/268 - 14s - loss: 0.2949 - acc: 0.8807 - auc-prc: 0.9446 - auc-roc: 0.9463 - val_loss: 0.2738 - val_acc: 0.8761 - val_auc-prc: 0.9558 - val_auc-roc: 0.9553 - 14s/epoch - 52ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2921 - acc: 0.8806 - auc-prc: 0.9463 - auc-roc: 0.9474 - val_loss: 0.2522 - val_acc: 0.9013 - val_auc-prc: 0.9611 - val_auc-roc: 0.9616 - 15s/epoch - 56ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2788 - acc: 0.8883 - auc-prc: 0.9509 - auc-roc: 0.9520 - val_loss: 0.2674 - val_acc: 0.8866 - val_auc-prc: 0.9562 - val_auc-roc: 0.9568 - 15s/epoch - 56ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2793 - acc: 0.8855 - auc-prc: 0.9508 - auc-roc: 0.9521 - val_loss: 0.2518 - val_acc: 0.8929 - val_auc-prc: 0.9616 - val_auc-roc: 0.9615 - 14s/epoch - 54ms/step
Epoch 6/100
268/268 - 14s - loss: 0.2740 - acc: 0.8884 - auc-prc: 0.9526 - auc-roc: 0.9536 - val_loss: 0.2385 - val_acc: 0.9055 - val_auc-prc: 0.9656 - val_auc-roc: 0.9657 - 14s/epoch - 53ms/step
Epoch 7/100
268/268 - 14s - loss: 0.2726 - acc: 0.8886 - auc-prc: 0.9535 - auc-roc: 0.9541 - val_loss: 0.2469 - val_acc: 0.9097 - val_auc-prc: 0.9655 - val_auc-roc: 0.9659 - 14s/epoch - 52ms/step
Epoch 8/100
268/268 - 14s - loss: 0.2717 - acc: 0.8884 - auc-prc: 0.9540 - auc-roc: 0.9545 - val_loss: 0.2454 - val_acc: 0.9013 - val_auc-prc: 0.9628 - val_auc-roc: 0.9636 - 14s/epoch - 53ms/step
Epoch 9/100
268/268 - 14s - loss: 0.2661 - acc: 0.8907 - auc-prc: 0.9555 - auc-roc: 0.9564 - val_loss: 0.2369 - val_acc: 0.8992 - val_auc-prc: 0.9643 - val_auc-roc: 0.9647 - 14s/epoch - 54ms/step
Epoch 10/100
268/268 - 14s - loss: 0.2678 - acc: 0.8897 - auc-prc: 0.9548 - auc-roc: 0.9557 - val_loss: 0.2412 - val_acc: 0.9034 - val_auc-prc: 0.9637 - val_auc-roc: 0.9644 - 14s/epoch - 54ms/step
Epoch 11/100
268/268 - 14s - loss: 0.2642 - acc: 0.8910 - auc-prc: 0.9559 - auc-roc: 0.9572 - val_loss: 0.2517 - val_acc: 0.9002 - val_auc-prc: 0.9616 - val_auc-roc: 0.9618 - 14s/epoch - 53ms/step
Epoch 12/100
268/268 - 14s - loss: 0.2617 - acc: 0.8941 - auc-prc: 0.9575 - auc-roc: 0.9578 - val_loss: 0.2596 - val_acc: 0.8918 - val_auc-prc: 0.9590 - val_auc-roc: 0.9596 - 14s/epoch - 54ms/step
Epoch 13/100
268/268 - 14s - loss: 0.2623 - acc: 0.8935 - auc-prc: 0.9572 - auc-roc: 0.9576 - val_loss: 0.2351 - val_acc: 0.8981 - val_auc-prc: 0.9659 - val_auc-roc: 0.9662 - 14s/epoch - 54ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2579 - acc: 0.8928 - auc-prc: 0.9593 - auc-roc: 0.9593 - val_loss: 0.2371 - val_acc: 0.9086 - val_auc-prc: 0.9673 - val_auc-roc: 0.9674 - 15s/epoch - 54ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2535 - acc: 0.8974 - auc-prc: 0.9605 - auc-roc: 0.9607 - val_loss: 0.2408 - val_acc: 0.8981 - val_auc-prc: 0.9633 - val_auc-roc: 0.9642 - 15s/epoch - 57ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2510 - acc: 0.8959 - auc-prc: 0.9616 - auc-roc: 0.9615 - val_loss: 0.2355 - val_acc: 0.9076 - val_auc-prc: 0.9648 - val_auc-roc: 0.9654 - 15s/epoch - 54ms/step
Epoch 17/100
268/268 - 14s - loss: 0.2483 - acc: 0.9001 - auc-prc: 0.9621 - auc-roc: 0.9622 - val_loss: 0.2328 - val_acc: 0.9097 - val_auc-prc: 0.9658 - val_auc-roc: 0.9666 - 14s/epoch - 54ms/step
Epoch 18/100
268/268 - 14s - loss: 0.2436 - acc: 0.9010 - auc-prc: 0.9636 - auc-roc: 0.9636 - val_loss: 0.2386 - val_acc: 0.9034 - val_auc-prc: 0.9636 - val_auc-roc: 0.9647 - 14s/epoch - 54ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2461 - acc: 0.8962 - auc-prc: 0.9635 - auc-roc: 0.9632 - val_loss: 0.2410 - val_acc: 0.9055 - val_auc-prc: 0.9645 - val_auc-roc: 0.9646 - 14s/epoch - 54ms/step
Epoch 20/100
268/268 - 14s - loss: 0.2393 - acc: 0.9027 - auc-prc: 0.9650 - auc-roc: 0.9649 - val_loss: 0.2486 - val_acc: 0.8929 - val_auc-prc: 0.9599 - val_auc-roc: 0.9621 - 14s/epoch - 54ms/step
Epoch 21/100
268/268 - 14s - loss: 0.2341 - acc: 0.9038 - auc-prc: 0.9671 - auc-roc: 0.9667 - val_loss: 0.2398 - val_acc: 0.9097 - val_auc-prc: 0.9631 - val_auc-roc: 0.9637 - 14s/epoch - 54ms/step
Epoch 22/100
268/268 - 14s - loss: 0.2314 - acc: 0.9048 - auc-prc: 0.9679 - auc-roc: 0.9674 - val_loss: 0.2370 - val_acc: 0.8992 - val_auc-prc: 0.9659 - val_auc-roc: 0.9656 - 14s/epoch - 54ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
30/30 - 1s - 696ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.91      0.87      0.89       392
           1       0.91      0.94      0.92       560

    accuracy                           0.91       952
   macro avg       0.91      0.90      0.91       952
weighted avg       0.91      0.91      0.91       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.45      0.41       392
           1       0.55      0.47      0.51       560

    accuracy                           0.46       952
   macro avg       0.46      0.46      0.46       952
weighted avg       0.48      0.46      0.47       952

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3323 - acc: 0.8563 - auc-prc: 0.9310 - auc-roc: 0.9322 - val_loss: 0.3070 - val_acc: 0.8708 - val_auc-prc: 0.9425 - val_auc-roc: 0.9426 - 17s/epoch - 62ms/step
Epoch 2/100
268/268 - 14s - loss: 0.2906 - acc: 0.8830 - auc-prc: 0.9456 - auc-roc: 0.9475 - val_loss: 0.3023 - val_acc: 0.8824 - val_auc-prc: 0.9435 - val_auc-roc: 0.9432 - 14s/epoch - 54ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2851 - acc: 0.8843 - auc-prc: 0.9485 - auc-roc: 0.9497 - val_loss: 0.2878 - val_acc: 0.8834 - val_auc-prc: 0.9477 - val_auc-roc: 0.9481 - 15s/epoch - 55ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2795 - acc: 0.8866 - auc-prc: 0.9500 - auc-roc: 0.9517 - val_loss: 0.2829 - val_acc: 0.8845 - val_auc-prc: 0.9489 - val_auc-roc: 0.9497 - 15s/epoch - 54ms/step
Epoch 5/100
268/268 - 14s - loss: 0.2753 - acc: 0.8890 - auc-prc: 0.9520 - auc-roc: 0.9531 - val_loss: 0.2750 - val_acc: 0.8866 - val_auc-prc: 0.9533 - val_auc-roc: 0.9528 - 14s/epoch - 54ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2707 - acc: 0.8915 - auc-prc: 0.9538 - auc-roc: 0.9548 - val_loss: 0.2731 - val_acc: 0.8897 - val_auc-prc: 0.9544 - val_auc-roc: 0.9540 - 15s/epoch - 54ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2674 - acc: 0.8914 - auc-prc: 0.9548 - auc-roc: 0.9559 - val_loss: 0.2702 - val_acc: 0.8855 - val_auc-prc: 0.9555 - val_auc-roc: 0.9551 - 15s/epoch - 55ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2660 - acc: 0.8922 - auc-prc: 0.9554 - auc-roc: 0.9564 - val_loss: 0.2763 - val_acc: 0.8845 - val_auc-prc: 0.9541 - val_auc-roc: 0.9533 - 15s/epoch - 56ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2643 - acc: 0.8925 - auc-prc: 0.9564 - auc-roc: 0.9571 - val_loss: 0.2730 - val_acc: 0.8908 - val_auc-prc: 0.9549 - val_auc-roc: 0.9546 - 15s/epoch - 57ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2619 - acc: 0.8948 - auc-prc: 0.9575 - auc-roc: 0.9579 - val_loss: 0.2754 - val_acc: 0.8897 - val_auc-prc: 0.9539 - val_auc-roc: 0.9537 - 15s/epoch - 55ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2597 - acc: 0.8957 - auc-prc: 0.9579 - auc-roc: 0.9585 - val_loss: 0.2710 - val_acc: 0.8929 - val_auc-prc: 0.9558 - val_auc-roc: 0.9550 - 15s/epoch - 57ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2559 - acc: 0.8947 - auc-prc: 0.9592 - auc-roc: 0.9598 - val_loss: 0.2803 - val_acc: 0.8855 - val_auc-prc: 0.9533 - val_auc-roc: 0.9525 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2550 - acc: 0.8987 - auc-prc: 0.9588 - auc-roc: 0.9598 - val_loss: 0.2789 - val_acc: 0.8866 - val_auc-prc: 0.9526 - val_auc-roc: 0.9526 - 15s/epoch - 57ms/step
Epoch 14/100
268/268 - 14s - loss: 0.2516 - acc: 0.8953 - auc-prc: 0.9612 - auc-roc: 0.9611 - val_loss: 0.2685 - val_acc: 0.8887 - val_auc-prc: 0.9566 - val_auc-roc: 0.9560 - 14s/epoch - 53ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2472 - acc: 0.8990 - auc-prc: 0.9623 - auc-roc: 0.9625 - val_loss: 0.2766 - val_acc: 0.8834 - val_auc-prc: 0.9556 - val_auc-roc: 0.9546 - 15s/epoch - 54ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2440 - acc: 0.9024 - auc-prc: 0.9633 - auc-roc: 0.9634 - val_loss: 0.3007 - val_acc: 0.8792 - val_auc-prc: 0.9507 - val_auc-roc: 0.9495 - 15s/epoch - 55ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2460 - acc: 0.9016 - auc-prc: 0.9624 - auc-roc: 0.9627 - val_loss: 0.2736 - val_acc: 0.8824 - val_auc-prc: 0.9563 - val_auc-roc: 0.9552 - 15s/epoch - 57ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2414 - acc: 0.9017 - auc-prc: 0.9641 - auc-roc: 0.9643 - val_loss: 0.2867 - val_acc: 0.8855 - val_auc-prc: 0.9501 - val_auc-roc: 0.9506 - 15s/epoch - 54ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2341 - acc: 0.9030 - auc-prc: 0.9667 - auc-roc: 0.9665 - val_loss: 0.2875 - val_acc: 0.8834 - val_auc-prc: 0.9482 - val_auc-roc: 0.9489 - 14s/epoch - 54ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2324 - acc: 0.9071 - auc-prc: 0.9666 - auc-roc: 0.9667 - val_loss: 0.2858 - val_acc: 0.8855 - val_auc-prc: 0.9544 - val_auc-roc: 0.9534 - 15s/epoch - 56ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2343 - acc: 0.9058 - auc-prc: 0.9668 - auc-roc: 0.9664 - val_loss: 0.2758 - val_acc: 0.8887 - val_auc-prc: 0.9532 - val_auc-roc: 0.9531 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 747ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.89      0.84      0.86       392
           1       0.89      0.93      0.91       560

    accuracy                           0.89       952
   macro avg       0.89      0.88      0.88       952
weighted avg       0.89      0.89      0.89       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.52      0.47       392
           1       0.60      0.50      0.55       560

    accuracy                           0.51       952
   macro avg       0.51      0.51      0.51       952
weighted avg       0.53      0.51      0.51       952

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3258 - acc: 0.8601 - auc-prc: 0.9335 - auc-roc: 0.9347 - val_loss: 0.3036 - val_acc: 0.8761 - val_auc-prc: 0.9420 - val_auc-roc: 0.9453 - 18s/epoch - 66ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2885 - acc: 0.8814 - auc-prc: 0.9466 - auc-roc: 0.9484 - val_loss: 0.2868 - val_acc: 0.8824 - val_auc-prc: 0.9481 - val_auc-roc: 0.9507 - 15s/epoch - 58ms/step
Epoch 3/100
268/268 - 16s - loss: 0.2836 - acc: 0.8839 - auc-prc: 0.9488 - auc-roc: 0.9503 - val_loss: 0.2887 - val_acc: 0.8708 - val_auc-prc: 0.9485 - val_auc-roc: 0.9493 - 16s/epoch - 58ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2774 - acc: 0.8877 - auc-prc: 0.9514 - auc-roc: 0.9523 - val_loss: 0.2774 - val_acc: 0.8908 - val_auc-prc: 0.9519 - val_auc-roc: 0.9534 - 15s/epoch - 57ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2733 - acc: 0.8918 - auc-prc: 0.9527 - auc-roc: 0.9537 - val_loss: 0.2790 - val_acc: 0.8782 - val_auc-prc: 0.9519 - val_auc-roc: 0.9534 - 15s/epoch - 57ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2695 - acc: 0.8929 - auc-prc: 0.9540 - auc-roc: 0.9549 - val_loss: 0.2748 - val_acc: 0.8876 - val_auc-prc: 0.9531 - val_auc-roc: 0.9546 - 15s/epoch - 57ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2656 - acc: 0.8924 - auc-prc: 0.9558 - auc-roc: 0.9563 - val_loss: 0.2773 - val_acc: 0.8750 - val_auc-prc: 0.9533 - val_auc-roc: 0.9540 - 15s/epoch - 56ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2644 - acc: 0.8918 - auc-prc: 0.9559 - auc-roc: 0.9567 - val_loss: 0.2862 - val_acc: 0.8718 - val_auc-prc: 0.9511 - val_auc-roc: 0.9511 - 15s/epoch - 56ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2627 - acc: 0.8950 - auc-prc: 0.9570 - auc-roc: 0.9575 - val_loss: 0.2770 - val_acc: 0.8750 - val_auc-prc: 0.9527 - val_auc-roc: 0.9533 - 15s/epoch - 57ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2570 - acc: 0.8970 - auc-prc: 0.9588 - auc-roc: 0.9594 - val_loss: 0.2701 - val_acc: 0.8845 - val_auc-prc: 0.9560 - val_auc-roc: 0.9560 - 15s/epoch - 57ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2560 - acc: 0.8976 - auc-prc: 0.9590 - auc-roc: 0.9595 - val_loss: 0.2716 - val_acc: 0.8845 - val_auc-prc: 0.9563 - val_auc-roc: 0.9561 - 15s/epoch - 57ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2554 - acc: 0.8962 - auc-prc: 0.9591 - auc-roc: 0.9596 - val_loss: 0.2831 - val_acc: 0.8845 - val_auc-prc: 0.9541 - val_auc-roc: 0.9546 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2509 - acc: 0.9013 - auc-prc: 0.9601 - auc-roc: 0.9609 - val_loss: 0.2928 - val_acc: 0.8666 - val_auc-prc: 0.9499 - val_auc-roc: 0.9492 - 15s/epoch - 55ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2482 - acc: 0.9011 - auc-prc: 0.9619 - auc-roc: 0.9622 - val_loss: 0.2882 - val_acc: 0.8739 - val_auc-prc: 0.9515 - val_auc-roc: 0.9511 - 15s/epoch - 57ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2464 - acc: 0.9018 - auc-prc: 0.9627 - auc-roc: 0.9628 - val_loss: 0.2815 - val_acc: 0.8897 - val_auc-prc: 0.9555 - val_auc-roc: 0.9551 - 15s/epoch - 57ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2465 - acc: 0.9020 - auc-prc: 0.9628 - auc-roc: 0.9627 - val_loss: 0.2807 - val_acc: 0.8824 - val_auc-prc: 0.9538 - val_auc-roc: 0.9535 - 15s/epoch - 57ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2433 - acc: 0.9036 - auc-prc: 0.9631 - auc-roc: 0.9636 - val_loss: 0.2877 - val_acc: 0.8845 - val_auc-prc: 0.9494 - val_auc-roc: 0.9498 - 15s/epoch - 57ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2392 - acc: 0.9037 - auc-prc: 0.9648 - auc-roc: 0.9648 - val_loss: 0.2795 - val_acc: 0.8887 - val_auc-prc: 0.9529 - val_auc-roc: 0.9524 - 15s/epoch - 57ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2346 - acc: 0.9059 - auc-prc: 0.9664 - auc-roc: 0.9662 - val_loss: 0.2859 - val_acc: 0.8824 - val_auc-prc: 0.9511 - val_auc-roc: 0.9509 - 15s/epoch - 55ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2355 - acc: 0.9061 - auc-prc: 0.9661 - auc-roc: 0.9660 - val_loss: 0.2807 - val_acc: 0.8855 - val_auc-prc: 0.9511 - val_auc-roc: 0.9512 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2314 - acc: 0.9051 - auc-prc: 0.9674 - auc-roc: 0.9671 - val_loss: 0.2878 - val_acc: 0.8824 - val_auc-prc: 0.9520 - val_auc-roc: 0.9520 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 746ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.88      0.83      0.86       392
           1       0.89      0.92      0.90       560

    accuracy                           0.88       952
   macro avg       0.88      0.88      0.88       952
weighted avg       0.88      0.88      0.88       952

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.50      0.44       392
           1       0.56      0.45      0.50       560

    accuracy                           0.47       952
   macro avg       0.47      0.47      0.47       952
weighted avg       0.49      0.47      0.47       952

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3231 - acc: 0.8608 - auc-prc: 0.9352 - auc-roc: 0.9360 - val_loss: 0.2945 - val_acc: 0.8822 - val_auc-prc: 0.9441 - val_auc-roc: 0.9458 - 17s/epoch - 65ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2905 - acc: 0.8830 - auc-prc: 0.9460 - auc-roc: 0.9479 - val_loss: 0.2841 - val_acc: 0.8885 - val_auc-prc: 0.9488 - val_auc-roc: 0.9498 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2804 - acc: 0.8868 - auc-prc: 0.9504 - auc-roc: 0.9516 - val_loss: 0.2897 - val_acc: 0.8812 - val_auc-prc: 0.9481 - val_auc-roc: 0.9482 - 15s/epoch - 57ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2794 - acc: 0.8862 - auc-prc: 0.9508 - auc-roc: 0.9520 - val_loss: 0.2774 - val_acc: 0.8991 - val_auc-prc: 0.9525 - val_auc-roc: 0.9529 - 15s/epoch - 57ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2710 - acc: 0.8919 - auc-prc: 0.9534 - auc-roc: 0.9547 - val_loss: 0.2741 - val_acc: 0.8906 - val_auc-prc: 0.9528 - val_auc-roc: 0.9533 - 15s/epoch - 57ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2712 - acc: 0.8892 - auc-prc: 0.9533 - auc-roc: 0.9544 - val_loss: 0.2849 - val_acc: 0.8906 - val_auc-prc: 0.9514 - val_auc-roc: 0.9510 - 15s/epoch - 55ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2675 - acc: 0.8918 - auc-prc: 0.9549 - auc-roc: 0.9558 - val_loss: 0.2704 - val_acc: 0.9001 - val_auc-prc: 0.9548 - val_auc-roc: 0.9547 - 15s/epoch - 54ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2644 - acc: 0.8907 - auc-prc: 0.9559 - auc-roc: 0.9567 - val_loss: 0.2735 - val_acc: 0.8948 - val_auc-prc: 0.9543 - val_auc-roc: 0.9543 - 15s/epoch - 56ms/step
Epoch 9/100
268/268 - 15s - loss: 0.2638 - acc: 0.8914 - auc-prc: 0.9563 - auc-roc: 0.9571 - val_loss: 0.2694 - val_acc: 0.8948 - val_auc-prc: 0.9559 - val_auc-roc: 0.9555 - 15s/epoch - 57ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2630 - acc: 0.8938 - auc-prc: 0.9565 - auc-roc: 0.9573 - val_loss: 0.2845 - val_acc: 0.8854 - val_auc-prc: 0.9512 - val_auc-roc: 0.9519 - 15s/epoch - 56ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2585 - acc: 0.8914 - auc-prc: 0.9586 - auc-roc: 0.9590 - val_loss: 0.2722 - val_acc: 0.8938 - val_auc-prc: 0.9543 - val_auc-roc: 0.9545 - 15s/epoch - 56ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2594 - acc: 0.8945 - auc-prc: 0.9578 - auc-roc: 0.9583 - val_loss: 0.2655 - val_acc: 0.8948 - val_auc-prc: 0.9579 - val_auc-roc: 0.9571 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2556 - acc: 0.8929 - auc-prc: 0.9592 - auc-roc: 0.9597 - val_loss: 0.2662 - val_acc: 0.8980 - val_auc-prc: 0.9571 - val_auc-roc: 0.9564 - 15s/epoch - 57ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2531 - acc: 0.8961 - auc-prc: 0.9607 - auc-roc: 0.9607 - val_loss: 0.2676 - val_acc: 0.8917 - val_auc-prc: 0.9572 - val_auc-roc: 0.9566 - 15s/epoch - 56ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2500 - acc: 0.8968 - auc-prc: 0.9617 - auc-roc: 0.9617 - val_loss: 0.2646 - val_acc: 0.8917 - val_auc-prc: 0.9578 - val_auc-roc: 0.9572 - 15s/epoch - 57ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2482 - acc: 0.8970 - auc-prc: 0.9619 - auc-roc: 0.9620 - val_loss: 0.2799 - val_acc: 0.8875 - val_auc-prc: 0.9530 - val_auc-roc: 0.9523 - 15s/epoch - 57ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2462 - acc: 0.8998 - auc-prc: 0.9629 - auc-roc: 0.9628 - val_loss: 0.2676 - val_acc: 0.8938 - val_auc-prc: 0.9590 - val_auc-roc: 0.9581 - 15s/epoch - 55ms/step
Epoch 18/100
268/268 - 14s - loss: 0.2416 - acc: 0.9015 - auc-prc: 0.9640 - auc-roc: 0.9640 - val_loss: 0.2750 - val_acc: 0.8896 - val_auc-prc: 0.9556 - val_auc-roc: 0.9552 - 14s/epoch - 53ms/step
Epoch 19/100
268/268 - 14s - loss: 0.2390 - acc: 0.9015 - auc-prc: 0.9649 - auc-roc: 0.9650 - val_loss: 0.2729 - val_acc: 0.8885 - val_auc-prc: 0.9593 - val_auc-roc: 0.9583 - 14s/epoch - 53ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2393 - acc: 0.9021 - auc-prc: 0.9646 - auc-roc: 0.9648 - val_loss: 0.2818 - val_acc: 0.8864 - val_auc-prc: 0.9546 - val_auc-roc: 0.9538 - 15s/epoch - 56ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2352 - acc: 0.9004 - auc-prc: 0.9663 - auc-roc: 0.9661 - val_loss: 0.2832 - val_acc: 0.8770 - val_auc-prc: 0.9523 - val_auc-roc: 0.9513 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 770ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.88      0.84      0.86       391
           1       0.89      0.92      0.91       560

    accuracy                           0.89       951
   macro avg       0.89      0.88      0.88       951
weighted avg       0.89      0.89      0.89       951

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.48      0.44       391
           1       0.59      0.51      0.55       560

    accuracy                           0.50       951
   macro avg       0.50      0.50      0.49       951
weighted avg       0.51      0.50      0.50       951

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 18s - loss: 0.3322 - acc: 0.8534 - auc-prc: 0.9310 - auc-roc: 0.9322 - val_loss: 0.3081 - val_acc: 0.8696 - val_auc-prc: 0.9420 - val_auc-roc: 0.9424 - 18s/epoch - 66ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2906 - acc: 0.8829 - auc-prc: 0.9453 - auc-roc: 0.9476 - val_loss: 0.2850 - val_acc: 0.8854 - val_auc-prc: 0.9524 - val_auc-roc: 0.9520 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2855 - acc: 0.8848 - auc-prc: 0.9473 - auc-roc: 0.9492 - val_loss: 0.3048 - val_acc: 0.8654 - val_auc-prc: 0.9447 - val_auc-roc: 0.9439 - 15s/epoch - 57ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2773 - acc: 0.8875 - auc-prc: 0.9508 - auc-roc: 0.9524 - val_loss: 0.2757 - val_acc: 0.8875 - val_auc-prc: 0.9551 - val_auc-roc: 0.9544 - 15s/epoch - 57ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2746 - acc: 0.8880 - auc-prc: 0.9522 - auc-roc: 0.9532 - val_loss: 0.2867 - val_acc: 0.8749 - val_auc-prc: 0.9521 - val_auc-roc: 0.9510 - 15s/epoch - 56ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2694 - acc: 0.8934 - auc-prc: 0.9534 - auc-roc: 0.9547 - val_loss: 0.2753 - val_acc: 0.8938 - val_auc-prc: 0.9568 - val_auc-roc: 0.9558 - 15s/epoch - 57ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2678 - acc: 0.8906 - auc-prc: 0.9548 - auc-roc: 0.9557 - val_loss: 0.2817 - val_acc: 0.8875 - val_auc-prc: 0.9568 - val_auc-roc: 0.9557 - 15s/epoch - 56ms/step
Epoch 8/100
268/268 - 14s - loss: 0.2673 - acc: 0.8915 - auc-prc: 0.9548 - auc-roc: 0.9559 - val_loss: 0.2745 - val_acc: 0.8822 - val_auc-prc: 0.9565 - val_auc-roc: 0.9552 - 14s/epoch - 54ms/step
Epoch 9/100
268/268 - 14s - loss: 0.2658 - acc: 0.8945 - auc-prc: 0.9553 - auc-roc: 0.9562 - val_loss: 0.2755 - val_acc: 0.8738 - val_auc-prc: 0.9558 - val_auc-roc: 0.9547 - 14s/epoch - 53ms/step
Epoch 10/100
268/268 - 15s - loss: 0.2627 - acc: 0.8939 - auc-prc: 0.9564 - auc-roc: 0.9574 - val_loss: 0.2750 - val_acc: 0.8854 - val_auc-prc: 0.9573 - val_auc-roc: 0.9559 - 15s/epoch - 57ms/step
Epoch 11/100
268/268 - 15s - loss: 0.2584 - acc: 0.8980 - auc-prc: 0.9579 - auc-roc: 0.9586 - val_loss: 0.2672 - val_acc: 0.8843 - val_auc-prc: 0.9596 - val_auc-roc: 0.9580 - 15s/epoch - 57ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2570 - acc: 0.8973 - auc-prc: 0.9586 - auc-roc: 0.9591 - val_loss: 0.2970 - val_acc: 0.8717 - val_auc-prc: 0.9496 - val_auc-roc: 0.9475 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2550 - acc: 0.8973 - auc-prc: 0.9592 - auc-roc: 0.9600 - val_loss: 0.2695 - val_acc: 0.8938 - val_auc-prc: 0.9598 - val_auc-roc: 0.9585 - 15s/epoch - 57ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2547 - acc: 0.9012 - auc-prc: 0.9594 - auc-roc: 0.9599 - val_loss: 0.2580 - val_acc: 0.8927 - val_auc-prc: 0.9627 - val_auc-roc: 0.9613 - 15s/epoch - 57ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2512 - acc: 0.8977 - auc-prc: 0.9609 - auc-roc: 0.9613 - val_loss: 0.2591 - val_acc: 0.8875 - val_auc-prc: 0.9618 - val_auc-roc: 0.9602 - 15s/epoch - 57ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2472 - acc: 0.8996 - auc-prc: 0.9619 - auc-roc: 0.9625 - val_loss: 0.2615 - val_acc: 0.8822 - val_auc-prc: 0.9606 - val_auc-roc: 0.9593 - 15s/epoch - 54ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2480 - acc: 0.8984 - auc-prc: 0.9619 - auc-roc: 0.9622 - val_loss: 0.2609 - val_acc: 0.8875 - val_auc-prc: 0.9606 - val_auc-roc: 0.9593 - 15s/epoch - 57ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2432 - acc: 0.8996 - auc-prc: 0.9636 - auc-roc: 0.9636 - val_loss: 0.2788 - val_acc: 0.8791 - val_auc-prc: 0.9544 - val_auc-roc: 0.9529 - 15s/epoch - 57ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2418 - acc: 0.9023 - auc-prc: 0.9639 - auc-roc: 0.9640 - val_loss: 0.2667 - val_acc: 0.8812 - val_auc-prc: 0.9597 - val_auc-roc: 0.9581 - 15s/epoch - 57ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2387 - acc: 0.9038 - auc-prc: 0.9649 - auc-roc: 0.9650 - val_loss: 0.2653 - val_acc: 0.8822 - val_auc-prc: 0.9604 - val_auc-roc: 0.9589 - 15s/epoch - 57ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2373 - acc: 0.9023 - auc-prc: 0.9654 - auc-roc: 0.9654 - val_loss: 0.2653 - val_acc: 0.8875 - val_auc-prc: 0.9589 - val_auc-roc: 0.9576 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 745ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       391
           1       0.90      0.92      0.91       560

    accuracy                           0.89       951
   macro avg       0.89      0.89      0.89       951
weighted avg       0.89      0.89      0.89       951

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.45      0.41       391
           1       0.56      0.49      0.52       560

    accuracy                           0.47       951
   macro avg       0.47      0.47      0.47       951
weighted avg       0.49      0.47      0.48       951

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
268/268 - 17s - loss: 0.3278 - acc: 0.8591 - auc-prc: 0.9330 - auc-roc: 0.9344 - val_loss: 0.2835 - val_acc: 0.8875 - val_auc-prc: 0.9491 - val_auc-roc: 0.9500 - 17s/epoch - 64ms/step
Epoch 2/100
268/268 - 15s - loss: 0.2960 - acc: 0.8774 - auc-prc: 0.9446 - auc-roc: 0.9460 - val_loss: 0.2743 - val_acc: 0.8885 - val_auc-prc: 0.9521 - val_auc-roc: 0.9531 - 15s/epoch - 57ms/step
Epoch 3/100
268/268 - 15s - loss: 0.2844 - acc: 0.8847 - auc-prc: 0.9484 - auc-roc: 0.9499 - val_loss: 0.2740 - val_acc: 0.8833 - val_auc-prc: 0.9520 - val_auc-roc: 0.9534 - 15s/epoch - 57ms/step
Epoch 4/100
268/268 - 15s - loss: 0.2805 - acc: 0.8871 - auc-prc: 0.9503 - auc-roc: 0.9515 - val_loss: 0.2635 - val_acc: 0.8959 - val_auc-prc: 0.9551 - val_auc-roc: 0.9565 - 15s/epoch - 56ms/step
Epoch 5/100
268/268 - 15s - loss: 0.2754 - acc: 0.8875 - auc-prc: 0.9518 - auc-roc: 0.9530 - val_loss: 0.2638 - val_acc: 0.8896 - val_auc-prc: 0.9567 - val_auc-roc: 0.9570 - 15s/epoch - 56ms/step
Epoch 6/100
268/268 - 15s - loss: 0.2718 - acc: 0.8899 - auc-prc: 0.9532 - auc-roc: 0.9542 - val_loss: 0.2651 - val_acc: 0.8948 - val_auc-prc: 0.9564 - val_auc-roc: 0.9570 - 15s/epoch - 56ms/step
Epoch 7/100
268/268 - 15s - loss: 0.2706 - acc: 0.8896 - auc-prc: 0.9541 - auc-roc: 0.9546 - val_loss: 0.2795 - val_acc: 0.8896 - val_auc-prc: 0.9505 - val_auc-roc: 0.9516 - 15s/epoch - 56ms/step
Epoch 8/100
268/268 - 15s - loss: 0.2713 - acc: 0.8903 - auc-prc: 0.9543 - auc-roc: 0.9546 - val_loss: 0.2723 - val_acc: 0.8917 - val_auc-prc: 0.9547 - val_auc-roc: 0.9550 - 15s/epoch - 56ms/step
Epoch 9/100
268/268 - 16s - loss: 0.2683 - acc: 0.8900 - auc-prc: 0.9552 - auc-roc: 0.9557 - val_loss: 0.2613 - val_acc: 0.8959 - val_auc-prc: 0.9574 - val_auc-roc: 0.9584 - 16s/epoch - 58ms/step
Epoch 10/100
268/268 - 16s - loss: 0.2644 - acc: 0.8925 - auc-prc: 0.9563 - auc-roc: 0.9569 - val_loss: 0.2594 - val_acc: 0.8938 - val_auc-prc: 0.9575 - val_auc-roc: 0.9587 - 16s/epoch - 59ms/step
Epoch 11/100
268/268 - 16s - loss: 0.2632 - acc: 0.8919 - auc-prc: 0.9571 - auc-roc: 0.9573 - val_loss: 0.2553 - val_acc: 0.8959 - val_auc-prc: 0.9600 - val_auc-roc: 0.9602 - 16s/epoch - 58ms/step
Epoch 12/100
268/268 - 15s - loss: 0.2617 - acc: 0.8932 - auc-prc: 0.9575 - auc-roc: 0.9579 - val_loss: 0.2562 - val_acc: 0.8959 - val_auc-prc: 0.9600 - val_auc-roc: 0.9601 - 15s/epoch - 57ms/step
Epoch 13/100
268/268 - 15s - loss: 0.2570 - acc: 0.8949 - auc-prc: 0.9592 - auc-roc: 0.9594 - val_loss: 0.2557 - val_acc: 0.8938 - val_auc-prc: 0.9609 - val_auc-roc: 0.9610 - 15s/epoch - 58ms/step
Epoch 14/100
268/268 - 15s - loss: 0.2553 - acc: 0.8949 - auc-prc: 0.9598 - auc-roc: 0.9600 - val_loss: 0.2523 - val_acc: 0.8938 - val_auc-prc: 0.9608 - val_auc-roc: 0.9616 - 15s/epoch - 58ms/step
Epoch 15/100
268/268 - 15s - loss: 0.2539 - acc: 0.8934 - auc-prc: 0.9601 - auc-roc: 0.9604 - val_loss: 0.2592 - val_acc: 0.8980 - val_auc-prc: 0.9609 - val_auc-roc: 0.9615 - 15s/epoch - 57ms/step
Epoch 16/100
268/268 - 15s - loss: 0.2541 - acc: 0.8938 - auc-prc: 0.9608 - auc-roc: 0.9605 - val_loss: 0.2531 - val_acc: 0.8991 - val_auc-prc: 0.9612 - val_auc-roc: 0.9619 - 15s/epoch - 57ms/step
Epoch 17/100
268/268 - 15s - loss: 0.2484 - acc: 0.8976 - auc-prc: 0.9624 - auc-roc: 0.9623 - val_loss: 0.2589 - val_acc: 0.8854 - val_auc-prc: 0.9610 - val_auc-roc: 0.9604 - 15s/epoch - 57ms/step
Epoch 18/100
268/268 - 15s - loss: 0.2444 - acc: 0.8991 - auc-prc: 0.9640 - auc-roc: 0.9635 - val_loss: 0.2462 - val_acc: 0.9022 - val_auc-prc: 0.9621 - val_auc-roc: 0.9628 - 15s/epoch - 57ms/step
Epoch 19/100
268/268 - 15s - loss: 0.2436 - acc: 0.8997 - auc-prc: 0.9637 - auc-roc: 0.9636 - val_loss: 0.2537 - val_acc: 0.8938 - val_auc-prc: 0.9610 - val_auc-roc: 0.9611 - 15s/epoch - 57ms/step
Epoch 20/100
268/268 - 15s - loss: 0.2451 - acc: 0.8982 - auc-prc: 0.9636 - auc-roc: 0.9633 - val_loss: 0.2704 - val_acc: 0.8854 - val_auc-prc: 0.9573 - val_auc-roc: 0.9574 - 15s/epoch - 58ms/step
Epoch 21/100
268/268 - 15s - loss: 0.2380 - acc: 0.9016 - auc-prc: 0.9657 - auc-roc: 0.9654 - val_loss: 0.2495 - val_acc: 0.8970 - val_auc-prc: 0.9625 - val_auc-roc: 0.9632 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 748ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       391
           1       0.91      0.92      0.91       560

    accuracy                           0.90       951
   macro avg       0.89      0.89      0.89       951
weighted avg       0.90      0.90      0.90       951

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.52      0.46       391
           1       0.59      0.48      0.53       560

    accuracy                           0.50       951
   macro avg       0.50      0.50      0.50       951
weighted avg       0.52      0.50      0.50       951

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8849] IC [0.8792, 0.8906]
Mean Accuracy[0.8920] IC [0.8861, 0.8978]
Mean Recall[0.8849] IC [0.8792, 0.8906]
Mean F1[0.8876] IC [0.8817, 0.8936]
Median AUC_ROC[0.8811]
Median Accuracy[0.8886]
Median Recall[0.8811]
Median F1[0.8840]
********************txid85962********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.87      0.75      0.81       114
           1       0.96      0.98      0.97       744

    accuracy                           0.95       858
   macro avg       0.92      0.87      0.89       858
weighted avg       0.95      0.95      0.95       858

Predicted  0.0  1.0  All
True                    
0           86   28  114
1           13  731  744
All         99  759  858
**************************************************
fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 19s - loss: 0.3196 - acc: 0.8632 - auc-prc: 0.9360 - auc-roc: 0.9372 - val_loss: 0.2760 - val_acc: 0.8826 - val_auc-prc: 0.9559 - val_auc-roc: 0.9555 - 19s/epoch - 71ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2815 - acc: 0.8859 - auc-prc: 0.9484 - auc-roc: 0.9505 - val_loss: 0.2593 - val_acc: 0.8954 - val_auc-prc: 0.9599 - val_auc-roc: 0.9591 - 15s/epoch - 58ms/step
Epoch 3/100
264/264 - 15s - loss: 0.2731 - acc: 0.8891 - auc-prc: 0.9519 - auc-roc: 0.9537 - val_loss: 0.2703 - val_acc: 0.8858 - val_auc-prc: 0.9572 - val_auc-roc: 0.9563 - 15s/epoch - 56ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2737 - acc: 0.8897 - auc-prc: 0.9523 - auc-roc: 0.9536 - val_loss: 0.2518 - val_acc: 0.8975 - val_auc-prc: 0.9637 - val_auc-roc: 0.9627 - 15s/epoch - 56ms/step
Epoch 5/100
264/264 - 15s - loss: 0.2641 - acc: 0.8944 - auc-prc: 0.9561 - auc-roc: 0.9570 - val_loss: 0.2500 - val_acc: 0.8933 - val_auc-prc: 0.9646 - val_auc-roc: 0.9635 - 15s/epoch - 55ms/step
Epoch 6/100
264/264 - 15s - loss: 0.2620 - acc: 0.8947 - auc-prc: 0.9570 - auc-roc: 0.9576 - val_loss: 0.2523 - val_acc: 0.8890 - val_auc-prc: 0.9653 - val_auc-roc: 0.9637 - 15s/epoch - 56ms/step
Epoch 7/100
264/264 - 15s - loss: 0.2584 - acc: 0.8947 - auc-prc: 0.9579 - auc-roc: 0.9588 - val_loss: 0.2530 - val_acc: 0.8879 - val_auc-prc: 0.9645 - val_auc-roc: 0.9633 - 15s/epoch - 56ms/step
Epoch 8/100
264/264 - 15s - loss: 0.2587 - acc: 0.8934 - auc-prc: 0.9578 - auc-roc: 0.9587 - val_loss: 0.2579 - val_acc: 0.8869 - val_auc-prc: 0.9653 - val_auc-roc: 0.9638 - 15s/epoch - 56ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2534 - acc: 0.8972 - auc-prc: 0.9599 - auc-roc: 0.9604 - val_loss: 0.2422 - val_acc: 0.8954 - val_auc-prc: 0.9678 - val_auc-roc: 0.9665 - 15s/epoch - 57ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2505 - acc: 0.8995 - auc-prc: 0.9607 - auc-roc: 0.9613 - val_loss: 0.2505 - val_acc: 0.8901 - val_auc-prc: 0.9641 - val_auc-roc: 0.9630 - 15s/epoch - 57ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2509 - acc: 0.8998 - auc-prc: 0.9606 - auc-roc: 0.9613 - val_loss: 0.2382 - val_acc: 0.9018 - val_auc-prc: 0.9676 - val_auc-roc: 0.9664 - 15s/epoch - 56ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2474 - acc: 0.9013 - auc-prc: 0.9616 - auc-roc: 0.9621 - val_loss: 0.2406 - val_acc: 0.8975 - val_auc-prc: 0.9677 - val_auc-roc: 0.9664 - 15s/epoch - 56ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2430 - acc: 0.9032 - auc-prc: 0.9627 - auc-roc: 0.9637 - val_loss: 0.2452 - val_acc: 0.8965 - val_auc-prc: 0.9660 - val_auc-roc: 0.9650 - 15s/epoch - 57ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2417 - acc: 0.9064 - auc-prc: 0.9632 - auc-roc: 0.9640 - val_loss: 0.2434 - val_acc: 0.8933 - val_auc-prc: 0.9670 - val_auc-roc: 0.9658 - 15s/epoch - 57ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2389 - acc: 0.9061 - auc-prc: 0.9647 - auc-roc: 0.9648 - val_loss: 0.2385 - val_acc: 0.8933 - val_auc-prc: 0.9675 - val_auc-roc: 0.9663 - 15s/epoch - 57ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2363 - acc: 0.9050 - auc-prc: 0.9654 - auc-roc: 0.9658 - val_loss: 0.2465 - val_acc: 0.8943 - val_auc-prc: 0.9643 - val_auc-roc: 0.9634 - 15s/epoch - 56ms/step
Epoch 17/100
264/264 - 14s - loss: 0.2319 - acc: 0.9090 - auc-prc: 0.9667 - auc-roc: 0.9667 - val_loss: 0.2411 - val_acc: 0.9018 - val_auc-prc: 0.9674 - val_auc-roc: 0.9662 - 14s/epoch - 55ms/step
Epoch 18/100
264/264 - 14s - loss: 0.2300 - acc: 0.9065 - auc-prc: 0.9671 - auc-roc: 0.9676 - val_loss: 0.2416 - val_acc: 0.8943 - val_auc-prc: 0.9659 - val_auc-roc: 0.9649 - 14s/epoch - 52ms/step
Epoch 19/100
264/264 - 14s - loss: 0.2299 - acc: 0.9086 - auc-prc: 0.9673 - auc-roc: 0.9673 - val_loss: 0.2599 - val_acc: 0.8943 - val_auc-prc: 0.9639 - val_auc-roc: 0.9628 - 14s/epoch - 52ms/step
Epoch 20/100
264/264 - 14s - loss: 0.2237 - acc: 0.9090 - auc-prc: 0.9693 - auc-roc: 0.9692 - val_loss: 0.2506 - val_acc: 0.9029 - val_auc-prc: 0.9667 - val_auc-roc: 0.9658 - 14s/epoch - 52ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2210 - acc: 0.9107 - auc-prc: 0.9701 - auc-roc: 0.9700 - val_loss: 0.2486 - val_acc: 0.9007 - val_auc-prc: 0.9652 - val_auc-roc: 0.9644 - 15s/epoch - 55ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 825ms/epoch - 28ms/step
              precision    recall  f1-score   support

           0       0.91      0.83      0.87       390
           1       0.89      0.94      0.91       547

    accuracy                           0.90       937
   macro avg       0.90      0.89      0.89       937
weighted avg       0.90      0.90      0.89       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.47      0.43       390
           1       0.57      0.49      0.53       547

    accuracy                           0.48       937
   macro avg       0.48      0.48      0.48       937
weighted avg       0.50      0.48      0.49       937

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 17s - loss: 0.3227 - acc: 0.8619 - auc-prc: 0.9351 - auc-roc: 0.9361 - val_loss: 0.2371 - val_acc: 0.9029 - val_auc-prc: 0.9644 - val_auc-roc: 0.9675 - 17s/epoch - 65ms/step
Epoch 2/100
264/264 - 14s - loss: 0.2873 - acc: 0.8831 - auc-prc: 0.9479 - auc-roc: 0.9491 - val_loss: 0.2141 - val_acc: 0.9200 - val_auc-prc: 0.9686 - val_auc-roc: 0.9715 - 14s/epoch - 55ms/step
Epoch 3/100
264/264 - 14s - loss: 0.2787 - acc: 0.8833 - auc-prc: 0.9512 - auc-roc: 0.9519 - val_loss: 0.2114 - val_acc: 0.9232 - val_auc-prc: 0.9703 - val_auc-roc: 0.9731 - 14s/epoch - 52ms/step
Epoch 4/100
264/264 - 14s - loss: 0.2770 - acc: 0.8861 - auc-prc: 0.9521 - auc-roc: 0.9526 - val_loss: 0.2130 - val_acc: 0.9253 - val_auc-prc: 0.9700 - val_auc-roc: 0.9726 - 14s/epoch - 53ms/step
Epoch 5/100
264/264 - 14s - loss: 0.2715 - acc: 0.8912 - auc-prc: 0.9534 - auc-roc: 0.9543 - val_loss: 0.2283 - val_acc: 0.9200 - val_auc-prc: 0.9678 - val_auc-roc: 0.9701 - 14s/epoch - 54ms/step
Epoch 6/100
264/264 - 14s - loss: 0.2683 - acc: 0.8916 - auc-prc: 0.9549 - auc-roc: 0.9557 - val_loss: 0.2184 - val_acc: 0.9221 - val_auc-prc: 0.9690 - val_auc-roc: 0.9714 - 14s/epoch - 53ms/step
Epoch 7/100
264/264 - 14s - loss: 0.2632 - acc: 0.8918 - auc-prc: 0.9570 - auc-roc: 0.9574 - val_loss: 0.2141 - val_acc: 0.9157 - val_auc-prc: 0.9703 - val_auc-roc: 0.9718 - 14s/epoch - 53ms/step
Epoch 8/100
264/264 - 14s - loss: 0.2608 - acc: 0.8935 - auc-prc: 0.9582 - auc-roc: 0.9583 - val_loss: 0.2137 - val_acc: 0.9253 - val_auc-prc: 0.9731 - val_auc-roc: 0.9743 - 14s/epoch - 55ms/step
Epoch 9/100
264/264 - 14s - loss: 0.2595 - acc: 0.8940 - auc-prc: 0.9587 - auc-roc: 0.9587 - val_loss: 0.2012 - val_acc: 0.9253 - val_auc-prc: 0.9731 - val_auc-roc: 0.9751 - 14s/epoch - 54ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2575 - acc: 0.8943 - auc-prc: 0.9587 - auc-roc: 0.9593 - val_loss: 0.1998 - val_acc: 0.9264 - val_auc-prc: 0.9731 - val_auc-roc: 0.9752 - 15s/epoch - 56ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2549 - acc: 0.8941 - auc-prc: 0.9602 - auc-roc: 0.9603 - val_loss: 0.2148 - val_acc: 0.9157 - val_auc-prc: 0.9710 - val_auc-roc: 0.9714 - 15s/epoch - 56ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2525 - acc: 0.8966 - auc-prc: 0.9609 - auc-roc: 0.9611 - val_loss: 0.2051 - val_acc: 0.9221 - val_auc-prc: 0.9748 - val_auc-roc: 0.9755 - 15s/epoch - 56ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2491 - acc: 0.8993 - auc-prc: 0.9614 - auc-roc: 0.9619 - val_loss: 0.2004 - val_acc: 0.9221 - val_auc-prc: 0.9731 - val_auc-roc: 0.9751 - 15s/epoch - 56ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2483 - acc: 0.8974 - auc-prc: 0.9624 - auc-roc: 0.9624 - val_loss: 0.2041 - val_acc: 0.9221 - val_auc-prc: 0.9726 - val_auc-roc: 0.9742 - 15s/epoch - 55ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2440 - acc: 0.8994 - auc-prc: 0.9633 - auc-roc: 0.9635 - val_loss: 0.2050 - val_acc: 0.9168 - val_auc-prc: 0.9717 - val_auc-roc: 0.9733 - 15s/epoch - 56ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2451 - acc: 0.8986 - auc-prc: 0.9631 - auc-roc: 0.9633 - val_loss: 0.1993 - val_acc: 0.9200 - val_auc-prc: 0.9737 - val_auc-roc: 0.9750 - 15s/epoch - 56ms/step
Epoch 17/100
264/264 - 15s - loss: 0.2430 - acc: 0.8987 - auc-prc: 0.9639 - auc-roc: 0.9639 - val_loss: 0.1931 - val_acc: 0.9242 - val_auc-prc: 0.9752 - val_auc-roc: 0.9764 - 15s/epoch - 56ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2373 - acc: 0.9017 - auc-prc: 0.9661 - auc-roc: 0.9656 - val_loss: 0.2047 - val_acc: 0.9221 - val_auc-prc: 0.9729 - val_auc-roc: 0.9738 - 15s/epoch - 56ms/step
Epoch 19/100
264/264 - 14s - loss: 0.2355 - acc: 0.9040 - auc-prc: 0.9662 - auc-roc: 0.9660 - val_loss: 0.2128 - val_acc: 0.9157 - val_auc-prc: 0.9716 - val_auc-roc: 0.9723 - 14s/epoch - 55ms/step
Epoch 20/100
264/264 - 14s - loss: 0.2317 - acc: 0.9027 - auc-prc: 0.9674 - auc-roc: 0.9672 - val_loss: 0.2117 - val_acc: 0.9136 - val_auc-prc: 0.9701 - val_auc-roc: 0.9720 - 14s/epoch - 53ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2282 - acc: 0.9069 - auc-prc: 0.9685 - auc-roc: 0.9682 - val_loss: 0.2403 - val_acc: 0.9050 - val_auc-prc: 0.9641 - val_auc-roc: 0.9648 - 15s/epoch - 55ms/step
Epoch 22/100
264/264 - 15s - loss: 0.2261 - acc: 0.9062 - auc-prc: 0.9692 - auc-roc: 0.9688 - val_loss: 0.2125 - val_acc: 0.9125 - val_auc-prc: 0.9706 - val_auc-roc: 0.9720 - 15s/epoch - 56ms/step
Epoch 23/100
264/264 - 15s - loss: 0.2234 - acc: 0.9082 - auc-prc: 0.9699 - auc-roc: 0.9696 - val_loss: 0.2116 - val_acc: 0.9104 - val_auc-prc: 0.9710 - val_auc-roc: 0.9720 - 15s/epoch - 57ms/step
Epoch 24/100
264/264 - 15s - loss: 0.2158 - acc: 0.9123 - auc-prc: 0.9718 - auc-roc: 0.9716 - val_loss: 0.2066 - val_acc: 0.9189 - val_auc-prc: 0.9712 - val_auc-roc: 0.9728 - 15s/epoch - 55ms/step
Epoch 25/100
264/264 - 15s - loss: 0.2123 - acc: 0.9125 - auc-prc: 0.9732 - auc-roc: 0.9726 - val_loss: 0.2143 - val_acc: 0.9157 - val_auc-prc: 0.9697 - val_auc-roc: 0.9710 - 15s/epoch - 56ms/step
Epoch 26/100
264/264 - 15s - loss: 0.2061 - acc: 0.9141 - auc-prc: 0.9741 - auc-roc: 0.9740 - val_loss: 0.2148 - val_acc: 0.9136 - val_auc-prc: 0.9725 - val_auc-roc: 0.9719 - 15s/epoch - 56ms/step
Epoch 27/100
264/264 - 15s - loss: 0.2060 - acc: 0.9141 - auc-prc: 0.9745 - auc-roc: 0.9742 - val_loss: 0.2138 - val_acc: 0.9125 - val_auc-prc: 0.9704 - val_auc-roc: 0.9715 - 15s/epoch - 56ms/step
Epoch 28/100
264/264 - 15s - loss: 0.1992 - acc: 0.9184 - auc-prc: 0.9761 - auc-roc: 0.9758 - val_loss: 0.2190 - val_acc: 0.9136 - val_auc-prc: 0.9719 - val_auc-roc: 0.9713 - 15s/epoch - 56ms/step
Epoch 29/100
264/264 - 15s - loss: 0.1887 - acc: 0.9212 - auc-prc: 0.9785 - auc-roc: 0.9782 - val_loss: 0.2247 - val_acc: 0.9104 - val_auc-prc: 0.9685 - val_auc-roc: 0.9701 - 15s/epoch - 56ms/step
Epoch 30/100
264/264 - 15s - loss: 0.1870 - acc: 0.9248 - auc-prc: 0.9789 - auc-roc: 0.9786 - val_loss: 0.2343 - val_acc: 0.9082 - val_auc-prc: 0.9673 - val_auc-roc: 0.9676 - 15s/epoch - 56ms/step
Epoch 31/100
264/264 - 15s - loss: 0.1795 - acc: 0.9260 - auc-prc: 0.9806 - auc-roc: 0.9804 - val_loss: 0.2440 - val_acc: 0.9061 - val_auc-prc: 0.9642 - val_auc-roc: 0.9648 - 15s/epoch - 56ms/step
Epoch 32/100
264/264 - 15s - loss: 0.1737 - acc: 0.9303 - auc-prc: 0.9816 - auc-roc: 0.9814 - val_loss: 0.2442 - val_acc: 0.9061 - val_auc-prc: 0.9635 - val_auc-roc: 0.9655 - 15s/epoch - 56ms/step
Epoch 33/100
264/264 - 14s - loss: 0.1687 - acc: 0.9312 - auc-prc: 0.9826 - auc-roc: 0.9825 - val_loss: 0.2448 - val_acc: 0.9050 - val_auc-prc: 0.9637 - val_auc-roc: 0.9653 - 14s/epoch - 54ms/step
Epoch 34/100
264/264 - 14s - loss: 0.1637 - acc: 0.9335 - auc-prc: 0.9830 - auc-roc: 0.9833 - val_loss: 0.2382 - val_acc: 0.9114 - val_auc-prc: 0.9672 - val_auc-roc: 0.9685 - 14s/epoch - 53ms/step
Epoch 35/100
264/264 - 14s - loss: 0.1557 - acc: 0.9371 - auc-prc: 0.9843 - auc-roc: 0.9848 - val_loss: 0.2503 - val_acc: 0.9114 - val_auc-prc: 0.9643 - val_auc-roc: 0.9661 - 14s/epoch - 53ms/step
Epoch 36/100
264/264 - 14s - loss: 0.1448 - acc: 0.9415 - auc-prc: 0.9871 - auc-roc: 0.9870 - val_loss: 0.2797 - val_acc: 0.9114 - val_auc-prc: 0.9577 - val_auc-roc: 0.9605 - 14s/epoch - 53ms/step
Epoch 37/100
264/264 - 15s - loss: 0.1442 - acc: 0.9421 - auc-prc: 0.9872 - auc-roc: 0.9871 - val_loss: 0.2740 - val_acc: 0.8986 - val_auc-prc: 0.9574 - val_auc-roc: 0.9598 - 15s/epoch - 56ms/step
Epoch 38/100
264/264 - 15s - loss: 0.1383 - acc: 0.9443 - auc-prc: 0.9880 - auc-roc: 0.9881 - val_loss: 0.2736 - val_acc: 0.9082 - val_auc-prc: 0.9615 - val_auc-roc: 0.9645 - 15s/epoch - 56ms/step
Epoch 39/100
264/264 - 15s - loss: 0.1286 - acc: 0.9477 - auc-prc: 0.9898 - auc-roc: 0.9898 - val_loss: 0.2825 - val_acc: 0.9029 - val_auc-prc: 0.9588 - val_auc-roc: 0.9616 - 15s/epoch - 56ms/step
Epoch 40/100
264/264 - 15s - loss: 0.1268 - acc: 0.9505 - auc-prc: 0.9898 - auc-roc: 0.9899 - val_loss: 0.2823 - val_acc: 0.9104 - val_auc-prc: 0.9582 - val_auc-roc: 0.9621 - 15s/epoch - 56ms/step
Epoch 41/100
264/264 - 14s - loss: 0.1155 - acc: 0.9568 - auc-prc: 0.9912 - auc-roc: 0.9914 - val_loss: 0.3063 - val_acc: 0.8997 - val_auc-prc: 0.9467 - val_auc-roc: 0.9527 - 14s/epoch - 53ms/step
Epoch 42/100
264/264 - 14s - loss: 0.1046 - acc: 0.9571 - auc-prc: 0.9934 - auc-roc: 0.9933 - val_loss: 0.3329 - val_acc: 0.8954 - val_auc-prc: 0.9453 - val_auc-roc: 0.9519 - 14s/epoch - 52ms/step
Epoch 43/100
264/264 - 13s - loss: 0.1005 - acc: 0.9610 - auc-prc: 0.9931 - auc-roc: 0.9934 - val_loss: 0.3456 - val_acc: 0.8837 - val_auc-prc: 0.9419 - val_auc-roc: 0.9469 - 13s/epoch - 51ms/step
Epoch 44/100
264/264 - 13s - loss: 0.1015 - acc: 0.9623 - auc-prc: 0.9935 - auc-roc: 0.9935 - val_loss: 0.3268 - val_acc: 0.8965 - val_auc-prc: 0.9515 - val_auc-roc: 0.9579 - 13s/epoch - 51ms/step
Epoch 45/100
264/264 - 13s - loss: 0.0923 - acc: 0.9651 - auc-prc: 0.9943 - auc-roc: 0.9945 - val_loss: 0.3622 - val_acc: 0.8890 - val_auc-prc: 0.9422 - val_auc-roc: 0.9498 - 13s/epoch - 50ms/step
Epoch 46/100
264/264 - 14s - loss: 0.1009 - acc: 0.9617 - auc-prc: 0.9928 - auc-roc: 0.9932 - val_loss: 0.3466 - val_acc: 0.9029 - val_auc-prc: 0.9428 - val_auc-roc: 0.9510 - 14s/epoch - 52ms/step
Epoch 47/100
264/264 - 13s - loss: 0.0809 - acc: 0.9693 - auc-prc: 0.9958 - auc-roc: 0.9959 - val_loss: 0.3652 - val_acc: 0.8975 - val_auc-prc: 0.9452 - val_auc-roc: 0.9524 - 13s/epoch - 50ms/step
Epoch 48/100
264/264 - 13s - loss: 0.0811 - acc: 0.9683 - auc-prc: 0.9958 - auc-roc: 0.9959 - val_loss: 0.3791 - val_acc: 0.8986 - val_auc-prc: 0.9404 - val_auc-roc: 0.9489 - 13s/epoch - 50ms/step
Epoch 49/100
264/264 - 13s - loss: 0.0792 - acc: 0.9718 - auc-prc: 0.9958 - auc-roc: 0.9959 - val_loss: 0.3854 - val_acc: 0.8965 - val_auc-prc: 0.9397 - val_auc-roc: 0.9491 - 13s/epoch - 50ms/step
Epoch 50/100
264/264 - 13s - loss: 0.0723 - acc: 0.9725 - auc-prc: 0.9963 - auc-roc: 0.9965 - val_loss: 0.3905 - val_acc: 0.8837 - val_auc-prc: 0.9401 - val_auc-roc: 0.9475 - 13s/epoch - 50ms/step
Epoch 51/100
264/264 - 13s - loss: 0.0802 - acc: 0.9684 - auc-prc: 0.9958 - auc-roc: 0.9958 - val_loss: 0.4192 - val_acc: 0.8901 - val_auc-prc: 0.9326 - val_auc-roc: 0.9420 - 13s/epoch - 51ms/step
Epoch 52/100
264/264 - 13s - loss: 0.0588 - acc: 0.9807 - auc-prc: 0.9979 - auc-roc: 0.9979 - val_loss: 0.4366 - val_acc: 0.8805 - val_auc-prc: 0.9358 - val_auc-roc: 0.9446 - 13s/epoch - 50ms/step
Epoch 53/100
264/264 - 13s - loss: 0.0719 - acc: 0.9725 - auc-prc: 0.9964 - auc-roc: 0.9965 - val_loss: 0.4027 - val_acc: 0.8922 - val_auc-prc: 0.9409 - val_auc-roc: 0.9493 - 13s/epoch - 51ms/step
Epoch 54/100
264/264 - 13s - loss: 0.0583 - acc: 0.9795 - auc-prc: 0.9975 - auc-roc: 0.9977 - val_loss: 0.3821 - val_acc: 0.9050 - val_auc-prc: 0.9476 - val_auc-roc: 0.9557 - 13s/epoch - 50ms/step
Epoch 55/100
264/264 - 13s - loss: 0.0579 - acc: 0.9773 - auc-prc: 0.9975 - auc-roc: 0.9976 - val_loss: 0.4250 - val_acc: 0.8901 - val_auc-prc: 0.9389 - val_auc-roc: 0.9474 - 13s/epoch - 50ms/step
Epoch 56/100
264/264 - 13s - loss: 0.0468 - acc: 0.9822 - auc-prc: 0.9987 - auc-roc: 0.9987 - val_loss: 0.4377 - val_acc: 0.8954 - val_auc-prc: 0.9375 - val_auc-roc: 0.9469 - 13s/epoch - 50ms/step
Epoch 57/100
264/264 - 13s - loss: 0.0586 - acc: 0.9775 - auc-prc: 0.9976 - auc-roc: 0.9977 - val_loss: 0.4893 - val_acc: 0.8815 - val_auc-prc: 0.9292 - val_auc-roc: 0.9400 - 13s/epoch - 50ms/step
Epoch 58/100
264/264 - 14s - loss: 0.0479 - acc: 0.9807 - auc-prc: 0.9986 - auc-roc: 0.9986 - val_loss: 0.4788 - val_acc: 0.8869 - val_auc-prc: 0.9340 - val_auc-roc: 0.9439 - 14s/epoch - 51ms/step
Epoch 59/100
264/264 - 13s - loss: 0.0775 - acc: 0.9700 - auc-prc: 0.9955 - auc-roc: 0.9958 - val_loss: 0.4098 - val_acc: 0.8965 - val_auc-prc: 0.9440 - val_auc-roc: 0.9514 - 13s/epoch - 51ms/step
Epoch 60/100
264/264 - 13s - loss: 0.0737 - acc: 0.9727 - auc-prc: 0.9961 - auc-roc: 0.9963 - val_loss: 0.4554 - val_acc: 0.8922 - val_auc-prc: 0.9350 - val_auc-roc: 0.9450 - 13s/epoch - 51ms/step
Epoch 61/100
264/264 - 13s - loss: 0.0446 - acc: 0.9859 - auc-prc: 0.9987 - auc-roc: 0.9987 - val_loss: 0.4667 - val_acc: 0.8933 - val_auc-prc: 0.9391 - val_auc-roc: 0.9478 - 13s/epoch - 50ms/step
Epoch 62/100
264/264 - 13s - loss: 0.0360 - acc: 0.9871 - auc-prc: 0.9991 - auc-roc: 0.9991 - val_loss: 0.4851 - val_acc: 0.8858 - val_auc-prc: 0.9270 - val_auc-roc: 0.9378 - 13s/epoch - 50ms/step
Epoch 63/100
264/264 - 14s - loss: 0.0473 - acc: 0.9833 - auc-prc: 0.9986 - auc-roc: 0.9986 - val_loss: 0.4674 - val_acc: 0.8986 - val_auc-prc: 0.9375 - val_auc-roc: 0.9483 - 14s/epoch - 54ms/step
Epoch 64/100
264/264 - 14s - loss: 0.0463 - acc: 0.9821 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.4796 - val_acc: 0.8975 - val_auc-prc: 0.9360 - val_auc-roc: 0.9464 - 14s/epoch - 54ms/step
Epoch 65/100
264/264 - 15s - loss: 0.0367 - acc: 0.9867 - auc-prc: 0.9992 - auc-roc: 0.9992 - val_loss: 0.4933 - val_acc: 0.9018 - val_auc-prc: 0.9322 - val_auc-roc: 0.9439 - 15s/epoch - 56ms/step
Epoch 66/100
264/264 - 14s - loss: 0.0372 - acc: 0.9884 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.5108 - val_acc: 0.8975 - val_auc-prc: 0.9254 - val_auc-roc: 0.9393 - 14s/epoch - 52ms/step
Epoch 67/100
264/264 - 14s - loss: 0.0447 - acc: 0.9824 - auc-prc: 0.9987 - auc-roc: 0.9987 - val_loss: 0.5032 - val_acc: 0.8826 - val_auc-prc: 0.9324 - val_auc-roc: 0.9423 - 14s/epoch - 52ms/step
Epoch 68/100
264/264 - 14s - loss: 0.0438 - acc: 0.9822 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.5512 - val_acc: 0.8922 - val_auc-prc: 0.9262 - val_auc-roc: 0.9394 - 14s/epoch - 52ms/step
Epoch 69/100
264/264 - 14s - loss: 0.0367 - acc: 0.9873 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.5487 - val_acc: 0.8837 - val_auc-prc: 0.9259 - val_auc-roc: 0.9385 - 14s/epoch - 52ms/step
Epoch 70/100
264/264 - 14s - loss: 0.0318 - acc: 0.9896 - auc-prc: 0.9989 - auc-roc: 0.9991 - val_loss: 0.5895 - val_acc: 0.8805 - val_auc-prc: 0.9148 - val_auc-roc: 0.9302 - 14s/epoch - 52ms/step
Epoch 71/100
264/264 - 13s - loss: 0.0422 - acc: 0.9836 - auc-prc: 0.9985 - auc-roc: 0.9986 - val_loss: 0.5337 - val_acc: 0.8901 - val_auc-prc: 0.9276 - val_auc-roc: 0.9404 - 13s/epoch - 51ms/step
Epoch 72/100
264/264 - 14s - loss: 0.0450 - acc: 0.9835 - auc-prc: 0.9985 - auc-roc: 0.9985 - val_loss: 0.5054 - val_acc: 0.8943 - val_auc-prc: 0.9351 - val_auc-roc: 0.9458 - 14s/epoch - 51ms/step
Epoch 73/100
264/264 - 14s - loss: 0.0311 - acc: 0.9881 - auc-prc: 0.9995 - auc-roc: 0.9994 - val_loss: 0.5103 - val_acc: 0.8986 - val_auc-prc: 0.9343 - val_auc-roc: 0.9463 - 14s/epoch - 51ms/step
Epoch 74/100
264/264 - 13s - loss: 0.0357 - acc: 0.9875 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.5288 - val_acc: 0.8911 - val_auc-prc: 0.9236 - val_auc-roc: 0.9377 - 13s/epoch - 51ms/step
Epoch 75/100
264/264 - 14s - loss: 0.0278 - acc: 0.9911 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.5588 - val_acc: 0.8943 - val_auc-prc: 0.9270 - val_auc-roc: 0.9405 - 14s/epoch - 51ms/step
Epoch 76/100
264/264 - 14s - loss: 0.0309 - acc: 0.9890 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.5619 - val_acc: 0.8911 - val_auc-prc: 0.9196 - val_auc-roc: 0.9342 - 14s/epoch - 52ms/step
Epoch 77/100
264/264 - 14s - loss: 0.0313 - acc: 0.9884 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.5855 - val_acc: 0.8858 - val_auc-prc: 0.9223 - val_auc-roc: 0.9360 - 14s/epoch - 53ms/step
Epoch 78/100
264/264 - 14s - loss: 0.0309 - acc: 0.9904 - auc-prc: 0.9988 - auc-roc: 0.9990 - val_loss: 0.5434 - val_acc: 0.8954 - val_auc-prc: 0.9295 - val_auc-roc: 0.9420 - 14s/epoch - 53ms/step
Epoch 79/100
264/264 - 14s - loss: 0.0435 - acc: 0.9836 - auc-prc: 0.9983 - auc-roc: 0.9984 - val_loss: 0.5855 - val_acc: 0.8869 - val_auc-prc: 0.9223 - val_auc-roc: 0.9352 - 14s/epoch - 54ms/step
Epoch 80/100
264/264 - 14s - loss: 0.0306 - acc: 0.9902 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.5249 - val_acc: 0.9050 - val_auc-prc: 0.9311 - val_auc-roc: 0.9442 - 14s/epoch - 53ms/step
Epoch 81/100
264/264 - 14s - loss: 0.0596 - acc: 0.9775 - auc-prc: 0.9974 - auc-roc: 0.9975 - val_loss: 0.5204 - val_acc: 0.9039 - val_auc-prc: 0.9372 - val_auc-roc: 0.9479 - 14s/epoch - 53ms/step
Epoch 82/100
264/264 - 14s - loss: 0.0283 - acc: 0.9898 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.5259 - val_acc: 0.9018 - val_auc-prc: 0.9370 - val_auc-roc: 0.9483 - 14s/epoch - 53ms/step
Epoch 83/100
264/264 - 14s - loss: 0.0179 - acc: 0.9931 - auc-prc: 0.9999 - auc-roc: 0.9999 - val_loss: 0.5823 - val_acc: 0.8901 - val_auc-prc: 0.9268 - val_auc-roc: 0.9399 - 14s/epoch - 52ms/step
Epoch 84/100
264/264 - 15s - loss: 0.0314 - acc: 0.9885 - auc-prc: 0.9987 - auc-roc: 0.9989 - val_loss: 0.6500 - val_acc: 0.8901 - val_auc-prc: 0.9214 - val_auc-roc: 0.9355 - 15s/epoch - 55ms/step
Epoch 85/100
264/264 - 15s - loss: 0.0231 - acc: 0.9919 - auc-prc: 0.9997 - auc-roc: 0.9997 - val_loss: 0.6116 - val_acc: 0.8933 - val_auc-prc: 0.9255 - val_auc-roc: 0.9395 - 15s/epoch - 55ms/step
Epoch 86/100
264/264 - 15s - loss: 0.0290 - acc: 0.9886 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.6345 - val_acc: 0.8869 - val_auc-prc: 0.9218 - val_auc-roc: 0.9356 - 15s/epoch - 56ms/step
Epoch 87/100
264/264 - 15s - loss: 0.0337 - acc: 0.9881 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.5861 - val_acc: 0.8901 - val_auc-prc: 0.9218 - val_auc-roc: 0.9363 - 15s/epoch - 56ms/step
Epoch 88/100
264/264 - 15s - loss: 0.0410 - acc: 0.9854 - auc-prc: 0.9980 - auc-roc: 0.9983 - val_loss: 0.5643 - val_acc: 0.8997 - val_auc-prc: 0.9355 - val_auc-roc: 0.9474 - 15s/epoch - 56ms/step
Epoch 89/100
264/264 - 14s - loss: 0.0328 - acc: 0.9872 - auc-prc: 0.9989 - auc-roc: 0.9990 - val_loss: 0.5408 - val_acc: 0.8869 - val_auc-prc: 0.9289 - val_auc-roc: 0.9410 - 14s/epoch - 54ms/step
Epoch 90/100
264/264 - 14s - loss: 0.0228 - acc: 0.9940 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.6352 - val_acc: 0.8783 - val_auc-prc: 0.9250 - val_auc-roc: 0.9372 - 14s/epoch - 52ms/step
Early stopping epoch: 89
******Evaluating TEST set*********
30/30 - 1s - 718ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.91      0.90      0.91       390
           1       0.93      0.94      0.94       547

    accuracy                           0.92       937
   macro avg       0.92      0.92      0.92       937
weighted avg       0.92      0.92      0.92       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.51      0.45       390
           1       0.58      0.48      0.52       547

    accuracy                           0.49       937
   macro avg       0.49      0.49      0.49       937
weighted avg       0.51      0.49      0.49       937

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 18s - loss: 0.3106 - acc: 0.8677 - auc-prc: 0.9401 - auc-roc: 0.9409 - val_loss: 0.3326 - val_acc: 0.8613 - val_auc-prc: 0.9304 - val_auc-roc: 0.9326 - 18s/epoch - 67ms/step
Epoch 2/100
264/264 - 14s - loss: 0.2783 - acc: 0.8865 - auc-prc: 0.9512 - auc-roc: 0.9526 - val_loss: 0.3214 - val_acc: 0.8687 - val_auc-prc: 0.9345 - val_auc-roc: 0.9365 - 14s/epoch - 54ms/step
Epoch 3/100
264/264 - 14s - loss: 0.2672 - acc: 0.8929 - auc-prc: 0.9547 - auc-roc: 0.9561 - val_loss: 0.3315 - val_acc: 0.8709 - val_auc-prc: 0.9353 - val_auc-roc: 0.9388 - 14s/epoch - 53ms/step
Epoch 4/100
264/264 - 14s - loss: 0.2640 - acc: 0.8889 - auc-prc: 0.9561 - auc-roc: 0.9570 - val_loss: 0.3091 - val_acc: 0.8783 - val_auc-prc: 0.9395 - val_auc-roc: 0.9406 - 14s/epoch - 52ms/step
Epoch 5/100
264/264 - 14s - loss: 0.2594 - acc: 0.8954 - auc-prc: 0.9577 - auc-roc: 0.9584 - val_loss: 0.3118 - val_acc: 0.8730 - val_auc-prc: 0.9399 - val_auc-roc: 0.9405 - 14s/epoch - 53ms/step
Epoch 6/100
264/264 - 14s - loss: 0.2579 - acc: 0.8938 - auc-prc: 0.9584 - auc-roc: 0.9590 - val_loss: 0.3137 - val_acc: 0.8751 - val_auc-prc: 0.9415 - val_auc-roc: 0.9419 - 14s/epoch - 54ms/step
Epoch 7/100
264/264 - 14s - loss: 0.2558 - acc: 0.8961 - auc-prc: 0.9591 - auc-roc: 0.9597 - val_loss: 0.3092 - val_acc: 0.8709 - val_auc-prc: 0.9424 - val_auc-roc: 0.9427 - 14s/epoch - 52ms/step
Epoch 8/100
264/264 - 14s - loss: 0.2541 - acc: 0.8974 - auc-prc: 0.9597 - auc-roc: 0.9603 - val_loss: 0.3120 - val_acc: 0.8741 - val_auc-prc: 0.9410 - val_auc-roc: 0.9410 - 14s/epoch - 54ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2508 - acc: 0.8980 - auc-prc: 0.9604 - auc-roc: 0.9611 - val_loss: 0.3082 - val_acc: 0.8741 - val_auc-prc: 0.9418 - val_auc-roc: 0.9426 - 15s/epoch - 55ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2502 - acc: 0.8968 - auc-prc: 0.9612 - auc-roc: 0.9615 - val_loss: 0.3569 - val_acc: 0.8485 - val_auc-prc: 0.9319 - val_auc-roc: 0.9323 - 15s/epoch - 56ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2493 - acc: 0.8986 - auc-prc: 0.9613 - auc-roc: 0.9617 - val_loss: 0.3135 - val_acc: 0.8762 - val_auc-prc: 0.9417 - val_auc-roc: 0.9414 - 15s/epoch - 56ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2449 - acc: 0.8994 - auc-prc: 0.9627 - auc-roc: 0.9632 - val_loss: 0.3059 - val_acc: 0.8773 - val_auc-prc: 0.9427 - val_auc-roc: 0.9427 - 15s/epoch - 56ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2428 - acc: 0.9037 - auc-prc: 0.9632 - auc-roc: 0.9637 - val_loss: 0.3104 - val_acc: 0.8805 - val_auc-prc: 0.9447 - val_auc-roc: 0.9442 - 15s/epoch - 57ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2392 - acc: 0.9016 - auc-prc: 0.9649 - auc-roc: 0.9648 - val_loss: 0.3251 - val_acc: 0.8783 - val_auc-prc: 0.9432 - val_auc-roc: 0.9435 - 15s/epoch - 56ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2362 - acc: 0.9051 - auc-prc: 0.9656 - auc-roc: 0.9657 - val_loss: 0.3038 - val_acc: 0.8773 - val_auc-prc: 0.9438 - val_auc-roc: 0.9432 - 15s/epoch - 57ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2341 - acc: 0.9057 - auc-prc: 0.9662 - auc-roc: 0.9663 - val_loss: 0.3016 - val_acc: 0.8805 - val_auc-prc: 0.9462 - val_auc-roc: 0.9454 - 15s/epoch - 57ms/step
Epoch 17/100
264/264 - 15s - loss: 0.2326 - acc: 0.9044 - auc-prc: 0.9668 - auc-roc: 0.9669 - val_loss: 0.2980 - val_acc: 0.8858 - val_auc-prc: 0.9463 - val_auc-roc: 0.9455 - 15s/epoch - 57ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2293 - acc: 0.9062 - auc-prc: 0.9676 - auc-roc: 0.9677 - val_loss: 0.3194 - val_acc: 0.8815 - val_auc-prc: 0.9472 - val_auc-roc: 0.9462 - 15s/epoch - 57ms/step
Epoch 19/100
264/264 - 15s - loss: 0.2271 - acc: 0.9072 - auc-prc: 0.9680 - auc-roc: 0.9682 - val_loss: 0.3086 - val_acc: 0.8762 - val_auc-prc: 0.9455 - val_auc-roc: 0.9443 - 15s/epoch - 56ms/step
Epoch 20/100
264/264 - 15s - loss: 0.2239 - acc: 0.9083 - auc-prc: 0.9691 - auc-roc: 0.9692 - val_loss: 0.3142 - val_acc: 0.8762 - val_auc-prc: 0.9457 - val_auc-roc: 0.9462 - 15s/epoch - 55ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2207 - acc: 0.9137 - auc-prc: 0.9697 - auc-roc: 0.9700 - val_loss: 0.3040 - val_acc: 0.8773 - val_auc-prc: 0.9484 - val_auc-roc: 0.9472 - 15s/epoch - 57ms/step
Epoch 22/100
264/264 - 15s - loss: 0.2176 - acc: 0.9125 - auc-prc: 0.9708 - auc-roc: 0.9709 - val_loss: 0.3153 - val_acc: 0.8773 - val_auc-prc: 0.9454 - val_auc-roc: 0.9453 - 15s/epoch - 56ms/step
Epoch 23/100
264/264 - 15s - loss: 0.2135 - acc: 0.9139 - auc-prc: 0.9715 - auc-roc: 0.9719 - val_loss: 0.3177 - val_acc: 0.8730 - val_auc-prc: 0.9417 - val_auc-roc: 0.9411 - 15s/epoch - 56ms/step
Epoch 24/100
264/264 - 15s - loss: 0.2118 - acc: 0.9154 - auc-prc: 0.9720 - auc-roc: 0.9724 - val_loss: 0.3117 - val_acc: 0.8826 - val_auc-prc: 0.9482 - val_auc-roc: 0.9478 - 15s/epoch - 57ms/step
Epoch 25/100
264/264 - 15s - loss: 0.2051 - acc: 0.9159 - auc-prc: 0.9745 - auc-roc: 0.9742 - val_loss: 0.3193 - val_acc: 0.8805 - val_auc-prc: 0.9485 - val_auc-roc: 0.9479 - 15s/epoch - 57ms/step
Epoch 26/100
264/264 - 15s - loss: 0.2018 - acc: 0.9173 - auc-prc: 0.9747 - auc-roc: 0.9749 - val_loss: 0.3125 - val_acc: 0.8730 - val_auc-prc: 0.9472 - val_auc-roc: 0.9479 - 15s/epoch - 56ms/step
Epoch 27/100
264/264 - 15s - loss: 0.1959 - acc: 0.9202 - auc-prc: 0.9767 - auc-roc: 0.9764 - val_loss: 0.3364 - val_acc: 0.8719 - val_auc-prc: 0.9412 - val_auc-roc: 0.9438 - 15s/epoch - 56ms/step
Epoch 28/100
264/264 - 15s - loss: 0.1940 - acc: 0.9214 - auc-prc: 0.9771 - auc-roc: 0.9769 - val_loss: 0.3251 - val_acc: 0.8805 - val_auc-prc: 0.9456 - val_auc-roc: 0.9469 - 15s/epoch - 56ms/step
Epoch 29/100
264/264 - 15s - loss: 0.1872 - acc: 0.9265 - auc-prc: 0.9783 - auc-roc: 0.9784 - val_loss: 0.3177 - val_acc: 0.8751 - val_auc-prc: 0.9473 - val_auc-roc: 0.9458 - 15s/epoch - 56ms/step
Epoch 30/100
264/264 - 15s - loss: 0.1844 - acc: 0.9267 - auc-prc: 0.9793 - auc-roc: 0.9791 - val_loss: 0.3392 - val_acc: 0.8677 - val_auc-prc: 0.9380 - val_auc-roc: 0.9377 - 15s/epoch - 56ms/step
Early stopping epoch: 29
******Evaluating TEST set*********
30/30 - 1s - 745ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.87      0.84      0.85       390
           1       0.89      0.91      0.90       547

    accuracy                           0.88       937
   macro avg       0.88      0.88      0.88       937
weighted avg       0.88      0.88      0.88       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.43      0.52      0.47       390
           1       0.59      0.50      0.55       547

    accuracy                           0.51       937
   macro avg       0.51      0.51      0.51       937
weighted avg       0.52      0.51      0.51       937

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 16s - loss: 0.3143 - acc: 0.8668 - auc-prc: 0.9383 - auc-roc: 0.9396 - val_loss: 0.2975 - val_acc: 0.8730 - val_auc-prc: 0.9460 - val_auc-roc: 0.9458 - 16s/epoch - 61ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2868 - acc: 0.8809 - auc-prc: 0.9470 - auc-roc: 0.9491 - val_loss: 0.2739 - val_acc: 0.8890 - val_auc-prc: 0.9526 - val_auc-roc: 0.9530 - 15s/epoch - 57ms/step
Epoch 3/100
264/264 - 15s - loss: 0.2766 - acc: 0.8889 - auc-prc: 0.9506 - auc-roc: 0.9523 - val_loss: 0.2785 - val_acc: 0.8869 - val_auc-prc: 0.9535 - val_auc-roc: 0.9534 - 15s/epoch - 57ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2753 - acc: 0.8887 - auc-prc: 0.9510 - auc-roc: 0.9529 - val_loss: 0.2679 - val_acc: 0.8975 - val_auc-prc: 0.9564 - val_auc-roc: 0.9559 - 15s/epoch - 57ms/step
Epoch 5/100
264/264 - 15s - loss: 0.2652 - acc: 0.8921 - auc-prc: 0.9559 - auc-roc: 0.9566 - val_loss: 0.2604 - val_acc: 0.8943 - val_auc-prc: 0.9593 - val_auc-roc: 0.9587 - 15s/epoch - 57ms/step
Epoch 6/100
264/264 - 15s - loss: 0.2624 - acc: 0.8930 - auc-prc: 0.9566 - auc-roc: 0.9576 - val_loss: 0.2608 - val_acc: 0.8943 - val_auc-prc: 0.9588 - val_auc-roc: 0.9581 - 15s/epoch - 57ms/step
Epoch 7/100
264/264 - 15s - loss: 0.2607 - acc: 0.8925 - auc-prc: 0.9571 - auc-roc: 0.9580 - val_loss: 0.2582 - val_acc: 0.9007 - val_auc-prc: 0.9613 - val_auc-roc: 0.9604 - 15s/epoch - 57ms/step
Epoch 8/100
264/264 - 15s - loss: 0.2575 - acc: 0.8959 - auc-prc: 0.9584 - auc-roc: 0.9591 - val_loss: 0.2856 - val_acc: 0.8911 - val_auc-prc: 0.9560 - val_auc-roc: 0.9547 - 15s/epoch - 57ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2597 - acc: 0.8940 - auc-prc: 0.9579 - auc-roc: 0.9586 - val_loss: 0.2554 - val_acc: 0.8954 - val_auc-prc: 0.9608 - val_auc-roc: 0.9601 - 15s/epoch - 56ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2530 - acc: 0.8978 - auc-prc: 0.9595 - auc-roc: 0.9603 - val_loss: 0.2540 - val_acc: 0.8954 - val_auc-prc: 0.9625 - val_auc-roc: 0.9616 - 15s/epoch - 57ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2499 - acc: 0.8984 - auc-prc: 0.9615 - auc-roc: 0.9616 - val_loss: 0.2817 - val_acc: 0.8911 - val_auc-prc: 0.9526 - val_auc-roc: 0.9526 - 15s/epoch - 57ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2492 - acc: 0.8974 - auc-prc: 0.9616 - auc-roc: 0.9618 - val_loss: 0.2565 - val_acc: 0.8933 - val_auc-prc: 0.9613 - val_auc-roc: 0.9606 - 15s/epoch - 57ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2473 - acc: 0.8992 - auc-prc: 0.9622 - auc-roc: 0.9625 - val_loss: 0.2500 - val_acc: 0.8911 - val_auc-prc: 0.9635 - val_auc-roc: 0.9624 - 15s/epoch - 56ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2439 - acc: 0.9000 - auc-prc: 0.9628 - auc-roc: 0.9634 - val_loss: 0.2671 - val_acc: 0.8890 - val_auc-prc: 0.9605 - val_auc-roc: 0.9594 - 15s/epoch - 56ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2418 - acc: 0.9007 - auc-prc: 0.9640 - auc-roc: 0.9640 - val_loss: 0.2408 - val_acc: 0.9029 - val_auc-prc: 0.9665 - val_auc-roc: 0.9659 - 15s/epoch - 57ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2430 - acc: 0.8981 - auc-prc: 0.9638 - auc-roc: 0.9638 - val_loss: 0.2655 - val_acc: 0.8879 - val_auc-prc: 0.9584 - val_auc-roc: 0.9580 - 15s/epoch - 55ms/step
Epoch 17/100
264/264 - 14s - loss: 0.2377 - acc: 0.9035 - auc-prc: 0.9654 - auc-roc: 0.9654 - val_loss: 0.2454 - val_acc: 0.9050 - val_auc-prc: 0.9651 - val_auc-roc: 0.9647 - 14s/epoch - 52ms/step
Epoch 18/100
264/264 - 14s - loss: 0.2346 - acc: 0.9007 - auc-prc: 0.9668 - auc-roc: 0.9665 - val_loss: 0.2463 - val_acc: 0.8954 - val_auc-prc: 0.9637 - val_auc-roc: 0.9632 - 14s/epoch - 52ms/step
Epoch 19/100
264/264 - 14s - loss: 0.2328 - acc: 0.9030 - auc-prc: 0.9672 - auc-roc: 0.9668 - val_loss: 0.2650 - val_acc: 0.8879 - val_auc-prc: 0.9594 - val_auc-roc: 0.9585 - 14s/epoch - 53ms/step
Epoch 20/100
264/264 - 14s - loss: 0.2291 - acc: 0.9074 - auc-prc: 0.9681 - auc-roc: 0.9680 - val_loss: 0.2490 - val_acc: 0.8997 - val_auc-prc: 0.9638 - val_auc-roc: 0.9629 - 14s/epoch - 54ms/step
Epoch 21/100
264/264 - 14s - loss: 0.2255 - acc: 0.9068 - auc-prc: 0.9690 - auc-roc: 0.9688 - val_loss: 0.2507 - val_acc: 0.9018 - val_auc-prc: 0.9636 - val_auc-roc: 0.9627 - 14s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 699ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.90      0.86      0.88       390
           1       0.90      0.93      0.92       547

    accuracy                           0.90       937
   macro avg       0.90      0.90      0.90       937
weighted avg       0.90      0.90      0.90       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.48      0.44       390
           1       0.58      0.51      0.54       547

    accuracy                           0.50       937
   macro avg       0.49      0.49      0.49       937
weighted avg       0.51      0.50      0.50       937

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 17s - loss: 0.3165 - acc: 0.8649 - auc-prc: 0.9380 - auc-roc: 0.9389 - val_loss: 0.3110 - val_acc: 0.8762 - val_auc-prc: 0.9386 - val_auc-roc: 0.9414 - 17s/epoch - 65ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2819 - acc: 0.8868 - auc-prc: 0.9488 - auc-roc: 0.9508 - val_loss: 0.2990 - val_acc: 0.8815 - val_auc-prc: 0.9423 - val_auc-roc: 0.9449 - 15s/epoch - 55ms/step
Epoch 3/100
264/264 - 14s - loss: 0.2729 - acc: 0.8900 - auc-prc: 0.9523 - auc-roc: 0.9537 - val_loss: 0.3383 - val_acc: 0.8591 - val_auc-prc: 0.9322 - val_auc-roc: 0.9323 - 14s/epoch - 55ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2717 - acc: 0.8879 - auc-prc: 0.9539 - auc-roc: 0.9546 - val_loss: 0.3055 - val_acc: 0.8858 - val_auc-prc: 0.9416 - val_auc-roc: 0.9438 - 15s/epoch - 55ms/step
Epoch 5/100
264/264 - 14s - loss: 0.2651 - acc: 0.8951 - auc-prc: 0.9559 - auc-roc: 0.9567 - val_loss: 0.2993 - val_acc: 0.8698 - val_auc-prc: 0.9434 - val_auc-roc: 0.9446 - 14s/epoch - 55ms/step
Epoch 6/100
264/264 - 14s - loss: 0.2572 - acc: 0.8972 - auc-prc: 0.9584 - auc-roc: 0.9590 - val_loss: 0.2896 - val_acc: 0.8847 - val_auc-prc: 0.9473 - val_auc-roc: 0.9481 - 14s/epoch - 54ms/step
Epoch 7/100
264/264 - 14s - loss: 0.2548 - acc: 0.8976 - auc-prc: 0.9593 - auc-roc: 0.9598 - val_loss: 0.2885 - val_acc: 0.8762 - val_auc-prc: 0.9486 - val_auc-roc: 0.9496 - 14s/epoch - 52ms/step
Epoch 8/100
264/264 - 14s - loss: 0.2557 - acc: 0.8974 - auc-prc: 0.9588 - auc-roc: 0.9594 - val_loss: 0.2860 - val_acc: 0.8869 - val_auc-prc: 0.9492 - val_auc-roc: 0.9502 - 14s/epoch - 53ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2508 - acc: 0.8999 - auc-prc: 0.9611 - auc-roc: 0.9615 - val_loss: 0.2985 - val_acc: 0.8698 - val_auc-prc: 0.9457 - val_auc-roc: 0.9466 - 15s/epoch - 56ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2495 - acc: 0.8985 - auc-prc: 0.9614 - auc-roc: 0.9617 - val_loss: 0.2856 - val_acc: 0.8837 - val_auc-prc: 0.9498 - val_auc-roc: 0.9507 - 15s/epoch - 56ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2464 - acc: 0.8984 - auc-prc: 0.9621 - auc-roc: 0.9627 - val_loss: 0.2887 - val_acc: 0.8879 - val_auc-prc: 0.9491 - val_auc-roc: 0.9493 - 15s/epoch - 56ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2403 - acc: 0.9019 - auc-prc: 0.9646 - auc-roc: 0.9646 - val_loss: 0.2905 - val_acc: 0.8794 - val_auc-prc: 0.9491 - val_auc-roc: 0.9493 - 15s/epoch - 56ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2395 - acc: 0.9014 - auc-prc: 0.9645 - auc-roc: 0.9649 - val_loss: 0.2852 - val_acc: 0.8890 - val_auc-prc: 0.9506 - val_auc-roc: 0.9514 - 15s/epoch - 56ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2346 - acc: 0.9067 - auc-prc: 0.9661 - auc-roc: 0.9663 - val_loss: 0.2939 - val_acc: 0.8805 - val_auc-prc: 0.9491 - val_auc-roc: 0.9489 - 15s/epoch - 56ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2367 - acc: 0.9037 - auc-prc: 0.9655 - auc-roc: 0.9656 - val_loss: 0.2934 - val_acc: 0.8805 - val_auc-prc: 0.9499 - val_auc-roc: 0.9503 - 15s/epoch - 56ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2319 - acc: 0.9052 - auc-prc: 0.9666 - auc-roc: 0.9669 - val_loss: 0.3005 - val_acc: 0.8826 - val_auc-prc: 0.9491 - val_auc-roc: 0.9493 - 15s/epoch - 56ms/step
Epoch 17/100
264/264 - 15s - loss: 0.2323 - acc: 0.9062 - auc-prc: 0.9669 - auc-roc: 0.9671 - val_loss: 0.2813 - val_acc: 0.8869 - val_auc-prc: 0.9520 - val_auc-roc: 0.9520 - 15s/epoch - 56ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2274 - acc: 0.9067 - auc-prc: 0.9683 - auc-roc: 0.9685 - val_loss: 0.2825 - val_acc: 0.8911 - val_auc-prc: 0.9510 - val_auc-roc: 0.9518 - 15s/epoch - 56ms/step
Epoch 19/100
264/264 - 15s - loss: 0.2236 - acc: 0.9094 - auc-prc: 0.9690 - auc-roc: 0.9693 - val_loss: 0.2978 - val_acc: 0.8826 - val_auc-prc: 0.9462 - val_auc-roc: 0.9467 - 15s/epoch - 56ms/step
Epoch 20/100
264/264 - 15s - loss: 0.2238 - acc: 0.9103 - auc-prc: 0.9695 - auc-roc: 0.9695 - val_loss: 0.2947 - val_acc: 0.8805 - val_auc-prc: 0.9479 - val_auc-roc: 0.9489 - 15s/epoch - 57ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2165 - acc: 0.9153 - auc-prc: 0.9713 - auc-roc: 0.9711 - val_loss: 0.3141 - val_acc: 0.8751 - val_auc-prc: 0.9416 - val_auc-roc: 0.9419 - 15s/epoch - 57ms/step
Epoch 22/100
264/264 - 15s - loss: 0.2139 - acc: 0.9129 - auc-prc: 0.9723 - auc-roc: 0.9721 - val_loss: 0.2975 - val_acc: 0.8719 - val_auc-prc: 0.9468 - val_auc-roc: 0.9461 - 15s/epoch - 56ms/step
Epoch 23/100
264/264 - 15s - loss: 0.2089 - acc: 0.9163 - auc-prc: 0.9733 - auc-roc: 0.9733 - val_loss: 0.2908 - val_acc: 0.8933 - val_auc-prc: 0.9491 - val_auc-roc: 0.9511 - 15s/epoch - 57ms/step
Early stopping epoch: 22
******Evaluating TEST set*********
30/30 - 1s - 727ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.84      0.86       390
           1       0.89      0.92      0.90       547

    accuracy                           0.89       937
   macro avg       0.89      0.88      0.88       937
weighted avg       0.89      0.89      0.89       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.46      0.42       390
           1       0.56      0.49      0.52       547

    accuracy                           0.47       937
   macro avg       0.47      0.47      0.47       937
weighted avg       0.49      0.47      0.48       937

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 17s - loss: 0.3203 - acc: 0.8613 - auc-prc: 0.9363 - auc-roc: 0.9373 - val_loss: 0.2898 - val_acc: 0.8634 - val_auc-prc: 0.9477 - val_auc-roc: 0.9484 - 17s/epoch - 65ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2890 - acc: 0.8822 - auc-prc: 0.9464 - auc-roc: 0.9484 - val_loss: 0.2767 - val_acc: 0.8826 - val_auc-prc: 0.9515 - val_auc-roc: 0.9527 - 15s/epoch - 56ms/step
Epoch 3/100
264/264 - 15s - loss: 0.2760 - acc: 0.8906 - auc-prc: 0.9507 - auc-roc: 0.9523 - val_loss: 0.2697 - val_acc: 0.8890 - val_auc-prc: 0.9545 - val_auc-roc: 0.9551 - 15s/epoch - 55ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2726 - acc: 0.8918 - auc-prc: 0.9519 - auc-roc: 0.9536 - val_loss: 0.2696 - val_acc: 0.8975 - val_auc-prc: 0.9544 - val_auc-roc: 0.9556 - 15s/epoch - 56ms/step
Epoch 5/100
264/264 - 15s - loss: 0.2697 - acc: 0.8923 - auc-prc: 0.9537 - auc-roc: 0.9549 - val_loss: 0.2624 - val_acc: 0.8933 - val_auc-prc: 0.9573 - val_auc-roc: 0.9579 - 15s/epoch - 56ms/step
Epoch 6/100
264/264 - 14s - loss: 0.2616 - acc: 0.8956 - auc-prc: 0.9566 - auc-roc: 0.9577 - val_loss: 0.2598 - val_acc: 0.8986 - val_auc-prc: 0.9590 - val_auc-roc: 0.9591 - 14s/epoch - 55ms/step
Epoch 7/100
264/264 - 14s - loss: 0.2601 - acc: 0.8962 - auc-prc: 0.9577 - auc-roc: 0.9582 - val_loss: 0.2596 - val_acc: 0.8954 - val_auc-prc: 0.9576 - val_auc-roc: 0.9585 - 14s/epoch - 54ms/step
Epoch 8/100
264/264 - 15s - loss: 0.2565 - acc: 0.8970 - auc-prc: 0.9588 - auc-roc: 0.9596 - val_loss: 0.2641 - val_acc: 0.8922 - val_auc-prc: 0.9593 - val_auc-roc: 0.9596 - 15s/epoch - 55ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2553 - acc: 0.8978 - auc-prc: 0.9594 - auc-roc: 0.9598 - val_loss: 0.2590 - val_acc: 0.8922 - val_auc-prc: 0.9590 - val_auc-roc: 0.9597 - 15s/epoch - 58ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2501 - acc: 0.8989 - auc-prc: 0.9611 - auc-roc: 0.9618 - val_loss: 0.2657 - val_acc: 0.8762 - val_auc-prc: 0.9578 - val_auc-roc: 0.9568 - 15s/epoch - 57ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2509 - acc: 0.8969 - auc-prc: 0.9611 - auc-roc: 0.9613 - val_loss: 0.2549 - val_acc: 0.9018 - val_auc-prc: 0.9587 - val_auc-roc: 0.9598 - 15s/epoch - 55ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2474 - acc: 0.8993 - auc-prc: 0.9619 - auc-roc: 0.9624 - val_loss: 0.2655 - val_acc: 0.8997 - val_auc-prc: 0.9576 - val_auc-roc: 0.9586 - 15s/epoch - 56ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2439 - acc: 0.8998 - auc-prc: 0.9631 - auc-roc: 0.9635 - val_loss: 0.2538 - val_acc: 0.8997 - val_auc-prc: 0.9612 - val_auc-roc: 0.9618 - 15s/epoch - 57ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2423 - acc: 0.9023 - auc-prc: 0.9639 - auc-roc: 0.9640 - val_loss: 0.2555 - val_acc: 0.8933 - val_auc-prc: 0.9594 - val_auc-roc: 0.9599 - 15s/epoch - 57ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2393 - acc: 0.9026 - auc-prc: 0.9644 - auc-roc: 0.9648 - val_loss: 0.2616 - val_acc: 0.8922 - val_auc-prc: 0.9586 - val_auc-roc: 0.9588 - 15s/epoch - 56ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2355 - acc: 0.9059 - auc-prc: 0.9655 - auc-roc: 0.9659 - val_loss: 0.2716 - val_acc: 0.8911 - val_auc-prc: 0.9581 - val_auc-roc: 0.9574 - 15s/epoch - 57ms/step
Epoch 17/100
264/264 - 15s - loss: 0.2346 - acc: 0.9014 - auc-prc: 0.9659 - auc-roc: 0.9663 - val_loss: 0.2590 - val_acc: 0.8965 - val_auc-prc: 0.9581 - val_auc-roc: 0.9589 - 15s/epoch - 57ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2304 - acc: 0.9065 - auc-prc: 0.9672 - auc-roc: 0.9674 - val_loss: 0.2675 - val_acc: 0.8975 - val_auc-prc: 0.9581 - val_auc-roc: 0.9587 - 15s/epoch - 57ms/step
Epoch 19/100
264/264 - 15s - loss: 0.2302 - acc: 0.9048 - auc-prc: 0.9672 - auc-roc: 0.9674 - val_loss: 0.2620 - val_acc: 0.8901 - val_auc-prc: 0.9575 - val_auc-roc: 0.9578 - 15s/epoch - 57ms/step
Epoch 20/100
264/264 - 15s - loss: 0.2254 - acc: 0.9077 - auc-prc: 0.9690 - auc-roc: 0.9690 - val_loss: 0.2777 - val_acc: 0.8879 - val_auc-prc: 0.9520 - val_auc-roc: 0.9534 - 15s/epoch - 57ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2220 - acc: 0.9084 - auc-prc: 0.9695 - auc-roc: 0.9698 - val_loss: 0.2753 - val_acc: 0.8965 - val_auc-prc: 0.9523 - val_auc-roc: 0.9537 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 764ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.90      0.85      0.88       390
           1       0.90      0.93      0.92       547

    accuracy                           0.90       937
   macro avg       0.90      0.89      0.90       937
weighted avg       0.90      0.90      0.90       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.45      0.55      0.49       390
           1       0.62      0.52      0.56       547

    accuracy                           0.53       937
   macro avg       0.53      0.53      0.53       937
weighted avg       0.55      0.53      0.53       937

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 17s - loss: 0.3125 - acc: 0.8672 - auc-prc: 0.9387 - auc-roc: 0.9405 - val_loss: 0.3290 - val_acc: 0.8666 - val_auc-prc: 0.9336 - val_auc-roc: 0.9359 - 17s/epoch - 64ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2790 - acc: 0.8866 - auc-prc: 0.9504 - auc-roc: 0.9519 - val_loss: 0.3252 - val_acc: 0.8655 - val_auc-prc: 0.9380 - val_auc-roc: 0.9397 - 15s/epoch - 57ms/step
Epoch 3/100
264/264 - 14s - loss: 0.2703 - acc: 0.8917 - auc-prc: 0.9533 - auc-roc: 0.9550 - val_loss: 0.3039 - val_acc: 0.8751 - val_auc-prc: 0.9402 - val_auc-roc: 0.9425 - 14s/epoch - 53ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2640 - acc: 0.8931 - auc-prc: 0.9556 - auc-roc: 0.9568 - val_loss: 0.3045 - val_acc: 0.8645 - val_auc-prc: 0.9460 - val_auc-roc: 0.9469 - 15s/epoch - 57ms/step
Epoch 5/100
264/264 - 15s - loss: 0.2648 - acc: 0.8923 - auc-prc: 0.9559 - auc-roc: 0.9568 - val_loss: 0.3205 - val_acc: 0.8730 - val_auc-prc: 0.9335 - val_auc-roc: 0.9359 - 15s/epoch - 57ms/step
Epoch 6/100
264/264 - 15s - loss: 0.2550 - acc: 0.8978 - auc-prc: 0.9595 - auc-roc: 0.9601 - val_loss: 0.3074 - val_acc: 0.8719 - val_auc-prc: 0.9406 - val_auc-roc: 0.9422 - 15s/epoch - 56ms/step
Epoch 7/100
264/264 - 15s - loss: 0.2550 - acc: 0.8981 - auc-prc: 0.9596 - auc-roc: 0.9601 - val_loss: 0.3269 - val_acc: 0.8698 - val_auc-prc: 0.9458 - val_auc-roc: 0.9469 - 15s/epoch - 57ms/step
Epoch 8/100
264/264 - 15s - loss: 0.2514 - acc: 0.9004 - auc-prc: 0.9611 - auc-roc: 0.9613 - val_loss: 0.3121 - val_acc: 0.8719 - val_auc-prc: 0.9419 - val_auc-roc: 0.9429 - 15s/epoch - 57ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2508 - acc: 0.8966 - auc-prc: 0.9606 - auc-roc: 0.9612 - val_loss: 0.2974 - val_acc: 0.8762 - val_auc-prc: 0.9471 - val_auc-roc: 0.9483 - 15s/epoch - 58ms/step
Epoch 10/100
264/264 - 15s - loss: 0.2496 - acc: 0.9011 - auc-prc: 0.9613 - auc-roc: 0.9617 - val_loss: 0.2903 - val_acc: 0.8709 - val_auc-prc: 0.9490 - val_auc-roc: 0.9503 - 15s/epoch - 58ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2470 - acc: 0.8998 - auc-prc: 0.9626 - auc-roc: 0.9626 - val_loss: 0.2960 - val_acc: 0.8666 - val_auc-prc: 0.9491 - val_auc-roc: 0.9499 - 15s/epoch - 57ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2449 - acc: 0.8997 - auc-prc: 0.9631 - auc-roc: 0.9633 - val_loss: 0.2865 - val_acc: 0.8741 - val_auc-prc: 0.9514 - val_auc-roc: 0.9517 - 15s/epoch - 58ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2433 - acc: 0.9001 - auc-prc: 0.9639 - auc-roc: 0.9638 - val_loss: 0.3059 - val_acc: 0.8687 - val_auc-prc: 0.9456 - val_auc-roc: 0.9475 - 15s/epoch - 57ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2394 - acc: 0.9042 - auc-prc: 0.9646 - auc-roc: 0.9647 - val_loss: 0.2955 - val_acc: 0.8719 - val_auc-prc: 0.9509 - val_auc-roc: 0.9523 - 15s/epoch - 57ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2373 - acc: 0.9027 - auc-prc: 0.9655 - auc-roc: 0.9656 - val_loss: 0.2907 - val_acc: 0.8751 - val_auc-prc: 0.9495 - val_auc-roc: 0.9509 - 15s/epoch - 57ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2345 - acc: 0.9053 - auc-prc: 0.9662 - auc-roc: 0.9660 - val_loss: 0.2802 - val_acc: 0.8815 - val_auc-prc: 0.9504 - val_auc-roc: 0.9528 - 15s/epoch - 57ms/step
Epoch 17/100
264/264 - 15s - loss: 0.2319 - acc: 0.9048 - auc-prc: 0.9670 - auc-roc: 0.9669 - val_loss: 0.2878 - val_acc: 0.8709 - val_auc-prc: 0.9509 - val_auc-roc: 0.9510 - 15s/epoch - 57ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2273 - acc: 0.9083 - auc-prc: 0.9684 - auc-roc: 0.9681 - val_loss: 0.2819 - val_acc: 0.8762 - val_auc-prc: 0.9544 - val_auc-roc: 0.9545 - 15s/epoch - 57ms/step
Epoch 19/100
264/264 - 15s - loss: 0.2290 - acc: 0.9065 - auc-prc: 0.9680 - auc-roc: 0.9679 - val_loss: 0.2813 - val_acc: 0.8805 - val_auc-prc: 0.9541 - val_auc-roc: 0.9547 - 15s/epoch - 57ms/step
Epoch 20/100
264/264 - 15s - loss: 0.2257 - acc: 0.9071 - auc-prc: 0.9690 - auc-roc: 0.9687 - val_loss: 0.2797 - val_acc: 0.8773 - val_auc-prc: 0.9527 - val_auc-roc: 0.9544 - 15s/epoch - 57ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2216 - acc: 0.9096 - auc-prc: 0.9703 - auc-roc: 0.9699 - val_loss: 0.2885 - val_acc: 0.8762 - val_auc-prc: 0.9520 - val_auc-roc: 0.9528 - 15s/epoch - 57ms/step
Epoch 22/100
264/264 - 15s - loss: 0.2171 - acc: 0.9109 - auc-prc: 0.9711 - auc-roc: 0.9711 - val_loss: 0.2990 - val_acc: 0.8719 - val_auc-prc: 0.9519 - val_auc-roc: 0.9535 - 15s/epoch - 57ms/step
Epoch 23/100
264/264 - 15s - loss: 0.2142 - acc: 0.9128 - auc-prc: 0.9724 - auc-roc: 0.9720 - val_loss: 0.3107 - val_acc: 0.8783 - val_auc-prc: 0.9426 - val_auc-roc: 0.9447 - 15s/epoch - 57ms/step
Epoch 24/100
264/264 - 15s - loss: 0.2136 - acc: 0.9112 - auc-prc: 0.9718 - auc-roc: 0.9719 - val_loss: 0.2964 - val_acc: 0.8751 - val_auc-prc: 0.9532 - val_auc-roc: 0.9540 - 15s/epoch - 57ms/step
Epoch 25/100
264/264 - 15s - loss: 0.2055 - acc: 0.9155 - auc-prc: 0.9744 - auc-roc: 0.9742 - val_loss: 0.2791 - val_acc: 0.8805 - val_auc-prc: 0.9531 - val_auc-roc: 0.9539 - 15s/epoch - 57ms/step
Early stopping epoch: 24
******Evaluating TEST set*********
30/30 - 1s - 770ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.88      0.83      0.85       390
           1       0.88      0.92      0.90       547

    accuracy                           0.88       937
   macro avg       0.88      0.87      0.88       937
weighted avg       0.88      0.88      0.88       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.53      0.46       390
           1       0.57      0.46      0.51       547

    accuracy                           0.49       937
   macro avg       0.49      0.49      0.48       937
weighted avg       0.51      0.49      0.49       937

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 18s - loss: 0.3205 - acc: 0.8581 - auc-prc: 0.9363 - auc-roc: 0.9369 - val_loss: 0.2860 - val_acc: 0.8773 - val_auc-prc: 0.9495 - val_auc-roc: 0.9513 - 18s/epoch - 68ms/step
Epoch 2/100
264/264 - 14s - loss: 0.2852 - acc: 0.8870 - auc-prc: 0.9479 - auc-roc: 0.9498 - val_loss: 0.2725 - val_acc: 0.8847 - val_auc-prc: 0.9544 - val_auc-roc: 0.9557 - 14s/epoch - 54ms/step
Epoch 3/100
264/264 - 15s - loss: 0.2770 - acc: 0.8867 - auc-prc: 0.9515 - auc-roc: 0.9527 - val_loss: 0.2834 - val_acc: 0.8815 - val_auc-prc: 0.9514 - val_auc-roc: 0.9516 - 15s/epoch - 57ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2695 - acc: 0.8916 - auc-prc: 0.9541 - auc-roc: 0.9551 - val_loss: 0.2646 - val_acc: 0.8815 - val_auc-prc: 0.9555 - val_auc-roc: 0.9571 - 15s/epoch - 56ms/step
Epoch 5/100
264/264 - 14s - loss: 0.2618 - acc: 0.8965 - auc-prc: 0.9571 - auc-roc: 0.9578 - val_loss: 0.2670 - val_acc: 0.8922 - val_auc-prc: 0.9565 - val_auc-roc: 0.9573 - 14s/epoch - 54ms/step
Epoch 6/100
264/264 - 14s - loss: 0.2650 - acc: 0.8928 - auc-prc: 0.9559 - auc-roc: 0.9566 - val_loss: 0.2606 - val_acc: 0.8911 - val_auc-prc: 0.9574 - val_auc-roc: 0.9587 - 14s/epoch - 54ms/step
Epoch 7/100
264/264 - 15s - loss: 0.2614 - acc: 0.8965 - auc-prc: 0.9573 - auc-roc: 0.9579 - val_loss: 0.2654 - val_acc: 0.8943 - val_auc-prc: 0.9572 - val_auc-roc: 0.9584 - 15s/epoch - 56ms/step
Epoch 8/100
264/264 - 14s - loss: 0.2567 - acc: 0.8982 - auc-prc: 0.9589 - auc-roc: 0.9594 - val_loss: 0.2614 - val_acc: 0.8943 - val_auc-prc: 0.9595 - val_auc-roc: 0.9602 - 14s/epoch - 54ms/step
Epoch 9/100
264/264 - 15s - loss: 0.2531 - acc: 0.8974 - auc-prc: 0.9597 - auc-roc: 0.9604 - val_loss: 0.2532 - val_acc: 0.8965 - val_auc-prc: 0.9608 - val_auc-roc: 0.9617 - 15s/epoch - 55ms/step
Epoch 10/100
264/264 - 14s - loss: 0.2516 - acc: 0.8976 - auc-prc: 0.9606 - auc-roc: 0.9611 - val_loss: 0.2620 - val_acc: 0.8965 - val_auc-prc: 0.9591 - val_auc-roc: 0.9600 - 14s/epoch - 53ms/step
Epoch 11/100
264/264 - 14s - loss: 0.2486 - acc: 0.8982 - auc-prc: 0.9614 - auc-roc: 0.9618 - val_loss: 0.2552 - val_acc: 0.8943 - val_auc-prc: 0.9590 - val_auc-roc: 0.9603 - 14s/epoch - 54ms/step
Epoch 12/100
264/264 - 14s - loss: 0.2470 - acc: 0.9006 - auc-prc: 0.9622 - auc-roc: 0.9625 - val_loss: 0.2499 - val_acc: 0.8986 - val_auc-prc: 0.9599 - val_auc-roc: 0.9616 - 14s/epoch - 53ms/step
Epoch 13/100
264/264 - 14s - loss: 0.2422 - acc: 0.9010 - auc-prc: 0.9639 - auc-roc: 0.9640 - val_loss: 0.2498 - val_acc: 0.9072 - val_auc-prc: 0.9610 - val_auc-roc: 0.9625 - 14s/epoch - 52ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2422 - acc: 0.9020 - auc-prc: 0.9640 - auc-roc: 0.9640 - val_loss: 0.2488 - val_acc: 0.8997 - val_auc-prc: 0.9615 - val_auc-roc: 0.9626 - 15s/epoch - 55ms/step
Epoch 15/100
264/264 - 14s - loss: 0.2426 - acc: 0.8999 - auc-prc: 0.9641 - auc-roc: 0.9639 - val_loss: 0.2526 - val_acc: 0.8975 - val_auc-prc: 0.9592 - val_auc-roc: 0.9606 - 14s/epoch - 54ms/step
Epoch 16/100
264/264 - 15s - loss: 0.2391 - acc: 0.9031 - auc-prc: 0.9646 - auc-roc: 0.9647 - val_loss: 0.2473 - val_acc: 0.8997 - val_auc-prc: 0.9615 - val_auc-roc: 0.9627 - 15s/epoch - 55ms/step
Epoch 17/100
264/264 - 14s - loss: 0.2359 - acc: 0.9030 - auc-prc: 0.9665 - auc-roc: 0.9661 - val_loss: 0.2500 - val_acc: 0.8986 - val_auc-prc: 0.9615 - val_auc-roc: 0.9624 - 14s/epoch - 55ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2345 - acc: 0.9048 - auc-prc: 0.9664 - auc-roc: 0.9663 - val_loss: 0.2495 - val_acc: 0.8975 - val_auc-prc: 0.9613 - val_auc-roc: 0.9628 - 15s/epoch - 56ms/step
Epoch 19/100
264/264 - 14s - loss: 0.2320 - acc: 0.9053 - auc-prc: 0.9672 - auc-roc: 0.9671 - val_loss: 0.2501 - val_acc: 0.8954 - val_auc-prc: 0.9622 - val_auc-roc: 0.9623 - 14s/epoch - 54ms/step
Epoch 20/100
264/264 - 14s - loss: 0.2260 - acc: 0.9082 - auc-prc: 0.9691 - auc-roc: 0.9688 - val_loss: 0.2554 - val_acc: 0.8965 - val_auc-prc: 0.9606 - val_auc-roc: 0.9612 - 14s/epoch - 54ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2224 - acc: 0.9094 - auc-prc: 0.9699 - auc-roc: 0.9697 - val_loss: 0.2355 - val_acc: 0.9029 - val_auc-prc: 0.9661 - val_auc-roc: 0.9660 - 15s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 719ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.89      0.87      0.88       390
           1       0.91      0.93      0.92       547

    accuracy                           0.90       937
   macro avg       0.90      0.90      0.90       937
weighted avg       0.90      0.90      0.90       937

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.46      0.42       390
           1       0.56      0.50      0.53       547

    accuracy                           0.48       937
   macro avg       0.48      0.48      0.48       937
weighted avg       0.49      0.48      0.48       937

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 17s - loss: 0.3198 - acc: 0.8603 - auc-prc: 0.9358 - auc-roc: 0.9372 - val_loss: 0.2599 - val_acc: 0.8996 - val_auc-prc: 0.9588 - val_auc-roc: 0.9589 - 17s/epoch - 64ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2857 - acc: 0.8819 - auc-prc: 0.9474 - auc-roc: 0.9494 - val_loss: 0.2434 - val_acc: 0.8953 - val_auc-prc: 0.9626 - val_auc-roc: 0.9628 - 15s/epoch - 55ms/step
Epoch 3/100
264/264 - 15s - loss: 0.2753 - acc: 0.8896 - auc-prc: 0.9513 - auc-roc: 0.9526 - val_loss: 0.2483 - val_acc: 0.8942 - val_auc-prc: 0.9640 - val_auc-roc: 0.9634 - 15s/epoch - 55ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2731 - acc: 0.8915 - auc-prc: 0.9522 - auc-roc: 0.9540 - val_loss: 0.2413 - val_acc: 0.8942 - val_auc-prc: 0.9654 - val_auc-roc: 0.9649 - 15s/epoch - 55ms/step
Epoch 5/100
264/264 - 15s - loss: 0.2670 - acc: 0.8936 - auc-prc: 0.9543 - auc-roc: 0.9559 - val_loss: 0.2352 - val_acc: 0.9124 - val_auc-prc: 0.9671 - val_auc-roc: 0.9665 - 15s/epoch - 55ms/step
Epoch 6/100
264/264 - 14s - loss: 0.2630 - acc: 0.8959 - auc-prc: 0.9564 - auc-roc: 0.9572 - val_loss: 0.2653 - val_acc: 0.8974 - val_auc-prc: 0.9586 - val_auc-roc: 0.9581 - 14s/epoch - 54ms/step
Epoch 7/100
264/264 - 16s - loss: 0.2592 - acc: 0.8926 - auc-prc: 0.9580 - auc-roc: 0.9586 - val_loss: 0.2327 - val_acc: 0.9049 - val_auc-prc: 0.9675 - val_auc-roc: 0.9669 - 16s/epoch - 59ms/step
Epoch 8/100
264/264 - 14s - loss: 0.2563 - acc: 0.8927 - auc-prc: 0.9589 - auc-roc: 0.9596 - val_loss: 0.2420 - val_acc: 0.9038 - val_auc-prc: 0.9655 - val_auc-roc: 0.9649 - 14s/epoch - 55ms/step
Epoch 9/100
264/264 - 14s - loss: 0.2536 - acc: 0.8978 - auc-prc: 0.9596 - auc-roc: 0.9604 - val_loss: 0.2609 - val_acc: 0.8846 - val_auc-prc: 0.9611 - val_auc-roc: 0.9599 - 14s/epoch - 55ms/step
Epoch 10/100
264/264 - 14s - loss: 0.2504 - acc: 0.8981 - auc-prc: 0.9612 - auc-roc: 0.9617 - val_loss: 0.2380 - val_acc: 0.8985 - val_auc-prc: 0.9670 - val_auc-roc: 0.9663 - 14s/epoch - 55ms/step
Epoch 11/100
264/264 - 14s - loss: 0.2474 - acc: 0.8991 - auc-prc: 0.9622 - auc-roc: 0.9625 - val_loss: 0.2342 - val_acc: 0.9006 - val_auc-prc: 0.9669 - val_auc-roc: 0.9663 - 14s/epoch - 55ms/step
Epoch 12/100
264/264 - 14s - loss: 0.2472 - acc: 0.8969 - auc-prc: 0.9628 - auc-roc: 0.9627 - val_loss: 0.2421 - val_acc: 0.8953 - val_auc-prc: 0.9646 - val_auc-roc: 0.9641 - 14s/epoch - 55ms/step
Epoch 13/100
264/264 - 20s - loss: 0.2438 - acc: 0.9000 - auc-prc: 0.9638 - auc-roc: 0.9638 - val_loss: 0.2370 - val_acc: 0.9071 - val_auc-prc: 0.9682 - val_auc-roc: 0.9675 - 20s/epoch - 77ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2400 - acc: 0.8994 - auc-prc: 0.9649 - auc-roc: 0.9648 - val_loss: 0.2296 - val_acc: 0.9017 - val_auc-prc: 0.9683 - val_auc-roc: 0.9677 - 15s/epoch - 56ms/step
Epoch 15/100
264/264 - 15s - loss: 0.2385 - acc: 0.9041 - auc-prc: 0.9652 - auc-roc: 0.9652 - val_loss: 0.2429 - val_acc: 0.8921 - val_auc-prc: 0.9650 - val_auc-roc: 0.9641 - 15s/epoch - 55ms/step
Epoch 16/100
264/264 - 14s - loss: 0.2351 - acc: 0.9057 - auc-prc: 0.9661 - auc-roc: 0.9662 - val_loss: 0.2302 - val_acc: 0.8996 - val_auc-prc: 0.9680 - val_auc-roc: 0.9677 - 14s/epoch - 55ms/step
Epoch 17/100
264/264 - 15s - loss: 0.2311 - acc: 0.9049 - auc-prc: 0.9672 - auc-roc: 0.9673 - val_loss: 0.2367 - val_acc: 0.9017 - val_auc-prc: 0.9682 - val_auc-roc: 0.9674 - 15s/epoch - 55ms/step
Epoch 18/100
264/264 - 15s - loss: 0.2290 - acc: 0.9057 - auc-prc: 0.9684 - auc-roc: 0.9680 - val_loss: 0.2360 - val_acc: 0.8953 - val_auc-prc: 0.9676 - val_auc-roc: 0.9668 - 15s/epoch - 55ms/step
Epoch 19/100
264/264 - 14s - loss: 0.2255 - acc: 0.9076 - auc-prc: 0.9692 - auc-roc: 0.9689 - val_loss: 0.2355 - val_acc: 0.8953 - val_auc-prc: 0.9679 - val_auc-roc: 0.9670 - 14s/epoch - 55ms/step
Epoch 20/100
264/264 - 15s - loss: 0.2241 - acc: 0.9086 - auc-prc: 0.9688 - auc-roc: 0.9692 - val_loss: 0.2319 - val_acc: 0.9049 - val_auc-prc: 0.9677 - val_auc-roc: 0.9672 - 15s/epoch - 56ms/step
Epoch 21/100
264/264 - 15s - loss: 0.2188 - acc: 0.9095 - auc-prc: 0.9710 - auc-roc: 0.9707 - val_loss: 0.2382 - val_acc: 0.9017 - val_auc-prc: 0.9669 - val_auc-roc: 0.9659 - 15s/epoch - 57ms/step
Epoch 22/100
264/264 - 15s - loss: 0.2113 - acc: 0.9157 - auc-prc: 0.9730 - auc-roc: 0.9727 - val_loss: 0.2755 - val_acc: 0.8846 - val_auc-prc: 0.9535 - val_auc-roc: 0.9534 - 15s/epoch - 56ms/step
Epoch 23/100
264/264 - 15s - loss: 0.2167 - acc: 0.9128 - auc-prc: 0.9715 - auc-roc: 0.9713 - val_loss: 0.2814 - val_acc: 0.8835 - val_auc-prc: 0.9533 - val_auc-roc: 0.9543 - 15s/epoch - 56ms/step
Epoch 24/100
264/264 - 15s - loss: 0.2080 - acc: 0.9165 - auc-prc: 0.9737 - auc-roc: 0.9734 - val_loss: 0.2439 - val_acc: 0.9038 - val_auc-prc: 0.9634 - val_auc-roc: 0.9640 - 15s/epoch - 57ms/step
Epoch 25/100
264/264 - 15s - loss: 0.2003 - acc: 0.9211 - auc-prc: 0.9759 - auc-roc: 0.9755 - val_loss: 0.2514 - val_acc: 0.8953 - val_auc-prc: 0.9633 - val_auc-roc: 0.9635 - 15s/epoch - 57ms/step
Epoch 26/100
264/264 - 15s - loss: 0.1964 - acc: 0.9192 - auc-prc: 0.9768 - auc-roc: 0.9765 - val_loss: 0.2467 - val_acc: 0.8974 - val_auc-prc: 0.9649 - val_auc-roc: 0.9648 - 15s/epoch - 57ms/step
Epoch 27/100
264/264 - 15s - loss: 0.1925 - acc: 0.9211 - auc-prc: 0.9776 - auc-roc: 0.9773 - val_loss: 0.2482 - val_acc: 0.8921 - val_auc-prc: 0.9648 - val_auc-roc: 0.9648 - 15s/epoch - 57ms/step
Epoch 28/100
264/264 - 15s - loss: 0.1856 - acc: 0.9243 - auc-prc: 0.9791 - auc-roc: 0.9789 - val_loss: 0.2479 - val_acc: 0.9049 - val_auc-prc: 0.9641 - val_auc-roc: 0.9665 - 15s/epoch - 57ms/step
Epoch 29/100
264/264 - 15s - loss: 0.1802 - acc: 0.9277 - auc-prc: 0.9803 - auc-roc: 0.9800 - val_loss: 0.2468 - val_acc: 0.8964 - val_auc-prc: 0.9666 - val_auc-roc: 0.9663 - 15s/epoch - 57ms/step
Epoch 30/100
264/264 - 15s - loss: 0.1798 - acc: 0.9274 - auc-prc: 0.9804 - auc-roc: 0.9802 - val_loss: 0.2626 - val_acc: 0.9028 - val_auc-prc: 0.9640 - val_auc-roc: 0.9658 - 15s/epoch - 57ms/step
Epoch 31/100
264/264 - 15s - loss: 0.1693 - acc: 0.9335 - auc-prc: 0.9823 - auc-roc: 0.9822 - val_loss: 0.2553 - val_acc: 0.9017 - val_auc-prc: 0.9617 - val_auc-roc: 0.9634 - 15s/epoch - 57ms/step
Epoch 32/100
264/264 - 15s - loss: 0.1620 - acc: 0.9363 - auc-prc: 0.9839 - auc-roc: 0.9838 - val_loss: 0.2614 - val_acc: 0.9028 - val_auc-prc: 0.9633 - val_auc-roc: 0.9628 - 15s/epoch - 57ms/step
Epoch 33/100
264/264 - 14s - loss: 0.1635 - acc: 0.9317 - auc-prc: 0.9839 - auc-roc: 0.9837 - val_loss: 0.2648 - val_acc: 0.8921 - val_auc-prc: 0.9579 - val_auc-roc: 0.9614 - 14s/epoch - 53ms/step
Epoch 34/100
264/264 - 14s - loss: 0.1520 - acc: 0.9402 - auc-prc: 0.9854 - auc-roc: 0.9856 - val_loss: 0.2771 - val_acc: 0.8974 - val_auc-prc: 0.9572 - val_auc-roc: 0.9599 - 14s/epoch - 52ms/step
Epoch 35/100
264/264 - 21s - loss: 0.1521 - acc: 0.9371 - auc-prc: 0.9856 - auc-roc: 0.9857 - val_loss: 0.2959 - val_acc: 0.8921 - val_auc-prc: 0.9552 - val_auc-roc: 0.9568 - 21s/epoch - 79ms/step
Epoch 36/100
264/264 - 14s - loss: 0.1390 - acc: 0.9457 - auc-prc: 0.9882 - auc-roc: 0.9881 - val_loss: 0.2918 - val_acc: 0.9038 - val_auc-prc: 0.9525 - val_auc-roc: 0.9583 - 14s/epoch - 53ms/step
Epoch 37/100
264/264 - 15s - loss: 0.1353 - acc: 0.9463 - auc-prc: 0.9887 - auc-roc: 0.9886 - val_loss: 0.2953 - val_acc: 0.8868 - val_auc-prc: 0.9509 - val_auc-roc: 0.9531 - 15s/epoch - 55ms/step
Epoch 38/100
264/264 - 15s - loss: 0.1245 - acc: 0.9523 - auc-prc: 0.9903 - auc-roc: 0.9903 - val_loss: 0.3069 - val_acc: 0.8921 - val_auc-prc: 0.9500 - val_auc-roc: 0.9544 - 15s/epoch - 56ms/step
Epoch 39/100
264/264 - 15s - loss: 0.1151 - acc: 0.9547 - auc-prc: 0.9921 - auc-roc: 0.9919 - val_loss: 0.2971 - val_acc: 0.8996 - val_auc-prc: 0.9564 - val_auc-roc: 0.9580 - 15s/epoch - 56ms/step
Epoch 40/100
264/264 - 15s - loss: 0.1178 - acc: 0.9532 - auc-prc: 0.9915 - auc-roc: 0.9914 - val_loss: 0.3142 - val_acc: 0.9006 - val_auc-prc: 0.9489 - val_auc-roc: 0.9554 - 15s/epoch - 57ms/step
Epoch 41/100
264/264 - 15s - loss: 0.1098 - acc: 0.9573 - auc-prc: 0.9925 - auc-roc: 0.9925 - val_loss: 0.2918 - val_acc: 0.9028 - val_auc-prc: 0.9577 - val_auc-roc: 0.9609 - 15s/epoch - 57ms/step
Epoch 42/100
264/264 - 15s - loss: 0.1072 - acc: 0.9567 - auc-prc: 0.9930 - auc-roc: 0.9930 - val_loss: 0.3143 - val_acc: 0.8974 - val_auc-prc: 0.9525 - val_auc-roc: 0.9577 - 15s/epoch - 57ms/step
Epoch 43/100
264/264 - 15s - loss: 0.0936 - acc: 0.9634 - auc-prc: 0.9946 - auc-roc: 0.9946 - val_loss: 0.3117 - val_acc: 0.8932 - val_auc-prc: 0.9554 - val_auc-roc: 0.9579 - 15s/epoch - 56ms/step
Epoch 44/100
264/264 - 15s - loss: 0.1003 - acc: 0.9606 - auc-prc: 0.9934 - auc-roc: 0.9935 - val_loss: 0.3183 - val_acc: 0.8953 - val_auc-prc: 0.9511 - val_auc-roc: 0.9569 - 15s/epoch - 56ms/step
Epoch 45/100
264/264 - 15s - loss: 0.0928 - acc: 0.9649 - auc-prc: 0.9946 - auc-roc: 0.9946 - val_loss: 0.3519 - val_acc: 0.8964 - val_auc-prc: 0.9480 - val_auc-roc: 0.9532 - 15s/epoch - 56ms/step
Epoch 46/100
264/264 - 15s - loss: 0.0886 - acc: 0.9670 - auc-prc: 0.9947 - auc-roc: 0.9948 - val_loss: 0.3997 - val_acc: 0.8889 - val_auc-prc: 0.9360 - val_auc-roc: 0.9451 - 15s/epoch - 56ms/step
Epoch 47/100
264/264 - 15s - loss: 0.0810 - acc: 0.9689 - auc-prc: 0.9958 - auc-roc: 0.9958 - val_loss: 0.3357 - val_acc: 0.8910 - val_auc-prc: 0.9482 - val_auc-roc: 0.9542 - 15s/epoch - 57ms/step
Epoch 48/100
264/264 - 15s - loss: 0.0811 - acc: 0.9692 - auc-prc: 0.9953 - auc-roc: 0.9955 - val_loss: 0.3414 - val_acc: 0.8782 - val_auc-prc: 0.9466 - val_auc-roc: 0.9526 - 15s/epoch - 57ms/step
Epoch 49/100
264/264 - 15s - loss: 0.0686 - acc: 0.9745 - auc-prc: 0.9970 - auc-roc: 0.9971 - val_loss: 0.3875 - val_acc: 0.8921 - val_auc-prc: 0.9447 - val_auc-roc: 0.9508 - 15s/epoch - 57ms/step
Epoch 50/100
264/264 - 15s - loss: 0.0733 - acc: 0.9730 - auc-prc: 0.9963 - auc-roc: 0.9964 - val_loss: 0.3386 - val_acc: 0.8942 - val_auc-prc: 0.9526 - val_auc-roc: 0.9571 - 15s/epoch - 57ms/step
Epoch 51/100
264/264 - 15s - loss: 0.0764 - acc: 0.9713 - auc-prc: 0.9959 - auc-roc: 0.9960 - val_loss: 0.3788 - val_acc: 0.8878 - val_auc-prc: 0.9445 - val_auc-roc: 0.9515 - 15s/epoch - 57ms/step
Epoch 52/100
264/264 - 15s - loss: 0.0626 - acc: 0.9772 - auc-prc: 0.9973 - auc-roc: 0.9974 - val_loss: 0.3915 - val_acc: 0.8857 - val_auc-prc: 0.9419 - val_auc-roc: 0.9499 - 15s/epoch - 56ms/step
Epoch 53/100
264/264 - 15s - loss: 0.0841 - acc: 0.9675 - auc-prc: 0.9949 - auc-roc: 0.9951 - val_loss: 0.4333 - val_acc: 0.8600 - val_auc-prc: 0.9281 - val_auc-roc: 0.9341 - 15s/epoch - 57ms/step
Epoch 54/100
264/264 - 15s - loss: 0.0742 - acc: 0.9706 - auc-prc: 0.9964 - auc-roc: 0.9964 - val_loss: 0.3842 - val_acc: 0.8900 - val_auc-prc: 0.9430 - val_auc-roc: 0.9496 - 15s/epoch - 57ms/step
Epoch 55/100
264/264 - 15s - loss: 0.0597 - acc: 0.9784 - auc-prc: 0.9976 - auc-roc: 0.9977 - val_loss: 0.3828 - val_acc: 0.8921 - val_auc-prc: 0.9414 - val_auc-roc: 0.9498 - 15s/epoch - 57ms/step
Epoch 56/100
264/264 - 15s - loss: 0.0578 - acc: 0.9784 - auc-prc: 0.9977 - auc-roc: 0.9978 - val_loss: 0.4064 - val_acc: 0.9028 - val_auc-prc: 0.9393 - val_auc-roc: 0.9494 - 15s/epoch - 58ms/step
Epoch 57/100
264/264 - 15s - loss: 0.0558 - acc: 0.9816 - auc-prc: 0.9973 - auc-roc: 0.9975 - val_loss: 0.4794 - val_acc: 0.8857 - val_auc-prc: 0.9294 - val_auc-roc: 0.9398 - 15s/epoch - 58ms/step
Epoch 58/100
264/264 - 15s - loss: 0.0519 - acc: 0.9806 - auc-prc: 0.9985 - auc-roc: 0.9984 - val_loss: 0.4072 - val_acc: 0.8974 - val_auc-prc: 0.9357 - val_auc-roc: 0.9463 - 15s/epoch - 58ms/step
Epoch 59/100
264/264 - 15s - loss: 0.0453 - acc: 0.9846 - auc-prc: 0.9982 - auc-roc: 0.9984 - val_loss: 0.4355 - val_acc: 0.8932 - val_auc-prc: 0.9348 - val_auc-roc: 0.9452 - 15s/epoch - 58ms/step
Epoch 60/100
264/264 - 15s - loss: 0.0527 - acc: 0.9803 - auc-prc: 0.9982 - auc-roc: 0.9982 - val_loss: 0.4499 - val_acc: 0.8878 - val_auc-prc: 0.9363 - val_auc-roc: 0.9460 - 15s/epoch - 57ms/step
Epoch 61/100
264/264 - 15s - loss: 0.0406 - acc: 0.9855 - auc-prc: 0.9989 - auc-roc: 0.9990 - val_loss: 0.4691 - val_acc: 0.8942 - val_auc-prc: 0.9313 - val_auc-roc: 0.9433 - 15s/epoch - 57ms/step
Epoch 62/100
264/264 - 15s - loss: 0.0413 - acc: 0.9843 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.4889 - val_acc: 0.8974 - val_auc-prc: 0.9329 - val_auc-roc: 0.9437 - 15s/epoch - 57ms/step
Epoch 63/100
264/264 - 15s - loss: 0.0415 - acc: 0.9856 - auc-prc: 0.9990 - auc-roc: 0.9990 - val_loss: 0.4724 - val_acc: 0.8910 - val_auc-prc: 0.9327 - val_auc-roc: 0.9434 - 15s/epoch - 57ms/step
Epoch 64/100
264/264 - 15s - loss: 0.0570 - acc: 0.9796 - auc-prc: 0.9973 - auc-roc: 0.9975 - val_loss: 0.5236 - val_acc: 0.8985 - val_auc-prc: 0.9188 - val_auc-roc: 0.9342 - 15s/epoch - 56ms/step
Epoch 65/100
264/264 - 15s - loss: 0.0481 - acc: 0.9830 - auc-prc: 0.9985 - auc-roc: 0.9985 - val_loss: 0.5055 - val_acc: 0.8889 - val_auc-prc: 0.9246 - val_auc-roc: 0.9376 - 15s/epoch - 57ms/step
Epoch 66/100
264/264 - 15s - loss: 0.0514 - acc: 0.9807 - auc-prc: 0.9980 - auc-roc: 0.9981 - val_loss: 0.4990 - val_acc: 0.8889 - val_auc-prc: 0.9293 - val_auc-roc: 0.9409 - 15s/epoch - 58ms/step
Epoch 67/100
264/264 - 15s - loss: 0.0411 - acc: 0.9849 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.5242 - val_acc: 0.8846 - val_auc-prc: 0.9277 - val_auc-roc: 0.9394 - 15s/epoch - 58ms/step
Epoch 68/100
264/264 - 15s - loss: 0.0274 - acc: 0.9915 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.4932 - val_acc: 0.8964 - val_auc-prc: 0.9344 - val_auc-roc: 0.9456 - 15s/epoch - 57ms/step
Epoch 69/100
264/264 - 15s - loss: 0.0337 - acc: 0.9875 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.5215 - val_acc: 0.8910 - val_auc-prc: 0.9265 - val_auc-roc: 0.9394 - 15s/epoch - 57ms/step
Epoch 70/100
264/264 - 15s - loss: 0.0368 - acc: 0.9872 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.5206 - val_acc: 0.9081 - val_auc-prc: 0.9327 - val_auc-roc: 0.9445 - 15s/epoch - 57ms/step
Epoch 71/100
264/264 - 15s - loss: 0.0382 - acc: 0.9856 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.5733 - val_acc: 0.8846 - val_auc-prc: 0.9213 - val_auc-roc: 0.9345 - 15s/epoch - 57ms/step
Epoch 72/100
264/264 - 15s - loss: 0.0414 - acc: 0.9834 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.4969 - val_acc: 0.9006 - val_auc-prc: 0.9295 - val_auc-roc: 0.9423 - 15s/epoch - 57ms/step
Epoch 73/100
264/264 - 15s - loss: 0.0236 - acc: 0.9935 - auc-prc: 0.9997 - auc-roc: 0.9997 - val_loss: 0.5474 - val_acc: 0.8942 - val_auc-prc: 0.9248 - val_auc-roc: 0.9379 - 15s/epoch - 56ms/step
Early stopping epoch: 72
******Evaluating TEST set*********
30/30 - 3s - 3s/epoch - 97ms/step
              precision    recall  f1-score   support

           0       0.88      0.87      0.88       390
           1       0.91      0.92      0.91       546

    accuracy                           0.90       936
   macro avg       0.90      0.90      0.90       936
weighted avg       0.90      0.90      0.90       936

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.40      0.47      0.43       390
           1       0.57      0.49      0.53       546

    accuracy                           0.49       936
   macro avg       0.48      0.48      0.48       936
weighted avg       0.50      0.49      0.49       936

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
264/264 - 20s - loss: 0.3237 - acc: 0.8612 - auc-prc: 0.9349 - auc-roc: 0.9362 - val_loss: 0.2629 - val_acc: 0.9006 - val_auc-prc: 0.9556 - val_auc-roc: 0.9575 - 20s/epoch - 75ms/step
Epoch 2/100
264/264 - 15s - loss: 0.2862 - acc: 0.8832 - auc-prc: 0.9474 - auc-roc: 0.9494 - val_loss: 0.2419 - val_acc: 0.9081 - val_auc-prc: 0.9621 - val_auc-roc: 0.9640 - 15s/epoch - 57ms/step
Epoch 3/100
264/264 - 15s - loss: 0.2769 - acc: 0.8870 - auc-prc: 0.9508 - auc-roc: 0.9524 - val_loss: 0.2426 - val_acc: 0.9006 - val_auc-prc: 0.9615 - val_auc-roc: 0.9632 - 15s/epoch - 57ms/step
Epoch 4/100
264/264 - 15s - loss: 0.2789 - acc: 0.8865 - auc-prc: 0.9510 - auc-roc: 0.9521 - val_loss: 0.2389 - val_acc: 0.9145 - val_auc-prc: 0.9644 - val_auc-roc: 0.9650 - 15s/epoch - 57ms/step
Epoch 5/100
264/264 - 15s - loss: 0.2653 - acc: 0.8911 - auc-prc: 0.9559 - auc-roc: 0.9567 - val_loss: 0.2460 - val_acc: 0.9060 - val_auc-prc: 0.9628 - val_auc-roc: 0.9638 - 15s/epoch - 57ms/step
Epoch 6/100
264/264 - 15s - loss: 0.2646 - acc: 0.8930 - auc-prc: 0.9565 - auc-roc: 0.9569 - val_loss: 0.2434 - val_acc: 0.9060 - val_auc-prc: 0.9625 - val_auc-roc: 0.9638 - 15s/epoch - 57ms/step
Epoch 7/100
264/264 - 15s - loss: 0.2625 - acc: 0.8910 - auc-prc: 0.9571 - auc-roc: 0.9577 - val_loss: 0.2415 - val_acc: 0.9081 - val_auc-prc: 0.9623 - val_auc-roc: 0.9632 - 15s/epoch - 57ms/step
Epoch 8/100
264/264 - 15s - loss: 0.2589 - acc: 0.8953 - auc-prc: 0.9583 - auc-roc: 0.9589 - val_loss: 0.2298 - val_acc: 0.9092 - val_auc-prc: 0.9662 - val_auc-roc: 0.9673 - 15s/epoch - 58ms/step
Epoch 9/100
264/264 - 14s - loss: 0.2599 - acc: 0.8961 - auc-prc: 0.9580 - auc-roc: 0.9585 - val_loss: 0.2314 - val_acc: 0.9071 - val_auc-prc: 0.9661 - val_auc-roc: 0.9671 - 14s/epoch - 55ms/step
Epoch 10/100
264/264 - 14s - loss: 0.2583 - acc: 0.8949 - auc-prc: 0.9587 - auc-roc: 0.9590 - val_loss: 0.2342 - val_acc: 0.9103 - val_auc-prc: 0.9637 - val_auc-roc: 0.9661 - 14s/epoch - 54ms/step
Epoch 11/100
264/264 - 15s - loss: 0.2521 - acc: 0.8967 - auc-prc: 0.9610 - auc-roc: 0.9611 - val_loss: 0.2344 - val_acc: 0.9124 - val_auc-prc: 0.9654 - val_auc-roc: 0.9656 - 15s/epoch - 55ms/step
Epoch 12/100
264/264 - 15s - loss: 0.2509 - acc: 0.8986 - auc-prc: 0.9611 - auc-roc: 0.9615 - val_loss: 0.2232 - val_acc: 0.9113 - val_auc-prc: 0.9686 - val_auc-roc: 0.9698 - 15s/epoch - 55ms/step
Epoch 13/100
264/264 - 15s - loss: 0.2491 - acc: 0.8974 - auc-prc: 0.9620 - auc-roc: 0.9620 - val_loss: 0.2262 - val_acc: 0.9145 - val_auc-prc: 0.9692 - val_auc-roc: 0.9698 - 15s/epoch - 55ms/step
Epoch 14/100
264/264 - 15s - loss: 0.2451 - acc: 0.8998 - auc-prc: 0.9633 - auc-roc: 0.9632 - val_loss: 0.2288 - val_acc: 0.9060 - val_auc-prc: 0.9672 - val_auc-roc: 0.9680 - 15s/epoch - 55ms/step
Epoch 15/100
264/264 - 14s - loss: 0.2412 - acc: 0.9025 - auc-prc: 0.9644 - auc-roc: 0.9645 - val_loss: 0.2357 - val_acc: 0.9113 - val_auc-prc: 0.9664 - val_auc-roc: 0.9664 - 14s/epoch - 54ms/step
Epoch 16/100
264/264 - 14s - loss: 0.2448 - acc: 0.9003 - auc-prc: 0.9634 - auc-roc: 0.9634 - val_loss: 0.2297 - val_acc: 0.9156 - val_auc-prc: 0.9655 - val_auc-roc: 0.9662 - 14s/epoch - 53ms/step
Epoch 17/100
264/264 - 14s - loss: 0.2381 - acc: 0.9009 - auc-prc: 0.9655 - auc-roc: 0.9653 - val_loss: 0.2262 - val_acc: 0.9124 - val_auc-prc: 0.9678 - val_auc-roc: 0.9682 - 14s/epoch - 52ms/step
Epoch 18/100
264/264 - 14s - loss: 0.2374 - acc: 0.9014 - auc-prc: 0.9657 - auc-roc: 0.9655 - val_loss: 0.2208 - val_acc: 0.9188 - val_auc-prc: 0.9688 - val_auc-roc: 0.9694 - 14s/epoch - 54ms/step
Epoch 19/100
264/264 - 14s - loss: 0.2338 - acc: 0.9054 - auc-prc: 0.9669 - auc-roc: 0.9666 - val_loss: 0.2264 - val_acc: 0.9092 - val_auc-prc: 0.9674 - val_auc-roc: 0.9679 - 14s/epoch - 54ms/step
Epoch 20/100
264/264 - 14s - loss: 0.2338 - acc: 0.9028 - auc-prc: 0.9666 - auc-roc: 0.9664 - val_loss: 0.2359 - val_acc: 0.9071 - val_auc-prc: 0.9663 - val_auc-roc: 0.9669 - 14s/epoch - 54ms/step
Epoch 21/100
264/264 - 14s - loss: 0.2329 - acc: 0.9062 - auc-prc: 0.9672 - auc-roc: 0.9667 - val_loss: 0.2218 - val_acc: 0.9156 - val_auc-prc: 0.9692 - val_auc-roc: 0.9698 - 14s/epoch - 55ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
30/30 - 1s - 693ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.91      0.88      0.90       390
           1       0.92      0.94      0.93       546

    accuracy                           0.91       936
   macro avg       0.91      0.91      0.91       936
weighted avg       0.91      0.91      0.91       936

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.52      0.47       390
           1       0.59      0.48      0.53       546

    accuracy                           0.50       936
   macro avg       0.50      0.50      0.50       936
weighted avg       0.52      0.50      0.50       936

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8929] IC [0.8841, 0.9016]
Mean Accuracy[0.8987] IC [0.8906, 0.9068]
Mean Recall[0.8929] IC [0.8841, 0.9016]
Mean F1[0.8951] IC [0.8867, 0.9036]
Median AUC_ROC[0.8944]
Median Accuracy[0.8996]
Median Recall[0.8944]
Median F1[0.8962]
********************txid297246********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.65      0.62      0.63       130
           1       0.94      0.95      0.95       877

    accuracy                           0.91      1007
   macro avg       0.79      0.78      0.79      1007
weighted avg       0.90      0.91      0.91      1007

Predicted  0.0  1.0   All
True                     
0           80   50   130
1           44  833   877
All        124  883  1007
**************************************************
fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 18s - loss: 0.3311 - acc: 0.8570 - auc-prc: 0.9317 - auc-roc: 0.9331 - val_loss: 0.2833 - val_acc: 0.8824 - val_auc-prc: 0.9528 - val_auc-roc: 0.9524 - 18s/epoch - 68ms/step
Epoch 2/100
258/258 - 14s - loss: 0.2994 - acc: 0.8791 - auc-prc: 0.9425 - auc-roc: 0.9445 - val_loss: 0.2705 - val_acc: 0.8965 - val_auc-prc: 0.9559 - val_auc-roc: 0.9555 - 14s/epoch - 55ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2931 - acc: 0.8825 - auc-prc: 0.9452 - auc-roc: 0.9468 - val_loss: 0.2677 - val_acc: 0.8965 - val_auc-prc: 0.9551 - val_auc-roc: 0.9553 - 14s/epoch - 55ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2850 - acc: 0.8855 - auc-prc: 0.9471 - auc-roc: 0.9491 - val_loss: 0.2645 - val_acc: 0.9031 - val_auc-prc: 0.9590 - val_auc-roc: 0.9587 - 14s/epoch - 55ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2813 - acc: 0.8879 - auc-prc: 0.9489 - auc-roc: 0.9506 - val_loss: 0.2654 - val_acc: 0.8922 - val_auc-prc: 0.9568 - val_auc-roc: 0.9569 - 14s/epoch - 56ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2773 - acc: 0.8905 - auc-prc: 0.9500 - auc-roc: 0.9518 - val_loss: 0.2841 - val_acc: 0.8769 - val_auc-prc: 0.9517 - val_auc-roc: 0.9517 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 15s - loss: 0.2702 - acc: 0.8896 - auc-prc: 0.9534 - auc-roc: 0.9547 - val_loss: 0.2517 - val_acc: 0.9009 - val_auc-prc: 0.9599 - val_auc-roc: 0.9604 - 15s/epoch - 57ms/step
Epoch 8/100
258/258 - 15s - loss: 0.2681 - acc: 0.8944 - auc-prc: 0.9546 - auc-roc: 0.9555 - val_loss: 0.2594 - val_acc: 0.8932 - val_auc-prc: 0.9574 - val_auc-roc: 0.9575 - 15s/epoch - 57ms/step
Epoch 9/100
258/258 - 15s - loss: 0.2678 - acc: 0.8917 - auc-prc: 0.9545 - auc-roc: 0.9556 - val_loss: 0.2674 - val_acc: 0.8911 - val_auc-prc: 0.9567 - val_auc-roc: 0.9562 - 15s/epoch - 56ms/step
Epoch 10/100
258/258 - 15s - loss: 0.2660 - acc: 0.8890 - auc-prc: 0.9553 - auc-roc: 0.9562 - val_loss: 0.2515 - val_acc: 0.8998 - val_auc-prc: 0.9603 - val_auc-roc: 0.9606 - 15s/epoch - 56ms/step
Epoch 11/100
258/258 - 15s - loss: 0.2635 - acc: 0.8950 - auc-prc: 0.9566 - auc-roc: 0.9571 - val_loss: 0.2557 - val_acc: 0.8932 - val_auc-prc: 0.9588 - val_auc-roc: 0.9589 - 15s/epoch - 57ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2626 - acc: 0.8935 - auc-prc: 0.9565 - auc-roc: 0.9574 - val_loss: 0.2527 - val_acc: 0.8900 - val_auc-prc: 0.9599 - val_auc-roc: 0.9604 - 14s/epoch - 56ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2577 - acc: 0.8928 - auc-prc: 0.9589 - auc-roc: 0.9592 - val_loss: 0.2712 - val_acc: 0.8889 - val_auc-prc: 0.9552 - val_auc-roc: 0.9555 - 14s/epoch - 56ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2571 - acc: 0.8956 - auc-prc: 0.9584 - auc-roc: 0.9592 - val_loss: 0.2588 - val_acc: 0.8943 - val_auc-prc: 0.9590 - val_auc-roc: 0.9591 - 14s/epoch - 54ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2553 - acc: 0.8985 - auc-prc: 0.9590 - auc-roc: 0.9596 - val_loss: 0.2577 - val_acc: 0.8954 - val_auc-prc: 0.9594 - val_auc-roc: 0.9598 - 14s/epoch - 53ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2516 - acc: 0.8961 - auc-prc: 0.9604 - auc-roc: 0.9609 - val_loss: 0.2546 - val_acc: 0.8954 - val_auc-prc: 0.9598 - val_auc-roc: 0.9598 - 14s/epoch - 54ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2502 - acc: 0.8975 - auc-prc: 0.9607 - auc-roc: 0.9613 - val_loss: 0.2527 - val_acc: 0.8932 - val_auc-prc: 0.9611 - val_auc-roc: 0.9610 - 14s/epoch - 54ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2474 - acc: 0.8979 - auc-prc: 0.9620 - auc-roc: 0.9622 - val_loss: 0.2730 - val_acc: 0.8900 - val_auc-prc: 0.9559 - val_auc-roc: 0.9558 - 14s/epoch - 54ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2475 - acc: 0.8999 - auc-prc: 0.9617 - auc-roc: 0.9621 - val_loss: 0.2498 - val_acc: 0.9009 - val_auc-prc: 0.9620 - val_auc-roc: 0.9617 - 14s/epoch - 54ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2437 - acc: 0.9020 - auc-prc: 0.9633 - auc-roc: 0.9633 - val_loss: 0.2510 - val_acc: 0.8943 - val_auc-prc: 0.9616 - val_auc-roc: 0.9613 - 14s/epoch - 55ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2397 - acc: 0.9034 - auc-prc: 0.9639 - auc-roc: 0.9644 - val_loss: 0.2542 - val_acc: 0.8998 - val_auc-prc: 0.9605 - val_auc-roc: 0.9601 - 14s/epoch - 55ms/step
Epoch 22/100
258/258 - 14s - loss: 0.2420 - acc: 0.9017 - auc-prc: 0.9642 - auc-roc: 0.9641 - val_loss: 0.2574 - val_acc: 0.9009 - val_auc-prc: 0.9589 - val_auc-roc: 0.9590 - 14s/epoch - 55ms/step
Epoch 23/100
258/258 - 14s - loss: 0.2356 - acc: 0.9038 - auc-prc: 0.9656 - auc-roc: 0.9660 - val_loss: 0.2627 - val_acc: 0.8932 - val_auc-prc: 0.9576 - val_auc-roc: 0.9576 - 14s/epoch - 55ms/step
Epoch 24/100
258/258 - 14s - loss: 0.2343 - acc: 0.9059 - auc-prc: 0.9658 - auc-roc: 0.9662 - val_loss: 0.2696 - val_acc: 0.8845 - val_auc-prc: 0.9562 - val_auc-roc: 0.9565 - 14s/epoch - 56ms/step
Epoch 25/100
258/258 - 14s - loss: 0.2278 - acc: 0.9080 - auc-prc: 0.9678 - auc-roc: 0.9680 - val_loss: 0.2607 - val_acc: 0.8943 - val_auc-prc: 0.9575 - val_auc-roc: 0.9581 - 14s/epoch - 55ms/step
Epoch 26/100
258/258 - 15s - loss: 0.2271 - acc: 0.9080 - auc-prc: 0.9678 - auc-roc: 0.9682 - val_loss: 0.2681 - val_acc: 0.9009 - val_auc-prc: 0.9583 - val_auc-roc: 0.9580 - 15s/epoch - 57ms/step
Early stopping epoch: 25
******Evaluating TEST set*********
29/29 - 1s - 716ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.88      0.88      0.88       386
           1       0.91      0.92      0.91       532

    accuracy                           0.90       918
   macro avg       0.90      0.90      0.90       918
weighted avg       0.90      0.90      0.90       918

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.43      0.51      0.47       386
           1       0.59      0.52      0.55       532

    accuracy                           0.52       918
   macro avg       0.51      0.51      0.51       918
weighted avg       0.53      0.52      0.52       918

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3285 - acc: 0.8626 - auc-prc: 0.9323 - auc-roc: 0.9340 - val_loss: 0.2872 - val_acc: 0.8802 - val_auc-prc: 0.9523 - val_auc-roc: 0.9514 - 17s/epoch - 65ms/step
Epoch 2/100
258/258 - 15s - loss: 0.2967 - acc: 0.8788 - auc-prc: 0.9429 - auc-roc: 0.9452 - val_loss: 0.2776 - val_acc: 0.8878 - val_auc-prc: 0.9541 - val_auc-roc: 0.9533 - 15s/epoch - 57ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2907 - acc: 0.8837 - auc-prc: 0.9452 - auc-roc: 0.9474 - val_loss: 0.2851 - val_acc: 0.8791 - val_auc-prc: 0.9513 - val_auc-roc: 0.9503 - 14s/epoch - 53ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2861 - acc: 0.8859 - auc-prc: 0.9469 - auc-roc: 0.9486 - val_loss: 0.2657 - val_acc: 0.8867 - val_auc-prc: 0.9581 - val_auc-roc: 0.9572 - 14s/epoch - 54ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2775 - acc: 0.8911 - auc-prc: 0.9500 - auc-roc: 0.9519 - val_loss: 0.2583 - val_acc: 0.8878 - val_auc-prc: 0.9594 - val_auc-roc: 0.9588 - 14s/epoch - 53ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2762 - acc: 0.8896 - auc-prc: 0.9505 - auc-roc: 0.9521 - val_loss: 0.2829 - val_acc: 0.8802 - val_auc-prc: 0.9520 - val_auc-roc: 0.9518 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2750 - acc: 0.8879 - auc-prc: 0.9519 - auc-roc: 0.9532 - val_loss: 0.2656 - val_acc: 0.8867 - val_auc-prc: 0.9588 - val_auc-roc: 0.9578 - 14s/epoch - 53ms/step
Epoch 8/100
258/258 - 15s - loss: 0.2694 - acc: 0.8914 - auc-prc: 0.9539 - auc-roc: 0.9550 - val_loss: 0.2647 - val_acc: 0.8932 - val_auc-prc: 0.9594 - val_auc-roc: 0.9581 - 15s/epoch - 57ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2712 - acc: 0.8905 - auc-prc: 0.9532 - auc-roc: 0.9545 - val_loss: 0.2577 - val_acc: 0.8922 - val_auc-prc: 0.9619 - val_auc-roc: 0.9607 - 14s/epoch - 56ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2669 - acc: 0.8913 - auc-prc: 0.9548 - auc-roc: 0.9558 - val_loss: 0.2542 - val_acc: 0.8911 - val_auc-prc: 0.9631 - val_auc-roc: 0.9620 - 14s/epoch - 54ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2650 - acc: 0.8937 - auc-prc: 0.9560 - auc-roc: 0.9567 - val_loss: 0.2578 - val_acc: 0.8867 - val_auc-prc: 0.9613 - val_auc-roc: 0.9605 - 14s/epoch - 53ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2606 - acc: 0.8951 - auc-prc: 0.9572 - auc-roc: 0.9579 - val_loss: 0.2525 - val_acc: 0.8911 - val_auc-prc: 0.9628 - val_auc-roc: 0.9618 - 14s/epoch - 52ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2585 - acc: 0.8959 - auc-prc: 0.9579 - auc-roc: 0.9588 - val_loss: 0.2499 - val_acc: 0.8932 - val_auc-prc: 0.9639 - val_auc-roc: 0.9628 - 14s/epoch - 55ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2575 - acc: 0.8973 - auc-prc: 0.9586 - auc-roc: 0.9593 - val_loss: 0.2585 - val_acc: 0.8943 - val_auc-prc: 0.9623 - val_auc-roc: 0.9611 - 14s/epoch - 53ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2559 - acc: 0.8979 - auc-prc: 0.9589 - auc-roc: 0.9597 - val_loss: 0.2576 - val_acc: 0.8976 - val_auc-prc: 0.9609 - val_auc-roc: 0.9604 - 14s/epoch - 53ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2546 - acc: 0.8951 - auc-prc: 0.9594 - auc-roc: 0.9602 - val_loss: 0.2509 - val_acc: 0.8965 - val_auc-prc: 0.9634 - val_auc-roc: 0.9625 - 14s/epoch - 53ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2498 - acc: 0.8981 - auc-prc: 0.9616 - auc-roc: 0.9619 - val_loss: 0.2504 - val_acc: 0.9031 - val_auc-prc: 0.9638 - val_auc-roc: 0.9628 - 14s/epoch - 56ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2501 - acc: 0.8997 - auc-prc: 0.9610 - auc-roc: 0.9614 - val_loss: 0.2538 - val_acc: 0.8889 - val_auc-prc: 0.9633 - val_auc-roc: 0.9623 - 14s/epoch - 55ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2449 - acc: 0.9015 - auc-prc: 0.9628 - auc-roc: 0.9631 - val_loss: 0.2565 - val_acc: 0.8878 - val_auc-prc: 0.9638 - val_auc-roc: 0.9627 - 14s/epoch - 53ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2431 - acc: 0.9021 - auc-prc: 0.9632 - auc-roc: 0.9638 - val_loss: 0.2625 - val_acc: 0.8943 - val_auc-prc: 0.9593 - val_auc-roc: 0.9584 - 14s/epoch - 55ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2402 - acc: 0.9019 - auc-prc: 0.9643 - auc-roc: 0.9644 - val_loss: 0.2535 - val_acc: 0.8998 - val_auc-prc: 0.9621 - val_auc-roc: 0.9612 - 14s/epoch - 54ms/step
Epoch 22/100
258/258 - 14s - loss: 0.2364 - acc: 0.9063 - auc-prc: 0.9656 - auc-roc: 0.9656 - val_loss: 0.2660 - val_acc: 0.8889 - val_auc-prc: 0.9582 - val_auc-roc: 0.9573 - 14s/epoch - 54ms/step
Epoch 23/100
258/258 - 14s - loss: 0.2348 - acc: 0.9038 - auc-prc: 0.9657 - auc-roc: 0.9660 - val_loss: 0.2849 - val_acc: 0.8834 - val_auc-prc: 0.9512 - val_auc-roc: 0.9503 - 14s/epoch - 55ms/step
Epoch 24/100
258/258 - 14s - loss: 0.2318 - acc: 0.9038 - auc-prc: 0.9670 - auc-roc: 0.9670 - val_loss: 0.2618 - val_acc: 0.8856 - val_auc-prc: 0.9610 - val_auc-roc: 0.9602 - 14s/epoch - 55ms/step
Epoch 25/100
258/258 - 14s - loss: 0.2255 - acc: 0.9100 - auc-prc: 0.9686 - auc-roc: 0.9688 - val_loss: 0.2982 - val_acc: 0.8791 - val_auc-prc: 0.9484 - val_auc-roc: 0.9478 - 14s/epoch - 53ms/step
Epoch 26/100
258/258 - 14s - loss: 0.2267 - acc: 0.9096 - auc-prc: 0.9683 - auc-roc: 0.9684 - val_loss: 0.2720 - val_acc: 0.8813 - val_auc-prc: 0.9594 - val_auc-roc: 0.9585 - 14s/epoch - 52ms/step
Epoch 27/100
258/258 - 14s - loss: 0.2195 - acc: 0.9128 - auc-prc: 0.9707 - auc-roc: 0.9704 - val_loss: 0.2732 - val_acc: 0.8900 - val_auc-prc: 0.9576 - val_auc-roc: 0.9569 - 14s/epoch - 53ms/step
Epoch 28/100
258/258 - 14s - loss: 0.2136 - acc: 0.9136 - auc-prc: 0.9722 - auc-roc: 0.9720 - val_loss: 0.2976 - val_acc: 0.8943 - val_auc-prc: 0.9549 - val_auc-roc: 0.9557 - 14s/epoch - 56ms/step
Epoch 29/100
258/258 - 14s - loss: 0.2081 - acc: 0.9164 - auc-prc: 0.9733 - auc-roc: 0.9733 - val_loss: 0.2825 - val_acc: 0.8878 - val_auc-prc: 0.9518 - val_auc-roc: 0.9527 - 14s/epoch - 55ms/step
Epoch 30/100
258/258 - 14s - loss: 0.2036 - acc: 0.9176 - auc-prc: 0.9750 - auc-roc: 0.9746 - val_loss: 0.2849 - val_acc: 0.8976 - val_auc-prc: 0.9529 - val_auc-roc: 0.9540 - 14s/epoch - 55ms/step
Epoch 31/100
258/258 - 14s - loss: 0.1997 - acc: 0.9225 - auc-prc: 0.9753 - auc-roc: 0.9753 - val_loss: 0.3010 - val_acc: 0.8802 - val_auc-prc: 0.9538 - val_auc-roc: 0.9535 - 14s/epoch - 55ms/step
Epoch 32/100
258/258 - 14s - loss: 0.1952 - acc: 0.9232 - auc-prc: 0.9764 - auc-roc: 0.9764 - val_loss: 0.3069 - val_acc: 0.8802 - val_auc-prc: 0.9500 - val_auc-roc: 0.9514 - 14s/epoch - 55ms/step
Epoch 33/100
258/258 - 14s - loss: 0.1826 - acc: 0.9261 - auc-prc: 0.9797 - auc-roc: 0.9794 - val_loss: 0.3055 - val_acc: 0.8780 - val_auc-prc: 0.9456 - val_auc-roc: 0.9489 - 14s/epoch - 55ms/step
Epoch 34/100
258/258 - 14s - loss: 0.1820 - acc: 0.9263 - auc-prc: 0.9796 - auc-roc: 0.9795 - val_loss: 0.3077 - val_acc: 0.8802 - val_auc-prc: 0.9469 - val_auc-roc: 0.9479 - 14s/epoch - 55ms/step
Epoch 35/100
258/258 - 14s - loss: 0.1758 - acc: 0.9323 - auc-prc: 0.9810 - auc-roc: 0.9807 - val_loss: 0.3124 - val_acc: 0.8845 - val_auc-prc: 0.9407 - val_auc-roc: 0.9443 - 14s/epoch - 55ms/step
Epoch 36/100
258/258 - 14s - loss: 0.1689 - acc: 0.9358 - auc-prc: 0.9821 - auc-roc: 0.9821 - val_loss: 0.3397 - val_acc: 0.8769 - val_auc-prc: 0.9448 - val_auc-roc: 0.9469 - 14s/epoch - 55ms/step
Epoch 37/100
258/258 - 14s - loss: 0.1639 - acc: 0.9375 - auc-prc: 0.9831 - auc-roc: 0.9832 - val_loss: 0.3196 - val_acc: 0.8791 - val_auc-prc: 0.9445 - val_auc-roc: 0.9479 - 14s/epoch - 55ms/step
Epoch 38/100
258/258 - 14s - loss: 0.1628 - acc: 0.9370 - auc-prc: 0.9833 - auc-roc: 0.9834 - val_loss: 0.3344 - val_acc: 0.8780 - val_auc-prc: 0.9440 - val_auc-roc: 0.9470 - 14s/epoch - 53ms/step
Epoch 39/100
258/258 - 13s - loss: 0.1502 - acc: 0.9423 - auc-prc: 0.9856 - auc-roc: 0.9858 - val_loss: 0.3469 - val_acc: 0.8856 - val_auc-prc: 0.9401 - val_auc-roc: 0.9448 - 13s/epoch - 51ms/step
Epoch 40/100
258/258 - 14s - loss: 0.1495 - acc: 0.9433 - auc-prc: 0.9859 - auc-roc: 0.9859 - val_loss: 0.3574 - val_acc: 0.8747 - val_auc-prc: 0.9383 - val_auc-roc: 0.9448 - 14s/epoch - 53ms/step
Epoch 41/100
258/258 - 14s - loss: 0.1421 - acc: 0.9455 - auc-prc: 0.9870 - auc-roc: 0.9871 - val_loss: 0.3650 - val_acc: 0.8834 - val_auc-prc: 0.9386 - val_auc-roc: 0.9447 - 14s/epoch - 53ms/step
Epoch 42/100
258/258 - 14s - loss: 0.1305 - acc: 0.9509 - auc-prc: 0.9891 - auc-roc: 0.9892 - val_loss: 0.3560 - val_acc: 0.8813 - val_auc-prc: 0.9454 - val_auc-roc: 0.9493 - 14s/epoch - 53ms/step
Epoch 43/100
258/258 - 14s - loss: 0.1289 - acc: 0.9500 - auc-prc: 0.9893 - auc-roc: 0.9894 - val_loss: 0.3928 - val_acc: 0.8758 - val_auc-prc: 0.9339 - val_auc-roc: 0.9403 - 14s/epoch - 54ms/step
Epoch 44/100
258/258 - 14s - loss: 0.1215 - acc: 0.9535 - auc-prc: 0.9904 - auc-roc: 0.9905 - val_loss: 0.3849 - val_acc: 0.8791 - val_auc-prc: 0.9388 - val_auc-roc: 0.9423 - 14s/epoch - 53ms/step
Epoch 45/100
258/258 - 14s - loss: 0.1263 - acc: 0.9484 - auc-prc: 0.9899 - auc-roc: 0.9900 - val_loss: 0.3799 - val_acc: 0.8769 - val_auc-prc: 0.9385 - val_auc-roc: 0.9430 - 14s/epoch - 53ms/step
Epoch 46/100
258/258 - 14s - loss: 0.1160 - acc: 0.9560 - auc-prc: 0.9914 - auc-roc: 0.9915 - val_loss: 0.4102 - val_acc: 0.8747 - val_auc-prc: 0.9344 - val_auc-roc: 0.9414 - 14s/epoch - 53ms/step
Epoch 47/100
258/258 - 14s - loss: 0.1061 - acc: 0.9612 - auc-prc: 0.9927 - auc-roc: 0.9927 - val_loss: 0.4492 - val_acc: 0.8693 - val_auc-prc: 0.9228 - val_auc-roc: 0.9318 - 14s/epoch - 53ms/step
Epoch 48/100
258/258 - 14s - loss: 0.1046 - acc: 0.9616 - auc-prc: 0.9930 - auc-roc: 0.9930 - val_loss: 0.4241 - val_acc: 0.8736 - val_auc-prc: 0.9290 - val_auc-roc: 0.9375 - 14s/epoch - 53ms/step
Epoch 49/100
258/258 - 14s - loss: 0.0944 - acc: 0.9654 - auc-prc: 0.9938 - auc-roc: 0.9940 - val_loss: 0.4374 - val_acc: 0.8638 - val_auc-prc: 0.9232 - val_auc-roc: 0.9324 - 14s/epoch - 53ms/step
Epoch 50/100
258/258 - 14s - loss: 0.0996 - acc: 0.9626 - auc-prc: 0.9935 - auc-roc: 0.9935 - val_loss: 0.4422 - val_acc: 0.8769 - val_auc-prc: 0.9191 - val_auc-roc: 0.9308 - 14s/epoch - 54ms/step
Epoch 51/100
258/258 - 14s - loss: 0.0876 - acc: 0.9674 - auc-prc: 0.9951 - auc-roc: 0.9951 - val_loss: 0.4739 - val_acc: 0.8725 - val_auc-prc: 0.9211 - val_auc-roc: 0.9311 - 14s/epoch - 53ms/step
Epoch 52/100
258/258 - 14s - loss: 0.0864 - acc: 0.9683 - auc-prc: 0.9953 - auc-roc: 0.9953 - val_loss: 0.4877 - val_acc: 0.8660 - val_auc-prc: 0.9231 - val_auc-roc: 0.9342 - 14s/epoch - 53ms/step
Epoch 53/100
258/258 - 14s - loss: 0.0854 - acc: 0.9673 - auc-prc: 0.9948 - auc-roc: 0.9950 - val_loss: 0.4923 - val_acc: 0.8769 - val_auc-prc: 0.9226 - val_auc-roc: 0.9343 - 14s/epoch - 54ms/step
Epoch 54/100
258/258 - 14s - loss: 0.0749 - acc: 0.9721 - auc-prc: 0.9966 - auc-roc: 0.9965 - val_loss: 0.5281 - val_acc: 0.8682 - val_auc-prc: 0.9084 - val_auc-roc: 0.9212 - 14s/epoch - 53ms/step
Epoch 55/100
258/258 - 14s - loss: 0.0710 - acc: 0.9737 - auc-prc: 0.9969 - auc-roc: 0.9969 - val_loss: 0.5512 - val_acc: 0.8638 - val_auc-prc: 0.9143 - val_auc-roc: 0.9274 - 14s/epoch - 54ms/step
Epoch 56/100
258/258 - 14s - loss: 0.0776 - acc: 0.9721 - auc-prc: 0.9957 - auc-roc: 0.9958 - val_loss: 0.5078 - val_acc: 0.8747 - val_auc-prc: 0.9159 - val_auc-roc: 0.9285 - 14s/epoch - 54ms/step
Epoch 57/100
258/258 - 14s - loss: 0.0649 - acc: 0.9767 - auc-prc: 0.9972 - auc-roc: 0.9972 - val_loss: 0.5740 - val_acc: 0.8693 - val_auc-prc: 0.9133 - val_auc-roc: 0.9263 - 14s/epoch - 54ms/step
Epoch 58/100
258/258 - 14s - loss: 0.0646 - acc: 0.9766 - auc-prc: 0.9972 - auc-roc: 0.9972 - val_loss: 0.5896 - val_acc: 0.8617 - val_auc-prc: 0.9037 - val_auc-roc: 0.9173 - 14s/epoch - 53ms/step
Epoch 59/100
258/258 - 14s - loss: 0.0717 - acc: 0.9729 - auc-prc: 0.9962 - auc-roc: 0.9964 - val_loss: 0.5655 - val_acc: 0.8693 - val_auc-prc: 0.9084 - val_auc-roc: 0.9219 - 14s/epoch - 56ms/step
Epoch 60/100
258/258 - 14s - loss: 0.0660 - acc: 0.9749 - auc-prc: 0.9971 - auc-roc: 0.9971 - val_loss: 0.6481 - val_acc: 0.8551 - val_auc-prc: 0.8944 - val_auc-roc: 0.9115 - 14s/epoch - 56ms/step
Epoch 61/100
258/258 - 15s - loss: 0.0708 - acc: 0.9730 - auc-prc: 0.9964 - auc-roc: 0.9966 - val_loss: 0.5950 - val_acc: 0.8584 - val_auc-prc: 0.8984 - val_auc-roc: 0.9142 - 15s/epoch - 57ms/step
Epoch 62/100
258/258 - 14s - loss: 0.0632 - acc: 0.9764 - auc-prc: 0.9973 - auc-roc: 0.9973 - val_loss: 0.6130 - val_acc: 0.8649 - val_auc-prc: 0.9064 - val_auc-roc: 0.9212 - 14s/epoch - 56ms/step
Epoch 63/100
258/258 - 14s - loss: 0.0637 - acc: 0.9770 - auc-prc: 0.9971 - auc-roc: 0.9972 - val_loss: 0.6173 - val_acc: 0.8529 - val_auc-prc: 0.8975 - val_auc-roc: 0.9140 - 14s/epoch - 55ms/step
Epoch 64/100
258/258 - 14s - loss: 0.0556 - acc: 0.9804 - auc-prc: 0.9975 - auc-roc: 0.9977 - val_loss: 0.6299 - val_acc: 0.8649 - val_auc-prc: 0.9025 - val_auc-roc: 0.9186 - 14s/epoch - 55ms/step
Epoch 65/100
258/258 - 14s - loss: 0.0557 - acc: 0.9790 - auc-prc: 0.9979 - auc-roc: 0.9980 - val_loss: 0.5852 - val_acc: 0.8725 - val_auc-prc: 0.9099 - val_auc-roc: 0.9233 - 14s/epoch - 56ms/step
Epoch 66/100
258/258 - 14s - loss: 0.0442 - acc: 0.9838 - auc-prc: 0.9986 - auc-roc: 0.9986 - val_loss: 0.6558 - val_acc: 0.8606 - val_auc-prc: 0.8991 - val_auc-roc: 0.9158 - 14s/epoch - 53ms/step
Epoch 67/100
258/258 - 14s - loss: 0.0422 - acc: 0.9853 - auc-prc: 0.9988 - auc-roc: 0.9988 - val_loss: 0.7371 - val_acc: 0.8573 - val_auc-prc: 0.8913 - val_auc-roc: 0.9097 - 14s/epoch - 56ms/step
Epoch 68/100
258/258 - 14s - loss: 0.0622 - acc: 0.9773 - auc-prc: 0.9970 - auc-roc: 0.9972 - val_loss: 0.6143 - val_acc: 0.8606 - val_auc-prc: 0.9112 - val_auc-roc: 0.9246 - 14s/epoch - 55ms/step
Epoch 69/100
258/258 - 13s - loss: 0.0656 - acc: 0.9769 - auc-prc: 0.9966 - auc-roc: 0.9968 - val_loss: 0.6494 - val_acc: 0.8595 - val_auc-prc: 0.9033 - val_auc-roc: 0.9179 - 13s/epoch - 51ms/step
Epoch 70/100
258/258 - 13s - loss: 0.0378 - acc: 0.9885 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.6911 - val_acc: 0.8627 - val_auc-prc: 0.8991 - val_auc-roc: 0.9166 - 13s/epoch - 52ms/step
Epoch 71/100
258/258 - 13s - loss: 0.0427 - acc: 0.9844 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.6800 - val_acc: 0.8682 - val_auc-prc: 0.8988 - val_auc-roc: 0.9167 - 13s/epoch - 51ms/step
Epoch 72/100
258/258 - 14s - loss: 0.0361 - acc: 0.9878 - auc-prc: 0.9992 - auc-roc: 0.9992 - val_loss: 0.6997 - val_acc: 0.8638 - val_auc-prc: 0.8941 - val_auc-roc: 0.9124 - 14s/epoch - 53ms/step
Epoch 73/100
258/258 - 14s - loss: 0.0442 - acc: 0.9841 - auc-prc: 0.9981 - auc-roc: 0.9983 - val_loss: 0.7015 - val_acc: 0.8736 - val_auc-prc: 0.9043 - val_auc-roc: 0.9208 - 14s/epoch - 54ms/step
Epoch 74/100
258/258 - 14s - loss: 0.0466 - acc: 0.9827 - auc-prc: 0.9981 - auc-roc: 0.9982 - val_loss: 0.7498 - val_acc: 0.8715 - val_auc-prc: 0.8962 - val_auc-roc: 0.9148 - 14s/epoch - 54ms/step
Epoch 75/100
258/258 - 14s - loss: 0.0547 - acc: 0.9823 - auc-prc: 0.9968 - auc-roc: 0.9972 - val_loss: 0.7422 - val_acc: 0.8519 - val_auc-prc: 0.8981 - val_auc-roc: 0.9150 - 14s/epoch - 53ms/step
Epoch 76/100
258/258 - 14s - loss: 0.0501 - acc: 0.9816 - auc-prc: 0.9978 - auc-roc: 0.9980 - val_loss: 0.7128 - val_acc: 0.8704 - val_auc-prc: 0.8971 - val_auc-roc: 0.9160 - 14s/epoch - 53ms/step
Epoch 77/100
258/258 - 14s - loss: 0.0419 - acc: 0.9843 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.7059 - val_acc: 0.8736 - val_auc-prc: 0.8989 - val_auc-roc: 0.9168 - 14s/epoch - 53ms/step
Epoch 78/100
258/258 - 14s - loss: 0.0348 - acc: 0.9876 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.7499 - val_acc: 0.8736 - val_auc-prc: 0.8981 - val_auc-roc: 0.9169 - 14s/epoch - 53ms/step
Epoch 79/100
258/258 - 14s - loss: 0.0277 - acc: 0.9899 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.7593 - val_acc: 0.8660 - val_auc-prc: 0.9008 - val_auc-roc: 0.9180 - 14s/epoch - 53ms/step
Epoch 80/100
258/258 - 14s - loss: 0.0601 - acc: 0.9772 - auc-prc: 0.9973 - auc-roc: 0.9975 - val_loss: 0.6717 - val_acc: 0.8606 - val_auc-prc: 0.8949 - val_auc-roc: 0.9117 - 14s/epoch - 53ms/step
Epoch 81/100
258/258 - 14s - loss: 0.0376 - acc: 0.9873 - auc-prc: 0.9990 - auc-roc: 0.9990 - val_loss: 0.7695 - val_acc: 0.8671 - val_auc-prc: 0.8892 - val_auc-roc: 0.9089 - 14s/epoch - 53ms/step
Epoch 82/100
258/258 - 14s - loss: 0.0282 - acc: 0.9909 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.7678 - val_acc: 0.8736 - val_auc-prc: 0.8978 - val_auc-roc: 0.9158 - 14s/epoch - 53ms/step
Epoch 83/100
258/258 - 14s - loss: 0.0274 - acc: 0.9922 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.8091 - val_acc: 0.8802 - val_auc-prc: 0.8991 - val_auc-roc: 0.9176 - 14s/epoch - 53ms/step
Epoch 84/100
258/258 - 14s - loss: 0.0431 - acc: 0.9840 - auc-prc: 0.9981 - auc-roc: 0.9983 - val_loss: 0.7274 - val_acc: 0.8606 - val_auc-prc: 0.8973 - val_auc-roc: 0.9155 - 14s/epoch - 53ms/step
Epoch 85/100
258/258 - 14s - loss: 0.0223 - acc: 0.9918 - auc-prc: 0.9996 - auc-roc: 0.9996 - val_loss: 0.7818 - val_acc: 0.8747 - val_auc-prc: 0.8961 - val_auc-roc: 0.9150 - 14s/epoch - 55ms/step
Epoch 86/100
258/258 - 15s - loss: 0.0233 - acc: 0.9919 - auc-prc: 0.9997 - auc-roc: 0.9997 - val_loss: 0.8398 - val_acc: 0.8747 - val_auc-prc: 0.8987 - val_auc-roc: 0.9175 - 15s/epoch - 57ms/step
Epoch 87/100
258/258 - 14s - loss: 0.0302 - acc: 0.9881 - auc-prc: 0.9993 - auc-roc: 0.9994 - val_loss: 0.7920 - val_acc: 0.8606 - val_auc-prc: 0.8832 - val_auc-roc: 0.9042 - 14s/epoch - 56ms/step
Epoch 88/100
258/258 - 14s - loss: 0.0327 - acc: 0.9889 - auc-prc: 0.9992 - auc-roc: 0.9992 - val_loss: 0.8179 - val_acc: 0.8627 - val_auc-prc: 0.8925 - val_auc-roc: 0.9114 - 14s/epoch - 56ms/step
Epoch 89/100
258/258 - 14s - loss: 0.0457 - acc: 0.9822 - auc-prc: 0.9983 - auc-roc: 0.9984 - val_loss: 0.7763 - val_acc: 0.8638 - val_auc-prc: 0.8942 - val_auc-roc: 0.9128 - 14s/epoch - 54ms/step
Epoch 90/100
258/258 - 14s - loss: 0.0519 - acc: 0.9819 - auc-prc: 0.9972 - auc-roc: 0.9976 - val_loss: 0.7583 - val_acc: 0.8682 - val_auc-prc: 0.8926 - val_auc-roc: 0.9119 - 14s/epoch - 53ms/step
Epoch 91/100
258/258 - 14s - loss: 0.0338 - acc: 0.9891 - auc-prc: 0.9987 - auc-roc: 0.9989 - val_loss: 0.7762 - val_acc: 0.8682 - val_auc-prc: 0.8893 - val_auc-roc: 0.9094 - 14s/epoch - 53ms/step
Epoch 92/100
258/258 - 14s - loss: 0.0338 - acc: 0.9869 - auc-prc: 0.9992 - auc-roc: 0.9992 - val_loss: 0.7933 - val_acc: 0.8769 - val_auc-prc: 0.8935 - val_auc-roc: 0.9132 - 14s/epoch - 53ms/step
Epoch 93/100
258/258 - 14s - loss: 0.0279 - acc: 0.9910 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.7733 - val_acc: 0.8715 - val_auc-prc: 0.8908 - val_auc-roc: 0.9106 - 14s/epoch - 54ms/step
Epoch 94/100
258/258 - 14s - loss: 0.0343 - acc: 0.9869 - auc-prc: 0.9987 - auc-roc: 0.9989 - val_loss: 0.7949 - val_acc: 0.8736 - val_auc-prc: 0.8905 - val_auc-roc: 0.9106 - 14s/epoch - 53ms/step
Epoch 95/100
258/258 - 14s - loss: 0.0349 - acc: 0.9864 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.8042 - val_acc: 0.8584 - val_auc-prc: 0.8948 - val_auc-roc: 0.9133 - 14s/epoch - 53ms/step
Epoch 96/100
258/258 - 14s - loss: 0.0183 - acc: 0.9938 - auc-prc: 0.9995 - auc-roc: 0.9996 - val_loss: 0.8672 - val_acc: 0.8715 - val_auc-prc: 0.8908 - val_auc-roc: 0.9108 - 14s/epoch - 53ms/step
Epoch 97/100
258/258 - 14s - loss: 0.0215 - acc: 0.9929 - auc-prc: 0.9991 - auc-roc: 0.9993 - val_loss: 0.8337 - val_acc: 0.8715 - val_auc-prc: 0.8863 - val_auc-roc: 0.9072 - 14s/epoch - 53ms/step
Epoch 98/100
258/258 - 14s - loss: 0.0369 - acc: 0.9866 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.8318 - val_acc: 0.8627 - val_auc-prc: 0.8924 - val_auc-roc: 0.9110 - 14s/epoch - 53ms/step
Epoch 99/100
258/258 - 13s - loss: 0.0410 - acc: 0.9858 - auc-prc: 0.9982 - auc-roc: 0.9984 - val_loss: 0.7880 - val_acc: 0.8671 - val_auc-prc: 0.8927 - val_auc-roc: 0.9125 - 13s/epoch - 51ms/step
Epoch 100/100
258/258 - 14s - loss: 0.0495 - acc: 0.9822 - auc-prc: 0.9974 - auc-roc: 0.9978 - val_loss: 0.7742 - val_acc: 0.8682 - val_auc-prc: 0.8957 - val_auc-roc: 0.9140 - 14s/epoch - 53ms/step
Early stopping epoch: 0
******Evaluating TEST set*********
29/29 - 1s - 741ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.87      0.87      0.87       386
           1       0.91      0.91      0.91       532

    accuracy                           0.89       918
   macro avg       0.89      0.89      0.89       918
weighted avg       0.89      0.89      0.89       918

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.52      0.47       386
           1       0.58      0.48      0.53       532

    accuracy                           0.50       918
   macro avg       0.50      0.50      0.50       918
weighted avg       0.51      0.50      0.50       918

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 16s - loss: 0.3243 - acc: 0.8643 - auc-prc: 0.9340 - auc-roc: 0.9357 - val_loss: 0.3338 - val_acc: 0.8571 - val_auc-prc: 0.9302 - val_auc-roc: 0.9309 - 16s/epoch - 63ms/step
Epoch 2/100
258/258 - 15s - loss: 0.2942 - acc: 0.8824 - auc-prc: 0.9445 - auc-roc: 0.9461 - val_loss: 0.3532 - val_acc: 0.8550 - val_auc-prc: 0.9312 - val_auc-roc: 0.9312 - 15s/epoch - 57ms/step
Epoch 3/100
258/258 - 15s - loss: 0.2867 - acc: 0.8873 - auc-prc: 0.9469 - auc-roc: 0.9489 - val_loss: 0.3128 - val_acc: 0.8702 - val_auc-prc: 0.9420 - val_auc-roc: 0.9416 - 15s/epoch - 57ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2811 - acc: 0.8866 - auc-prc: 0.9491 - auc-roc: 0.9507 - val_loss: 0.3053 - val_acc: 0.8757 - val_auc-prc: 0.9432 - val_auc-roc: 0.9429 - 14s/epoch - 56ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2723 - acc: 0.8894 - auc-prc: 0.9530 - auc-roc: 0.9538 - val_loss: 0.3060 - val_acc: 0.8746 - val_auc-prc: 0.9427 - val_auc-roc: 0.9424 - 14s/epoch - 55ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2707 - acc: 0.8912 - auc-prc: 0.9530 - auc-roc: 0.9543 - val_loss: 0.2938 - val_acc: 0.8757 - val_auc-prc: 0.9469 - val_auc-roc: 0.9472 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2661 - acc: 0.8905 - auc-prc: 0.9555 - auc-roc: 0.9560 - val_loss: 0.3012 - val_acc: 0.8670 - val_auc-prc: 0.9416 - val_auc-roc: 0.9450 - 14s/epoch - 54ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2665 - acc: 0.8918 - auc-prc: 0.9547 - auc-roc: 0.9556 - val_loss: 0.3244 - val_acc: 0.8593 - val_auc-prc: 0.9337 - val_auc-roc: 0.9398 - 14s/epoch - 53ms/step
Epoch 9/100
258/258 - 13s - loss: 0.2646 - acc: 0.8923 - auc-prc: 0.9564 - auc-roc: 0.9567 - val_loss: 0.2901 - val_acc: 0.8800 - val_auc-prc: 0.9498 - val_auc-roc: 0.9492 - 13s/epoch - 52ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2624 - acc: 0.8962 - auc-prc: 0.9567 - auc-roc: 0.9575 - val_loss: 0.2928 - val_acc: 0.8768 - val_auc-prc: 0.9484 - val_auc-roc: 0.9487 - 14s/epoch - 53ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2585 - acc: 0.8978 - auc-prc: 0.9582 - auc-roc: 0.9586 - val_loss: 0.2930 - val_acc: 0.8779 - val_auc-prc: 0.9481 - val_auc-roc: 0.9485 - 14s/epoch - 54ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2560 - acc: 0.8956 - auc-prc: 0.9593 - auc-roc: 0.9596 - val_loss: 0.2932 - val_acc: 0.8757 - val_auc-prc: 0.9466 - val_auc-roc: 0.9487 - 14s/epoch - 54ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2532 - acc: 0.8986 - auc-prc: 0.9599 - auc-roc: 0.9604 - val_loss: 0.2857 - val_acc: 0.8757 - val_auc-prc: 0.9500 - val_auc-roc: 0.9507 - 14s/epoch - 54ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2507 - acc: 0.8957 - auc-prc: 0.9612 - auc-roc: 0.9613 - val_loss: 0.2857 - val_acc: 0.8735 - val_auc-prc: 0.9516 - val_auc-roc: 0.9509 - 14s/epoch - 54ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2507 - acc: 0.8981 - auc-prc: 0.9610 - auc-roc: 0.9613 - val_loss: 0.2812 - val_acc: 0.8822 - val_auc-prc: 0.9520 - val_auc-roc: 0.9526 - 14s/epoch - 54ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2479 - acc: 0.9022 - auc-prc: 0.9618 - auc-roc: 0.9620 - val_loss: 0.3194 - val_acc: 0.8691 - val_auc-prc: 0.9448 - val_auc-roc: 0.9468 - 14s/epoch - 54ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2440 - acc: 0.9033 - auc-prc: 0.9635 - auc-roc: 0.9633 - val_loss: 0.2813 - val_acc: 0.8811 - val_auc-prc: 0.9526 - val_auc-roc: 0.9527 - 14s/epoch - 54ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2395 - acc: 0.9022 - auc-prc: 0.9652 - auc-roc: 0.9649 - val_loss: 0.3073 - val_acc: 0.8735 - val_auc-prc: 0.9432 - val_auc-roc: 0.9466 - 14s/epoch - 54ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2448 - acc: 0.8986 - auc-prc: 0.9635 - auc-roc: 0.9633 - val_loss: 0.2849 - val_acc: 0.8768 - val_auc-prc: 0.9526 - val_auc-roc: 0.9524 - 14s/epoch - 54ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2382 - acc: 0.9009 - auc-prc: 0.9652 - auc-roc: 0.9650 - val_loss: 0.2786 - val_acc: 0.8768 - val_auc-prc: 0.9537 - val_auc-roc: 0.9537 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2343 - acc: 0.9036 - auc-prc: 0.9665 - auc-roc: 0.9664 - val_loss: 0.3052 - val_acc: 0.8691 - val_auc-prc: 0.9437 - val_auc-roc: 0.9472 - 14s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
29/29 - 1s - 667ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.88      0.82      0.85       385
           1       0.87      0.92      0.90       532

    accuracy                           0.88       917
   macro avg       0.88      0.87      0.87       917
weighted avg       0.88      0.88      0.88       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.50      0.46       385
           1       0.58      0.50      0.54       532

    accuracy                           0.50       917
   macro avg       0.50      0.50      0.50       917
weighted avg       0.52      0.50      0.51       917

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3278 - acc: 0.8569 - auc-prc: 0.9327 - auc-roc: 0.9338 - val_loss: 0.2918 - val_acc: 0.8757 - val_auc-prc: 0.9462 - val_auc-roc: 0.9483 - 17s/epoch - 64ms/step
Epoch 2/100
258/258 - 14s - loss: 0.2973 - acc: 0.8779 - auc-prc: 0.9440 - auc-roc: 0.9456 - val_loss: 0.2854 - val_acc: 0.8866 - val_auc-prc: 0.9485 - val_auc-roc: 0.9510 - 14s/epoch - 55ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2881 - acc: 0.8848 - auc-prc: 0.9467 - auc-roc: 0.9483 - val_loss: 0.2859 - val_acc: 0.8779 - val_auc-prc: 0.9494 - val_auc-roc: 0.9510 - 14s/epoch - 55ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2817 - acc: 0.8861 - auc-prc: 0.9495 - auc-roc: 0.9507 - val_loss: 0.2760 - val_acc: 0.8822 - val_auc-prc: 0.9537 - val_auc-roc: 0.9542 - 14s/epoch - 55ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2767 - acc: 0.8904 - auc-prc: 0.9508 - auc-roc: 0.9523 - val_loss: 0.2911 - val_acc: 0.8888 - val_auc-prc: 0.9491 - val_auc-roc: 0.9497 - 14s/epoch - 55ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2763 - acc: 0.8888 - auc-prc: 0.9516 - auc-roc: 0.9526 - val_loss: 0.2646 - val_acc: 0.8866 - val_auc-prc: 0.9565 - val_auc-roc: 0.9569 - 14s/epoch - 54ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2716 - acc: 0.8915 - auc-prc: 0.9530 - auc-roc: 0.9543 - val_loss: 0.2655 - val_acc: 0.8877 - val_auc-prc: 0.9574 - val_auc-roc: 0.9573 - 14s/epoch - 54ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2704 - acc: 0.8911 - auc-prc: 0.9535 - auc-roc: 0.9547 - val_loss: 0.2597 - val_acc: 0.8899 - val_auc-prc: 0.9586 - val_auc-roc: 0.9585 - 14s/epoch - 55ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2651 - acc: 0.8921 - auc-prc: 0.9554 - auc-roc: 0.9565 - val_loss: 0.2689 - val_acc: 0.8877 - val_auc-prc: 0.9580 - val_auc-roc: 0.9574 - 14s/epoch - 56ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2619 - acc: 0.8934 - auc-prc: 0.9569 - auc-roc: 0.9577 - val_loss: 0.2570 - val_acc: 0.8931 - val_auc-prc: 0.9584 - val_auc-roc: 0.9586 - 14s/epoch - 55ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2633 - acc: 0.8939 - auc-prc: 0.9567 - auc-roc: 0.9574 - val_loss: 0.2604 - val_acc: 0.8888 - val_auc-prc: 0.9600 - val_auc-roc: 0.9593 - 14s/epoch - 55ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2603 - acc: 0.8923 - auc-prc: 0.9578 - auc-roc: 0.9584 - val_loss: 0.2577 - val_acc: 0.8888 - val_auc-prc: 0.9592 - val_auc-roc: 0.9593 - 14s/epoch - 55ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2588 - acc: 0.8957 - auc-prc: 0.9582 - auc-roc: 0.9588 - val_loss: 0.2674 - val_acc: 0.8844 - val_auc-prc: 0.9586 - val_auc-roc: 0.9580 - 14s/epoch - 55ms/step
Epoch 14/100
258/258 - 15s - loss: 0.2562 - acc: 0.8969 - auc-prc: 0.9585 - auc-roc: 0.9594 - val_loss: 0.2639 - val_acc: 0.8866 - val_auc-prc: 0.9588 - val_auc-roc: 0.9584 - 15s/epoch - 57ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2582 - acc: 0.8978 - auc-prc: 0.9581 - auc-roc: 0.9589 - val_loss: 0.2565 - val_acc: 0.8964 - val_auc-prc: 0.9608 - val_auc-roc: 0.9603 - 14s/epoch - 54ms/step
Epoch 16/100
258/258 - 15s - loss: 0.2530 - acc: 0.8959 - auc-prc: 0.9602 - auc-roc: 0.9608 - val_loss: 0.2569 - val_acc: 0.8931 - val_auc-prc: 0.9598 - val_auc-roc: 0.9594 - 15s/epoch - 56ms/step
Epoch 17/100
258/258 - 15s - loss: 0.2516 - acc: 0.8978 - auc-prc: 0.9606 - auc-roc: 0.9611 - val_loss: 0.2648 - val_acc: 0.8844 - val_auc-prc: 0.9590 - val_auc-roc: 0.9585 - 15s/epoch - 57ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2442 - acc: 0.9008 - auc-prc: 0.9631 - auc-roc: 0.9635 - val_loss: 0.2627 - val_acc: 0.8866 - val_auc-prc: 0.9600 - val_auc-roc: 0.9590 - 14s/epoch - 53ms/step
Epoch 19/100
258/258 - 13s - loss: 0.2465 - acc: 0.8978 - auc-prc: 0.9626 - auc-roc: 0.9628 - val_loss: 0.2544 - val_acc: 0.8931 - val_auc-prc: 0.9613 - val_auc-roc: 0.9605 - 13s/epoch - 52ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2420 - acc: 0.8990 - auc-prc: 0.9640 - auc-roc: 0.9641 - val_loss: 0.2474 - val_acc: 0.8986 - val_auc-prc: 0.9624 - val_auc-roc: 0.9621 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2387 - acc: 0.9035 - auc-prc: 0.9648 - auc-roc: 0.9650 - val_loss: 0.2478 - val_acc: 0.8953 - val_auc-prc: 0.9636 - val_auc-roc: 0.9628 - 14s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
29/29 - 1s - 723ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.90      0.84      0.87       385
           1       0.89      0.93      0.91       532

    accuracy                           0.90       917
   macro avg       0.90      0.89      0.89       917
weighted avg       0.90      0.90      0.89       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.48      0.44       385
           1       0.57      0.50      0.53       532

    accuracy                           0.49       917
   macro avg       0.49      0.49      0.49       917
weighted avg       0.50      0.49      0.49       917

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3289 - acc: 0.8573 - auc-prc: 0.9327 - auc-roc: 0.9335 - val_loss: 0.3067 - val_acc: 0.8811 - val_auc-prc: 0.9403 - val_auc-roc: 0.9421 - 17s/epoch - 67ms/step
Epoch 2/100
258/258 - 14s - loss: 0.2977 - acc: 0.8797 - auc-prc: 0.9429 - auc-roc: 0.9449 - val_loss: 0.3115 - val_acc: 0.8670 - val_auc-prc: 0.9406 - val_auc-roc: 0.9409 - 14s/epoch - 55ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2829 - acc: 0.8890 - auc-prc: 0.9485 - auc-roc: 0.9503 - val_loss: 0.2948 - val_acc: 0.8855 - val_auc-prc: 0.9476 - val_auc-roc: 0.9480 - 14s/epoch - 55ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2760 - acc: 0.8896 - auc-prc: 0.9512 - auc-roc: 0.9526 - val_loss: 0.2813 - val_acc: 0.8779 - val_auc-prc: 0.9524 - val_auc-roc: 0.9524 - 14s/epoch - 56ms/step
Epoch 5/100
258/258 - 15s - loss: 0.2715 - acc: 0.8933 - auc-prc: 0.9528 - auc-roc: 0.9544 - val_loss: 0.2917 - val_acc: 0.8899 - val_auc-prc: 0.9516 - val_auc-roc: 0.9518 - 15s/epoch - 56ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2682 - acc: 0.8923 - auc-prc: 0.9547 - auc-roc: 0.9555 - val_loss: 0.2764 - val_acc: 0.8811 - val_auc-prc: 0.9538 - val_auc-roc: 0.9533 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2679 - acc: 0.8933 - auc-prc: 0.9546 - auc-roc: 0.9555 - val_loss: 0.2764 - val_acc: 0.8844 - val_auc-prc: 0.9534 - val_auc-roc: 0.9530 - 14s/epoch - 55ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2679 - acc: 0.8921 - auc-prc: 0.9550 - auc-roc: 0.9559 - val_loss: 0.2842 - val_acc: 0.8724 - val_auc-prc: 0.9521 - val_auc-roc: 0.9514 - 14s/epoch - 55ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2631 - acc: 0.8934 - auc-prc: 0.9566 - auc-roc: 0.9573 - val_loss: 0.2741 - val_acc: 0.8866 - val_auc-prc: 0.9554 - val_auc-roc: 0.9548 - 14s/epoch - 56ms/step
Epoch 10/100
258/258 - 15s - loss: 0.2618 - acc: 0.8918 - auc-prc: 0.9570 - auc-roc: 0.9580 - val_loss: 0.2803 - val_acc: 0.8899 - val_auc-prc: 0.9529 - val_auc-roc: 0.9523 - 15s/epoch - 58ms/step
Epoch 11/100
258/258 - 15s - loss: 0.2600 - acc: 0.8945 - auc-prc: 0.9577 - auc-roc: 0.9584 - val_loss: 0.2734 - val_acc: 0.8909 - val_auc-prc: 0.9548 - val_auc-roc: 0.9543 - 15s/epoch - 57ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2560 - acc: 0.8941 - auc-prc: 0.9592 - auc-roc: 0.9597 - val_loss: 0.2741 - val_acc: 0.8866 - val_auc-prc: 0.9553 - val_auc-roc: 0.9544 - 14s/epoch - 56ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2543 - acc: 0.8969 - auc-prc: 0.9593 - auc-roc: 0.9601 - val_loss: 0.2941 - val_acc: 0.8811 - val_auc-prc: 0.9480 - val_auc-roc: 0.9483 - 14s/epoch - 54ms/step
Epoch 14/100
258/258 - 15s - loss: 0.2507 - acc: 0.8945 - auc-prc: 0.9611 - auc-roc: 0.9615 - val_loss: 0.2794 - val_acc: 0.8866 - val_auc-prc: 0.9526 - val_auc-roc: 0.9523 - 15s/epoch - 56ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2498 - acc: 0.8985 - auc-prc: 0.9612 - auc-roc: 0.9617 - val_loss: 0.2846 - val_acc: 0.8844 - val_auc-prc: 0.9527 - val_auc-roc: 0.9520 - 14s/epoch - 52ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2463 - acc: 0.8986 - auc-prc: 0.9626 - auc-roc: 0.9627 - val_loss: 0.2825 - val_acc: 0.8800 - val_auc-prc: 0.9521 - val_auc-roc: 0.9525 - 14s/epoch - 54ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2423 - acc: 0.9015 - auc-prc: 0.9639 - auc-roc: 0.9639 - val_loss: 0.2675 - val_acc: 0.8877 - val_auc-prc: 0.9576 - val_auc-roc: 0.9569 - 14s/epoch - 54ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2402 - acc: 0.9001 - auc-prc: 0.9646 - auc-roc: 0.9647 - val_loss: 0.2857 - val_acc: 0.8790 - val_auc-prc: 0.9509 - val_auc-roc: 0.9514 - 14s/epoch - 55ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2358 - acc: 0.9053 - auc-prc: 0.9655 - auc-roc: 0.9657 - val_loss: 0.2783 - val_acc: 0.8909 - val_auc-prc: 0.9549 - val_auc-roc: 0.9549 - 14s/epoch - 55ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2376 - acc: 0.9026 - auc-prc: 0.9651 - auc-roc: 0.9653 - val_loss: 0.2797 - val_acc: 0.8844 - val_auc-prc: 0.9522 - val_auc-roc: 0.9529 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2305 - acc: 0.9072 - auc-prc: 0.9666 - auc-roc: 0.9672 - val_loss: 0.2910 - val_acc: 0.8855 - val_auc-prc: 0.9525 - val_auc-roc: 0.9527 - 14s/epoch - 55ms/step
Epoch 22/100
258/258 - 14s - loss: 0.2277 - acc: 0.9098 - auc-prc: 0.9683 - auc-roc: 0.9681 - val_loss: 0.2885 - val_acc: 0.8877 - val_auc-prc: 0.9499 - val_auc-roc: 0.9509 - 14s/epoch - 55ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
29/29 - 1s - 707ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.85      0.86       386
           1       0.89      0.91      0.90       531

    accuracy                           0.89       917
   macro avg       0.89      0.88      0.88       917
weighted avg       0.89      0.89      0.89       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.43      0.49      0.46       386
           1       0.59      0.53      0.56       531

    accuracy                           0.51       917
   macro avg       0.51      0.51      0.51       917
weighted avg       0.52      0.51      0.52       917

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3324 - acc: 0.8581 - auc-prc: 0.9310 - auc-roc: 0.9322 - val_loss: 0.2646 - val_acc: 0.8920 - val_auc-prc: 0.9551 - val_auc-roc: 0.9562 - 17s/epoch - 64ms/step
Epoch 2/100
258/258 - 14s - loss: 0.3033 - acc: 0.8778 - auc-prc: 0.9405 - auc-roc: 0.9430 - val_loss: 0.2581 - val_acc: 0.8931 - val_auc-prc: 0.9574 - val_auc-roc: 0.9579 - 14s/epoch - 56ms/step
Epoch 3/100
258/258 - 15s - loss: 0.2894 - acc: 0.8848 - auc-prc: 0.9461 - auc-roc: 0.9479 - val_loss: 0.2489 - val_acc: 0.8942 - val_auc-prc: 0.9614 - val_auc-roc: 0.9614 - 15s/epoch - 58ms/step
Epoch 4/100
258/258 - 15s - loss: 0.2857 - acc: 0.8826 - auc-prc: 0.9478 - auc-roc: 0.9493 - val_loss: 0.2464 - val_acc: 0.8986 - val_auc-prc: 0.9617 - val_auc-roc: 0.9617 - 15s/epoch - 57ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2839 - acc: 0.8849 - auc-prc: 0.9485 - auc-roc: 0.9498 - val_loss: 0.2400 - val_acc: 0.9073 - val_auc-prc: 0.9648 - val_auc-roc: 0.9650 - 14s/epoch - 56ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2817 - acc: 0.8871 - auc-prc: 0.9489 - auc-roc: 0.9507 - val_loss: 0.2428 - val_acc: 0.9095 - val_auc-prc: 0.9647 - val_auc-roc: 0.9647 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2758 - acc: 0.8855 - auc-prc: 0.9517 - auc-roc: 0.9529 - val_loss: 0.2407 - val_acc: 0.8997 - val_auc-prc: 0.9661 - val_auc-roc: 0.9657 - 14s/epoch - 55ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2732 - acc: 0.8898 - auc-prc: 0.9528 - auc-roc: 0.9536 - val_loss: 0.2374 - val_acc: 0.9106 - val_auc-prc: 0.9653 - val_auc-roc: 0.9653 - 14s/epoch - 55ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2697 - acc: 0.8913 - auc-prc: 0.9537 - auc-roc: 0.9550 - val_loss: 0.2422 - val_acc: 0.9062 - val_auc-prc: 0.9670 - val_auc-roc: 0.9667 - 14s/epoch - 56ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2669 - acc: 0.8907 - auc-prc: 0.9556 - auc-roc: 0.9562 - val_loss: 0.2329 - val_acc: 0.9062 - val_auc-prc: 0.9677 - val_auc-roc: 0.9676 - 14s/epoch - 56ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2673 - acc: 0.8934 - auc-prc: 0.9553 - auc-roc: 0.9559 - val_loss: 0.2295 - val_acc: 0.8986 - val_auc-prc: 0.9678 - val_auc-roc: 0.9678 - 14s/epoch - 55ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2610 - acc: 0.8933 - auc-prc: 0.9578 - auc-roc: 0.9583 - val_loss: 0.2412 - val_acc: 0.8986 - val_auc-prc: 0.9658 - val_auc-roc: 0.9656 - 14s/epoch - 55ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2634 - acc: 0.8905 - auc-prc: 0.9570 - auc-roc: 0.9574 - val_loss: 0.2282 - val_acc: 0.9084 - val_auc-prc: 0.9678 - val_auc-roc: 0.9679 - 14s/epoch - 55ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2589 - acc: 0.8927 - auc-prc: 0.9582 - auc-roc: 0.9586 - val_loss: 0.2275 - val_acc: 0.8986 - val_auc-prc: 0.9682 - val_auc-roc: 0.9682 - 14s/epoch - 54ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2552 - acc: 0.8959 - auc-prc: 0.9597 - auc-roc: 0.9601 - val_loss: 0.2335 - val_acc: 0.8997 - val_auc-prc: 0.9667 - val_auc-roc: 0.9669 - 14s/epoch - 54ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2533 - acc: 0.8947 - auc-prc: 0.9604 - auc-roc: 0.9605 - val_loss: 0.2396 - val_acc: 0.8975 - val_auc-prc: 0.9670 - val_auc-roc: 0.9669 - 14s/epoch - 55ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2497 - acc: 0.8951 - auc-prc: 0.9617 - auc-roc: 0.9618 - val_loss: 0.2856 - val_acc: 0.8822 - val_auc-prc: 0.9535 - val_auc-roc: 0.9561 - 14s/epoch - 55ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2505 - acc: 0.8982 - auc-prc: 0.9610 - auc-roc: 0.9615 - val_loss: 0.2448 - val_acc: 0.8975 - val_auc-prc: 0.9638 - val_auc-roc: 0.9637 - 14s/epoch - 55ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2487 - acc: 0.8993 - auc-prc: 0.9615 - auc-roc: 0.9621 - val_loss: 0.2460 - val_acc: 0.8964 - val_auc-prc: 0.9638 - val_auc-roc: 0.9635 - 14s/epoch - 55ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2419 - acc: 0.9007 - auc-prc: 0.9637 - auc-roc: 0.9641 - val_loss: 0.2353 - val_acc: 0.8986 - val_auc-prc: 0.9667 - val_auc-roc: 0.9664 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2396 - acc: 0.9037 - auc-prc: 0.9642 - auc-roc: 0.9647 - val_loss: 0.2327 - val_acc: 0.9095 - val_auc-prc: 0.9672 - val_auc-roc: 0.9667 - 14s/epoch - 54ms/step
Epoch 22/100
258/258 - 14s - loss: 0.2323 - acc: 0.9036 - auc-prc: 0.9668 - auc-roc: 0.9668 - val_loss: 0.2296 - val_acc: 0.9019 - val_auc-prc: 0.9683 - val_auc-roc: 0.9684 - 14s/epoch - 55ms/step
Epoch 23/100
258/258 - 14s - loss: 0.2319 - acc: 0.9041 - auc-prc: 0.9667 - auc-roc: 0.9671 - val_loss: 0.2445 - val_acc: 0.8877 - val_auc-prc: 0.9628 - val_auc-roc: 0.9636 - 14s/epoch - 55ms/step
Epoch 24/100
258/258 - 14s - loss: 0.2337 - acc: 0.9072 - auc-prc: 0.9661 - auc-roc: 0.9664 - val_loss: 0.2295 - val_acc: 0.9019 - val_auc-prc: 0.9686 - val_auc-roc: 0.9681 - 14s/epoch - 55ms/step
Epoch 25/100
258/258 - 14s - loss: 0.2261 - acc: 0.9087 - auc-prc: 0.9682 - auc-roc: 0.9686 - val_loss: 0.2277 - val_acc: 0.9008 - val_auc-prc: 0.9687 - val_auc-roc: 0.9683 - 14s/epoch - 56ms/step
Epoch 26/100
258/258 - 14s - loss: 0.2195 - acc: 0.9076 - auc-prc: 0.9699 - auc-roc: 0.9704 - val_loss: 0.2400 - val_acc: 0.9106 - val_auc-prc: 0.9648 - val_auc-roc: 0.9647 - 14s/epoch - 55ms/step
Epoch 27/100
258/258 - 14s - loss: 0.2205 - acc: 0.9105 - auc-prc: 0.9700 - auc-roc: 0.9701 - val_loss: 0.2275 - val_acc: 0.9062 - val_auc-prc: 0.9683 - val_auc-roc: 0.9689 - 14s/epoch - 55ms/step
Epoch 28/100
258/258 - 14s - loss: 0.2146 - acc: 0.9129 - auc-prc: 0.9717 - auc-roc: 0.9718 - val_loss: 0.2404 - val_acc: 0.9008 - val_auc-prc: 0.9646 - val_auc-roc: 0.9648 - 14s/epoch - 55ms/step
Epoch 29/100
258/258 - 14s - loss: 0.2113 - acc: 0.9156 - auc-prc: 0.9724 - auc-roc: 0.9726 - val_loss: 0.2608 - val_acc: 0.8888 - val_auc-prc: 0.9588 - val_auc-roc: 0.9584 - 14s/epoch - 55ms/step
Epoch 30/100
258/258 - 15s - loss: 0.2081 - acc: 0.9156 - auc-prc: 0.9738 - auc-roc: 0.9735 - val_loss: 0.2437 - val_acc: 0.9029 - val_auc-prc: 0.9632 - val_auc-roc: 0.9644 - 15s/epoch - 57ms/step
Epoch 31/100
258/258 - 15s - loss: 0.1951 - acc: 0.9233 - auc-prc: 0.9761 - auc-roc: 0.9763 - val_loss: 0.2536 - val_acc: 0.8953 - val_auc-prc: 0.9608 - val_auc-roc: 0.9607 - 15s/epoch - 58ms/step
Epoch 32/100
258/258 - 15s - loss: 0.1915 - acc: 0.9214 - auc-prc: 0.9769 - auc-roc: 0.9772 - val_loss: 0.2558 - val_acc: 0.8942 - val_auc-prc: 0.9586 - val_auc-roc: 0.9601 - 15s/epoch - 57ms/step
Epoch 33/100
258/258 - 15s - loss: 0.1902 - acc: 0.9227 - auc-prc: 0.9779 - auc-roc: 0.9777 - val_loss: 0.2617 - val_acc: 0.8920 - val_auc-prc: 0.9610 - val_auc-roc: 0.9603 - 15s/epoch - 58ms/step
Epoch 34/100
258/258 - 15s - loss: 0.1822 - acc: 0.9272 - auc-prc: 0.9792 - auc-roc: 0.9794 - val_loss: 0.2561 - val_acc: 0.8920 - val_auc-prc: 0.9609 - val_auc-roc: 0.9607 - 15s/epoch - 57ms/step
Epoch 35/100
258/258 - 14s - loss: 0.1796 - acc: 0.9284 - auc-prc: 0.9801 - auc-roc: 0.9801 - val_loss: 0.2715 - val_acc: 0.8899 - val_auc-prc: 0.9587 - val_auc-roc: 0.9583 - 14s/epoch - 53ms/step
Epoch 36/100
258/258 - 14s - loss: 0.1734 - acc: 0.9306 - auc-prc: 0.9811 - auc-roc: 0.9813 - val_loss: 0.3062 - val_acc: 0.8790 - val_auc-prc: 0.9447 - val_auc-roc: 0.9499 - 14s/epoch - 53ms/step
Epoch 37/100
258/258 - 14s - loss: 0.1627 - acc: 0.9369 - auc-prc: 0.9830 - auc-roc: 0.9834 - val_loss: 0.2660 - val_acc: 0.9040 - val_auc-prc: 0.9579 - val_auc-roc: 0.9600 - 14s/epoch - 53ms/step
Epoch 38/100
258/258 - 14s - loss: 0.1598 - acc: 0.9379 - auc-prc: 0.9836 - auc-roc: 0.9840 - val_loss: 0.3093 - val_acc: 0.8920 - val_auc-prc: 0.9458 - val_auc-roc: 0.9514 - 14s/epoch - 54ms/step
Epoch 39/100
258/258 - 14s - loss: 0.1528 - acc: 0.9408 - auc-prc: 0.9856 - auc-roc: 0.9855 - val_loss: 0.3185 - val_acc: 0.8877 - val_auc-prc: 0.9506 - val_auc-roc: 0.9547 - 14s/epoch - 54ms/step
Epoch 40/100
258/258 - 14s - loss: 0.1468 - acc: 0.9409 - auc-prc: 0.9868 - auc-roc: 0.9867 - val_loss: 0.2976 - val_acc: 0.8920 - val_auc-prc: 0.9531 - val_auc-roc: 0.9561 - 14s/epoch - 55ms/step
Epoch 41/100
258/258 - 14s - loss: 0.1435 - acc: 0.9435 - auc-prc: 0.9866 - auc-roc: 0.9870 - val_loss: 0.3202 - val_acc: 0.8779 - val_auc-prc: 0.9445 - val_auc-roc: 0.9456 - 14s/epoch - 54ms/step
Epoch 42/100
258/258 - 14s - loss: 0.1429 - acc: 0.9431 - auc-prc: 0.9872 - auc-roc: 0.9872 - val_loss: 0.3296 - val_acc: 0.8920 - val_auc-prc: 0.9466 - val_auc-roc: 0.9520 - 14s/epoch - 55ms/step
Epoch 43/100
258/258 - 14s - loss: 0.1336 - acc: 0.9509 - auc-prc: 0.9884 - auc-roc: 0.9886 - val_loss: 0.3055 - val_acc: 0.8942 - val_auc-prc: 0.9505 - val_auc-roc: 0.9541 - 14s/epoch - 55ms/step
Epoch 44/100
258/258 - 14s - loss: 0.1217 - acc: 0.9542 - auc-prc: 0.9906 - auc-roc: 0.9906 - val_loss: 0.3481 - val_acc: 0.8899 - val_auc-prc: 0.9430 - val_auc-roc: 0.9482 - 14s/epoch - 55ms/step
Epoch 45/100
258/258 - 14s - loss: 0.1201 - acc: 0.9549 - auc-prc: 0.9905 - auc-roc: 0.9907 - val_loss: 0.3171 - val_acc: 0.8866 - val_auc-prc: 0.9496 - val_auc-roc: 0.9517 - 14s/epoch - 55ms/step
Epoch 46/100
258/258 - 15s - loss: 0.1124 - acc: 0.9571 - auc-prc: 0.9918 - auc-roc: 0.9920 - val_loss: 0.3300 - val_acc: 0.8920 - val_auc-prc: 0.9485 - val_auc-roc: 0.9531 - 15s/epoch - 56ms/step
Epoch 47/100
258/258 - 15s - loss: 0.1098 - acc: 0.9581 - auc-prc: 0.9918 - auc-roc: 0.9921 - val_loss: 0.3358 - val_acc: 0.8702 - val_auc-prc: 0.9433 - val_auc-roc: 0.9473 - 15s/epoch - 57ms/step
Epoch 48/100
258/258 - 14s - loss: 0.1045 - acc: 0.9606 - auc-prc: 0.9924 - auc-roc: 0.9927 - val_loss: 0.3451 - val_acc: 0.8920 - val_auc-prc: 0.9456 - val_auc-roc: 0.9511 - 14s/epoch - 56ms/step
Epoch 49/100
258/258 - 14s - loss: 0.0978 - acc: 0.9640 - auc-prc: 0.9937 - auc-roc: 0.9938 - val_loss: 0.3722 - val_acc: 0.8877 - val_auc-prc: 0.9431 - val_auc-roc: 0.9494 - 14s/epoch - 56ms/step
Epoch 50/100
258/258 - 15s - loss: 0.1035 - acc: 0.9603 - auc-prc: 0.9925 - auc-roc: 0.9928 - val_loss: 0.3592 - val_acc: 0.8899 - val_auc-prc: 0.9395 - val_auc-roc: 0.9459 - 15s/epoch - 58ms/step
Epoch 51/100
258/258 - 14s - loss: 0.0846 - acc: 0.9694 - auc-prc: 0.9950 - auc-roc: 0.9952 - val_loss: 0.3590 - val_acc: 0.8757 - val_auc-prc: 0.9424 - val_auc-roc: 0.9467 - 14s/epoch - 55ms/step
Epoch 52/100
258/258 - 14s - loss: 0.0947 - acc: 0.9639 - auc-prc: 0.9938 - auc-roc: 0.9940 - val_loss: 0.3525 - val_acc: 0.8844 - val_auc-prc: 0.9437 - val_auc-roc: 0.9504 - 14s/epoch - 55ms/step
Epoch 53/100
258/258 - 15s - loss: 0.0906 - acc: 0.9654 - auc-prc: 0.9947 - auc-roc: 0.9948 - val_loss: 0.3405 - val_acc: 0.8909 - val_auc-prc: 0.9482 - val_auc-roc: 0.9539 - 15s/epoch - 58ms/step
Epoch 54/100
258/258 - 14s - loss: 0.0889 - acc: 0.9662 - auc-prc: 0.9947 - auc-roc: 0.9949 - val_loss: 0.3519 - val_acc: 0.8964 - val_auc-prc: 0.9512 - val_auc-roc: 0.9562 - 14s/epoch - 55ms/step
Epoch 55/100
258/258 - 14s - loss: 0.0793 - acc: 0.9698 - auc-prc: 0.9959 - auc-roc: 0.9960 - val_loss: 0.3817 - val_acc: 0.8909 - val_auc-prc: 0.9429 - val_auc-roc: 0.9500 - 14s/epoch - 54ms/step
Epoch 56/100
258/258 - 15s - loss: 0.0745 - acc: 0.9731 - auc-prc: 0.9958 - auc-roc: 0.9961 - val_loss: 0.4053 - val_acc: 0.8844 - val_auc-prc: 0.9293 - val_auc-roc: 0.9395 - 15s/epoch - 56ms/step
Epoch 57/100
258/258 - 15s - loss: 0.0762 - acc: 0.9733 - auc-prc: 0.9960 - auc-roc: 0.9961 - val_loss: 0.4001 - val_acc: 0.8833 - val_auc-prc: 0.9443 - val_auc-roc: 0.9496 - 15s/epoch - 58ms/step
Epoch 58/100
258/258 - 15s - loss: 0.0746 - acc: 0.9726 - auc-prc: 0.9957 - auc-roc: 0.9960 - val_loss: 0.3806 - val_acc: 0.8822 - val_auc-prc: 0.9428 - val_auc-roc: 0.9485 - 15s/epoch - 57ms/step
Epoch 59/100
258/258 - 14s - loss: 0.0758 - acc: 0.9712 - auc-prc: 0.9960 - auc-roc: 0.9961 - val_loss: 0.4133 - val_acc: 0.8779 - val_auc-prc: 0.9383 - val_auc-roc: 0.9458 - 14s/epoch - 56ms/step
Epoch 60/100
258/258 - 15s - loss: 0.0684 - acc: 0.9740 - auc-prc: 0.9968 - auc-roc: 0.9969 - val_loss: 0.3816 - val_acc: 0.8888 - val_auc-prc: 0.9393 - val_auc-roc: 0.9475 - 15s/epoch - 57ms/step
Epoch 61/100
258/258 - 15s - loss: 0.0497 - acc: 0.9833 - auc-prc: 0.9984 - auc-roc: 0.9985 - val_loss: 0.3896 - val_acc: 0.8899 - val_auc-prc: 0.9390 - val_auc-roc: 0.9480 - 15s/epoch - 58ms/step
Epoch 62/100
258/258 - 15s - loss: 0.0594 - acc: 0.9767 - auc-prc: 0.9977 - auc-roc: 0.9977 - val_loss: 0.3972 - val_acc: 0.8899 - val_auc-prc: 0.9432 - val_auc-roc: 0.9506 - 15s/epoch - 58ms/step
Epoch 63/100
258/258 - 15s - loss: 0.0540 - acc: 0.9793 - auc-prc: 0.9980 - auc-roc: 0.9981 - val_loss: 0.4323 - val_acc: 0.8931 - val_auc-prc: 0.9379 - val_auc-roc: 0.9476 - 15s/epoch - 58ms/step
Epoch 64/100
258/258 - 15s - loss: 0.0559 - acc: 0.9786 - auc-prc: 0.9982 - auc-roc: 0.9981 - val_loss: 0.4258 - val_acc: 0.8866 - val_auc-prc: 0.9360 - val_auc-roc: 0.9455 - 15s/epoch - 58ms/step
Epoch 65/100
258/258 - 14s - loss: 0.0531 - acc: 0.9810 - auc-prc: 0.9975 - auc-roc: 0.9978 - val_loss: 0.4349 - val_acc: 0.8866 - val_auc-prc: 0.9286 - val_auc-roc: 0.9379 - 14s/epoch - 55ms/step
Epoch 66/100
258/258 - 14s - loss: 0.0673 - acc: 0.9760 - auc-prc: 0.9965 - auc-roc: 0.9967 - val_loss: 0.4654 - val_acc: 0.8866 - val_auc-prc: 0.9302 - val_auc-roc: 0.9413 - 14s/epoch - 55ms/step
Epoch 67/100
258/258 - 14s - loss: 0.0581 - acc: 0.9778 - auc-prc: 0.9972 - auc-roc: 0.9975 - val_loss: 0.4516 - val_acc: 0.8811 - val_auc-prc: 0.9394 - val_auc-roc: 0.9465 - 14s/epoch - 55ms/step
Epoch 68/100
258/258 - 14s - loss: 0.0486 - acc: 0.9815 - auc-prc: 0.9983 - auc-roc: 0.9984 - val_loss: 0.4190 - val_acc: 0.8899 - val_auc-prc: 0.9382 - val_auc-roc: 0.9471 - 14s/epoch - 55ms/step
Epoch 69/100
258/258 - 14s - loss: 0.0506 - acc: 0.9823 - auc-prc: 0.9984 - auc-roc: 0.9984 - val_loss: 0.4624 - val_acc: 0.8844 - val_auc-prc: 0.9305 - val_auc-roc: 0.9410 - 14s/epoch - 55ms/step
Epoch 70/100
258/258 - 14s - loss: 0.0374 - acc: 0.9873 - auc-prc: 0.9992 - auc-roc: 0.9992 - val_loss: 0.5133 - val_acc: 0.8822 - val_auc-prc: 0.9210 - val_auc-roc: 0.9345 - 14s/epoch - 55ms/step
Epoch 71/100
258/258 - 14s - loss: 0.0471 - acc: 0.9836 - auc-prc: 0.9975 - auc-roc: 0.9978 - val_loss: 0.5148 - val_acc: 0.8735 - val_auc-prc: 0.9265 - val_auc-roc: 0.9373 - 14s/epoch - 55ms/step
Epoch 72/100
258/258 - 14s - loss: 0.0555 - acc: 0.9799 - auc-prc: 0.9978 - auc-roc: 0.9979 - val_loss: 0.5023 - val_acc: 0.8811 - val_auc-prc: 0.9292 - val_auc-roc: 0.9406 - 14s/epoch - 55ms/step
Epoch 73/100
258/258 - 14s - loss: 0.0427 - acc: 0.9844 - auc-prc: 0.9983 - auc-roc: 0.9985 - val_loss: 0.4984 - val_acc: 0.8822 - val_auc-prc: 0.9252 - val_auc-roc: 0.9372 - 14s/epoch - 55ms/step
Epoch 74/100
258/258 - 14s - loss: 0.0534 - acc: 0.9804 - auc-prc: 0.9975 - auc-roc: 0.9977 - val_loss: 0.4885 - val_acc: 0.8942 - val_auc-prc: 0.9336 - val_auc-roc: 0.9445 - 14s/epoch - 55ms/step
Epoch 75/100
258/258 - 14s - loss: 0.0437 - acc: 0.9836 - auc-prc: 0.9987 - auc-roc: 0.9987 - val_loss: 0.4951 - val_acc: 0.8800 - val_auc-prc: 0.9290 - val_auc-roc: 0.9400 - 14s/epoch - 55ms/step
Epoch 76/100
258/258 - 14s - loss: 0.0347 - acc: 0.9872 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.4938 - val_acc: 0.8833 - val_auc-prc: 0.9287 - val_auc-roc: 0.9400 - 14s/epoch - 55ms/step
Epoch 77/100
258/258 - 14s - loss: 0.0329 - acc: 0.9864 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.5288 - val_acc: 0.8746 - val_auc-prc: 0.9271 - val_auc-roc: 0.9382 - 14s/epoch - 55ms/step
Epoch 78/100
258/258 - 14s - loss: 0.0438 - acc: 0.9836 - auc-prc: 0.9981 - auc-roc: 0.9983 - val_loss: 0.4895 - val_acc: 0.8888 - val_auc-prc: 0.9301 - val_auc-roc: 0.9415 - 14s/epoch - 55ms/step
Epoch 79/100
258/258 - 14s - loss: 0.0436 - acc: 0.9851 - auc-prc: 0.9981 - auc-roc: 0.9983 - val_loss: 0.4887 - val_acc: 0.8920 - val_auc-prc: 0.9322 - val_auc-roc: 0.9438 - 14s/epoch - 55ms/step
Epoch 80/100
258/258 - 14s - loss: 0.0457 - acc: 0.9851 - auc-prc: 0.9975 - auc-roc: 0.9979 - val_loss: 0.5141 - val_acc: 0.8844 - val_auc-prc: 0.9253 - val_auc-roc: 0.9373 - 14s/epoch - 55ms/step
Epoch 81/100
258/258 - 14s - loss: 0.0451 - acc: 0.9820 - auc-prc: 0.9983 - auc-roc: 0.9985 - val_loss: 0.4799 - val_acc: 0.8931 - val_auc-prc: 0.9342 - val_auc-roc: 0.9436 - 14s/epoch - 56ms/step
Epoch 82/100
258/258 - 14s - loss: 0.0508 - acc: 0.9816 - auc-prc: 0.9979 - auc-roc: 0.9980 - val_loss: 0.4976 - val_acc: 0.8866 - val_auc-prc: 0.9316 - val_auc-roc: 0.9431 - 14s/epoch - 55ms/step
Epoch 83/100
258/258 - 17s - loss: 0.0300 - acc: 0.9902 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.5011 - val_acc: 0.8866 - val_auc-prc: 0.9300 - val_auc-roc: 0.9422 - 17s/epoch - 65ms/step
Epoch 84/100
258/258 - 14s - loss: 0.0612 - acc: 0.9788 - auc-prc: 0.9963 - auc-roc: 0.9967 - val_loss: 0.4706 - val_acc: 0.8888 - val_auc-prc: 0.9345 - val_auc-roc: 0.9449 - 14s/epoch - 55ms/step
Epoch 85/100
258/258 - 15s - loss: 0.0354 - acc: 0.9873 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.5469 - val_acc: 0.8866 - val_auc-prc: 0.9191 - val_auc-roc: 0.9333 - 15s/epoch - 58ms/step
Epoch 86/100
258/258 - 14s - loss: 0.0365 - acc: 0.9884 - auc-prc: 0.9987 - auc-roc: 0.9989 - val_loss: 0.5587 - val_acc: 0.8800 - val_auc-prc: 0.9210 - val_auc-roc: 0.9348 - 14s/epoch - 56ms/step
Epoch 87/100
258/258 - 14s - loss: 0.0404 - acc: 0.9851 - auc-prc: 0.9988 - auc-roc: 0.9988 - val_loss: 0.5967 - val_acc: 0.8779 - val_auc-prc: 0.9167 - val_auc-roc: 0.9310 - 14s/epoch - 55ms/step
Epoch 88/100
258/258 - 14s - loss: 0.0248 - acc: 0.9906 - auc-prc: 0.9997 - auc-roc: 0.9997 - val_loss: 0.5436 - val_acc: 0.8931 - val_auc-prc: 0.9240 - val_auc-roc: 0.9377 - 14s/epoch - 55ms/step
Epoch 89/100
258/258 - 14s - loss: 0.0250 - acc: 0.9906 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.5815 - val_acc: 0.8811 - val_auc-prc: 0.9156 - val_auc-roc: 0.9307 - 14s/epoch - 55ms/step
Epoch 90/100
258/258 - 14s - loss: 0.0369 - acc: 0.9881 - auc-prc: 0.9986 - auc-roc: 0.9988 - val_loss: 0.5411 - val_acc: 0.8931 - val_auc-prc: 0.9275 - val_auc-roc: 0.9397 - 14s/epoch - 55ms/step
Epoch 91/100
258/258 - 14s - loss: 0.0343 - acc: 0.9866 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.5658 - val_acc: 0.8888 - val_auc-prc: 0.9245 - val_auc-roc: 0.9373 - 14s/epoch - 55ms/step
Epoch 92/100
258/258 - 14s - loss: 0.0355 - acc: 0.9880 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.6777 - val_acc: 0.8702 - val_auc-prc: 0.9040 - val_auc-roc: 0.9211 - 14s/epoch - 53ms/step
Epoch 93/100
258/258 - 14s - loss: 0.0337 - acc: 0.9886 - auc-prc: 0.9988 - auc-roc: 0.9990 - val_loss: 0.6077 - val_acc: 0.8768 - val_auc-prc: 0.9160 - val_auc-roc: 0.9304 - 14s/epoch - 53ms/step
Epoch 94/100
258/258 - 14s - loss: 0.0275 - acc: 0.9904 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.5566 - val_acc: 0.8713 - val_auc-prc: 0.9220 - val_auc-roc: 0.9348 - 14s/epoch - 53ms/step
Epoch 95/100
258/258 - 14s - loss: 0.0402 - acc: 0.9861 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.5746 - val_acc: 0.8822 - val_auc-prc: 0.9180 - val_auc-roc: 0.9326 - 14s/epoch - 53ms/step
Epoch 96/100
258/258 - 14s - loss: 0.0275 - acc: 0.9898 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.5872 - val_acc: 0.8800 - val_auc-prc: 0.9243 - val_auc-roc: 0.9361 - 14s/epoch - 53ms/step
Epoch 97/100
258/258 - 14s - loss: 0.0291 - acc: 0.9904 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.5999 - val_acc: 0.8844 - val_auc-prc: 0.9183 - val_auc-roc: 0.9326 - 14s/epoch - 53ms/step
Epoch 98/100
258/258 - 14s - loss: 0.0347 - acc: 0.9866 - auc-prc: 0.9993 - auc-roc: 0.9992 - val_loss: 0.6230 - val_acc: 0.8800 - val_auc-prc: 0.9151 - val_auc-roc: 0.9300 - 14s/epoch - 55ms/step
Epoch 99/100
258/258 - 14s - loss: 0.0411 - acc: 0.9850 - auc-prc: 0.9985 - auc-roc: 0.9986 - val_loss: 0.5642 - val_acc: 0.8833 - val_auc-prc: 0.9227 - val_auc-roc: 0.9358 - 14s/epoch - 55ms/step
Epoch 100/100
258/258 - 14s - loss: 0.0240 - acc: 0.9918 - auc-prc: 0.9994 - auc-roc: 0.9995 - val_loss: 0.5888 - val_acc: 0.8790 - val_auc-prc: 0.9187 - val_auc-roc: 0.9327 - 14s/epoch - 55ms/step
Early stopping epoch: 0
******Evaluating TEST set*********
29/29 - 1s - 1s/epoch - 37ms/step
              precision    recall  f1-score   support

           0       0.90      0.88      0.89       386
           1       0.91      0.93      0.92       531

    accuracy                           0.91       917
   macro avg       0.91      0.90      0.90       917
weighted avg       0.91      0.91      0.91       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.44      0.55      0.49       386
           1       0.60      0.50      0.54       531

    accuracy                           0.52       917
   macro avg       0.52      0.52      0.52       917
weighted avg       0.54      0.52      0.52       917

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3237 - acc: 0.8596 - auc-prc: 0.9350 - auc-roc: 0.9359 - val_loss: 0.3536 - val_acc: 0.8582 - val_auc-prc: 0.9188 - val_auc-roc: 0.9245 - 17s/epoch - 66ms/step
Epoch 2/100
258/258 - 14s - loss: 0.2919 - acc: 0.8821 - auc-prc: 0.9460 - auc-roc: 0.9475 - val_loss: 0.3434 - val_acc: 0.8539 - val_auc-prc: 0.9231 - val_auc-roc: 0.9265 - 14s/epoch - 55ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2836 - acc: 0.8856 - auc-prc: 0.9486 - auc-roc: 0.9500 - val_loss: 0.3238 - val_acc: 0.8888 - val_auc-prc: 0.9318 - val_auc-roc: 0.9359 - 14s/epoch - 55ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2755 - acc: 0.8900 - auc-prc: 0.9521 - auc-roc: 0.9530 - val_loss: 0.3371 - val_acc: 0.8724 - val_auc-prc: 0.9282 - val_auc-roc: 0.9316 - 14s/epoch - 55ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2726 - acc: 0.8896 - auc-prc: 0.9531 - auc-roc: 0.9541 - val_loss: 0.3101 - val_acc: 0.8877 - val_auc-prc: 0.9334 - val_auc-roc: 0.9370 - 14s/epoch - 55ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2688 - acc: 0.8909 - auc-prc: 0.9547 - auc-roc: 0.9555 - val_loss: 0.3163 - val_acc: 0.8844 - val_auc-prc: 0.9329 - val_auc-roc: 0.9388 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2685 - acc: 0.8918 - auc-prc: 0.9547 - auc-roc: 0.9555 - val_loss: 0.3039 - val_acc: 0.8899 - val_auc-prc: 0.9365 - val_auc-roc: 0.9402 - 14s/epoch - 55ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2659 - acc: 0.8916 - auc-prc: 0.9557 - auc-roc: 0.9564 - val_loss: 0.3080 - val_acc: 0.8942 - val_auc-prc: 0.9374 - val_auc-roc: 0.9403 - 14s/epoch - 55ms/step
Epoch 9/100
258/258 - 15s - loss: 0.2602 - acc: 0.8934 - auc-prc: 0.9575 - auc-roc: 0.9583 - val_loss: 0.2994 - val_acc: 0.8855 - val_auc-prc: 0.9405 - val_auc-roc: 0.9431 - 15s/epoch - 56ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2651 - acc: 0.8929 - auc-prc: 0.9566 - auc-roc: 0.9570 - val_loss: 0.3013 - val_acc: 0.8920 - val_auc-prc: 0.9406 - val_auc-roc: 0.9430 - 14s/epoch - 56ms/step
Epoch 11/100
258/258 - 15s - loss: 0.2575 - acc: 0.8941 - auc-prc: 0.9589 - auc-roc: 0.9593 - val_loss: 0.2991 - val_acc: 0.8844 - val_auc-prc: 0.9417 - val_auc-roc: 0.9438 - 15s/epoch - 57ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2538 - acc: 0.8944 - auc-prc: 0.9600 - auc-roc: 0.9603 - val_loss: 0.3077 - val_acc: 0.8800 - val_auc-prc: 0.9382 - val_auc-roc: 0.9422 - 14s/epoch - 55ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2526 - acc: 0.8958 - auc-prc: 0.9605 - auc-roc: 0.9609 - val_loss: 0.3215 - val_acc: 0.8811 - val_auc-prc: 0.9384 - val_auc-roc: 0.9412 - 14s/epoch - 55ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2501 - acc: 0.8965 - auc-prc: 0.9614 - auc-roc: 0.9619 - val_loss: 0.3096 - val_acc: 0.8866 - val_auc-prc: 0.9423 - val_auc-roc: 0.9436 - 14s/epoch - 55ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2467 - acc: 0.9001 - auc-prc: 0.9621 - auc-roc: 0.9628 - val_loss: 0.3036 - val_acc: 0.8811 - val_auc-prc: 0.9421 - val_auc-roc: 0.9432 - 14s/epoch - 55ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2445 - acc: 0.8975 - auc-prc: 0.9635 - auc-roc: 0.9635 - val_loss: 0.3138 - val_acc: 0.8844 - val_auc-prc: 0.9404 - val_auc-roc: 0.9439 - 14s/epoch - 53ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2413 - acc: 0.8987 - auc-prc: 0.9643 - auc-roc: 0.9643 - val_loss: 0.3028 - val_acc: 0.8790 - val_auc-prc: 0.9435 - val_auc-roc: 0.9451 - 14s/epoch - 55ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2398 - acc: 0.9025 - auc-prc: 0.9648 - auc-roc: 0.9647 - val_loss: 0.3136 - val_acc: 0.8702 - val_auc-prc: 0.9402 - val_auc-roc: 0.9415 - 14s/epoch - 54ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2387 - acc: 0.9010 - auc-prc: 0.9654 - auc-roc: 0.9653 - val_loss: 0.2973 - val_acc: 0.8866 - val_auc-prc: 0.9439 - val_auc-roc: 0.9459 - 14s/epoch - 55ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2302 - acc: 0.9055 - auc-prc: 0.9671 - auc-roc: 0.9674 - val_loss: 0.3008 - val_acc: 0.8833 - val_auc-prc: 0.9435 - val_auc-roc: 0.9448 - 14s/epoch - 55ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2277 - acc: 0.9058 - auc-prc: 0.9685 - auc-roc: 0.9683 - val_loss: 0.2984 - val_acc: 0.8779 - val_auc-prc: 0.9444 - val_auc-roc: 0.9454 - 14s/epoch - 55ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
29/29 - 1s - 743ms/epoch - 26ms/step
              precision    recall  f1-score   support

           0       0.90      0.82      0.86       386
           1       0.88      0.94      0.91       531

    accuracy                           0.89       917
   macro avg       0.89      0.88      0.88       917
weighted avg       0.89      0.89      0.89       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.44      0.54      0.49       386
           1       0.60      0.50      0.55       531

    accuracy                           0.52       917
   macro avg       0.52      0.52      0.52       917
weighted avg       0.53      0.52      0.52       917

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3260 - acc: 0.8591 - auc-prc: 0.9334 - auc-roc: 0.9346 - val_loss: 0.2827 - val_acc: 0.8866 - val_auc-prc: 0.9493 - val_auc-roc: 0.9501 - 17s/epoch - 66ms/step
Epoch 2/100
258/258 - 14s - loss: 0.2936 - acc: 0.8800 - auc-prc: 0.9451 - auc-roc: 0.9467 - val_loss: 0.2862 - val_acc: 0.8899 - val_auc-prc: 0.9488 - val_auc-roc: 0.9499 - 14s/epoch - 55ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2862 - acc: 0.8819 - auc-prc: 0.9477 - auc-roc: 0.9493 - val_loss: 0.2810 - val_acc: 0.8909 - val_auc-prc: 0.9489 - val_auc-roc: 0.9504 - 14s/epoch - 52ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2827 - acc: 0.8849 - auc-prc: 0.9489 - auc-roc: 0.9505 - val_loss: 0.2692 - val_acc: 0.8920 - val_auc-prc: 0.9556 - val_auc-roc: 0.9554 - 14s/epoch - 55ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2762 - acc: 0.8890 - auc-prc: 0.9516 - auc-roc: 0.9526 - val_loss: 0.2806 - val_acc: 0.8866 - val_auc-prc: 0.9502 - val_auc-roc: 0.9512 - 14s/epoch - 55ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2741 - acc: 0.8888 - auc-prc: 0.9516 - auc-roc: 0.9533 - val_loss: 0.2813 - val_acc: 0.8877 - val_auc-prc: 0.9518 - val_auc-roc: 0.9525 - 14s/epoch - 55ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2691 - acc: 0.8917 - auc-prc: 0.9539 - auc-roc: 0.9550 - val_loss: 0.2799 - val_acc: 0.8953 - val_auc-prc: 0.9542 - val_auc-roc: 0.9540 - 14s/epoch - 55ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2656 - acc: 0.8946 - auc-prc: 0.9552 - auc-roc: 0.9562 - val_loss: 0.2734 - val_acc: 0.8975 - val_auc-prc: 0.9551 - val_auc-roc: 0.9555 - 14s/epoch - 55ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2626 - acc: 0.8951 - auc-prc: 0.9560 - auc-roc: 0.9572 - val_loss: 0.2744 - val_acc: 0.8942 - val_auc-prc: 0.9541 - val_auc-roc: 0.9545 - 14s/epoch - 55ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2600 - acc: 0.8932 - auc-prc: 0.9575 - auc-roc: 0.9583 - val_loss: 0.2771 - val_acc: 0.8779 - val_auc-prc: 0.9539 - val_auc-roc: 0.9537 - 14s/epoch - 55ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2588 - acc: 0.8952 - auc-prc: 0.9579 - auc-roc: 0.9586 - val_loss: 0.2809 - val_acc: 0.8855 - val_auc-prc: 0.9535 - val_auc-roc: 0.9534 - 14s/epoch - 55ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2560 - acc: 0.8986 - auc-prc: 0.9592 - auc-roc: 0.9596 - val_loss: 0.2798 - val_acc: 0.8888 - val_auc-prc: 0.9524 - val_auc-roc: 0.9525 - 14s/epoch - 55ms/step
Epoch 13/100
258/258 - 13s - loss: 0.2516 - acc: 0.8981 - auc-prc: 0.9606 - auc-roc: 0.9610 - val_loss: 0.2814 - val_acc: 0.8877 - val_auc-prc: 0.9527 - val_auc-roc: 0.9525 - 13s/epoch - 52ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2504 - acc: 0.8984 - auc-prc: 0.9610 - auc-roc: 0.9614 - val_loss: 0.2849 - val_acc: 0.8811 - val_auc-prc: 0.9520 - val_auc-roc: 0.9515 - 14s/epoch - 53ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2458 - acc: 0.8993 - auc-prc: 0.9622 - auc-roc: 0.9627 - val_loss: 0.2998 - val_acc: 0.8920 - val_auc-prc: 0.9518 - val_auc-roc: 0.9522 - 14s/epoch - 53ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2450 - acc: 0.9013 - auc-prc: 0.9629 - auc-roc: 0.9630 - val_loss: 0.3044 - val_acc: 0.8790 - val_auc-prc: 0.9456 - val_auc-roc: 0.9464 - 14s/epoch - 53ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2408 - acc: 0.9031 - auc-prc: 0.9644 - auc-roc: 0.9645 - val_loss: 0.3116 - val_acc: 0.8877 - val_auc-prc: 0.9393 - val_auc-roc: 0.9431 - 14s/epoch - 53ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2380 - acc: 0.9035 - auc-prc: 0.9648 - auc-roc: 0.9651 - val_loss: 0.3268 - val_acc: 0.8790 - val_auc-prc: 0.9418 - val_auc-roc: 0.9421 - 14s/epoch - 54ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2484 - acc: 0.9004 - auc-prc: 0.9617 - auc-roc: 0.9621 - val_loss: 0.2849 - val_acc: 0.8877 - val_auc-prc: 0.9519 - val_auc-roc: 0.9518 - 14s/epoch - 54ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2465 - acc: 0.9003 - auc-prc: 0.9621 - auc-roc: 0.9627 - val_loss: 0.2804 - val_acc: 0.8866 - val_auc-prc: 0.9530 - val_auc-roc: 0.9542 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2357 - acc: 0.9059 - auc-prc: 0.9657 - auc-roc: 0.9657 - val_loss: 0.2917 - val_acc: 0.8877 - val_auc-prc: 0.9531 - val_auc-roc: 0.9542 - 14s/epoch - 54ms/step
Epoch 22/100
258/258 - 14s - loss: 0.2300 - acc: 0.9062 - auc-prc: 0.9673 - auc-roc: 0.9674 - val_loss: 0.3003 - val_acc: 0.8844 - val_auc-prc: 0.9490 - val_auc-roc: 0.9498 - 14s/epoch - 54ms/step
Epoch 23/100
258/258 - 14s - loss: 0.2249 - acc: 0.9111 - auc-prc: 0.9688 - auc-roc: 0.9687 - val_loss: 0.2883 - val_acc: 0.8877 - val_auc-prc: 0.9515 - val_auc-roc: 0.9521 - 14s/epoch - 54ms/step
Epoch 24/100
258/258 - 14s - loss: 0.2236 - acc: 0.9087 - auc-prc: 0.9696 - auc-roc: 0.9693 - val_loss: 0.3132 - val_acc: 0.8888 - val_auc-prc: 0.9483 - val_auc-roc: 0.9490 - 14s/epoch - 53ms/step
Epoch 25/100
258/258 - 14s - loss: 0.2209 - acc: 0.9133 - auc-prc: 0.9698 - auc-roc: 0.9698 - val_loss: 0.2984 - val_acc: 0.8779 - val_auc-prc: 0.9459 - val_auc-roc: 0.9468 - 14s/epoch - 53ms/step
Epoch 26/100
258/258 - 14s - loss: 0.2096 - acc: 0.9157 - auc-prc: 0.9731 - auc-roc: 0.9730 - val_loss: 0.3049 - val_acc: 0.8790 - val_auc-prc: 0.9471 - val_auc-roc: 0.9489 - 14s/epoch - 54ms/step
Epoch 27/100
258/258 - 14s - loss: 0.2141 - acc: 0.9144 - auc-prc: 0.9719 - auc-roc: 0.9718 - val_loss: 0.3016 - val_acc: 0.8888 - val_auc-prc: 0.9490 - val_auc-roc: 0.9514 - 14s/epoch - 54ms/step
Epoch 28/100
258/258 - 14s - loss: 0.2092 - acc: 0.9151 - auc-prc: 0.9730 - auc-roc: 0.9730 - val_loss: 0.3182 - val_acc: 0.8888 - val_auc-prc: 0.9490 - val_auc-roc: 0.9514 - 14s/epoch - 54ms/step
Epoch 29/100
258/258 - 14s - loss: 0.1997 - acc: 0.9220 - auc-prc: 0.9753 - auc-roc: 0.9753 - val_loss: 0.3250 - val_acc: 0.8757 - val_auc-prc: 0.9367 - val_auc-roc: 0.9413 - 14s/epoch - 54ms/step
Epoch 30/100
258/258 - 14s - loss: 0.1971 - acc: 0.9216 - auc-prc: 0.9761 - auc-roc: 0.9760 - val_loss: 0.3102 - val_acc: 0.8800 - val_auc-prc: 0.9464 - val_auc-roc: 0.9482 - 14s/epoch - 54ms/step
Epoch 31/100
258/258 - 14s - loss: 0.1912 - acc: 0.9227 - auc-prc: 0.9772 - auc-roc: 0.9773 - val_loss: 0.3274 - val_acc: 0.8833 - val_auc-prc: 0.9431 - val_auc-roc: 0.9473 - 14s/epoch - 53ms/step
Epoch 32/100
258/258 - 14s - loss: 0.1861 - acc: 0.9257 - auc-prc: 0.9787 - auc-roc: 0.9786 - val_loss: 0.3420 - val_acc: 0.8855 - val_auc-prc: 0.9331 - val_auc-roc: 0.9401 - 14s/epoch - 53ms/step
Epoch 33/100
258/258 - 14s - loss: 0.1835 - acc: 0.9249 - auc-prc: 0.9791 - auc-roc: 0.9791 - val_loss: 0.3190 - val_acc: 0.8746 - val_auc-prc: 0.9429 - val_auc-roc: 0.9466 - 14s/epoch - 53ms/step
Epoch 34/100
258/258 - 14s - loss: 0.1851 - acc: 0.9260 - auc-prc: 0.9785 - auc-roc: 0.9787 - val_loss: 0.3389 - val_acc: 0.8702 - val_auc-prc: 0.9395 - val_auc-roc: 0.9423 - 14s/epoch - 53ms/step
Epoch 35/100
258/258 - 14s - loss: 0.1721 - acc: 0.9333 - auc-prc: 0.9818 - auc-roc: 0.9816 - val_loss: 0.3402 - val_acc: 0.8702 - val_auc-prc: 0.9403 - val_auc-roc: 0.9429 - 14s/epoch - 53ms/step
Epoch 36/100
258/258 - 14s - loss: 0.1668 - acc: 0.9353 - auc-prc: 0.9829 - auc-roc: 0.9827 - val_loss: 0.3319 - val_acc: 0.8866 - val_auc-prc: 0.9438 - val_auc-roc: 0.9480 - 14s/epoch - 53ms/step
Epoch 37/100
258/258 - 14s - loss: 0.1650 - acc: 0.9330 - auc-prc: 0.9828 - auc-roc: 0.9830 - val_loss: 0.3608 - val_acc: 0.8768 - val_auc-prc: 0.9327 - val_auc-roc: 0.9383 - 14s/epoch - 53ms/step
Epoch 38/100
258/258 - 14s - loss: 0.1587 - acc: 0.9385 - auc-prc: 0.9844 - auc-roc: 0.9842 - val_loss: 0.3632 - val_acc: 0.8790 - val_auc-prc: 0.9372 - val_auc-roc: 0.9429 - 14s/epoch - 53ms/step
Epoch 39/100
258/258 - 13s - loss: 0.1525 - acc: 0.9422 - auc-prc: 0.9855 - auc-roc: 0.9854 - val_loss: 0.3729 - val_acc: 0.8790 - val_auc-prc: 0.9374 - val_auc-roc: 0.9425 - 13s/epoch - 52ms/step
Epoch 40/100
258/258 - 14s - loss: 0.1459 - acc: 0.9419 - auc-prc: 0.9868 - auc-roc: 0.9867 - val_loss: 0.3940 - val_acc: 0.8746 - val_auc-prc: 0.9278 - val_auc-roc: 0.9375 - 14s/epoch - 53ms/step
Epoch 41/100
258/258 - 14s - loss: 0.1386 - acc: 0.9460 - auc-prc: 0.9879 - auc-roc: 0.9879 - val_loss: 0.3724 - val_acc: 0.8790 - val_auc-prc: 0.9337 - val_auc-roc: 0.9391 - 14s/epoch - 53ms/step
Epoch 42/100
258/258 - 14s - loss: 0.1304 - acc: 0.9506 - auc-prc: 0.9892 - auc-roc: 0.9892 - val_loss: 0.3951 - val_acc: 0.8757 - val_auc-prc: 0.9255 - val_auc-roc: 0.9348 - 14s/epoch - 53ms/step
Epoch 43/100
258/258 - 14s - loss: 0.1287 - acc: 0.9507 - auc-prc: 0.9888 - auc-roc: 0.9892 - val_loss: 0.3989 - val_acc: 0.8724 - val_auc-prc: 0.9281 - val_auc-roc: 0.9355 - 14s/epoch - 53ms/step
Epoch 44/100
258/258 - 14s - loss: 0.1144 - acc: 0.9566 - auc-prc: 0.9911 - auc-roc: 0.9915 - val_loss: 0.4276 - val_acc: 0.8713 - val_auc-prc: 0.9251 - val_auc-roc: 0.9350 - 14s/epoch - 53ms/step
Epoch 45/100
258/258 - 14s - loss: 0.1176 - acc: 0.9577 - auc-prc: 0.9909 - auc-roc: 0.9910 - val_loss: 0.4551 - val_acc: 0.8746 - val_auc-prc: 0.9209 - val_auc-roc: 0.9329 - 14s/epoch - 53ms/step
Epoch 46/100
258/258 - 14s - loss: 0.1076 - acc: 0.9599 - auc-prc: 0.9926 - auc-roc: 0.9926 - val_loss: 0.4234 - val_acc: 0.8822 - val_auc-prc: 0.9262 - val_auc-roc: 0.9362 - 14s/epoch - 53ms/step
Epoch 47/100
258/258 - 14s - loss: 0.1112 - acc: 0.9569 - auc-prc: 0.9917 - auc-roc: 0.9920 - val_loss: 0.4408 - val_acc: 0.8779 - val_auc-prc: 0.9225 - val_auc-roc: 0.9330 - 14s/epoch - 53ms/step
Epoch 48/100
258/258 - 14s - loss: 0.1068 - acc: 0.9604 - auc-prc: 0.9927 - auc-roc: 0.9927 - val_loss: 0.4432 - val_acc: 0.8757 - val_auc-prc: 0.9255 - val_auc-roc: 0.9351 - 14s/epoch - 53ms/step
Epoch 49/100
258/258 - 14s - loss: 0.1015 - acc: 0.9592 - auc-prc: 0.9932 - auc-roc: 0.9934 - val_loss: 0.4554 - val_acc: 0.8724 - val_auc-prc: 0.9262 - val_auc-roc: 0.9360 - 14s/epoch - 53ms/step
Epoch 50/100
258/258 - 14s - loss: 0.0905 - acc: 0.9666 - auc-prc: 0.9949 - auc-roc: 0.9949 - val_loss: 0.4884 - val_acc: 0.8670 - val_auc-prc: 0.9176 - val_auc-roc: 0.9299 - 14s/epoch - 53ms/step
Epoch 51/100
258/258 - 14s - loss: 0.0944 - acc: 0.9645 - auc-prc: 0.9945 - auc-roc: 0.9944 - val_loss: 0.5003 - val_acc: 0.8615 - val_auc-prc: 0.9158 - val_auc-roc: 0.9280 - 14s/epoch - 53ms/step
Epoch 52/100
258/258 - 14s - loss: 0.0877 - acc: 0.9683 - auc-prc: 0.9947 - auc-roc: 0.9949 - val_loss: 0.5269 - val_acc: 0.8691 - val_auc-prc: 0.9140 - val_auc-roc: 0.9274 - 14s/epoch - 53ms/step
Epoch 53/100
258/258 - 14s - loss: 0.0926 - acc: 0.9635 - auc-prc: 0.9944 - auc-roc: 0.9945 - val_loss: 0.5621 - val_acc: 0.8768 - val_auc-prc: 0.9117 - val_auc-roc: 0.9251 - 14s/epoch - 53ms/step
Epoch 54/100
258/258 - 14s - loss: 0.0871 - acc: 0.9691 - auc-prc: 0.9950 - auc-roc: 0.9951 - val_loss: 0.5074 - val_acc: 0.8593 - val_auc-prc: 0.9161 - val_auc-roc: 0.9263 - 14s/epoch - 54ms/step
Epoch 55/100
258/258 - 14s - loss: 0.0795 - acc: 0.9675 - auc-prc: 0.9962 - auc-roc: 0.9961 - val_loss: 0.5191 - val_acc: 0.8757 - val_auc-prc: 0.9146 - val_auc-roc: 0.9279 - 14s/epoch - 54ms/step
Epoch 56/100
258/258 - 14s - loss: 0.0759 - acc: 0.9717 - auc-prc: 0.9961 - auc-roc: 0.9962 - val_loss: 0.5275 - val_acc: 0.8680 - val_auc-prc: 0.9163 - val_auc-roc: 0.9285 - 14s/epoch - 53ms/step
Epoch 57/100
258/258 - 14s - loss: 0.0746 - acc: 0.9713 - auc-prc: 0.9959 - auc-roc: 0.9961 - val_loss: 0.5513 - val_acc: 0.8659 - val_auc-prc: 0.9068 - val_auc-roc: 0.9215 - 14s/epoch - 53ms/step
Epoch 58/100
258/258 - 14s - loss: 0.0640 - acc: 0.9767 - auc-prc: 0.9972 - auc-roc: 0.9973 - val_loss: 0.4991 - val_acc: 0.8615 - val_auc-prc: 0.9209 - val_auc-roc: 0.9306 - 14s/epoch - 53ms/step
Epoch 59/100
258/258 - 14s - loss: 0.0683 - acc: 0.9747 - auc-prc: 0.9968 - auc-roc: 0.9969 - val_loss: 0.5653 - val_acc: 0.8691 - val_auc-prc: 0.9083 - val_auc-roc: 0.9228 - 14s/epoch - 53ms/step
Epoch 60/100
258/258 - 14s - loss: 0.0669 - acc: 0.9730 - auc-prc: 0.9974 - auc-roc: 0.9973 - val_loss: 0.5454 - val_acc: 0.8713 - val_auc-prc: 0.9094 - val_auc-roc: 0.9246 - 14s/epoch - 53ms/step
Epoch 61/100
258/258 - 14s - loss: 0.0600 - acc: 0.9764 - auc-prc: 0.9978 - auc-roc: 0.9978 - val_loss: 0.5678 - val_acc: 0.8713 - val_auc-prc: 0.9137 - val_auc-roc: 0.9263 - 14s/epoch - 53ms/step
Epoch 62/100
258/258 - 14s - loss: 0.0548 - acc: 0.9792 - auc-prc: 0.9981 - auc-roc: 0.9981 - val_loss: 0.6239 - val_acc: 0.8680 - val_auc-prc: 0.9076 - val_auc-roc: 0.9230 - 14s/epoch - 53ms/step
Epoch 63/100
258/258 - 14s - loss: 0.0586 - acc: 0.9780 - auc-prc: 0.9973 - auc-roc: 0.9975 - val_loss: 0.6392 - val_acc: 0.8680 - val_auc-prc: 0.9074 - val_auc-roc: 0.9228 - 14s/epoch - 53ms/step
Epoch 64/100
258/258 - 14s - loss: 0.0814 - acc: 0.9697 - auc-prc: 0.9953 - auc-roc: 0.9955 - val_loss: 0.5540 - val_acc: 0.8811 - val_auc-prc: 0.9125 - val_auc-roc: 0.9270 - 14s/epoch - 53ms/step
Epoch 65/100
258/258 - 14s - loss: 0.0553 - acc: 0.9805 - auc-prc: 0.9975 - auc-roc: 0.9977 - val_loss: 0.6131 - val_acc: 0.8746 - val_auc-prc: 0.9052 - val_auc-roc: 0.9217 - 14s/epoch - 53ms/step
Epoch 66/100
258/258 - 14s - loss: 0.0433 - acc: 0.9836 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.6160 - val_acc: 0.8768 - val_auc-prc: 0.9125 - val_auc-roc: 0.9274 - 14s/epoch - 53ms/step
Epoch 67/100
258/258 - 14s - loss: 0.0599 - acc: 0.9773 - auc-prc: 0.9972 - auc-roc: 0.9974 - val_loss: 0.6329 - val_acc: 0.8691 - val_auc-prc: 0.9100 - val_auc-roc: 0.9252 - 14s/epoch - 53ms/step
Epoch 68/100
258/258 - 14s - loss: 0.0585 - acc: 0.9777 - auc-prc: 0.9978 - auc-roc: 0.9979 - val_loss: 0.5859 - val_acc: 0.8800 - val_auc-prc: 0.9200 - val_auc-roc: 0.9337 - 14s/epoch - 53ms/step
Epoch 69/100
258/258 - 14s - loss: 0.0551 - acc: 0.9788 - auc-prc: 0.9975 - auc-roc: 0.9977 - val_loss: 0.6013 - val_acc: 0.8833 - val_auc-prc: 0.9152 - val_auc-roc: 0.9297 - 14s/epoch - 53ms/step
Epoch 70/100
258/258 - 14s - loss: 0.0450 - acc: 0.9839 - auc-prc: 0.9985 - auc-roc: 0.9986 - val_loss: 0.6477 - val_acc: 0.8800 - val_auc-prc: 0.9145 - val_auc-roc: 0.9294 - 14s/epoch - 53ms/step
Epoch 71/100
258/258 - 14s - loss: 0.0331 - acc: 0.9885 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.6456 - val_acc: 0.8779 - val_auc-prc: 0.9116 - val_auc-roc: 0.9267 - 14s/epoch - 53ms/step
Epoch 72/100
258/258 - 14s - loss: 0.0525 - acc: 0.9794 - auc-prc: 0.9976 - auc-roc: 0.9979 - val_loss: 0.6329 - val_acc: 0.8768 - val_auc-prc: 0.9083 - val_auc-roc: 0.9236 - 14s/epoch - 53ms/step
Epoch 73/100
258/258 - 14s - loss: 0.0388 - acc: 0.9856 - auc-prc: 0.9990 - auc-roc: 0.9990 - val_loss: 0.6851 - val_acc: 0.8582 - val_auc-prc: 0.9002 - val_auc-roc: 0.9165 - 14s/epoch - 54ms/step
Epoch 74/100
258/258 - 14s - loss: 0.0386 - acc: 0.9858 - auc-prc: 0.9991 - auc-roc: 0.9991 - val_loss: 0.7014 - val_acc: 0.8757 - val_auc-prc: 0.9048 - val_auc-roc: 0.9218 - 14s/epoch - 54ms/step
Epoch 75/100
258/258 - 14s - loss: 0.0403 - acc: 0.9859 - auc-prc: 0.9985 - auc-roc: 0.9987 - val_loss: 0.6760 - val_acc: 0.8691 - val_auc-prc: 0.9030 - val_auc-roc: 0.9204 - 14s/epoch - 53ms/step
Epoch 76/100
258/258 - 14s - loss: 0.0464 - acc: 0.9840 - auc-prc: 0.9985 - auc-roc: 0.9986 - val_loss: 0.6631 - val_acc: 0.8735 - val_auc-prc: 0.9035 - val_auc-roc: 0.9205 - 14s/epoch - 53ms/step
Epoch 77/100
258/258 - 14s - loss: 0.0463 - acc: 0.9833 - auc-prc: 0.9983 - auc-roc: 0.9984 - val_loss: 0.6814 - val_acc: 0.8441 - val_auc-prc: 0.9006 - val_auc-roc: 0.9154 - 14s/epoch - 53ms/step
Epoch 78/100
258/258 - 14s - loss: 0.0532 - acc: 0.9804 - auc-prc: 0.9976 - auc-roc: 0.9978 - val_loss: 0.6759 - val_acc: 0.8713 - val_auc-prc: 0.9037 - val_auc-roc: 0.9208 - 14s/epoch - 53ms/step
Epoch 79/100
258/258 - 14s - loss: 0.0453 - acc: 0.9844 - auc-prc: 0.9983 - auc-roc: 0.9984 - val_loss: 0.6799 - val_acc: 0.8822 - val_auc-prc: 0.9121 - val_auc-roc: 0.9280 - 14s/epoch - 53ms/step
Epoch 80/100
258/258 - 14s - loss: 0.0499 - acc: 0.9813 - auc-prc: 0.9979 - auc-roc: 0.9981 - val_loss: 0.7027 - val_acc: 0.8768 - val_auc-prc: 0.9036 - val_auc-roc: 0.9209 - 14s/epoch - 53ms/step
Epoch 81/100
258/258 - 14s - loss: 0.0322 - acc: 0.9891 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.6449 - val_acc: 0.8680 - val_auc-prc: 0.9106 - val_auc-roc: 0.9252 - 14s/epoch - 53ms/step
Epoch 82/100
258/258 - 14s - loss: 0.0306 - acc: 0.9880 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.7305 - val_acc: 0.8702 - val_auc-prc: 0.9111 - val_auc-roc: 0.9258 - 14s/epoch - 53ms/step
Epoch 83/100
258/258 - 14s - loss: 0.0488 - acc: 0.9829 - auc-prc: 0.9975 - auc-roc: 0.9978 - val_loss: 0.7086 - val_acc: 0.8604 - val_auc-prc: 0.8991 - val_auc-roc: 0.9166 - 14s/epoch - 53ms/step
Epoch 84/100
258/258 - 14s - loss: 0.0329 - acc: 0.9879 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.7233 - val_acc: 0.8659 - val_auc-prc: 0.9029 - val_auc-roc: 0.9195 - 14s/epoch - 53ms/step
Epoch 85/100
258/258 - 14s - loss: 0.0421 - acc: 0.9841 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.6506 - val_acc: 0.8670 - val_auc-prc: 0.9057 - val_auc-roc: 0.9214 - 14s/epoch - 53ms/step
Epoch 86/100
258/258 - 14s - loss: 0.0332 - acc: 0.9884 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.7354 - val_acc: 0.8779 - val_auc-prc: 0.9036 - val_auc-roc: 0.9212 - 14s/epoch - 53ms/step
Epoch 87/100
258/258 - 14s - loss: 0.0305 - acc: 0.9896 - auc-prc: 0.9989 - auc-roc: 0.9991 - val_loss: 0.7375 - val_acc: 0.8626 - val_auc-prc: 0.8956 - val_auc-roc: 0.9138 - 14s/epoch - 54ms/step
Epoch 88/100
258/258 - 14s - loss: 0.0262 - acc: 0.9913 - auc-prc: 0.9994 - auc-roc: 0.9995 - val_loss: 0.7163 - val_acc: 0.8746 - val_auc-prc: 0.9081 - val_auc-roc: 0.9241 - 14s/epoch - 53ms/step
Epoch 89/100
258/258 - 14s - loss: 0.0346 - acc: 0.9882 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.7079 - val_acc: 0.8593 - val_auc-prc: 0.9083 - val_auc-roc: 0.9221 - 14s/epoch - 53ms/step
Epoch 90/100
258/258 - 14s - loss: 0.0373 - acc: 0.9866 - auc-prc: 0.9985 - auc-roc: 0.9987 - val_loss: 0.7245 - val_acc: 0.8680 - val_auc-prc: 0.9092 - val_auc-roc: 0.9244 - 14s/epoch - 53ms/step
Epoch 91/100
258/258 - 14s - loss: 0.0299 - acc: 0.9895 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.7156 - val_acc: 0.8757 - val_auc-prc: 0.9073 - val_auc-roc: 0.9241 - 14s/epoch - 53ms/step
Epoch 92/100
258/258 - 14s - loss: 0.0313 - acc: 0.9893 - auc-prc: 0.9990 - auc-roc: 0.9991 - val_loss: 0.7802 - val_acc: 0.8691 - val_auc-prc: 0.8935 - val_auc-roc: 0.9130 - 14s/epoch - 53ms/step
Epoch 93/100
258/258 - 14s - loss: 0.0394 - acc: 0.9850 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.7370 - val_acc: 0.8680 - val_auc-prc: 0.8981 - val_auc-roc: 0.9164 - 14s/epoch - 53ms/step
Epoch 94/100
258/258 - 14s - loss: 0.0378 - acc: 0.9863 - auc-prc: 0.9990 - auc-roc: 0.9990 - val_loss: 0.7227 - val_acc: 0.8757 - val_auc-prc: 0.8997 - val_auc-roc: 0.9178 - 14s/epoch - 53ms/step
Epoch 95/100
258/258 - 14s - loss: 0.0309 - acc: 0.9889 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.7728 - val_acc: 0.8670 - val_auc-prc: 0.8992 - val_auc-roc: 0.9171 - 14s/epoch - 53ms/step
Epoch 96/100
258/258 - 14s - loss: 0.0285 - acc: 0.9902 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.7360 - val_acc: 0.8735 - val_auc-prc: 0.9043 - val_auc-roc: 0.9220 - 14s/epoch - 53ms/step
Epoch 97/100
258/258 - 14s - loss: 0.0597 - acc: 0.9776 - auc-prc: 0.9970 - auc-roc: 0.9973 - val_loss: 0.6921 - val_acc: 0.8746 - val_auc-prc: 0.9066 - val_auc-roc: 0.9232 - 14s/epoch - 53ms/step
Epoch 98/100
258/258 - 14s - loss: 0.0305 - acc: 0.9886 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.7064 - val_acc: 0.8779 - val_auc-prc: 0.9110 - val_auc-roc: 0.9270 - 14s/epoch - 53ms/step
Epoch 99/100
258/258 - 14s - loss: 0.0220 - acc: 0.9926 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.7308 - val_acc: 0.8768 - val_auc-prc: 0.9003 - val_auc-roc: 0.9183 - 14s/epoch - 53ms/step
Epoch 100/100
258/258 - 14s - loss: 0.0278 - acc: 0.9903 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.7227 - val_acc: 0.8768 - val_auc-prc: 0.9036 - val_auc-roc: 0.9211 - 14s/epoch - 53ms/step
Early stopping epoch: 0
******Evaluating TEST set*********
29/29 - 1s - 1s/epoch - 38ms/step
              precision    recall  f1-score   support

           0       0.91      0.84      0.87       386
           1       0.89      0.94      0.91       531

    accuracy                           0.90       917
   macro avg       0.90      0.89      0.89       917
weighted avg       0.90      0.90      0.90       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.45      0.41       386
           1       0.54      0.47      0.50       531

    accuracy                           0.46       917
   macro avg       0.46      0.46      0.45       917
weighted avg       0.47      0.46      0.46       917

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 16s - loss: 0.3259 - acc: 0.8583 - auc-prc: 0.9339 - auc-roc: 0.9346 - val_loss: 0.3269 - val_acc: 0.8670 - val_auc-prc: 0.9309 - val_auc-roc: 0.9371 - 16s/epoch - 63ms/step
Epoch 2/100
258/258 - 14s - loss: 0.2968 - acc: 0.8787 - auc-prc: 0.9437 - auc-roc: 0.9455 - val_loss: 0.3179 - val_acc: 0.8680 - val_auc-prc: 0.9345 - val_auc-roc: 0.9402 - 14s/epoch - 54ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2892 - acc: 0.8856 - auc-prc: 0.9467 - auc-roc: 0.9480 - val_loss: 0.3208 - val_acc: 0.8746 - val_auc-prc: 0.9353 - val_auc-roc: 0.9404 - 14s/epoch - 54ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2785 - acc: 0.8866 - auc-prc: 0.9507 - auc-roc: 0.9516 - val_loss: 0.2989 - val_acc: 0.8822 - val_auc-prc: 0.9402 - val_auc-roc: 0.9454 - 14s/epoch - 53ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2759 - acc: 0.8878 - auc-prc: 0.9518 - auc-roc: 0.9526 - val_loss: 0.2916 - val_acc: 0.8844 - val_auc-prc: 0.9423 - val_auc-roc: 0.9481 - 14s/epoch - 54ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2693 - acc: 0.8935 - auc-prc: 0.9542 - auc-roc: 0.9550 - val_loss: 0.2959 - val_acc: 0.8811 - val_auc-prc: 0.9407 - val_auc-roc: 0.9467 - 14s/epoch - 53ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2686 - acc: 0.8909 - auc-prc: 0.9545 - auc-roc: 0.9552 - val_loss: 0.2942 - val_acc: 0.8811 - val_auc-prc: 0.9400 - val_auc-roc: 0.9465 - 14s/epoch - 56ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2617 - acc: 0.8964 - auc-prc: 0.9567 - auc-roc: 0.9574 - val_loss: 0.2953 - val_acc: 0.8768 - val_auc-prc: 0.9444 - val_auc-roc: 0.9486 - 14s/epoch - 56ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2626 - acc: 0.8925 - auc-prc: 0.9568 - auc-roc: 0.9573 - val_loss: 0.2925 - val_acc: 0.8866 - val_auc-prc: 0.9450 - val_auc-roc: 0.9496 - 14s/epoch - 56ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2609 - acc: 0.8958 - auc-prc: 0.9570 - auc-roc: 0.9578 - val_loss: 0.2854 - val_acc: 0.8800 - val_auc-prc: 0.9454 - val_auc-roc: 0.9503 - 14s/epoch - 56ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2556 - acc: 0.8945 - auc-prc: 0.9592 - auc-roc: 0.9597 - val_loss: 0.3041 - val_acc: 0.8691 - val_auc-prc: 0.9413 - val_auc-roc: 0.9454 - 14s/epoch - 56ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2535 - acc: 0.8987 - auc-prc: 0.9598 - auc-roc: 0.9604 - val_loss: 0.2896 - val_acc: 0.8811 - val_auc-prc: 0.9467 - val_auc-roc: 0.9508 - 14s/epoch - 56ms/step
Epoch 13/100
258/258 - 13s - loss: 0.2536 - acc: 0.8951 - auc-prc: 0.9599 - auc-roc: 0.9603 - val_loss: 0.2798 - val_acc: 0.8833 - val_auc-prc: 0.9487 - val_auc-roc: 0.9523 - 13s/epoch - 52ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2512 - acc: 0.8984 - auc-prc: 0.9608 - auc-roc: 0.9612 - val_loss: 0.2844 - val_acc: 0.8822 - val_auc-prc: 0.9482 - val_auc-roc: 0.9520 - 14s/epoch - 54ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2472 - acc: 0.8976 - auc-prc: 0.9624 - auc-roc: 0.9625 - val_loss: 0.2954 - val_acc: 0.8855 - val_auc-prc: 0.9456 - val_auc-roc: 0.9493 - 14s/epoch - 54ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2484 - acc: 0.8992 - auc-prc: 0.9621 - auc-roc: 0.9621 - val_loss: 0.2880 - val_acc: 0.8757 - val_auc-prc: 0.9475 - val_auc-roc: 0.9498 - 14s/epoch - 53ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2436 - acc: 0.9010 - auc-prc: 0.9629 - auc-roc: 0.9632 - val_loss: 0.2890 - val_acc: 0.8746 - val_auc-prc: 0.9468 - val_auc-roc: 0.9491 - 14s/epoch - 53ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2421 - acc: 0.8997 - auc-prc: 0.9635 - auc-roc: 0.9639 - val_loss: 0.2828 - val_acc: 0.8800 - val_auc-prc: 0.9492 - val_auc-roc: 0.9511 - 14s/epoch - 53ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2379 - acc: 0.9039 - auc-prc: 0.9651 - auc-roc: 0.9652 - val_loss: 0.2844 - val_acc: 0.8844 - val_auc-prc: 0.9488 - val_auc-roc: 0.9505 - 14s/epoch - 53ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2354 - acc: 0.9058 - auc-prc: 0.9658 - auc-roc: 0.9660 - val_loss: 0.2905 - val_acc: 0.8866 - val_auc-prc: 0.9457 - val_auc-roc: 0.9497 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 14s - loss: 0.2329 - acc: 0.9056 - auc-prc: 0.9669 - auc-roc: 0.9667 - val_loss: 0.2894 - val_acc: 0.8768 - val_auc-prc: 0.9469 - val_auc-roc: 0.9495 - 14s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
29/29 - 1s - 682ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.83      0.86       386
           1       0.88      0.92      0.90       531

    accuracy                           0.88       917
   macro avg       0.88      0.88      0.88       917
weighted avg       0.88      0.88      0.88       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.44      0.49      0.47       386
           1       0.60      0.54      0.57       531

    accuracy                           0.52       917
   macro avg       0.52      0.52      0.52       917
weighted avg       0.53      0.52      0.52       917

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
258/258 - 17s - loss: 0.3337 - acc: 0.8575 - auc-prc: 0.9295 - auc-roc: 0.9315 - val_loss: 0.2689 - val_acc: 0.8909 - val_auc-prc: 0.9542 - val_auc-roc: 0.9549 - 17s/epoch - 66ms/step
Epoch 2/100
258/258 - 14s - loss: 0.3000 - acc: 0.8753 - auc-prc: 0.9428 - auc-roc: 0.9444 - val_loss: 0.2558 - val_acc: 0.8986 - val_auc-prc: 0.9582 - val_auc-roc: 0.9588 - 14s/epoch - 53ms/step
Epoch 3/100
258/258 - 14s - loss: 0.2886 - acc: 0.8843 - auc-prc: 0.9468 - auc-roc: 0.9484 - val_loss: 0.2654 - val_acc: 0.8986 - val_auc-prc: 0.9598 - val_auc-roc: 0.9601 - 14s/epoch - 53ms/step
Epoch 4/100
258/258 - 14s - loss: 0.2870 - acc: 0.8869 - auc-prc: 0.9477 - auc-roc: 0.9490 - val_loss: 0.2510 - val_acc: 0.8964 - val_auc-prc: 0.9617 - val_auc-roc: 0.9617 - 14s/epoch - 54ms/step
Epoch 5/100
258/258 - 14s - loss: 0.2776 - acc: 0.8886 - auc-prc: 0.9506 - auc-roc: 0.9522 - val_loss: 0.2442 - val_acc: 0.9062 - val_auc-prc: 0.9625 - val_auc-roc: 0.9630 - 14s/epoch - 54ms/step
Epoch 6/100
258/258 - 14s - loss: 0.2765 - acc: 0.8887 - auc-prc: 0.9509 - auc-roc: 0.9523 - val_loss: 0.2432 - val_acc: 0.9062 - val_auc-prc: 0.9632 - val_auc-roc: 0.9636 - 14s/epoch - 53ms/step
Epoch 7/100
258/258 - 14s - loss: 0.2702 - acc: 0.8905 - auc-prc: 0.9537 - auc-roc: 0.9547 - val_loss: 0.2365 - val_acc: 0.9095 - val_auc-prc: 0.9650 - val_auc-roc: 0.9656 - 14s/epoch - 54ms/step
Epoch 8/100
258/258 - 14s - loss: 0.2717 - acc: 0.8902 - auc-prc: 0.9528 - auc-roc: 0.9541 - val_loss: 0.2377 - val_acc: 0.9062 - val_auc-prc: 0.9646 - val_auc-roc: 0.9651 - 14s/epoch - 54ms/step
Epoch 9/100
258/258 - 14s - loss: 0.2674 - acc: 0.8912 - auc-prc: 0.9559 - auc-roc: 0.9561 - val_loss: 0.2522 - val_acc: 0.8953 - val_auc-prc: 0.9594 - val_auc-roc: 0.9613 - 14s/epoch - 54ms/step
Epoch 10/100
258/258 - 14s - loss: 0.2699 - acc: 0.8915 - auc-prc: 0.9541 - auc-roc: 0.9550 - val_loss: 0.2365 - val_acc: 0.9051 - val_auc-prc: 0.9658 - val_auc-roc: 0.9663 - 14s/epoch - 56ms/step
Epoch 11/100
258/258 - 14s - loss: 0.2631 - acc: 0.8921 - auc-prc: 0.9570 - auc-roc: 0.9575 - val_loss: 0.2340 - val_acc: 0.9128 - val_auc-prc: 0.9650 - val_auc-roc: 0.9654 - 14s/epoch - 53ms/step
Epoch 12/100
258/258 - 14s - loss: 0.2616 - acc: 0.8929 - auc-prc: 0.9573 - auc-roc: 0.9579 - val_loss: 0.2350 - val_acc: 0.9051 - val_auc-prc: 0.9665 - val_auc-roc: 0.9666 - 14s/epoch - 54ms/step
Epoch 13/100
258/258 - 14s - loss: 0.2566 - acc: 0.8975 - auc-prc: 0.9590 - auc-roc: 0.9594 - val_loss: 0.2321 - val_acc: 0.9117 - val_auc-prc: 0.9665 - val_auc-roc: 0.9669 - 14s/epoch - 54ms/step
Epoch 14/100
258/258 - 14s - loss: 0.2596 - acc: 0.8935 - auc-prc: 0.9577 - auc-roc: 0.9586 - val_loss: 0.2330 - val_acc: 0.9160 - val_auc-prc: 0.9662 - val_auc-roc: 0.9667 - 14s/epoch - 54ms/step
Epoch 15/100
258/258 - 14s - loss: 0.2535 - acc: 0.8938 - auc-prc: 0.9602 - auc-roc: 0.9607 - val_loss: 0.2355 - val_acc: 0.9084 - val_auc-prc: 0.9628 - val_auc-roc: 0.9658 - 14s/epoch - 54ms/step
Epoch 16/100
258/258 - 14s - loss: 0.2514 - acc: 0.8980 - auc-prc: 0.9608 - auc-roc: 0.9612 - val_loss: 0.2269 - val_acc: 0.8997 - val_auc-prc: 0.9686 - val_auc-roc: 0.9690 - 14s/epoch - 54ms/step
Epoch 17/100
258/258 - 14s - loss: 0.2477 - acc: 0.8953 - auc-prc: 0.9622 - auc-roc: 0.9623 - val_loss: 0.2663 - val_acc: 0.8920 - val_auc-prc: 0.9541 - val_auc-roc: 0.9586 - 14s/epoch - 54ms/step
Epoch 18/100
258/258 - 14s - loss: 0.2481 - acc: 0.8980 - auc-prc: 0.9622 - auc-roc: 0.9623 - val_loss: 0.2319 - val_acc: 0.9106 - val_auc-prc: 0.9638 - val_auc-roc: 0.9675 - 14s/epoch - 54ms/step
Epoch 19/100
258/258 - 14s - loss: 0.2457 - acc: 0.9024 - auc-prc: 0.9624 - auc-roc: 0.9628 - val_loss: 0.2424 - val_acc: 0.8953 - val_auc-prc: 0.9640 - val_auc-roc: 0.9646 - 14s/epoch - 54ms/step
Epoch 20/100
258/258 - 14s - loss: 0.2374 - acc: 0.9002 - auc-prc: 0.9657 - auc-roc: 0.9658 - val_loss: 0.2221 - val_acc: 0.9095 - val_auc-prc: 0.9689 - val_auc-roc: 0.9691 - 14s/epoch - 54ms/step
Epoch 21/100
258/258 - 15s - loss: 0.2330 - acc: 0.9035 - auc-prc: 0.9669 - auc-roc: 0.9668 - val_loss: 0.2433 - val_acc: 0.9062 - val_auc-prc: 0.9585 - val_auc-roc: 0.9633 - 15s/epoch - 57ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
29/29 - 1s - 721ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.90      0.88      0.89       386
           1       0.92      0.93      0.92       531

    accuracy                           0.91       917
   macro avg       0.91      0.91      0.91       917
weighted avg       0.91      0.91      0.91       917

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.42      0.52      0.46       386
           1       0.58      0.47      0.52       531

    accuracy                           0.49       917
   macro avg       0.50      0.50      0.49       917
weighted avg       0.51      0.49      0.50       917

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8880] IC [0.8811, 0.8949]
Mean Accuracy[0.8937] IC [0.8877, 0.8997]
Mean Recall[0.8880] IC [0.8811, 0.8949]
Mean F1[0.8902] IC [0.8839, 0.8966]
Median AUC_ROC[0.8889]
Median Accuracy[0.8943]
Median Recall[0.8889]
Median F1[0.8910]
********************txid169963********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.82      0.67      0.73       172
           1       0.95      0.97      0.96      1031

    accuracy                           0.93      1203
   macro avg       0.88      0.82      0.85      1203
weighted avg       0.93      0.93      0.93      1203

Predicted  0.0   1.0   All
True                      
0          115    57   172
1           26  1005  1031
All        141  1062  1203
**************************************************
fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 17s - loss: 0.3134 - acc: 0.8644 - auc-prc: 0.9382 - auc-roc: 0.9396 - val_loss: 0.2545 - val_acc: 0.9021 - val_auc-prc: 0.9594 - val_auc-roc: 0.9601 - 17s/epoch - 61ms/step
Epoch 2/100
282/282 - 15s - loss: 0.2752 - acc: 0.8907 - auc-prc: 0.9514 - auc-roc: 0.9531 - val_loss: 0.2384 - val_acc: 0.9051 - val_auc-prc: 0.9646 - val_auc-roc: 0.9651 - 15s/epoch - 53ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2714 - acc: 0.8902 - auc-prc: 0.9525 - auc-roc: 0.9543 - val_loss: 0.2386 - val_acc: 0.9071 - val_auc-prc: 0.9647 - val_auc-roc: 0.9652 - 15s/epoch - 52ms/step
Epoch 4/100
282/282 - 15s - loss: 0.2623 - acc: 0.8950 - auc-prc: 0.9558 - auc-roc: 0.9573 - val_loss: 0.2327 - val_acc: 0.9041 - val_auc-prc: 0.9669 - val_auc-roc: 0.9671 - 15s/epoch - 54ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2579 - acc: 0.8975 - auc-prc: 0.9579 - auc-roc: 0.9588 - val_loss: 0.2324 - val_acc: 0.9081 - val_auc-prc: 0.9672 - val_auc-roc: 0.9673 - 15s/epoch - 55ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2556 - acc: 0.8964 - auc-prc: 0.9589 - auc-roc: 0.9598 - val_loss: 0.2317 - val_acc: 0.9071 - val_auc-prc: 0.9678 - val_auc-roc: 0.9674 - 15s/epoch - 55ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2561 - acc: 0.8989 - auc-prc: 0.9581 - auc-roc: 0.9592 - val_loss: 0.2490 - val_acc: 0.8991 - val_auc-prc: 0.9641 - val_auc-roc: 0.9647 - 15s/epoch - 55ms/step
Epoch 8/100
282/282 - 15s - loss: 0.2519 - acc: 0.8980 - auc-prc: 0.9603 - auc-roc: 0.9609 - val_loss: 0.2295 - val_acc: 0.9071 - val_auc-prc: 0.9692 - val_auc-roc: 0.9688 - 15s/epoch - 52ms/step
Epoch 9/100
282/282 - 15s - loss: 0.2490 - acc: 0.8981 - auc-prc: 0.9609 - auc-roc: 0.9617 - val_loss: 0.2215 - val_acc: 0.9091 - val_auc-prc: 0.9697 - val_auc-roc: 0.9699 - 15s/epoch - 52ms/step
Epoch 10/100
282/282 - 14s - loss: 0.2486 - acc: 0.8988 - auc-prc: 0.9610 - auc-roc: 0.9618 - val_loss: 0.2187 - val_acc: 0.9091 - val_auc-prc: 0.9709 - val_auc-roc: 0.9707 - 14s/epoch - 50ms/step
Epoch 11/100
282/282 - 14s - loss: 0.2447 - acc: 0.9014 - auc-prc: 0.9629 - auc-roc: 0.9632 - val_loss: 0.2166 - val_acc: 0.9101 - val_auc-prc: 0.9695 - val_auc-roc: 0.9707 - 14s/epoch - 50ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2453 - acc: 0.8998 - auc-prc: 0.9626 - auc-roc: 0.9628 - val_loss: 0.2201 - val_acc: 0.9051 - val_auc-prc: 0.9722 - val_auc-roc: 0.9720 - 15s/epoch - 52ms/step
Epoch 13/100
282/282 - 14s - loss: 0.2439 - acc: 0.9018 - auc-prc: 0.9632 - auc-roc: 0.9634 - val_loss: 0.2212 - val_acc: 0.9111 - val_auc-prc: 0.9700 - val_auc-roc: 0.9700 - 14s/epoch - 50ms/step
Epoch 14/100
282/282 - 14s - loss: 0.2418 - acc: 0.9009 - auc-prc: 0.9631 - auc-roc: 0.9638 - val_loss: 0.2152 - val_acc: 0.9111 - val_auc-prc: 0.9707 - val_auc-roc: 0.9715 - 14s/epoch - 51ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2417 - acc: 0.9011 - auc-prc: 0.9636 - auc-roc: 0.9641 - val_loss: 0.2185 - val_acc: 0.9121 - val_auc-prc: 0.9719 - val_auc-roc: 0.9719 - 15s/epoch - 52ms/step
Epoch 16/100
282/282 - 14s - loss: 0.2394 - acc: 0.9012 - auc-prc: 0.9639 - auc-roc: 0.9647 - val_loss: 0.2126 - val_acc: 0.9151 - val_auc-prc: 0.9718 - val_auc-roc: 0.9720 - 14s/epoch - 51ms/step
Epoch 17/100
282/282 - 15s - loss: 0.2341 - acc: 0.9050 - auc-prc: 0.9659 - auc-roc: 0.9663 - val_loss: 0.2193 - val_acc: 0.9111 - val_auc-prc: 0.9712 - val_auc-roc: 0.9710 - 15s/epoch - 52ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2314 - acc: 0.9046 - auc-prc: 0.9662 - auc-roc: 0.9669 - val_loss: 0.2133 - val_acc: 0.9101 - val_auc-prc: 0.9719 - val_auc-roc: 0.9719 - 15s/epoch - 53ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2283 - acc: 0.9074 - auc-prc: 0.9677 - auc-roc: 0.9678 - val_loss: 0.2154 - val_acc: 0.9171 - val_auc-prc: 0.9721 - val_auc-roc: 0.9720 - 15s/epoch - 52ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2257 - acc: 0.9081 - auc-prc: 0.9685 - auc-roc: 0.9686 - val_loss: 0.2145 - val_acc: 0.9111 - val_auc-prc: 0.9717 - val_auc-roc: 0.9716 - 15s/epoch - 52ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2254 - acc: 0.9088 - auc-prc: 0.9684 - auc-roc: 0.9686 - val_loss: 0.2074 - val_acc: 0.9221 - val_auc-prc: 0.9735 - val_auc-roc: 0.9734 - 15s/epoch - 52ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 724ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.92      0.88      0.90       391
           1       0.92      0.95      0.94       610

    accuracy                           0.92      1001
   macro avg       0.92      0.91      0.92      1001
weighted avg       0.92      0.92      0.92      1001

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.49      0.44       391
           1       0.61      0.51      0.56       610

    accuracy                           0.50      1001
   macro avg       0.50      0.50      0.50      1001
weighted avg       0.53      0.50      0.51      1001

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 17s - loss: 0.3079 - acc: 0.8685 - auc-prc: 0.9406 - auc-roc: 0.9417 - val_loss: 0.2959 - val_acc: 0.8771 - val_auc-prc: 0.9424 - val_auc-roc: 0.9463 - 17s/epoch - 62ms/step
Epoch 2/100
282/282 - 15s - loss: 0.2756 - acc: 0.8877 - auc-prc: 0.9516 - auc-roc: 0.9531 - val_loss: 0.2704 - val_acc: 0.9001 - val_auc-prc: 0.9516 - val_auc-roc: 0.9543 - 15s/epoch - 53ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2630 - acc: 0.8968 - auc-prc: 0.9556 - auc-roc: 0.9570 - val_loss: 0.2711 - val_acc: 0.8991 - val_auc-prc: 0.9527 - val_auc-roc: 0.9541 - 15s/epoch - 53ms/step
Epoch 4/100
282/282 - 15s - loss: 0.2579 - acc: 0.8974 - auc-prc: 0.9576 - auc-roc: 0.9586 - val_loss: 0.2820 - val_acc: 0.8921 - val_auc-prc: 0.9489 - val_auc-roc: 0.9507 - 15s/epoch - 53ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2534 - acc: 0.8982 - auc-prc: 0.9593 - auc-roc: 0.9603 - val_loss: 0.2591 - val_acc: 0.9021 - val_auc-prc: 0.9583 - val_auc-roc: 0.9590 - 15s/epoch - 53ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2513 - acc: 0.8976 - auc-prc: 0.9598 - auc-roc: 0.9608 - val_loss: 0.2619 - val_acc: 0.9001 - val_auc-prc: 0.9559 - val_auc-roc: 0.9572 - 15s/epoch - 53ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2512 - acc: 0.8995 - auc-prc: 0.9603 - auc-roc: 0.9609 - val_loss: 0.2565 - val_acc: 0.9031 - val_auc-prc: 0.9588 - val_auc-roc: 0.9599 - 15s/epoch - 52ms/step
Epoch 8/100
282/282 - 14s - loss: 0.2479 - acc: 0.8998 - auc-prc: 0.9611 - auc-roc: 0.9621 - val_loss: 0.2532 - val_acc: 0.9021 - val_auc-prc: 0.9588 - val_auc-roc: 0.9604 - 14s/epoch - 51ms/step
Epoch 9/100
282/282 - 16s - loss: 0.2440 - acc: 0.9028 - auc-prc: 0.9627 - auc-roc: 0.9632 - val_loss: 0.2522 - val_acc: 0.9001 - val_auc-prc: 0.9607 - val_auc-roc: 0.9616 - 16s/epoch - 56ms/step
Epoch 10/100
282/282 - 16s - loss: 0.2424 - acc: 0.9026 - auc-prc: 0.9630 - auc-roc: 0.9637 - val_loss: 0.2550 - val_acc: 0.8981 - val_auc-prc: 0.9604 - val_auc-roc: 0.9605 - 16s/epoch - 56ms/step
Epoch 11/100
282/282 - 16s - loss: 0.2403 - acc: 0.9017 - auc-prc: 0.9636 - auc-roc: 0.9644 - val_loss: 0.2533 - val_acc: 0.8951 - val_auc-prc: 0.9598 - val_auc-roc: 0.9606 - 16s/epoch - 55ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2386 - acc: 0.9026 - auc-prc: 0.9647 - auc-roc: 0.9650 - val_loss: 0.2497 - val_acc: 0.8951 - val_auc-prc: 0.9625 - val_auc-roc: 0.9624 - 15s/epoch - 54ms/step
Epoch 13/100
282/282 - 14s - loss: 0.2337 - acc: 0.9059 - auc-prc: 0.9660 - auc-roc: 0.9666 - val_loss: 0.2521 - val_acc: 0.9001 - val_auc-prc: 0.9624 - val_auc-roc: 0.9632 - 14s/epoch - 51ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2329 - acc: 0.9065 - auc-prc: 0.9660 - auc-roc: 0.9666 - val_loss: 0.2674 - val_acc: 0.8861 - val_auc-prc: 0.9556 - val_auc-roc: 0.9566 - 15s/epoch - 52ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2327 - acc: 0.9040 - auc-prc: 0.9661 - auc-roc: 0.9667 - val_loss: 0.2667 - val_acc: 0.8871 - val_auc-prc: 0.9577 - val_auc-roc: 0.9581 - 15s/epoch - 54ms/step
Epoch 16/100
282/282 - 16s - loss: 0.2306 - acc: 0.9061 - auc-prc: 0.9672 - auc-roc: 0.9674 - val_loss: 0.2473 - val_acc: 0.9021 - val_auc-prc: 0.9629 - val_auc-roc: 0.9630 - 16s/epoch - 56ms/step
Epoch 17/100
282/282 - 16s - loss: 0.2289 - acc: 0.9074 - auc-prc: 0.9674 - auc-roc: 0.9678 - val_loss: 0.2448 - val_acc: 0.8961 - val_auc-prc: 0.9638 - val_auc-roc: 0.9635 - 16s/epoch - 55ms/step
Epoch 18/100
282/282 - 14s - loss: 0.2235 - acc: 0.9100 - auc-prc: 0.9685 - auc-roc: 0.9692 - val_loss: 0.2566 - val_acc: 0.8931 - val_auc-prc: 0.9623 - val_auc-roc: 0.9618 - 14s/epoch - 51ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2226 - acc: 0.9077 - auc-prc: 0.9693 - auc-roc: 0.9695 - val_loss: 0.2407 - val_acc: 0.9071 - val_auc-prc: 0.9639 - val_auc-roc: 0.9642 - 15s/epoch - 52ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2193 - acc: 0.9115 - auc-prc: 0.9703 - auc-roc: 0.9704 - val_loss: 0.2456 - val_acc: 0.9061 - val_auc-prc: 0.9629 - val_auc-roc: 0.9630 - 15s/epoch - 53ms/step
Epoch 21/100
282/282 - 16s - loss: 0.2156 - acc: 0.9124 - auc-prc: 0.9708 - auc-roc: 0.9712 - val_loss: 0.2508 - val_acc: 0.8961 - val_auc-prc: 0.9618 - val_auc-roc: 0.9625 - 16s/epoch - 55ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 762ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.88      0.88       391
           1       0.93      0.92      0.92       610

    accuracy                           0.91      1001
   macro avg       0.90      0.90      0.90      1001
weighted avg       0.91      0.91      0.91      1001

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.51      0.43       391
           1       0.59      0.46      0.52       610

    accuracy                           0.48      1001
   macro avg       0.49      0.49      0.48      1001
weighted avg       0.51      0.48      0.49      1001

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 18s - loss: 0.3153 - acc: 0.8654 - auc-prc: 0.9376 - auc-roc: 0.9392 - val_loss: 0.2616 - val_acc: 0.8961 - val_auc-prc: 0.9564 - val_auc-roc: 0.9573 - 18s/epoch - 64ms/step
Epoch 2/100
282/282 - 16s - loss: 0.2767 - acc: 0.8892 - auc-prc: 0.9511 - auc-roc: 0.9526 - val_loss: 0.2513 - val_acc: 0.8941 - val_auc-prc: 0.9614 - val_auc-roc: 0.9615 - 16s/epoch - 56ms/step
Epoch 3/100
282/282 - 16s - loss: 0.2655 - acc: 0.8948 - auc-prc: 0.9545 - auc-roc: 0.9561 - val_loss: 0.2450 - val_acc: 0.9071 - val_auc-prc: 0.9611 - val_auc-roc: 0.9619 - 16s/epoch - 56ms/step
Epoch 4/100
282/282 - 16s - loss: 0.2604 - acc: 0.8964 - auc-prc: 0.9563 - auc-roc: 0.9579 - val_loss: 0.2318 - val_acc: 0.9111 - val_auc-prc: 0.9660 - val_auc-roc: 0.9663 - 16s/epoch - 56ms/step
Epoch 5/100
282/282 - 16s - loss: 0.2575 - acc: 0.8971 - auc-prc: 0.9581 - auc-roc: 0.9589 - val_loss: 0.2364 - val_acc: 0.9061 - val_auc-prc: 0.9646 - val_auc-roc: 0.9650 - 16s/epoch - 56ms/step
Epoch 6/100
282/282 - 16s - loss: 0.2517 - acc: 0.8981 - auc-prc: 0.9597 - auc-roc: 0.9609 - val_loss: 0.2332 - val_acc: 0.9121 - val_auc-prc: 0.9640 - val_auc-roc: 0.9655 - 16s/epoch - 56ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2531 - acc: 0.8958 - auc-prc: 0.9600 - auc-roc: 0.9606 - val_loss: 0.2409 - val_acc: 0.9031 - val_auc-prc: 0.9660 - val_auc-roc: 0.9656 - 15s/epoch - 54ms/step
Epoch 8/100
282/282 - 16s - loss: 0.2506 - acc: 0.8986 - auc-prc: 0.9601 - auc-roc: 0.9612 - val_loss: 0.2368 - val_acc: 0.9051 - val_auc-prc: 0.9650 - val_auc-roc: 0.9653 - 16s/epoch - 55ms/step
Epoch 9/100
282/282 - 16s - loss: 0.2494 - acc: 0.8998 - auc-prc: 0.9608 - auc-roc: 0.9617 - val_loss: 0.2274 - val_acc: 0.9061 - val_auc-prc: 0.9675 - val_auc-roc: 0.9677 - 16s/epoch - 55ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2476 - acc: 0.9011 - auc-prc: 0.9619 - auc-roc: 0.9623 - val_loss: 0.2327 - val_acc: 0.9031 - val_auc-prc: 0.9673 - val_auc-roc: 0.9670 - 15s/epoch - 52ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2461 - acc: 0.8977 - auc-prc: 0.9621 - auc-roc: 0.9627 - val_loss: 0.2315 - val_acc: 0.9131 - val_auc-prc: 0.9671 - val_auc-roc: 0.9673 - 15s/epoch - 52ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2445 - acc: 0.8974 - auc-prc: 0.9628 - auc-roc: 0.9631 - val_loss: 0.2280 - val_acc: 0.9071 - val_auc-prc: 0.9679 - val_auc-roc: 0.9680 - 15s/epoch - 53ms/step
Epoch 13/100
282/282 - 15s - loss: 0.2431 - acc: 0.9014 - auc-prc: 0.9629 - auc-roc: 0.9636 - val_loss: 0.2315 - val_acc: 0.9111 - val_auc-prc: 0.9668 - val_auc-roc: 0.9668 - 15s/epoch - 53ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2393 - acc: 0.9031 - auc-prc: 0.9644 - auc-roc: 0.9649 - val_loss: 0.2282 - val_acc: 0.8971 - val_auc-prc: 0.9681 - val_auc-roc: 0.9679 - 15s/epoch - 53ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2377 - acc: 0.9044 - auc-prc: 0.9647 - auc-roc: 0.9653 - val_loss: 0.2282 - val_acc: 0.9041 - val_auc-prc: 0.9683 - val_auc-roc: 0.9682 - 15s/epoch - 53ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2360 - acc: 0.9050 - auc-prc: 0.9656 - auc-roc: 0.9659 - val_loss: 0.2281 - val_acc: 0.9031 - val_auc-prc: 0.9688 - val_auc-roc: 0.9686 - 15s/epoch - 52ms/step
Epoch 17/100
282/282 - 15s - loss: 0.2361 - acc: 0.9035 - auc-prc: 0.9650 - auc-roc: 0.9657 - val_loss: 0.2331 - val_acc: 0.9031 - val_auc-prc: 0.9672 - val_auc-roc: 0.9679 - 15s/epoch - 52ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2315 - acc: 0.9067 - auc-prc: 0.9667 - auc-roc: 0.9670 - val_loss: 0.2243 - val_acc: 0.9081 - val_auc-prc: 0.9700 - val_auc-roc: 0.9699 - 15s/epoch - 52ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2268 - acc: 0.9094 - auc-prc: 0.9679 - auc-roc: 0.9683 - val_loss: 0.2249 - val_acc: 0.9091 - val_auc-prc: 0.9691 - val_auc-roc: 0.9691 - 15s/epoch - 53ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2262 - acc: 0.9094 - auc-prc: 0.9685 - auc-roc: 0.9686 - val_loss: 0.2424 - val_acc: 0.9001 - val_auc-prc: 0.9666 - val_auc-roc: 0.9669 - 15s/epoch - 52ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2236 - acc: 0.9085 - auc-prc: 0.9689 - auc-roc: 0.9691 - val_loss: 0.2346 - val_acc: 0.9021 - val_auc-prc: 0.9662 - val_auc-roc: 0.9670 - 15s/epoch - 52ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 724ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.89      0.87      0.88       391
           1       0.92      0.93      0.93       610

    accuracy                           0.91      1001
   macro avg       0.91      0.90      0.90      1001
weighted avg       0.91      0.91      0.91      1001

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.50      0.44       391
           1       0.61      0.50      0.55       610

    accuracy                           0.50      1001
   macro avg       0.50      0.50      0.49      1001
weighted avg       0.52      0.50      0.50      1001

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 18s - loss: 0.3182 - acc: 0.8608 - auc-prc: 0.9367 - auc-roc: 0.9382 - val_loss: 0.2685 - val_acc: 0.8840 - val_auc-prc: 0.9540 - val_auc-roc: 0.9556 - 18s/epoch - 63ms/step
Epoch 2/100
282/282 - 16s - loss: 0.2837 - acc: 0.8876 - auc-prc: 0.9480 - auc-roc: 0.9504 - val_loss: 0.2511 - val_acc: 0.8980 - val_auc-prc: 0.9604 - val_auc-roc: 0.9613 - 16s/epoch - 56ms/step
Epoch 3/100
282/282 - 16s - loss: 0.2709 - acc: 0.8918 - auc-prc: 0.9531 - auc-roc: 0.9545 - val_loss: 0.2441 - val_acc: 0.9010 - val_auc-prc: 0.9619 - val_auc-roc: 0.9629 - 16s/epoch - 56ms/step
Epoch 4/100
282/282 - 15s - loss: 0.2627 - acc: 0.8938 - auc-prc: 0.9559 - auc-roc: 0.9573 - val_loss: 0.2412 - val_acc: 0.9130 - val_auc-prc: 0.9639 - val_auc-roc: 0.9650 - 15s/epoch - 55ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2580 - acc: 0.8973 - auc-prc: 0.9569 - auc-roc: 0.9586 - val_loss: 0.2364 - val_acc: 0.9050 - val_auc-prc: 0.9653 - val_auc-roc: 0.9660 - 15s/epoch - 52ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2549 - acc: 0.8967 - auc-prc: 0.9589 - auc-roc: 0.9599 - val_loss: 0.2438 - val_acc: 0.8950 - val_auc-prc: 0.9622 - val_auc-roc: 0.9632 - 15s/epoch - 53ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2541 - acc: 0.8981 - auc-prc: 0.9594 - auc-roc: 0.9602 - val_loss: 0.2295 - val_acc: 0.9170 - val_auc-prc: 0.9671 - val_auc-roc: 0.9678 - 15s/epoch - 53ms/step
Epoch 8/100
282/282 - 15s - loss: 0.2516 - acc: 0.8990 - auc-prc: 0.9600 - auc-roc: 0.9609 - val_loss: 0.2314 - val_acc: 0.9170 - val_auc-prc: 0.9679 - val_auc-roc: 0.9686 - 15s/epoch - 54ms/step
Epoch 9/100
282/282 - 15s - loss: 0.2498 - acc: 0.8995 - auc-prc: 0.9608 - auc-roc: 0.9617 - val_loss: 0.2235 - val_acc: 0.9220 - val_auc-prc: 0.9685 - val_auc-roc: 0.9693 - 15s/epoch - 54ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2494 - acc: 0.8998 - auc-prc: 0.9602 - auc-roc: 0.9615 - val_loss: 0.2370 - val_acc: 0.9000 - val_auc-prc: 0.9649 - val_auc-roc: 0.9660 - 15s/epoch - 52ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2435 - acc: 0.9006 - auc-prc: 0.9624 - auc-roc: 0.9634 - val_loss: 0.2306 - val_acc: 0.9050 - val_auc-prc: 0.9682 - val_auc-roc: 0.9680 - 15s/epoch - 52ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2416 - acc: 0.9019 - auc-prc: 0.9635 - auc-roc: 0.9640 - val_loss: 0.2424 - val_acc: 0.9020 - val_auc-prc: 0.9654 - val_auc-roc: 0.9653 - 15s/epoch - 53ms/step
Epoch 13/100
282/282 - 15s - loss: 0.2432 - acc: 0.9035 - auc-prc: 0.9630 - auc-roc: 0.9637 - val_loss: 0.2228 - val_acc: 0.9110 - val_auc-prc: 0.9691 - val_auc-roc: 0.9690 - 15s/epoch - 53ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2391 - acc: 0.9013 - auc-prc: 0.9647 - auc-roc: 0.9649 - val_loss: 0.2189 - val_acc: 0.9180 - val_auc-prc: 0.9696 - val_auc-roc: 0.9700 - 15s/epoch - 53ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2356 - acc: 0.9060 - auc-prc: 0.9651 - auc-roc: 0.9658 - val_loss: 0.2357 - val_acc: 0.8960 - val_auc-prc: 0.9669 - val_auc-roc: 0.9667 - 15s/epoch - 53ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2320 - acc: 0.9050 - auc-prc: 0.9665 - auc-roc: 0.9669 - val_loss: 0.2214 - val_acc: 0.9170 - val_auc-prc: 0.9701 - val_auc-roc: 0.9700 - 15s/epoch - 53ms/step
Epoch 17/100
282/282 - 15s - loss: 0.2301 - acc: 0.9056 - auc-prc: 0.9673 - auc-roc: 0.9676 - val_loss: 0.2185 - val_acc: 0.9170 - val_auc-prc: 0.9705 - val_auc-roc: 0.9704 - 15s/epoch - 53ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2310 - acc: 0.9045 - auc-prc: 0.9670 - auc-roc: 0.9671 - val_loss: 0.2249 - val_acc: 0.9200 - val_auc-prc: 0.9675 - val_auc-roc: 0.9678 - 15s/epoch - 54ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2289 - acc: 0.9073 - auc-prc: 0.9673 - auc-roc: 0.9678 - val_loss: 0.2173 - val_acc: 0.9180 - val_auc-prc: 0.9708 - val_auc-roc: 0.9705 - 15s/epoch - 53ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2201 - acc: 0.9107 - auc-prc: 0.9701 - auc-roc: 0.9703 - val_loss: 0.2242 - val_acc: 0.9110 - val_auc-prc: 0.9690 - val_auc-roc: 0.9691 - 15s/epoch - 53ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2180 - acc: 0.9139 - auc-prc: 0.9703 - auc-roc: 0.9707 - val_loss: 0.2215 - val_acc: 0.9090 - val_auc-prc: 0.9707 - val_auc-roc: 0.9702 - 15s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 713ms/epoch - 22ms/step
              precision    recall  f1-score   support

           0       0.89      0.90      0.90       390
           1       0.93      0.93      0.93       610

    accuracy                           0.92      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.92      0.92      0.92      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.45      0.41       390
           1       0.59      0.51      0.55       610

    accuracy                           0.49      1000
   macro avg       0.48      0.48      0.48      1000
weighted avg       0.51      0.49      0.49      1000

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 18s - loss: 0.3060 - acc: 0.8696 - auc-prc: 0.9407 - auc-roc: 0.9430 - val_loss: 0.2908 - val_acc: 0.8850 - val_auc-prc: 0.9460 - val_auc-roc: 0.9477 - 18s/epoch - 62ms/step
Epoch 2/100
282/282 - 15s - loss: 0.2721 - acc: 0.8909 - auc-prc: 0.9521 - auc-roc: 0.9541 - val_loss: 0.3069 - val_acc: 0.8740 - val_auc-prc: 0.9473 - val_auc-roc: 0.9471 - 15s/epoch - 53ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2617 - acc: 0.8967 - auc-prc: 0.9559 - auc-roc: 0.9574 - val_loss: 0.2785 - val_acc: 0.8920 - val_auc-prc: 0.9534 - val_auc-roc: 0.9542 - 15s/epoch - 53ms/step
Epoch 4/100
282/282 - 16s - loss: 0.2563 - acc: 0.8991 - auc-prc: 0.9578 - auc-roc: 0.9594 - val_loss: 0.2759 - val_acc: 0.8900 - val_auc-prc: 0.9531 - val_auc-roc: 0.9536 - 16s/epoch - 56ms/step
Epoch 5/100
282/282 - 16s - loss: 0.2524 - acc: 0.9009 - auc-prc: 0.9594 - auc-roc: 0.9603 - val_loss: 0.2752 - val_acc: 0.8850 - val_auc-prc: 0.9521 - val_auc-roc: 0.9537 - 16s/epoch - 56ms/step
Epoch 6/100
282/282 - 16s - loss: 0.2516 - acc: 0.8997 - auc-prc: 0.9595 - auc-roc: 0.9606 - val_loss: 0.2794 - val_acc: 0.8860 - val_auc-prc: 0.9526 - val_auc-roc: 0.9529 - 16s/epoch - 56ms/step
Epoch 7/100
282/282 - 16s - loss: 0.2473 - acc: 0.9015 - auc-prc: 0.9615 - auc-roc: 0.9622 - val_loss: 0.2769 - val_acc: 0.8880 - val_auc-prc: 0.9526 - val_auc-roc: 0.9536 - 16s/epoch - 55ms/step
Epoch 8/100
282/282 - 16s - loss: 0.2442 - acc: 0.9006 - auc-prc: 0.9624 - auc-roc: 0.9634 - val_loss: 0.2768 - val_acc: 0.8900 - val_auc-prc: 0.9531 - val_auc-roc: 0.9532 - 16s/epoch - 56ms/step
Epoch 9/100
282/282 - 16s - loss: 0.2451 - acc: 0.9045 - auc-prc: 0.9618 - auc-roc: 0.9627 - val_loss: 0.2690 - val_acc: 0.8840 - val_auc-prc: 0.9551 - val_auc-roc: 0.9565 - 16s/epoch - 56ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2434 - acc: 0.9031 - auc-prc: 0.9626 - auc-roc: 0.9635 - val_loss: 0.2754 - val_acc: 0.8900 - val_auc-prc: 0.9526 - val_auc-roc: 0.9531 - 15s/epoch - 54ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2396 - acc: 0.9024 - auc-prc: 0.9647 - auc-roc: 0.9648 - val_loss: 0.2631 - val_acc: 0.8900 - val_auc-prc: 0.9566 - val_auc-roc: 0.9578 - 15s/epoch - 53ms/step
Epoch 12/100
282/282 - 16s - loss: 0.2374 - acc: 0.9039 - auc-prc: 0.9644 - auc-roc: 0.9653 - val_loss: 0.2699 - val_acc: 0.8840 - val_auc-prc: 0.9538 - val_auc-roc: 0.9553 - 16s/epoch - 55ms/step
Epoch 13/100
282/282 - 15s - loss: 0.2354 - acc: 0.9048 - auc-prc: 0.9659 - auc-roc: 0.9660 - val_loss: 0.2679 - val_acc: 0.8870 - val_auc-prc: 0.9559 - val_auc-roc: 0.9568 - 15s/epoch - 53ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2311 - acc: 0.9050 - auc-prc: 0.9670 - auc-roc: 0.9674 - val_loss: 0.2820 - val_acc: 0.8890 - val_auc-prc: 0.9525 - val_auc-roc: 0.9539 - 15s/epoch - 52ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2300 - acc: 0.9051 - auc-prc: 0.9673 - auc-roc: 0.9674 - val_loss: 0.2676 - val_acc: 0.8880 - val_auc-prc: 0.9544 - val_auc-roc: 0.9562 - 15s/epoch - 53ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2300 - acc: 0.9063 - auc-prc: 0.9672 - auc-roc: 0.9676 - val_loss: 0.2645 - val_acc: 0.8880 - val_auc-prc: 0.9571 - val_auc-roc: 0.9587 - 15s/epoch - 54ms/step
Epoch 17/100
282/282 - 16s - loss: 0.2241 - acc: 0.9094 - auc-prc: 0.9691 - auc-roc: 0.9692 - val_loss: 0.2651 - val_acc: 0.8930 - val_auc-prc: 0.9555 - val_auc-roc: 0.9576 - 16s/epoch - 56ms/step
Epoch 18/100
282/282 - 16s - loss: 0.2197 - acc: 0.9105 - auc-prc: 0.9700 - auc-roc: 0.9703 - val_loss: 0.2924 - val_acc: 0.8860 - val_auc-prc: 0.9475 - val_auc-roc: 0.9494 - 16s/epoch - 56ms/step
Epoch 19/100
282/282 - 16s - loss: 0.2205 - acc: 0.9104 - auc-prc: 0.9697 - auc-roc: 0.9701 - val_loss: 0.2669 - val_acc: 0.8980 - val_auc-prc: 0.9568 - val_auc-roc: 0.9581 - 16s/epoch - 55ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2160 - acc: 0.9135 - auc-prc: 0.9714 - auc-roc: 0.9713 - val_loss: 0.2734 - val_acc: 0.8840 - val_auc-prc: 0.9520 - val_auc-roc: 0.9553 - 15s/epoch - 53ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2133 - acc: 0.9145 - auc-prc: 0.9712 - auc-roc: 0.9718 - val_loss: 0.2938 - val_acc: 0.8910 - val_auc-prc: 0.9474 - val_auc-roc: 0.9510 - 15s/epoch - 53ms/step
Epoch 22/100
282/282 - 15s - loss: 0.2108 - acc: 0.9147 - auc-prc: 0.9725 - auc-roc: 0.9727 - val_loss: 0.2746 - val_acc: 0.8860 - val_auc-prc: 0.9537 - val_auc-roc: 0.9561 - 15s/epoch - 53ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
32/32 - 1s - 720ms/epoch - 22ms/step
              precision    recall  f1-score   support

           0       0.89      0.82      0.85       390
           1       0.89      0.93      0.91       610

    accuracy                           0.89      1000
   macro avg       0.89      0.87      0.88      1000
weighted avg       0.89      0.89      0.89      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.52      0.45       390
           1       0.61      0.49      0.55       610

    accuracy                           0.50      1000
   macro avg       0.50      0.50      0.50      1000
weighted avg       0.53      0.50      0.51      1000

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 17s - loss: 0.3137 - acc: 0.8674 - auc-prc: 0.9383 - auc-roc: 0.9400 - val_loss: 0.2901 - val_acc: 0.8810 - val_auc-prc: 0.9468 - val_auc-roc: 0.9487 - 17s/epoch - 62ms/step
Epoch 2/100
282/282 - 16s - loss: 0.2809 - acc: 0.8861 - auc-prc: 0.9492 - auc-roc: 0.9510 - val_loss: 0.2757 - val_acc: 0.8890 - val_auc-prc: 0.9529 - val_auc-roc: 0.9543 - 16s/epoch - 56ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2683 - acc: 0.8946 - auc-prc: 0.9533 - auc-roc: 0.9550 - val_loss: 0.2564 - val_acc: 0.8990 - val_auc-prc: 0.9587 - val_auc-roc: 0.9598 - 15s/epoch - 54ms/step
Epoch 4/100
282/282 - 16s - loss: 0.2611 - acc: 0.8985 - auc-prc: 0.9562 - auc-roc: 0.9575 - val_loss: 0.2558 - val_acc: 0.9020 - val_auc-prc: 0.9602 - val_auc-roc: 0.9609 - 16s/epoch - 56ms/step
Epoch 5/100
282/282 - 16s - loss: 0.2592 - acc: 0.8955 - auc-prc: 0.9576 - auc-roc: 0.9584 - val_loss: 0.2593 - val_acc: 0.9030 - val_auc-prc: 0.9604 - val_auc-roc: 0.9609 - 16s/epoch - 55ms/step
Epoch 6/100
282/282 - 16s - loss: 0.2532 - acc: 0.9001 - auc-prc: 0.9591 - auc-roc: 0.9602 - val_loss: 0.2491 - val_acc: 0.9000 - val_auc-prc: 0.9616 - val_auc-roc: 0.9626 - 16s/epoch - 55ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2505 - acc: 0.8997 - auc-prc: 0.9604 - auc-roc: 0.9612 - val_loss: 0.2487 - val_acc: 0.9050 - val_auc-prc: 0.9611 - val_auc-roc: 0.9622 - 15s/epoch - 53ms/step
Epoch 8/100
282/282 - 16s - loss: 0.2485 - acc: 0.8988 - auc-prc: 0.9604 - auc-roc: 0.9616 - val_loss: 0.2531 - val_acc: 0.8980 - val_auc-prc: 0.9609 - val_auc-roc: 0.9616 - 16s/epoch - 55ms/step
Epoch 9/100
282/282 - 16s - loss: 0.2487 - acc: 0.9011 - auc-prc: 0.9608 - auc-roc: 0.9616 - val_loss: 0.2503 - val_acc: 0.8970 - val_auc-prc: 0.9627 - val_auc-roc: 0.9628 - 16s/epoch - 56ms/step
Epoch 10/100
282/282 - 16s - loss: 0.2426 - acc: 0.9024 - auc-prc: 0.9633 - auc-roc: 0.9636 - val_loss: 0.2468 - val_acc: 0.8970 - val_auc-prc: 0.9634 - val_auc-roc: 0.9633 - 16s/epoch - 56ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2426 - acc: 0.9014 - auc-prc: 0.9632 - auc-roc: 0.9637 - val_loss: 0.2499 - val_acc: 0.8990 - val_auc-prc: 0.9628 - val_auc-roc: 0.9626 - 15s/epoch - 54ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2412 - acc: 0.9038 - auc-prc: 0.9639 - auc-roc: 0.9644 - val_loss: 0.2644 - val_acc: 0.8990 - val_auc-prc: 0.9596 - val_auc-roc: 0.9594 - 15s/epoch - 53ms/step
Epoch 13/100
282/282 - 15s - loss: 0.2346 - acc: 0.9049 - auc-prc: 0.9652 - auc-roc: 0.9658 - val_loss: 0.2606 - val_acc: 0.8890 - val_auc-prc: 0.9596 - val_auc-roc: 0.9598 - 15s/epoch - 53ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2333 - acc: 0.9068 - auc-prc: 0.9666 - auc-roc: 0.9666 - val_loss: 0.2581 - val_acc: 0.8920 - val_auc-prc: 0.9600 - val_auc-roc: 0.9598 - 15s/epoch - 53ms/step
Epoch 15/100
282/282 - 16s - loss: 0.2321 - acc: 0.9065 - auc-prc: 0.9663 - auc-roc: 0.9669 - val_loss: 0.2577 - val_acc: 0.8890 - val_auc-prc: 0.9590 - val_auc-roc: 0.9595 - 16s/epoch - 55ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2299 - acc: 0.9055 - auc-prc: 0.9675 - auc-roc: 0.9676 - val_loss: 0.2503 - val_acc: 0.9040 - val_auc-prc: 0.9581 - val_auc-roc: 0.9613 - 15s/epoch - 55ms/step
Epoch 17/100
282/282 - 15s - loss: 0.2267 - acc: 0.9090 - auc-prc: 0.9686 - auc-roc: 0.9686 - val_loss: 0.2488 - val_acc: 0.8950 - val_auc-prc: 0.9615 - val_auc-roc: 0.9621 - 15s/epoch - 55ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2240 - acc: 0.9078 - auc-prc: 0.9689 - auc-roc: 0.9692 - val_loss: 0.2466 - val_acc: 0.9000 - val_auc-prc: 0.9630 - val_auc-roc: 0.9636 - 15s/epoch - 53ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2215 - acc: 0.9081 - auc-prc: 0.9696 - auc-roc: 0.9700 - val_loss: 0.2450 - val_acc: 0.9030 - val_auc-prc: 0.9626 - val_auc-roc: 0.9637 - 15s/epoch - 55ms/step
Epoch 20/100
282/282 - 16s - loss: 0.2193 - acc: 0.9111 - auc-prc: 0.9695 - auc-roc: 0.9703 - val_loss: 0.2520 - val_acc: 0.9000 - val_auc-prc: 0.9582 - val_auc-roc: 0.9612 - 16s/epoch - 56ms/step
Epoch 21/100
282/282 - 16s - loss: 0.2152 - acc: 0.9128 - auc-prc: 0.9711 - auc-roc: 0.9714 - val_loss: 0.2504 - val_acc: 0.9000 - val_auc-prc: 0.9585 - val_auc-roc: 0.9614 - 16s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 766ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.89      0.86      0.87       390
           1       0.91      0.93      0.92       610

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.50      0.43       390
           1       0.60      0.48      0.53       610

    accuracy                           0.49      1000
   macro avg       0.49      0.49      0.48      1000
weighted avg       0.52      0.49      0.49      1000

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 17s - loss: 0.3098 - acc: 0.8663 - auc-prc: 0.9402 - auc-roc: 0.9413 - val_loss: 0.2975 - val_acc: 0.8820 - val_auc-prc: 0.9436 - val_auc-roc: 0.9465 - 17s/epoch - 62ms/step
Epoch 2/100
282/282 - 16s - loss: 0.2760 - acc: 0.8855 - auc-prc: 0.9517 - auc-roc: 0.9530 - val_loss: 0.2928 - val_acc: 0.8790 - val_auc-prc: 0.9458 - val_auc-roc: 0.9493 - 16s/epoch - 55ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2650 - acc: 0.8906 - auc-prc: 0.9550 - auc-roc: 0.9564 - val_loss: 0.2761 - val_acc: 0.8850 - val_auc-prc: 0.9508 - val_auc-roc: 0.9530 - 15s/epoch - 53ms/step
Epoch 4/100
282/282 - 15s - loss: 0.2568 - acc: 0.8975 - auc-prc: 0.9571 - auc-roc: 0.9589 - val_loss: 0.2740 - val_acc: 0.8830 - val_auc-prc: 0.9512 - val_auc-roc: 0.9542 - 15s/epoch - 52ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2553 - acc: 0.8984 - auc-prc: 0.9586 - auc-roc: 0.9596 - val_loss: 0.2865 - val_acc: 0.8820 - val_auc-prc: 0.9503 - val_auc-roc: 0.9522 - 15s/epoch - 53ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2527 - acc: 0.9008 - auc-prc: 0.9592 - auc-roc: 0.9603 - val_loss: 0.2749 - val_acc: 0.8910 - val_auc-prc: 0.9536 - val_auc-roc: 0.9555 - 15s/epoch - 54ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2478 - acc: 0.9010 - auc-prc: 0.9610 - auc-roc: 0.9620 - val_loss: 0.2730 - val_acc: 0.8830 - val_auc-prc: 0.9543 - val_auc-roc: 0.9551 - 15s/epoch - 53ms/step
Epoch 8/100
282/282 - 15s - loss: 0.2461 - acc: 0.9019 - auc-prc: 0.9618 - auc-roc: 0.9626 - val_loss: 0.2803 - val_acc: 0.8820 - val_auc-prc: 0.9548 - val_auc-roc: 0.9562 - 15s/epoch - 54ms/step
Epoch 9/100
282/282 - 15s - loss: 0.2436 - acc: 0.9013 - auc-prc: 0.9629 - auc-roc: 0.9634 - val_loss: 0.2662 - val_acc: 0.8910 - val_auc-prc: 0.9558 - val_auc-roc: 0.9572 - 15s/epoch - 53ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2390 - acc: 0.9056 - auc-prc: 0.9640 - auc-roc: 0.9647 - val_loss: 0.2768 - val_acc: 0.8860 - val_auc-prc: 0.9531 - val_auc-roc: 0.9538 - 15s/epoch - 53ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2379 - acc: 0.9046 - auc-prc: 0.9650 - auc-roc: 0.9653 - val_loss: 0.2741 - val_acc: 0.8890 - val_auc-prc: 0.9544 - val_auc-roc: 0.9552 - 15s/epoch - 54ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2371 - acc: 0.9044 - auc-prc: 0.9647 - auc-roc: 0.9653 - val_loss: 0.2680 - val_acc: 0.8890 - val_auc-prc: 0.9575 - val_auc-roc: 0.9575 - 15s/epoch - 54ms/step
Epoch 13/100
282/282 - 15s - loss: 0.2351 - acc: 0.9048 - auc-prc: 0.9655 - auc-roc: 0.9660 - val_loss: 0.2657 - val_acc: 0.8830 - val_auc-prc: 0.9567 - val_auc-roc: 0.9580 - 15s/epoch - 53ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2329 - acc: 0.9056 - auc-prc: 0.9663 - auc-roc: 0.9665 - val_loss: 0.2623 - val_acc: 0.8950 - val_auc-prc: 0.9569 - val_auc-roc: 0.9576 - 15s/epoch - 54ms/step
Epoch 15/100
282/282 - 16s - loss: 0.2286 - acc: 0.9087 - auc-prc: 0.9672 - auc-roc: 0.9678 - val_loss: 0.2679 - val_acc: 0.8930 - val_auc-prc: 0.9561 - val_auc-roc: 0.9570 - 16s/epoch - 55ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2279 - acc: 0.9081 - auc-prc: 0.9679 - auc-roc: 0.9680 - val_loss: 0.2838 - val_acc: 0.8890 - val_auc-prc: 0.9554 - val_auc-roc: 0.9552 - 15s/epoch - 54ms/step
Epoch 17/100
282/282 - 14s - loss: 0.2270 - acc: 0.9103 - auc-prc: 0.9684 - auc-roc: 0.9683 - val_loss: 0.2657 - val_acc: 0.8910 - val_auc-prc: 0.9562 - val_auc-roc: 0.9582 - 14s/epoch - 51ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2242 - acc: 0.9090 - auc-prc: 0.9687 - auc-roc: 0.9690 - val_loss: 0.2659 - val_acc: 0.8940 - val_auc-prc: 0.9581 - val_auc-roc: 0.9593 - 15s/epoch - 53ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2199 - acc: 0.9083 - auc-prc: 0.9703 - auc-roc: 0.9703 - val_loss: 0.2599 - val_acc: 0.8890 - val_auc-prc: 0.9591 - val_auc-roc: 0.9599 - 15s/epoch - 53ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2126 - acc: 0.9144 - auc-prc: 0.9720 - auc-roc: 0.9720 - val_loss: 0.2748 - val_acc: 0.8920 - val_auc-prc: 0.9561 - val_auc-roc: 0.9577 - 15s/epoch - 53ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2137 - acc: 0.9159 - auc-prc: 0.9713 - auc-roc: 0.9716 - val_loss: 0.2720 - val_acc: 0.8850 - val_auc-prc: 0.9570 - val_auc-roc: 0.9569 - 15s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 728ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.87      0.84      0.86       390
           1       0.90      0.92      0.91       610

    accuracy                           0.89      1000
   macro avg       0.89      0.88      0.88      1000
weighted avg       0.89      0.89      0.89      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.50      0.44       390
           1       0.61      0.49      0.54       610

    accuracy                           0.49      1000
   macro avg       0.50      0.50      0.49      1000
weighted avg       0.52      0.49      0.50      1000

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 18s - loss: 0.3108 - acc: 0.8673 - auc-prc: 0.9397 - auc-roc: 0.9409 - val_loss: 0.2810 - val_acc: 0.8880 - val_auc-prc: 0.9513 - val_auc-roc: 0.9532 - 18s/epoch - 63ms/step
Epoch 2/100
282/282 - 15s - loss: 0.2750 - acc: 0.8879 - auc-prc: 0.9515 - auc-roc: 0.9530 - val_loss: 0.2571 - val_acc: 0.8990 - val_auc-prc: 0.9578 - val_auc-roc: 0.9590 - 15s/epoch - 54ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2628 - acc: 0.8927 - auc-prc: 0.9556 - auc-roc: 0.9571 - val_loss: 0.2421 - val_acc: 0.9040 - val_auc-prc: 0.9626 - val_auc-roc: 0.9631 - 15s/epoch - 54ms/step
Epoch 4/100
282/282 - 15s - loss: 0.2590 - acc: 0.8951 - auc-prc: 0.9578 - auc-roc: 0.9585 - val_loss: 0.2443 - val_acc: 0.9080 - val_auc-prc: 0.9631 - val_auc-roc: 0.9635 - 15s/epoch - 54ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2588 - acc: 0.8980 - auc-prc: 0.9570 - auc-roc: 0.9584 - val_loss: 0.2473 - val_acc: 0.9000 - val_auc-prc: 0.9621 - val_auc-roc: 0.9621 - 15s/epoch - 54ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2557 - acc: 0.8977 - auc-prc: 0.9586 - auc-roc: 0.9596 - val_loss: 0.2406 - val_acc: 0.9060 - val_auc-prc: 0.9642 - val_auc-roc: 0.9643 - 15s/epoch - 53ms/step
Epoch 7/100
282/282 - 16s - loss: 0.2543 - acc: 0.8979 - auc-prc: 0.9595 - auc-roc: 0.9602 - val_loss: 0.2377 - val_acc: 0.9060 - val_auc-prc: 0.9648 - val_auc-roc: 0.9649 - 16s/epoch - 56ms/step
Epoch 8/100
282/282 - 16s - loss: 0.2495 - acc: 0.8963 - auc-prc: 0.9608 - auc-roc: 0.9617 - val_loss: 0.2361 - val_acc: 0.9060 - val_auc-prc: 0.9648 - val_auc-roc: 0.9651 - 16s/epoch - 56ms/step
Epoch 9/100
282/282 - 15s - loss: 0.2484 - acc: 0.8983 - auc-prc: 0.9616 - auc-roc: 0.9621 - val_loss: 0.2523 - val_acc: 0.8990 - val_auc-prc: 0.9622 - val_auc-roc: 0.9618 - 15s/epoch - 53ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2477 - acc: 0.9005 - auc-prc: 0.9617 - auc-roc: 0.9621 - val_loss: 0.2315 - val_acc: 0.9100 - val_auc-prc: 0.9660 - val_auc-roc: 0.9664 - 15s/epoch - 53ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2436 - acc: 0.9024 - auc-prc: 0.9629 - auc-roc: 0.9635 - val_loss: 0.2421 - val_acc: 0.9090 - val_auc-prc: 0.9639 - val_auc-roc: 0.9641 - 15s/epoch - 53ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2434 - acc: 0.9023 - auc-prc: 0.9628 - auc-roc: 0.9634 - val_loss: 0.2319 - val_acc: 0.9120 - val_auc-prc: 0.9671 - val_auc-roc: 0.9672 - 15s/epoch - 53ms/step
Epoch 13/100
282/282 - 16s - loss: 0.2382 - acc: 0.9026 - auc-prc: 0.9646 - auc-roc: 0.9651 - val_loss: 0.2506 - val_acc: 0.8990 - val_auc-prc: 0.9608 - val_auc-roc: 0.9614 - 16s/epoch - 56ms/step
Epoch 14/100
282/282 - 16s - loss: 0.2388 - acc: 0.9008 - auc-prc: 0.9646 - auc-roc: 0.9649 - val_loss: 0.2354 - val_acc: 0.9080 - val_auc-prc: 0.9655 - val_auc-roc: 0.9659 - 16s/epoch - 55ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2335 - acc: 0.9054 - auc-prc: 0.9663 - auc-roc: 0.9665 - val_loss: 0.2362 - val_acc: 0.9070 - val_auc-prc: 0.9651 - val_auc-roc: 0.9653 - 15s/epoch - 54ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2318 - acc: 0.9066 - auc-prc: 0.9671 - auc-roc: 0.9671 - val_loss: 0.2453 - val_acc: 0.9060 - val_auc-prc: 0.9602 - val_auc-roc: 0.9630 - 15s/epoch - 54ms/step
Epoch 17/100
282/282 - 16s - loss: 0.2308 - acc: 0.9081 - auc-prc: 0.9668 - auc-roc: 0.9671 - val_loss: 0.2385 - val_acc: 0.9060 - val_auc-prc: 0.9644 - val_auc-roc: 0.9644 - 16s/epoch - 56ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2278 - acc: 0.9067 - auc-prc: 0.9681 - auc-roc: 0.9682 - val_loss: 0.2423 - val_acc: 0.9120 - val_auc-prc: 0.9635 - val_auc-roc: 0.9637 - 15s/epoch - 53ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2247 - acc: 0.9095 - auc-prc: 0.9685 - auc-roc: 0.9689 - val_loss: 0.2512 - val_acc: 0.9050 - val_auc-prc: 0.9602 - val_auc-roc: 0.9614 - 15s/epoch - 54ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2203 - acc: 0.9138 - auc-prc: 0.9701 - auc-roc: 0.9701 - val_loss: 0.2406 - val_acc: 0.9090 - val_auc-prc: 0.9637 - val_auc-roc: 0.9652 - 15s/epoch - 54ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2197 - acc: 0.9118 - auc-prc: 0.9696 - auc-roc: 0.9701 - val_loss: 0.2442 - val_acc: 0.9100 - val_auc-prc: 0.9630 - val_auc-roc: 0.9631 - 15s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 716ms/epoch - 22ms/step
              precision    recall  f1-score   support

           0       0.91      0.86      0.88       390
           1       0.92      0.94      0.93       610

    accuracy                           0.91      1000
   macro avg       0.91      0.90      0.91      1000
weighted avg       0.91      0.91      0.91      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.48      0.42       390
           1       0.60      0.50      0.54       610

    accuracy                           0.49      1000
   macro avg       0.49      0.49      0.48      1000
weighted avg       0.51      0.49      0.50      1000

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 17s - loss: 0.3132 - acc: 0.8678 - auc-prc: 0.9383 - auc-roc: 0.9402 - val_loss: 0.3109 - val_acc: 0.8710 - val_auc-prc: 0.9432 - val_auc-roc: 0.9440 - 17s/epoch - 62ms/step
Epoch 2/100
282/282 - 15s - loss: 0.2761 - acc: 0.8900 - auc-prc: 0.9506 - auc-roc: 0.9526 - val_loss: 0.2740 - val_acc: 0.8900 - val_auc-prc: 0.9527 - val_auc-roc: 0.9537 - 15s/epoch - 53ms/step
Epoch 3/100
282/282 - 15s - loss: 0.2664 - acc: 0.8934 - auc-prc: 0.9543 - auc-roc: 0.9560 - val_loss: 0.2710 - val_acc: 0.8930 - val_auc-prc: 0.9538 - val_auc-roc: 0.9547 - 15s/epoch - 53ms/step
Epoch 4/100
282/282 - 16s - loss: 0.2570 - acc: 0.8977 - auc-prc: 0.9570 - auc-roc: 0.9588 - val_loss: 0.2697 - val_acc: 0.8910 - val_auc-prc: 0.9541 - val_auc-roc: 0.9557 - 16s/epoch - 55ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2576 - acc: 0.8957 - auc-prc: 0.9583 - auc-roc: 0.9592 - val_loss: 0.2791 - val_acc: 0.8930 - val_auc-prc: 0.9547 - val_auc-roc: 0.9559 - 15s/epoch - 53ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2526 - acc: 0.8999 - auc-prc: 0.9583 - auc-roc: 0.9604 - val_loss: 0.2598 - val_acc: 0.8960 - val_auc-prc: 0.9580 - val_auc-roc: 0.9585 - 15s/epoch - 53ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2478 - acc: 0.9003 - auc-prc: 0.9615 - auc-roc: 0.9621 - val_loss: 0.2631 - val_acc: 0.8990 - val_auc-prc: 0.9570 - val_auc-roc: 0.9575 - 15s/epoch - 53ms/step
Epoch 8/100
282/282 - 15s - loss: 0.2487 - acc: 0.9017 - auc-prc: 0.9609 - auc-roc: 0.9616 - val_loss: 0.2574 - val_acc: 0.8990 - val_auc-prc: 0.9588 - val_auc-roc: 0.9591 - 15s/epoch - 53ms/step
Epoch 9/100
282/282 - 14s - loss: 0.2452 - acc: 0.8990 - auc-prc: 0.9626 - auc-roc: 0.9630 - val_loss: 0.2613 - val_acc: 0.8960 - val_auc-prc: 0.9568 - val_auc-roc: 0.9574 - 14s/epoch - 51ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2410 - acc: 0.9030 - auc-prc: 0.9643 - auc-roc: 0.9644 - val_loss: 0.2750 - val_acc: 0.8960 - val_auc-prc: 0.9550 - val_auc-roc: 0.9555 - 15s/epoch - 52ms/step
Epoch 11/100
282/282 - 15s - loss: 0.2399 - acc: 0.9039 - auc-prc: 0.9646 - auc-roc: 0.9647 - val_loss: 0.2606 - val_acc: 0.9000 - val_auc-prc: 0.9571 - val_auc-roc: 0.9581 - 15s/epoch - 53ms/step
Epoch 12/100
282/282 - 15s - loss: 0.2393 - acc: 0.9036 - auc-prc: 0.9643 - auc-roc: 0.9647 - val_loss: 0.2644 - val_acc: 0.8970 - val_auc-prc: 0.9576 - val_auc-roc: 0.9580 - 15s/epoch - 53ms/step
Epoch 13/100
282/282 - 16s - loss: 0.2358 - acc: 0.9043 - auc-prc: 0.9652 - auc-roc: 0.9659 - val_loss: 0.2649 - val_acc: 0.8900 - val_auc-prc: 0.9593 - val_auc-roc: 0.9592 - 16s/epoch - 56ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2339 - acc: 0.9073 - auc-prc: 0.9658 - auc-roc: 0.9662 - val_loss: 0.2809 - val_acc: 0.8950 - val_auc-prc: 0.9531 - val_auc-roc: 0.9556 - 15s/epoch - 55ms/step
Epoch 15/100
282/282 - 15s - loss: 0.2331 - acc: 0.9060 - auc-prc: 0.9656 - auc-roc: 0.9665 - val_loss: 0.2585 - val_acc: 0.8930 - val_auc-prc: 0.9579 - val_auc-roc: 0.9589 - 15s/epoch - 55ms/step
Epoch 16/100
282/282 - 16s - loss: 0.2280 - acc: 0.9077 - auc-prc: 0.9676 - auc-roc: 0.9682 - val_loss: 0.2571 - val_acc: 0.8920 - val_auc-prc: 0.9587 - val_auc-roc: 0.9592 - 16s/epoch - 56ms/step
Epoch 17/100
282/282 - 15s - loss: 0.2295 - acc: 0.9076 - auc-prc: 0.9673 - auc-roc: 0.9675 - val_loss: 0.2689 - val_acc: 0.8940 - val_auc-prc: 0.9560 - val_auc-roc: 0.9565 - 15s/epoch - 53ms/step
Epoch 18/100
282/282 - 15s - loss: 0.2254 - acc: 0.9099 - auc-prc: 0.9678 - auc-roc: 0.9686 - val_loss: 0.2628 - val_acc: 0.8910 - val_auc-prc: 0.9566 - val_auc-roc: 0.9573 - 15s/epoch - 52ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2218 - acc: 0.9104 - auc-prc: 0.9691 - auc-roc: 0.9697 - val_loss: 0.2552 - val_acc: 0.9000 - val_auc-prc: 0.9589 - val_auc-roc: 0.9594 - 15s/epoch - 53ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2187 - acc: 0.9120 - auc-prc: 0.9703 - auc-roc: 0.9707 - val_loss: 0.2530 - val_acc: 0.9010 - val_auc-prc: 0.9607 - val_auc-roc: 0.9608 - 15s/epoch - 53ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2170 - acc: 0.9130 - auc-prc: 0.9706 - auc-roc: 0.9709 - val_loss: 0.2668 - val_acc: 0.8940 - val_auc-prc: 0.9552 - val_auc-roc: 0.9560 - 15s/epoch - 52ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 765ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.92      0.82      0.87       390
           1       0.89      0.96      0.92       610

    accuracy                           0.90      1000
   macro avg       0.91      0.89      0.89      1000
weighted avg       0.90      0.90      0.90      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.47      0.41       390
           1       0.59      0.48      0.53       610

    accuracy                           0.48      1000
   macro avg       0.48      0.48      0.47      1000
weighted avg       0.50      0.48      0.48      1000

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
282/282 - 18s - loss: 0.3129 - acc: 0.8667 - auc-prc: 0.9391 - auc-roc: 0.9401 - val_loss: 0.3032 - val_acc: 0.8710 - val_auc-prc: 0.9418 - val_auc-roc: 0.9437 - 18s/epoch - 63ms/step
Epoch 2/100
282/282 - 16s - loss: 0.2786 - acc: 0.8870 - auc-prc: 0.9504 - auc-roc: 0.9522 - val_loss: 0.2787 - val_acc: 0.8930 - val_auc-prc: 0.9486 - val_auc-roc: 0.9514 - 16s/epoch - 56ms/step
Epoch 3/100
282/282 - 16s - loss: 0.2643 - acc: 0.8961 - auc-prc: 0.9549 - auc-roc: 0.9566 - val_loss: 0.2744 - val_acc: 0.8840 - val_auc-prc: 0.9526 - val_auc-roc: 0.9536 - 16s/epoch - 55ms/step
Epoch 4/100
282/282 - 15s - loss: 0.2582 - acc: 0.8996 - auc-prc: 0.9571 - auc-roc: 0.9585 - val_loss: 0.2920 - val_acc: 0.8760 - val_auc-prc: 0.9488 - val_auc-roc: 0.9496 - 15s/epoch - 53ms/step
Epoch 5/100
282/282 - 15s - loss: 0.2552 - acc: 0.8994 - auc-prc: 0.9590 - auc-roc: 0.9597 - val_loss: 0.2661 - val_acc: 0.8890 - val_auc-prc: 0.9573 - val_auc-roc: 0.9582 - 15s/epoch - 51ms/step
Epoch 6/100
282/282 - 15s - loss: 0.2549 - acc: 0.9009 - auc-prc: 0.9584 - auc-roc: 0.9595 - val_loss: 0.2673 - val_acc: 0.8850 - val_auc-prc: 0.9565 - val_auc-roc: 0.9574 - 15s/epoch - 53ms/step
Epoch 7/100
282/282 - 15s - loss: 0.2499 - acc: 0.9003 - auc-prc: 0.9602 - auc-roc: 0.9610 - val_loss: 0.2667 - val_acc: 0.8830 - val_auc-prc: 0.9569 - val_auc-roc: 0.9576 - 15s/epoch - 53ms/step
Epoch 8/100
282/282 - 15s - loss: 0.2485 - acc: 0.9008 - auc-prc: 0.9608 - auc-roc: 0.9618 - val_loss: 0.2783 - val_acc: 0.8750 - val_auc-prc: 0.9535 - val_auc-roc: 0.9533 - 15s/epoch - 52ms/step
Epoch 9/100
282/282 - 15s - loss: 0.2477 - acc: 0.9028 - auc-prc: 0.9613 - auc-roc: 0.9620 - val_loss: 0.2676 - val_acc: 0.8820 - val_auc-prc: 0.9555 - val_auc-roc: 0.9561 - 15s/epoch - 53ms/step
Epoch 10/100
282/282 - 15s - loss: 0.2453 - acc: 0.9005 - auc-prc: 0.9625 - auc-roc: 0.9628 - val_loss: 0.2865 - val_acc: 0.8800 - val_auc-prc: 0.9515 - val_auc-roc: 0.9518 - 15s/epoch - 53ms/step
Epoch 11/100
282/282 - 18s - loss: 0.2421 - acc: 0.9044 - auc-prc: 0.9630 - auc-roc: 0.9637 - val_loss: 0.2744 - val_acc: 0.8780 - val_auc-prc: 0.9536 - val_auc-roc: 0.9540 - 18s/epoch - 62ms/step
Epoch 12/100
282/282 - 16s - loss: 0.2396 - acc: 0.9050 - auc-prc: 0.9644 - auc-roc: 0.9647 - val_loss: 0.2795 - val_acc: 0.8880 - val_auc-prc: 0.9572 - val_auc-roc: 0.9576 - 16s/epoch - 55ms/step
Epoch 13/100
282/282 - 15s - loss: 0.2384 - acc: 0.9039 - auc-prc: 0.9642 - auc-roc: 0.9649 - val_loss: 0.2646 - val_acc: 0.8830 - val_auc-prc: 0.9575 - val_auc-roc: 0.9582 - 15s/epoch - 54ms/step
Epoch 14/100
282/282 - 15s - loss: 0.2350 - acc: 0.9075 - auc-prc: 0.9655 - auc-roc: 0.9660 - val_loss: 0.2715 - val_acc: 0.8780 - val_auc-prc: 0.9552 - val_auc-roc: 0.9566 - 15s/epoch - 52ms/step
Epoch 15/100
282/282 - 16s - loss: 0.2318 - acc: 0.9071 - auc-prc: 0.9662 - auc-roc: 0.9668 - val_loss: 0.2739 - val_acc: 0.8820 - val_auc-prc: 0.9563 - val_auc-roc: 0.9570 - 16s/epoch - 56ms/step
Epoch 16/100
282/282 - 15s - loss: 0.2289 - acc: 0.9068 - auc-prc: 0.9675 - auc-roc: 0.9677 - val_loss: 0.2650 - val_acc: 0.8800 - val_auc-prc: 0.9581 - val_auc-roc: 0.9580 - 15s/epoch - 53ms/step
Epoch 17/100
282/282 - 15s - loss: 0.2264 - acc: 0.9070 - auc-prc: 0.9677 - auc-roc: 0.9684 - val_loss: 0.2758 - val_acc: 0.8810 - val_auc-prc: 0.9579 - val_auc-roc: 0.9571 - 15s/epoch - 52ms/step
Epoch 18/100
282/282 - 14s - loss: 0.2267 - acc: 0.9068 - auc-prc: 0.9675 - auc-roc: 0.9683 - val_loss: 0.2767 - val_acc: 0.8780 - val_auc-prc: 0.9551 - val_auc-roc: 0.9558 - 14s/epoch - 51ms/step
Epoch 19/100
282/282 - 15s - loss: 0.2222 - acc: 0.9090 - auc-prc: 0.9696 - auc-roc: 0.9696 - val_loss: 0.2786 - val_acc: 0.8840 - val_auc-prc: 0.9557 - val_auc-roc: 0.9566 - 15s/epoch - 51ms/step
Epoch 20/100
282/282 - 15s - loss: 0.2212 - acc: 0.9105 - auc-prc: 0.9693 - auc-roc: 0.9698 - val_loss: 0.2750 - val_acc: 0.8830 - val_auc-prc: 0.9551 - val_auc-roc: 0.9556 - 15s/epoch - 53ms/step
Epoch 21/100
282/282 - 15s - loss: 0.2170 - acc: 0.9115 - auc-prc: 0.9709 - auc-roc: 0.9710 - val_loss: 0.3148 - val_acc: 0.8720 - val_auc-prc: 0.9447 - val_auc-roc: 0.9438 - 15s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
32/32 - 1s - 796ms/epoch - 25ms/step
              precision    recall  f1-score   support

           0       0.86      0.84      0.85       391
           1       0.90      0.91      0.90       609

    accuracy                           0.88      1000
   macro avg       0.88      0.87      0.88      1000
weighted avg       0.88      0.88      0.88      1000

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.49      0.43       391
           1       0.60      0.50      0.55       609

    accuracy                           0.49      1000
   macro avg       0.49      0.49      0.49      1000
weighted avg       0.52      0.49      0.50      1000

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8947] IC [0.8860, 0.9035]
Mean Accuracy[0.9031] IC [0.8955, 0.9107]
Mean Recall[0.8947] IC [0.8860, 0.9035]
Mean F1[0.8974] IC [0.8893, 0.9056]
Median AUC_ROC[0.8983]
Median Accuracy[0.9050]
Median Recall[0.8983]
Median F1[0.9000]
********************txid272634********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.88      0.56      0.69       126
           1       0.81      0.96      0.88       246

    accuracy                           0.83       372
   macro avg       0.84      0.76      0.78       372
weighted avg       0.83      0.83      0.81       372

Predicted  0.0  1.0  All
True                    
0           71   55  126
1           10  236  246
All         81  291  372
**************************************************
