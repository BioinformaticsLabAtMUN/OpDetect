Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid224308********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.88      0.80      0.84       208
           1       0.94      0.97      0.95       644

    accuracy                           0.92       852
   macro avg       0.91      0.88      0.89       852
weighted avg       0.92      0.92      0.92       852

Predicted  0.0  1.0  All
True                    
0          166   42  208
1           22  622  644
All        188  664  852
Total F1 score and recall
F1 score: 0.9510703363914373
Recall: 0.9658385093167702
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid196627********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.95      0.84      0.89      1182
           1       0.84      0.95      0.89      1077

    accuracy                           0.89      2259
   macro avg       0.90      0.90      0.89      2259
weighted avg       0.90      0.89      0.89      2259

Predicted   0.0   1.0   All
True                       
0           990   192  1182
1            51  1026  1077
All        1041  1218  2259
Total F1 score and recall
F1 score: 0.8941176470588236
Recall: 0.9526462395543176
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid511145********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.93      0.92      0.92      2098
           1       0.90      0.91      0.91      1726

    accuracy                           0.91      3824
   macro avg       0.91      0.91      0.91      3824
weighted avg       0.91      0.91      0.91      3824

Predicted   0.0   1.0   All
True                       
0          1925   173  2098
1           156  1570  1726
All        2081  1743  3824
Total F1 score and recall
F1 score: 0.9051599884692995
Recall: 0.9096176129779838
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid85962********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.93      0.69      0.79       114
           1       0.95      0.99      0.97       744

    accuracy                           0.95       858
   macro avg       0.94      0.84      0.88       858
weighted avg       0.95      0.95      0.95       858

Predicted  0.0  1.0  All
True                    
0           79   35  114
1            6  738  744
All         85  773  858
Total F1 score and recall
F1 score: 0.972972972972973
Recall: 0.9919354838709677
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid297246********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.81      0.57      0.67       130
           1       0.94      0.98      0.96       877

    accuracy                           0.93      1007
   macro avg       0.88      0.77      0.81      1007
weighted avg       0.92      0.93      0.92      1007

Predicted  0.0  1.0   All
True                     
0           74   56   130
1           17  860   877
All         91  916  1007
Total F1 score and recall
F1 score: 0.9592861126603458
Recall: 0.9806157354618016
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid169963********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.86      0.85      0.86       172
           1       0.97      0.98      0.98      1031

    accuracy                           0.96      1203
   macro avg       0.92      0.91      0.92      1203
weighted avg       0.96      0.96      0.96      1203

Predicted  0.0   1.0   All
True                      
0          146    26   172
1           23  1008  1031
All        169  1034  1203
Total F1 score and recall
F1 score: 0.976271186440678
Recall: 0.9776915615906887
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid272634********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.91      0.68      0.78       126
           1       0.86      0.97      0.91       246

    accuracy                           0.87       372
   macro avg       0.89      0.83      0.85       372
weighted avg       0.88      0.87      0.87       372

Predicted  0.0  1.0  All
True                    
0           86   40  126
1            8  238  246
All         94  278  372
Total F1 score and recall
F1 score: 0.9083969465648855
Recall: 0.967479674796748
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid298386********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.62      0.53      0.57        87
           1       0.94      0.96      0.95       676

    accuracy                           0.91       763
   macro avg       0.78      0.74      0.76       763
weighted avg       0.90      0.91      0.91       763

Predicted  0.0  1.0  All
True                    
0           46   41   87
1           28  648  676
All         74  689  763
Total F1 score and recall
F1 score: 0.9494505494505494
Recall: 0.9585798816568047
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid176299********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        14

    accuracy                           1.00        14
   macro avg       1.00      1.00      1.00        14
weighted avg       1.00      1.00      1.00        14

Predicted  1.0  All
True               
1           14   14
All         14   14
Total F1 score and recall
F1 score: 1.0
Recall: 1.0
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid224326********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           1       1.00      1.00      1.00        20

    accuracy                           1.00        20
   macro avg       1.00      1.00      1.00        20
weighted avg       1.00      1.00      1.00        20

Predicted  1.0  All
True               
1           20   20
All         20   20
Total F1 score and recall
F1 score: 1.0
Recall: 1.0
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid224911********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.50      0.50      0.50         2
           1       0.93      0.93      0.93        15

    accuracy                           0.88        17
   macro avg       0.72      0.72      0.72        17
weighted avg       0.88      0.88      0.88        17

Predicted  0.0  1.0  All
True                    
0            1    1    2
1            1   14   15
All          2   15   17
Total F1 score and recall
F1 score: 0.9333333333333333
Recall: 0.9333333333333333
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid208964********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.50      0.67      0.57         3
           1       0.98      0.97      0.98        67

    accuracy                           0.96        70
   macro avg       0.74      0.82      0.77        70
weighted avg       0.96      0.96      0.96        70

Predicted  0.0  1.0  All
True                    
0            2    1    3
1            2   65   67
All          4   66   70
Total F1 score and recall
F1 score: 0.9774436090225563
Recall: 0.9701492537313433
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid214092********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           1       1.00      1.00      1.00         6

    accuracy                           1.00         6
   macro avg       1.00      1.00      1.00         6
weighted avg       1.00      1.00      1.00         6

Predicted  1.0  All
True               
1            6    6
All          6    6
Total F1 score and recall
F1 score: 1.0
Recall: 1.0
**************************************************
Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer (InputLayer)        │ (None, 150, 6, 3)      │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d (Conv2D)                 │ (None, 146, 1, 64)     │         5,824 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lambda (Lambda)                 │ (None, 146, 64)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ [(None, 146, 64),      │        33,024 │
│                                 │ (None, 64), (None,     │               │
│                                 │ 64)]                   │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ self_attention (SelfAttention)  │ [(None, 1024), (None,  │         2,560 │
│                                 │ 16, 146)]              │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 2)              │         2,050 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 43,458 (169.76 KB)
 Trainable params: 43,458 (169.76 KB)
 Non-trainable params: 0 (0.00 B)
********************txid6239********************
0 non-operons were not labeled and 0 operons were not labeled 

Classification report
              precision    recall  f1-score   support

           0       0.13      0.64      0.22        56
           1       0.98      0.80      0.88      1184

    accuracy                           0.79      1240
   macro avg       0.56      0.72      0.55      1240
weighted avg       0.94      0.79      0.85      1240

Predicted  0.0  1.0   All
True                     
0           36   20    56
1          237  947  1184
All        273  967  1240
Total F1 score and recall
F1 score: 0.8805206880520688
Recall: 0.799831081081081
**************************************************