fold 0
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d (Conv2D)             (None, 146, 1, 64)        5824      
                                                                 
 lambda (Lambda)             (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention (SelfAttenti  ((None, 1024),           2560      
 on)                          (None, 16, 146))                   
                                                                 
 dense (Dense)               (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3180 - acc: 0.8653 - auc-prc: 0.9366 - auc-roc: 0.9378 - val_loss: 0.2991 - val_acc: 0.8699 - val_auc-prc: 0.9448 - val_auc-roc: 0.9470 - 19s/epoch - 64ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2860 - acc: 0.8817 - auc-prc: 0.9480 - auc-roc: 0.9496 - val_loss: 0.2779 - val_acc: 0.8844 - val_auc-prc: 0.9510 - val_auc-roc: 0.9529 - 16s/epoch - 54ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2697 - acc: 0.8904 - auc-prc: 0.9534 - auc-roc: 0.9549 - val_loss: 0.2554 - val_acc: 0.8998 - val_auc-prc: 0.9564 - val_auc-roc: 0.9587 - 16s/epoch - 54ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2678 - acc: 0.8910 - auc-prc: 0.9543 - auc-roc: 0.9555 - val_loss: 0.2482 - val_acc: 0.9046 - val_auc-prc: 0.9592 - val_auc-roc: 0.9614 - 16s/epoch - 54ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2611 - acc: 0.8954 - auc-prc: 0.9566 - auc-roc: 0.9578 - val_loss: 0.2669 - val_acc: 0.8950 - val_auc-prc: 0.9525 - val_auc-roc: 0.9552 - 16s/epoch - 55ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2579 - acc: 0.8987 - auc-prc: 0.9583 - auc-roc: 0.9589 - val_loss: 0.2485 - val_acc: 0.9017 - val_auc-prc: 0.9591 - val_auc-roc: 0.9613 - 16s/epoch - 53ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2540 - acc: 0.8988 - auc-prc: 0.9596 - auc-roc: 0.9603 - val_loss: 0.2594 - val_acc: 0.8969 - val_auc-prc: 0.9600 - val_auc-roc: 0.9618 - 16s/epoch - 55ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2541 - acc: 0.8981 - auc-prc: 0.9593 - auc-roc: 0.9601 - val_loss: 0.2423 - val_acc: 0.8988 - val_auc-prc: 0.9619 - val_auc-roc: 0.9632 - 16s/epoch - 55ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2513 - acc: 0.8970 - auc-prc: 0.9604 - auc-roc: 0.9612 - val_loss: 0.2528 - val_acc: 0.8969 - val_auc-prc: 0.9600 - val_auc-roc: 0.9612 - 16s/epoch - 57ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2500 - acc: 0.8987 - auc-prc: 0.9616 - auc-roc: 0.9617 - val_loss: 0.2486 - val_acc: 0.9017 - val_auc-prc: 0.9607 - val_auc-roc: 0.9618 - 16s/epoch - 55ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2481 - acc: 0.9001 - auc-prc: 0.9615 - auc-roc: 0.9623 - val_loss: 0.2507 - val_acc: 0.9066 - val_auc-prc: 0.9589 - val_auc-roc: 0.9604 - 16s/epoch - 56ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2444 - acc: 0.9009 - auc-prc: 0.9631 - auc-roc: 0.9633 - val_loss: 0.2486 - val_acc: 0.9114 - val_auc-prc: 0.9595 - val_auc-roc: 0.9613 - 16s/epoch - 56ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2447 - acc: 0.9001 - auc-prc: 0.9627 - auc-roc: 0.9631 - val_loss: 0.2408 - val_acc: 0.9046 - val_auc-prc: 0.9616 - val_auc-roc: 0.9631 - 16s/epoch - 56ms/step
Epoch 14/100
292/292 - 17s - loss: 0.2432 - acc: 0.9024 - auc-prc: 0.9633 - auc-roc: 0.9637 - val_loss: 0.2554 - val_acc: 0.8998 - val_auc-prc: 0.9574 - val_auc-roc: 0.9592 - 17s/epoch - 57ms/step
Epoch 15/100
292/292 - 17s - loss: 0.2406 - acc: 0.9024 - auc-prc: 0.9642 - auc-roc: 0.9645 - val_loss: 0.2413 - val_acc: 0.9075 - val_auc-prc: 0.9622 - val_auc-roc: 0.9634 - 17s/epoch - 57ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2393 - acc: 0.9061 - auc-prc: 0.9642 - auc-roc: 0.9646 - val_loss: 0.2576 - val_acc: 0.8979 - val_auc-prc: 0.9583 - val_auc-roc: 0.9600 - 16s/epoch - 56ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2385 - acc: 0.9051 - auc-prc: 0.9646 - auc-roc: 0.9650 - val_loss: 0.2461 - val_acc: 0.9114 - val_auc-prc: 0.9608 - val_auc-roc: 0.9620 - 16s/epoch - 56ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2349 - acc: 0.9054 - auc-prc: 0.9658 - auc-roc: 0.9661 - val_loss: 0.2435 - val_acc: 0.9123 - val_auc-prc: 0.9627 - val_auc-roc: 0.9639 - 16s/epoch - 54ms/step
Epoch 19/100
292/292 - 17s - loss: 0.2309 - acc: 0.9081 - auc-prc: 0.9674 - auc-roc: 0.9672 - val_loss: 0.2449 - val_acc: 0.9056 - val_auc-prc: 0.9597 - val_auc-roc: 0.9622 - 17s/epoch - 57ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2312 - acc: 0.9061 - auc-prc: 0.9668 - auc-roc: 0.9671 - val_loss: 0.2439 - val_acc: 0.9123 - val_auc-prc: 0.9623 - val_auc-roc: 0.9637 - 16s/epoch - 56ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2287 - acc: 0.9066 - auc-prc: 0.9681 - auc-roc: 0.9680 - val_loss: 0.2384 - val_acc: 0.9162 - val_auc-prc: 0.9631 - val_auc-roc: 0.9648 - 16s/epoch - 53ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 759ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.91      0.88      0.89       403
           1       0.92      0.94      0.93       635

    accuracy                           0.92      1038
   macro avg       0.91      0.91      0.91      1038
weighted avg       0.92      0.92      0.92      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.35      0.45      0.39       403
           1       0.58      0.48      0.52       635

    accuracy                           0.47      1038
   macro avg       0.46      0.46      0.46      1038
weighted avg       0.49      0.47      0.47      1038

______________________________________________________
fold 1
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_1 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_1 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_1 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_1 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 18s - loss: 0.3087 - acc: 0.8701 - auc-prc: 0.9396 - auc-roc: 0.9413 - val_loss: 0.3021 - val_acc: 0.8748 - val_auc-prc: 0.9432 - val_auc-roc: 0.9439 - 18s/epoch - 63ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2810 - acc: 0.8864 - auc-prc: 0.9486 - auc-roc: 0.9508 - val_loss: 0.2957 - val_acc: 0.8805 - val_auc-prc: 0.9467 - val_auc-roc: 0.9467 - 16s/epoch - 55ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2673 - acc: 0.8921 - auc-prc: 0.9536 - auc-roc: 0.9553 - val_loss: 0.2832 - val_acc: 0.8854 - val_auc-prc: 0.9520 - val_auc-roc: 0.9513 - 16s/epoch - 56ms/step
Epoch 4/100
292/292 - 17s - loss: 0.2610 - acc: 0.8969 - auc-prc: 0.9558 - auc-roc: 0.9575 - val_loss: 0.2914 - val_acc: 0.8767 - val_auc-prc: 0.9503 - val_auc-roc: 0.9492 - 17s/epoch - 57ms/step
Epoch 5/100
292/292 - 17s - loss: 0.2587 - acc: 0.8956 - auc-prc: 0.9571 - auc-roc: 0.9582 - val_loss: 0.2783 - val_acc: 0.8863 - val_auc-prc: 0.9544 - val_auc-roc: 0.9532 - 17s/epoch - 57ms/step
Epoch 6/100
292/292 - 17s - loss: 0.2559 - acc: 0.8983 - auc-prc: 0.9586 - auc-roc: 0.9595 - val_loss: 0.2870 - val_acc: 0.8738 - val_auc-prc: 0.9527 - val_auc-roc: 0.9516 - 17s/epoch - 57ms/step
Epoch 7/100
292/292 - 17s - loss: 0.2526 - acc: 0.8993 - auc-prc: 0.9595 - auc-roc: 0.9604 - val_loss: 0.2924 - val_acc: 0.8834 - val_auc-prc: 0.9519 - val_auc-roc: 0.9519 - 17s/epoch - 57ms/step
Epoch 8/100
292/292 - 17s - loss: 0.2542 - acc: 0.8973 - auc-prc: 0.9587 - auc-roc: 0.9600 - val_loss: 0.2790 - val_acc: 0.8805 - val_auc-prc: 0.9549 - val_auc-roc: 0.9537 - 17s/epoch - 57ms/step
Epoch 9/100
292/292 - 17s - loss: 0.2491 - acc: 0.8989 - auc-prc: 0.9608 - auc-roc: 0.9615 - val_loss: 0.2734 - val_acc: 0.8834 - val_auc-prc: 0.9561 - val_auc-roc: 0.9550 - 17s/epoch - 57ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2461 - acc: 0.9028 - auc-prc: 0.9617 - auc-roc: 0.9624 - val_loss: 0.2923 - val_acc: 0.8748 - val_auc-prc: 0.9518 - val_auc-roc: 0.9505 - 16s/epoch - 56ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2452 - acc: 0.9019 - auc-prc: 0.9618 - auc-roc: 0.9627 - val_loss: 0.2755 - val_acc: 0.8786 - val_auc-prc: 0.9559 - val_auc-roc: 0.9547 - 16s/epoch - 56ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2426 - acc: 0.9052 - auc-prc: 0.9627 - auc-roc: 0.9636 - val_loss: 0.2949 - val_acc: 0.8757 - val_auc-prc: 0.9500 - val_auc-roc: 0.9489 - 16s/epoch - 56ms/step
Epoch 13/100
292/292 - 17s - loss: 0.2417 - acc: 0.9031 - auc-prc: 0.9633 - auc-roc: 0.9638 - val_loss: 0.2841 - val_acc: 0.8805 - val_auc-prc: 0.9542 - val_auc-roc: 0.9532 - 17s/epoch - 57ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2382 - acc: 0.9022 - auc-prc: 0.9641 - auc-roc: 0.9649 - val_loss: 0.2689 - val_acc: 0.8911 - val_auc-prc: 0.9588 - val_auc-roc: 0.9576 - 16s/epoch - 56ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2379 - acc: 0.9045 - auc-prc: 0.9645 - auc-roc: 0.9649 - val_loss: 0.2725 - val_acc: 0.8805 - val_auc-prc: 0.9572 - val_auc-roc: 0.9559 - 16s/epoch - 56ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2361 - acc: 0.9037 - auc-prc: 0.9651 - auc-roc: 0.9657 - val_loss: 0.2757 - val_acc: 0.8911 - val_auc-prc: 0.9564 - val_auc-roc: 0.9550 - 16s/epoch - 56ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2339 - acc: 0.9059 - auc-prc: 0.9660 - auc-roc: 0.9662 - val_loss: 0.2703 - val_acc: 0.8911 - val_auc-prc: 0.9578 - val_auc-roc: 0.9569 - 16s/epoch - 56ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2330 - acc: 0.9050 - auc-prc: 0.9660 - auc-roc: 0.9665 - val_loss: 0.2727 - val_acc: 0.8902 - val_auc-prc: 0.9571 - val_auc-roc: 0.9559 - 16s/epoch - 56ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2270 - acc: 0.9082 - auc-prc: 0.9681 - auc-roc: 0.9683 - val_loss: 0.2750 - val_acc: 0.8805 - val_auc-prc: 0.9571 - val_auc-roc: 0.9561 - 16s/epoch - 56ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2251 - acc: 0.9090 - auc-prc: 0.9681 - auc-roc: 0.9686 - val_loss: 0.2707 - val_acc: 0.8882 - val_auc-prc: 0.9576 - val_auc-roc: 0.9574 - 16s/epoch - 56ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2249 - acc: 0.9146 - auc-prc: 0.9680 - auc-roc: 0.9686 - val_loss: 0.2748 - val_acc: 0.8786 - val_auc-prc: 0.9576 - val_auc-roc: 0.9561 - 16s/epoch - 55ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 789ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.84      0.86       403
           1       0.90      0.93      0.91       635

    accuracy                           0.89      1038
   macro avg       0.89      0.88      0.88      1038
weighted avg       0.89      0.89      0.89      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.51      0.43       403
           1       0.60      0.46      0.52       635

    accuracy                           0.48      1038
   macro avg       0.49      0.49      0.48      1038
weighted avg       0.51      0.48      0.49      1038

______________________________________________________
fold 2
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_2 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_2 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_2 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_2 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3190 - acc: 0.8615 - auc-prc: 0.9365 - auc-roc: 0.9377 - val_loss: 0.2773 - val_acc: 0.8940 - val_auc-prc: 0.9495 - val_auc-roc: 0.9520 - 19s/epoch - 64ms/step
Epoch 2/100
292/292 - 17s - loss: 0.2821 - acc: 0.8858 - auc-prc: 0.9492 - auc-roc: 0.9508 - val_loss: 0.2682 - val_acc: 0.8988 - val_auc-prc: 0.9530 - val_auc-roc: 0.9558 - 17s/epoch - 57ms/step
Epoch 3/100
292/292 - 17s - loss: 0.2733 - acc: 0.8904 - auc-prc: 0.9527 - auc-roc: 0.9537 - val_loss: 0.2589 - val_acc: 0.8969 - val_auc-prc: 0.9565 - val_auc-roc: 0.9579 - 17s/epoch - 58ms/step
Epoch 4/100
292/292 - 17s - loss: 0.2650 - acc: 0.8929 - auc-prc: 0.9549 - auc-roc: 0.9565 - val_loss: 0.2509 - val_acc: 0.9066 - val_auc-prc: 0.9597 - val_auc-roc: 0.9604 - 17s/epoch - 57ms/step
Epoch 5/100
292/292 - 17s - loss: 0.2636 - acc: 0.8962 - auc-prc: 0.9557 - auc-roc: 0.9569 - val_loss: 0.2570 - val_acc: 0.9017 - val_auc-prc: 0.9590 - val_auc-roc: 0.9598 - 17s/epoch - 57ms/step
Epoch 6/100
292/292 - 17s - loss: 0.2605 - acc: 0.8956 - auc-prc: 0.9571 - auc-roc: 0.9580 - val_loss: 0.2877 - val_acc: 0.8950 - val_auc-prc: 0.9466 - val_auc-roc: 0.9490 - 17s/epoch - 57ms/step
Epoch 7/100
292/292 - 17s - loss: 0.2603 - acc: 0.8977 - auc-prc: 0.9571 - auc-roc: 0.9580 - val_loss: 0.2470 - val_acc: 0.9037 - val_auc-prc: 0.9607 - val_auc-roc: 0.9613 - 17s/epoch - 57ms/step
Epoch 8/100
292/292 - 17s - loss: 0.2569 - acc: 0.8971 - auc-prc: 0.9587 - auc-roc: 0.9593 - val_loss: 0.2488 - val_acc: 0.9037 - val_auc-prc: 0.9603 - val_auc-roc: 0.9611 - 17s/epoch - 57ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2553 - acc: 0.8980 - auc-prc: 0.9588 - auc-roc: 0.9598 - val_loss: 0.2552 - val_acc: 0.9133 - val_auc-prc: 0.9595 - val_auc-roc: 0.9597 - 16s/epoch - 56ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2517 - acc: 0.8979 - auc-prc: 0.9600 - auc-roc: 0.9610 - val_loss: 0.2476 - val_acc: 0.9046 - val_auc-prc: 0.9616 - val_auc-roc: 0.9628 - 16s/epoch - 55ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2503 - acc: 0.8990 - auc-prc: 0.9607 - auc-roc: 0.9614 - val_loss: 0.2580 - val_acc: 0.8998 - val_auc-prc: 0.9590 - val_auc-roc: 0.9598 - 16s/epoch - 56ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2501 - acc: 0.8973 - auc-prc: 0.9616 - auc-roc: 0.9617 - val_loss: 0.2394 - val_acc: 0.9056 - val_auc-prc: 0.9635 - val_auc-roc: 0.9643 - 16s/epoch - 56ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2458 - acc: 0.9006 - auc-prc: 0.9625 - auc-roc: 0.9629 - val_loss: 0.2475 - val_acc: 0.8998 - val_auc-prc: 0.9606 - val_auc-roc: 0.9624 - 16s/epoch - 55ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2409 - acc: 0.9009 - auc-prc: 0.9641 - auc-roc: 0.9645 - val_loss: 0.2431 - val_acc: 0.9075 - val_auc-prc: 0.9617 - val_auc-roc: 0.9640 - 16s/epoch - 56ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2413 - acc: 0.9015 - auc-prc: 0.9639 - auc-roc: 0.9643 - val_loss: 0.2451 - val_acc: 0.9085 - val_auc-prc: 0.9619 - val_auc-roc: 0.9640 - 16s/epoch - 55ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2387 - acc: 0.9002 - auc-prc: 0.9646 - auc-roc: 0.9650 - val_loss: 0.2474 - val_acc: 0.9094 - val_auc-prc: 0.9628 - val_auc-roc: 0.9633 - 16s/epoch - 56ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2345 - acc: 0.9008 - auc-prc: 0.9663 - auc-roc: 0.9664 - val_loss: 0.2589 - val_acc: 0.9046 - val_auc-prc: 0.9581 - val_auc-roc: 0.9618 - 16s/epoch - 54ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2310 - acc: 0.9071 - auc-prc: 0.9665 - auc-roc: 0.9670 - val_loss: 0.2358 - val_acc: 0.9075 - val_auc-prc: 0.9639 - val_auc-roc: 0.9659 - 16s/epoch - 54ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2288 - acc: 0.9068 - auc-prc: 0.9674 - auc-roc: 0.9677 - val_loss: 0.2437 - val_acc: 0.9123 - val_auc-prc: 0.9601 - val_auc-roc: 0.9638 - 16s/epoch - 55ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2286 - acc: 0.9069 - auc-prc: 0.9683 - auc-roc: 0.9681 - val_loss: 0.2368 - val_acc: 0.9066 - val_auc-prc: 0.9633 - val_auc-roc: 0.9652 - 16s/epoch - 56ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2221 - acc: 0.9109 - auc-prc: 0.9697 - auc-roc: 0.9697 - val_loss: 0.2389 - val_acc: 0.9066 - val_auc-prc: 0.9630 - val_auc-roc: 0.9641 - 16s/epoch - 55ms/step
Epoch 22/100
292/292 - 16s - loss: 0.2184 - acc: 0.9129 - auc-prc: 0.9703 - auc-roc: 0.9705 - val_loss: 0.2421 - val_acc: 0.9123 - val_auc-prc: 0.9611 - val_auc-roc: 0.9644 - 16s/epoch - 56ms/step
Epoch 23/100
292/292 - 16s - loss: 0.2136 - acc: 0.9137 - auc-prc: 0.9717 - auc-roc: 0.9719 - val_loss: 0.2430 - val_acc: 0.9066 - val_auc-prc: 0.9622 - val_auc-roc: 0.9635 - 16s/epoch - 55ms/step
Epoch 24/100
292/292 - 16s - loss: 0.2088 - acc: 0.9157 - auc-prc: 0.9731 - auc-roc: 0.9732 - val_loss: 0.2473 - val_acc: 0.9094 - val_auc-prc: 0.9619 - val_auc-roc: 0.9631 - 16s/epoch - 55ms/step
Epoch 25/100
292/292 - 16s - loss: 0.2047 - acc: 0.9186 - auc-prc: 0.9747 - auc-roc: 0.9743 - val_loss: 0.2406 - val_acc: 0.9075 - val_auc-prc: 0.9635 - val_auc-roc: 0.9653 - 16s/epoch - 54ms/step
Epoch 26/100
292/292 - 16s - loss: 0.1999 - acc: 0.9176 - auc-prc: 0.9757 - auc-roc: 0.9755 - val_loss: 0.2519 - val_acc: 0.8988 - val_auc-prc: 0.9595 - val_auc-roc: 0.9629 - 16s/epoch - 54ms/step
Early stopping epoch: 25
******Evaluating TEST set*********
33/33 - 1s - 765ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.91      0.84      0.88       403
           1       0.91      0.95      0.93       635

    accuracy                           0.91      1038
   macro avg       0.91      0.90      0.90      1038
weighted avg       0.91      0.91      0.91      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.48      0.42       403
           1       0.60      0.49      0.54       635

    accuracy                           0.49      1038
   macro avg       0.49      0.49      0.48      1038
weighted avg       0.51      0.49      0.49      1038

______________________________________________________
fold 3
Model: "model_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_4 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_3 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_3 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_3 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_3 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3242 - acc: 0.8604 - auc-prc: 0.9338 - auc-roc: 0.9354 - val_loss: 0.2571 - val_acc: 0.8998 - val_auc-prc: 0.9586 - val_auc-roc: 0.9603 - 19s/epoch - 64ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2863 - acc: 0.8855 - auc-prc: 0.9475 - auc-roc: 0.9492 - val_loss: 0.2606 - val_acc: 0.8863 - val_auc-prc: 0.9595 - val_auc-roc: 0.9596 - 16s/epoch - 53ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2779 - acc: 0.8864 - auc-prc: 0.9503 - auc-roc: 0.9517 - val_loss: 0.2481 - val_acc: 0.9017 - val_auc-prc: 0.9629 - val_auc-roc: 0.9629 - 16s/epoch - 56ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2701 - acc: 0.8894 - auc-prc: 0.9529 - auc-roc: 0.9546 - val_loss: 0.2610 - val_acc: 0.8844 - val_auc-prc: 0.9618 - val_auc-roc: 0.9612 - 16s/epoch - 54ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2653 - acc: 0.8926 - auc-prc: 0.9553 - auc-roc: 0.9562 - val_loss: 0.2287 - val_acc: 0.9075 - val_auc-prc: 0.9680 - val_auc-roc: 0.9688 - 16s/epoch - 56ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2679 - acc: 0.8912 - auc-prc: 0.9544 - auc-roc: 0.9554 - val_loss: 0.2296 - val_acc: 0.9085 - val_auc-prc: 0.9671 - val_auc-roc: 0.9676 - 16s/epoch - 56ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2610 - acc: 0.8971 - auc-prc: 0.9565 - auc-roc: 0.9576 - val_loss: 0.2263 - val_acc: 0.9075 - val_auc-prc: 0.9701 - val_auc-roc: 0.9696 - 16s/epoch - 56ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2578 - acc: 0.8983 - auc-prc: 0.9578 - auc-roc: 0.9589 - val_loss: 0.2290 - val_acc: 0.9133 - val_auc-prc: 0.9686 - val_auc-roc: 0.9684 - 16s/epoch - 56ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2593 - acc: 0.8945 - auc-prc: 0.9578 - auc-roc: 0.9586 - val_loss: 0.2260 - val_acc: 0.9056 - val_auc-prc: 0.9704 - val_auc-roc: 0.9699 - 16s/epoch - 56ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2570 - acc: 0.8978 - auc-prc: 0.9583 - auc-roc: 0.9592 - val_loss: 0.2424 - val_acc: 0.8960 - val_auc-prc: 0.9670 - val_auc-roc: 0.9659 - 16s/epoch - 55ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2523 - acc: 0.8989 - auc-prc: 0.9600 - auc-roc: 0.9606 - val_loss: 0.2268 - val_acc: 0.9056 - val_auc-prc: 0.9700 - val_auc-roc: 0.9697 - 16s/epoch - 56ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2523 - acc: 0.8969 - auc-prc: 0.9605 - auc-roc: 0.9610 - val_loss: 0.2228 - val_acc: 0.9008 - val_auc-prc: 0.9717 - val_auc-roc: 0.9709 - 16s/epoch - 55ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2465 - acc: 0.8980 - auc-prc: 0.9620 - auc-roc: 0.9626 - val_loss: 0.2255 - val_acc: 0.9114 - val_auc-prc: 0.9696 - val_auc-roc: 0.9695 - 16s/epoch - 54ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2491 - acc: 0.9001 - auc-prc: 0.9612 - auc-roc: 0.9618 - val_loss: 0.2229 - val_acc: 0.9037 - val_auc-prc: 0.9708 - val_auc-roc: 0.9705 - 16s/epoch - 54ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2455 - acc: 0.8993 - auc-prc: 0.9627 - auc-roc: 0.9630 - val_loss: 0.2213 - val_acc: 0.9066 - val_auc-prc: 0.9716 - val_auc-roc: 0.9709 - 16s/epoch - 54ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2402 - acc: 0.9034 - auc-prc: 0.9639 - auc-roc: 0.9643 - val_loss: 0.2442 - val_acc: 0.8979 - val_auc-prc: 0.9657 - val_auc-roc: 0.9646 - 16s/epoch - 55ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2404 - acc: 0.9008 - auc-prc: 0.9644 - auc-roc: 0.9644 - val_loss: 0.2198 - val_acc: 0.9066 - val_auc-prc: 0.9717 - val_auc-roc: 0.9712 - 16s/epoch - 55ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2361 - acc: 0.9029 - auc-prc: 0.9654 - auc-roc: 0.9657 - val_loss: 0.2282 - val_acc: 0.9027 - val_auc-prc: 0.9685 - val_auc-roc: 0.9685 - 16s/epoch - 56ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2337 - acc: 0.9069 - auc-prc: 0.9661 - auc-roc: 0.9663 - val_loss: 0.2322 - val_acc: 0.9027 - val_auc-prc: 0.9677 - val_auc-roc: 0.9676 - 16s/epoch - 55ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2313 - acc: 0.9052 - auc-prc: 0.9667 - auc-roc: 0.9669 - val_loss: 0.2218 - val_acc: 0.9133 - val_auc-prc: 0.9717 - val_auc-roc: 0.9710 - 16s/epoch - 55ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2259 - acc: 0.9070 - auc-prc: 0.9683 - auc-roc: 0.9687 - val_loss: 0.2309 - val_acc: 0.8998 - val_auc-prc: 0.9684 - val_auc-roc: 0.9679 - 16s/epoch - 55ms/step
Epoch 22/100
292/292 - 16s - loss: 0.2219 - acc: 0.9099 - auc-prc: 0.9688 - auc-roc: 0.9695 - val_loss: 0.2586 - val_acc: 0.8950 - val_auc-prc: 0.9618 - val_auc-roc: 0.9627 - 16s/epoch - 55ms/step
Early stopping epoch: 21
******Evaluating TEST set*********
33/33 - 1s - 781ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.89      0.87      0.88       403
           1       0.92      0.93      0.92       635

    accuracy                           0.91      1038
   macro avg       0.90      0.90      0.90      1038
weighted avg       0.91      0.91      0.91      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.46      0.42       403
           1       0.60      0.52      0.56       635

    accuracy                           0.50      1038
   macro avg       0.49      0.49      0.49      1038
weighted avg       0.52      0.50      0.50      1038

______________________________________________________
fold 4
Model: "model_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_4 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_4 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_4 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_4 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3171 - acc: 0.8658 - auc-prc: 0.9372 - auc-roc: 0.9383 - val_loss: 0.2714 - val_acc: 0.8844 - val_auc-prc: 0.9547 - val_auc-roc: 0.9553 - 19s/epoch - 65ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2844 - acc: 0.8874 - auc-prc: 0.9478 - auc-roc: 0.9499 - val_loss: 0.2512 - val_acc: 0.8960 - val_auc-prc: 0.9615 - val_auc-roc: 0.9619 - 16s/epoch - 55ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2760 - acc: 0.8896 - auc-prc: 0.9511 - auc-roc: 0.9525 - val_loss: 0.2339 - val_acc: 0.9046 - val_auc-prc: 0.9664 - val_auc-roc: 0.9673 - 16s/epoch - 55ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2721 - acc: 0.8897 - auc-prc: 0.9525 - auc-roc: 0.9540 - val_loss: 0.2351 - val_acc: 0.8998 - val_auc-prc: 0.9651 - val_auc-roc: 0.9657 - 16s/epoch - 55ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2664 - acc: 0.8921 - auc-prc: 0.9547 - auc-roc: 0.9558 - val_loss: 0.2330 - val_acc: 0.9017 - val_auc-prc: 0.9663 - val_auc-roc: 0.9669 - 16s/epoch - 56ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2618 - acc: 0.8962 - auc-prc: 0.9562 - auc-roc: 0.9574 - val_loss: 0.2312 - val_acc: 0.9133 - val_auc-prc: 0.9679 - val_auc-roc: 0.9686 - 16s/epoch - 56ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2626 - acc: 0.8951 - auc-prc: 0.9563 - auc-roc: 0.9573 - val_loss: 0.2403 - val_acc: 0.8979 - val_auc-prc: 0.9651 - val_auc-roc: 0.9651 - 16s/epoch - 55ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2575 - acc: 0.8966 - auc-prc: 0.9580 - auc-roc: 0.9590 - val_loss: 0.2282 - val_acc: 0.9094 - val_auc-prc: 0.9667 - val_auc-roc: 0.9678 - 16s/epoch - 55ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2574 - acc: 0.8968 - auc-prc: 0.9582 - auc-roc: 0.9592 - val_loss: 0.2306 - val_acc: 0.9094 - val_auc-prc: 0.9669 - val_auc-roc: 0.9676 - 16s/epoch - 55ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2557 - acc: 0.8957 - auc-prc: 0.9586 - auc-roc: 0.9597 - val_loss: 0.2230 - val_acc: 0.9133 - val_auc-prc: 0.9691 - val_auc-roc: 0.9692 - 16s/epoch - 55ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2528 - acc: 0.8976 - auc-prc: 0.9601 - auc-roc: 0.9607 - val_loss: 0.2200 - val_acc: 0.9075 - val_auc-prc: 0.9701 - val_auc-roc: 0.9702 - 16s/epoch - 54ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2521 - acc: 0.8983 - auc-prc: 0.9601 - auc-roc: 0.9609 - val_loss: 0.2225 - val_acc: 0.9094 - val_auc-prc: 0.9701 - val_auc-roc: 0.9701 - 16s/epoch - 55ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2480 - acc: 0.9002 - auc-prc: 0.9616 - auc-roc: 0.9621 - val_loss: 0.2235 - val_acc: 0.9094 - val_auc-prc: 0.9711 - val_auc-roc: 0.9710 - 16s/epoch - 56ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2483 - acc: 0.8980 - auc-prc: 0.9614 - auc-roc: 0.9619 - val_loss: 0.2178 - val_acc: 0.9114 - val_auc-prc: 0.9708 - val_auc-roc: 0.9709 - 16s/epoch - 56ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2447 - acc: 0.9001 - auc-prc: 0.9629 - auc-roc: 0.9632 - val_loss: 0.2180 - val_acc: 0.9114 - val_auc-prc: 0.9716 - val_auc-roc: 0.9714 - 16s/epoch - 55ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2430 - acc: 0.9034 - auc-prc: 0.9633 - auc-roc: 0.9637 - val_loss: 0.2197 - val_acc: 0.9094 - val_auc-prc: 0.9709 - val_auc-roc: 0.9705 - 16s/epoch - 55ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2408 - acc: 0.9036 - auc-prc: 0.9637 - auc-roc: 0.9643 - val_loss: 0.2273 - val_acc: 0.9056 - val_auc-prc: 0.9691 - val_auc-roc: 0.9690 - 16s/epoch - 55ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2396 - acc: 0.9037 - auc-prc: 0.9643 - auc-roc: 0.9648 - val_loss: 0.2129 - val_acc: 0.9133 - val_auc-prc: 0.9732 - val_auc-roc: 0.9730 - 16s/epoch - 56ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2393 - acc: 0.9037 - auc-prc: 0.9647 - auc-roc: 0.9648 - val_loss: 0.2144 - val_acc: 0.9104 - val_auc-prc: 0.9735 - val_auc-roc: 0.9730 - 16s/epoch - 55ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2320 - acc: 0.9038 - auc-prc: 0.9663 - auc-roc: 0.9668 - val_loss: 0.2200 - val_acc: 0.9123 - val_auc-prc: 0.9712 - val_auc-roc: 0.9707 - 16s/epoch - 55ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2289 - acc: 0.9080 - auc-prc: 0.9675 - auc-roc: 0.9677 - val_loss: 0.2100 - val_acc: 0.9152 - val_auc-prc: 0.9741 - val_auc-roc: 0.9738 - 16s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 748ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.90      0.87      0.89       403
           1       0.92      0.94      0.93       635

    accuracy                           0.92      1038
   macro avg       0.91      0.91      0.91      1038
weighted avg       0.91      0.92      0.91      1038

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.52      0.44       403
           1       0.61      0.48      0.54       635

    accuracy                           0.50      1038
   macro avg       0.50      0.50      0.49      1038
weighted avg       0.53      0.50      0.50      1038

______________________________________________________
fold 5
Model: "model_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_6 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_5 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_5 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_5 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_5 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3178 - acc: 0.8699 - auc-prc: 0.9365 - auc-roc: 0.9382 - val_loss: 0.2928 - val_acc: 0.8756 - val_auc-prc: 0.9520 - val_auc-roc: 0.9509 - 19s/epoch - 64ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2835 - acc: 0.8848 - auc-prc: 0.9484 - auc-roc: 0.9501 - val_loss: 0.2702 - val_acc: 0.8843 - val_auc-prc: 0.9566 - val_auc-roc: 0.9557 - 16s/epoch - 56ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2696 - acc: 0.8919 - auc-prc: 0.9528 - auc-roc: 0.9547 - val_loss: 0.2669 - val_acc: 0.8891 - val_auc-prc: 0.9605 - val_auc-roc: 0.9595 - 16s/epoch - 54ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2650 - acc: 0.8929 - auc-prc: 0.9551 - auc-roc: 0.9562 - val_loss: 0.2577 - val_acc: 0.8920 - val_auc-prc: 0.9607 - val_auc-roc: 0.9599 - 16s/epoch - 56ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2613 - acc: 0.8922 - auc-prc: 0.9567 - auc-roc: 0.9577 - val_loss: 0.2570 - val_acc: 0.8901 - val_auc-prc: 0.9618 - val_auc-roc: 0.9611 - 16s/epoch - 56ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2625 - acc: 0.8940 - auc-prc: 0.9560 - auc-roc: 0.9571 - val_loss: 0.2727 - val_acc: 0.8824 - val_auc-prc: 0.9566 - val_auc-roc: 0.9558 - 16s/epoch - 56ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2585 - acc: 0.8972 - auc-prc: 0.9576 - auc-roc: 0.9584 - val_loss: 0.2531 - val_acc: 0.8901 - val_auc-prc: 0.9641 - val_auc-roc: 0.9631 - 16s/epoch - 56ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2559 - acc: 0.8976 - auc-prc: 0.9584 - auc-roc: 0.9594 - val_loss: 0.2521 - val_acc: 0.8920 - val_auc-prc: 0.9640 - val_auc-roc: 0.9629 - 16s/epoch - 55ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2527 - acc: 0.8992 - auc-prc: 0.9596 - auc-roc: 0.9603 - val_loss: 0.2557 - val_acc: 0.8910 - val_auc-prc: 0.9627 - val_auc-roc: 0.9617 - 16s/epoch - 55ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2495 - acc: 0.9013 - auc-prc: 0.9607 - auc-roc: 0.9615 - val_loss: 0.2528 - val_acc: 0.8949 - val_auc-prc: 0.9636 - val_auc-roc: 0.9627 - 16s/epoch - 55ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2488 - acc: 0.9003 - auc-prc: 0.9611 - auc-roc: 0.9619 - val_loss: 0.2628 - val_acc: 0.8959 - val_auc-prc: 0.9608 - val_auc-roc: 0.9603 - 16s/epoch - 55ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2477 - acc: 0.9014 - auc-prc: 0.9612 - auc-roc: 0.9621 - val_loss: 0.2554 - val_acc: 0.8891 - val_auc-prc: 0.9617 - val_auc-roc: 0.9613 - 16s/epoch - 55ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2438 - acc: 0.9034 - auc-prc: 0.9625 - auc-roc: 0.9632 - val_loss: 0.2451 - val_acc: 0.8978 - val_auc-prc: 0.9651 - val_auc-roc: 0.9643 - 16s/epoch - 55ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2406 - acc: 0.9051 - auc-prc: 0.9635 - auc-roc: 0.9641 - val_loss: 0.2474 - val_acc: 0.8968 - val_auc-prc: 0.9649 - val_auc-roc: 0.9642 - 16s/epoch - 54ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2375 - acc: 0.9063 - auc-prc: 0.9645 - auc-roc: 0.9651 - val_loss: 0.2571 - val_acc: 0.8862 - val_auc-prc: 0.9623 - val_auc-roc: 0.9615 - 16s/epoch - 55ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2365 - acc: 0.9044 - auc-prc: 0.9647 - auc-roc: 0.9655 - val_loss: 0.2487 - val_acc: 0.9016 - val_auc-prc: 0.9619 - val_auc-roc: 0.9625 - 16s/epoch - 54ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2342 - acc: 0.9060 - auc-prc: 0.9659 - auc-roc: 0.9663 - val_loss: 0.2528 - val_acc: 0.8987 - val_auc-prc: 0.9639 - val_auc-roc: 0.9639 - 16s/epoch - 56ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2319 - acc: 0.9064 - auc-prc: 0.9668 - auc-roc: 0.9669 - val_loss: 0.2542 - val_acc: 0.8949 - val_auc-prc: 0.9615 - val_auc-roc: 0.9622 - 16s/epoch - 55ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2311 - acc: 0.9074 - auc-prc: 0.9667 - auc-roc: 0.9670 - val_loss: 0.2497 - val_acc: 0.8920 - val_auc-prc: 0.9637 - val_auc-roc: 0.9633 - 16s/epoch - 56ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2287 - acc: 0.9078 - auc-prc: 0.9678 - auc-roc: 0.9679 - val_loss: 0.2576 - val_acc: 0.8959 - val_auc-prc: 0.9627 - val_auc-roc: 0.9628 - 16s/epoch - 54ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2247 - acc: 0.9094 - auc-prc: 0.9688 - auc-roc: 0.9690 - val_loss: 0.2489 - val_acc: 0.8930 - val_auc-prc: 0.9644 - val_auc-roc: 0.9636 - 16s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 766ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.87      0.86      0.87       403
           1       0.91      0.92      0.92       634

    accuracy                           0.90      1037
   macro avg       0.89      0.89      0.89      1037
weighted avg       0.90      0.90      0.90      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.51      0.44       403
           1       0.61      0.48      0.54       634

    accuracy                           0.49      1037
   macro avg       0.50      0.50      0.49      1037
weighted avg       0.52      0.49      0.50      1037

______________________________________________________
fold 6
Model: "model_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_6 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_6 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_6 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_6 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3119 - acc: 0.8656 - auc-prc: 0.9389 - auc-roc: 0.9403 - val_loss: 0.3050 - val_acc: 0.8775 - val_auc-prc: 0.9396 - val_auc-roc: 0.9414 - 19s/epoch - 64ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2766 - acc: 0.8918 - auc-prc: 0.9511 - auc-roc: 0.9527 - val_loss: 0.3113 - val_acc: 0.8843 - val_auc-prc: 0.9386 - val_auc-roc: 0.9426 - 16s/epoch - 56ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2670 - acc: 0.8931 - auc-prc: 0.9543 - auc-roc: 0.9558 - val_loss: 0.2938 - val_acc: 0.8833 - val_auc-prc: 0.9442 - val_auc-roc: 0.9463 - 16s/epoch - 56ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2606 - acc: 0.8982 - auc-prc: 0.9566 - auc-roc: 0.9578 - val_loss: 0.2934 - val_acc: 0.8843 - val_auc-prc: 0.9457 - val_auc-roc: 0.9480 - 16s/epoch - 56ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2587 - acc: 0.8986 - auc-prc: 0.9576 - auc-roc: 0.9586 - val_loss: 0.2968 - val_acc: 0.8891 - val_auc-prc: 0.9453 - val_auc-roc: 0.9485 - 16s/epoch - 56ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2587 - acc: 0.8970 - auc-prc: 0.9579 - auc-roc: 0.9587 - val_loss: 0.2860 - val_acc: 0.8881 - val_auc-prc: 0.9465 - val_auc-roc: 0.9487 - 16s/epoch - 56ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2542 - acc: 0.8984 - auc-prc: 0.9590 - auc-roc: 0.9601 - val_loss: 0.2914 - val_acc: 0.8910 - val_auc-prc: 0.9445 - val_auc-roc: 0.9482 - 16s/epoch - 56ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2537 - acc: 0.8986 - auc-prc: 0.9597 - auc-roc: 0.9603 - val_loss: 0.2828 - val_acc: 0.8881 - val_auc-prc: 0.9492 - val_auc-roc: 0.9518 - 16s/epoch - 55ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2500 - acc: 0.9001 - auc-prc: 0.9613 - auc-roc: 0.9616 - val_loss: 0.3119 - val_acc: 0.8833 - val_auc-prc: 0.9372 - val_auc-roc: 0.9432 - 16s/epoch - 56ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2504 - acc: 0.8975 - auc-prc: 0.9606 - auc-roc: 0.9613 - val_loss: 0.2793 - val_acc: 0.8881 - val_auc-prc: 0.9503 - val_auc-roc: 0.9524 - 16s/epoch - 54ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2450 - acc: 0.8997 - auc-prc: 0.9627 - auc-roc: 0.9631 - val_loss: 0.2761 - val_acc: 0.8785 - val_auc-prc: 0.9523 - val_auc-roc: 0.9532 - 16s/epoch - 56ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2441 - acc: 0.9010 - auc-prc: 0.9635 - auc-roc: 0.9636 - val_loss: 0.2849 - val_acc: 0.8862 - val_auc-prc: 0.9509 - val_auc-roc: 0.9519 - 16s/epoch - 56ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2399 - acc: 0.9001 - auc-prc: 0.9647 - auc-roc: 0.9648 - val_loss: 0.2841 - val_acc: 0.8852 - val_auc-prc: 0.9487 - val_auc-roc: 0.9506 - 16s/epoch - 56ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2386 - acc: 0.9036 - auc-prc: 0.9648 - auc-roc: 0.9650 - val_loss: 0.2809 - val_acc: 0.8833 - val_auc-prc: 0.9504 - val_auc-roc: 0.9517 - 16s/epoch - 54ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2354 - acc: 0.9046 - auc-prc: 0.9658 - auc-roc: 0.9660 - val_loss: 0.2786 - val_acc: 0.8930 - val_auc-prc: 0.9502 - val_auc-roc: 0.9522 - 16s/epoch - 55ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2350 - acc: 0.9055 - auc-prc: 0.9662 - auc-roc: 0.9664 - val_loss: 0.2822 - val_acc: 0.8814 - val_auc-prc: 0.9511 - val_auc-roc: 0.9514 - 16s/epoch - 54ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2279 - acc: 0.9096 - auc-prc: 0.9679 - auc-roc: 0.9680 - val_loss: 0.2919 - val_acc: 0.8872 - val_auc-prc: 0.9466 - val_auc-roc: 0.9485 - 16s/epoch - 54ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2310 - acc: 0.9057 - auc-prc: 0.9672 - auc-roc: 0.9674 - val_loss: 0.2751 - val_acc: 0.8833 - val_auc-prc: 0.9542 - val_auc-roc: 0.9546 - 16s/epoch - 55ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2258 - acc: 0.9061 - auc-prc: 0.9689 - auc-roc: 0.9687 - val_loss: 0.3040 - val_acc: 0.8814 - val_auc-prc: 0.9434 - val_auc-roc: 0.9448 - 16s/epoch - 55ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2258 - acc: 0.9075 - auc-prc: 0.9685 - auc-roc: 0.9687 - val_loss: 0.2933 - val_acc: 0.8891 - val_auc-prc: 0.9459 - val_auc-roc: 0.9504 - 16s/epoch - 55ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2195 - acc: 0.9098 - auc-prc: 0.9707 - auc-roc: 0.9705 - val_loss: 0.2884 - val_acc: 0.8843 - val_auc-prc: 0.9510 - val_auc-roc: 0.9538 - 16s/epoch - 56ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 792ms/epoch - 24ms/step
              precision    recall  f1-score   support

           0       0.88      0.82      0.84       403
           1       0.89      0.93      0.91       634

    accuracy                           0.88      1037
   macro avg       0.88      0.87      0.88      1037
weighted avg       0.88      0.88      0.88      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.39      0.51      0.44       403
           1       0.62      0.50      0.56       634

    accuracy                           0.51      1037
   macro avg       0.51      0.51      0.50      1037
weighted avg       0.53      0.51      0.51      1037

______________________________________________________
fold 7
Model: "model_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_8 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_7 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_7 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_7 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_7 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 19s - loss: 0.3196 - acc: 0.8631 - auc-prc: 0.9356 - auc-roc: 0.9372 - val_loss: 0.2681 - val_acc: 0.9016 - val_auc-prc: 0.9524 - val_auc-roc: 0.9558 - 19s/epoch - 65ms/step
Epoch 2/100
292/292 - 17s - loss: 0.2860 - acc: 0.8825 - auc-prc: 0.9483 - auc-roc: 0.9497 - val_loss: 0.2544 - val_acc: 0.9045 - val_auc-prc: 0.9556 - val_auc-roc: 0.9587 - 17s/epoch - 57ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2734 - acc: 0.8898 - auc-prc: 0.9522 - auc-roc: 0.9535 - val_loss: 0.2627 - val_acc: 0.8997 - val_auc-prc: 0.9558 - val_auc-roc: 0.9582 - 16s/epoch - 56ms/step
Epoch 4/100
292/292 - 17s - loss: 0.2654 - acc: 0.8923 - auc-prc: 0.9554 - auc-roc: 0.9563 - val_loss: 0.2709 - val_acc: 0.8891 - val_auc-prc: 0.9559 - val_auc-roc: 0.9561 - 17s/epoch - 58ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2634 - acc: 0.8945 - auc-prc: 0.9561 - auc-roc: 0.9569 - val_loss: 0.2486 - val_acc: 0.9007 - val_auc-prc: 0.9591 - val_auc-roc: 0.9612 - 16s/epoch - 56ms/step
Epoch 6/100
292/292 - 17s - loss: 0.2622 - acc: 0.8947 - auc-prc: 0.9566 - auc-roc: 0.9576 - val_loss: 0.2516 - val_acc: 0.9026 - val_auc-prc: 0.9616 - val_auc-roc: 0.9619 - 17s/epoch - 57ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2566 - acc: 0.8964 - auc-prc: 0.9587 - auc-roc: 0.9594 - val_loss: 0.2577 - val_acc: 0.8939 - val_auc-prc: 0.9578 - val_auc-roc: 0.9591 - 16s/epoch - 56ms/step
Epoch 8/100
292/292 - 17s - loss: 0.2536 - acc: 0.8970 - auc-prc: 0.9595 - auc-roc: 0.9602 - val_loss: 0.2569 - val_acc: 0.9036 - val_auc-prc: 0.9584 - val_auc-roc: 0.9593 - 17s/epoch - 57ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2526 - acc: 0.8953 - auc-prc: 0.9600 - auc-roc: 0.9606 - val_loss: 0.2570 - val_acc: 0.8949 - val_auc-prc: 0.9586 - val_auc-roc: 0.9591 - 16s/epoch - 56ms/step
Epoch 10/100
292/292 - 17s - loss: 0.2464 - acc: 0.8988 - auc-prc: 0.9622 - auc-roc: 0.9627 - val_loss: 0.2492 - val_acc: 0.8959 - val_auc-prc: 0.9604 - val_auc-roc: 0.9618 - 17s/epoch - 57ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2461 - acc: 0.9008 - auc-prc: 0.9621 - auc-roc: 0.9625 - val_loss: 0.2837 - val_acc: 0.8891 - val_auc-prc: 0.9511 - val_auc-roc: 0.9526 - 16s/epoch - 56ms/step
Epoch 12/100
292/292 - 17s - loss: 0.2434 - acc: 0.9016 - auc-prc: 0.9631 - auc-roc: 0.9636 - val_loss: 0.2555 - val_acc: 0.8949 - val_auc-prc: 0.9589 - val_auc-roc: 0.9602 - 17s/epoch - 57ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2456 - acc: 0.8982 - auc-prc: 0.9625 - auc-roc: 0.9630 - val_loss: 0.2574 - val_acc: 0.8930 - val_auc-prc: 0.9597 - val_auc-roc: 0.9607 - 16s/epoch - 56ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2368 - acc: 0.9037 - auc-prc: 0.9652 - auc-roc: 0.9655 - val_loss: 0.2572 - val_acc: 0.8987 - val_auc-prc: 0.9598 - val_auc-roc: 0.9601 - 16s/epoch - 56ms/step
Epoch 15/100
292/292 - 17s - loss: 0.2375 - acc: 0.9014 - auc-prc: 0.9654 - auc-roc: 0.9654 - val_loss: 0.2543 - val_acc: 0.9016 - val_auc-prc: 0.9597 - val_auc-roc: 0.9603 - 17s/epoch - 57ms/step
Epoch 16/100
292/292 - 17s - loss: 0.2339 - acc: 0.9050 - auc-prc: 0.9660 - auc-roc: 0.9662 - val_loss: 0.2628 - val_acc: 0.8939 - val_auc-prc: 0.9556 - val_auc-roc: 0.9574 - 17s/epoch - 57ms/step
Epoch 17/100
292/292 - 17s - loss: 0.2334 - acc: 0.9053 - auc-prc: 0.9665 - auc-roc: 0.9666 - val_loss: 0.2619 - val_acc: 0.9007 - val_auc-prc: 0.9569 - val_auc-roc: 0.9586 - 17s/epoch - 57ms/step
Epoch 18/100
292/292 - 17s - loss: 0.2286 - acc: 0.9079 - auc-prc: 0.9680 - auc-roc: 0.9680 - val_loss: 0.2647 - val_acc: 0.8959 - val_auc-prc: 0.9575 - val_auc-roc: 0.9577 - 17s/epoch - 57ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2267 - acc: 0.9094 - auc-prc: 0.9685 - auc-roc: 0.9684 - val_loss: 0.2723 - val_acc: 0.8949 - val_auc-prc: 0.9568 - val_auc-roc: 0.9583 - 16s/epoch - 55ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2234 - acc: 0.9094 - auc-prc: 0.9699 - auc-roc: 0.9695 - val_loss: 0.2692 - val_acc: 0.8930 - val_auc-prc: 0.9553 - val_auc-roc: 0.9565 - 16s/epoch - 56ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2191 - acc: 0.9120 - auc-prc: 0.9701 - auc-roc: 0.9704 - val_loss: 0.2684 - val_acc: 0.8959 - val_auc-prc: 0.9544 - val_auc-roc: 0.9561 - 16s/epoch - 56ms/step
Epoch 22/100
292/292 - 17s - loss: 0.2180 - acc: 0.9109 - auc-prc: 0.9704 - auc-roc: 0.9707 - val_loss: 0.2715 - val_acc: 0.8881 - val_auc-prc: 0.9527 - val_auc-roc: 0.9553 - 17s/epoch - 57ms/step
Epoch 23/100
292/292 - 16s - loss: 0.2114 - acc: 0.9142 - auc-prc: 0.9731 - auc-roc: 0.9727 - val_loss: 0.2735 - val_acc: 0.8901 - val_auc-prc: 0.9540 - val_auc-roc: 0.9552 - 16s/epoch - 56ms/step
Epoch 24/100
292/292 - 16s - loss: 0.2114 - acc: 0.9148 - auc-prc: 0.9728 - auc-roc: 0.9727 - val_loss: 0.2874 - val_acc: 0.8785 - val_auc-prc: 0.9482 - val_auc-roc: 0.9524 - 16s/epoch - 56ms/step
Epoch 25/100
292/292 - 16s - loss: 0.2074 - acc: 0.9160 - auc-prc: 0.9742 - auc-roc: 0.9738 - val_loss: 0.2808 - val_acc: 0.8814 - val_auc-prc: 0.9517 - val_auc-roc: 0.9525 - 16s/epoch - 56ms/step
Epoch 26/100
292/292 - 16s - loss: 0.2011 - acc: 0.9202 - auc-prc: 0.9754 - auc-roc: 0.9752 - val_loss: 0.2827 - val_acc: 0.8833 - val_auc-prc: 0.9505 - val_auc-roc: 0.9521 - 16s/epoch - 56ms/step
Epoch 27/100
292/292 - 16s - loss: 0.1967 - acc: 0.9194 - auc-prc: 0.9764 - auc-roc: 0.9764 - val_loss: 0.2707 - val_acc: 0.8872 - val_auc-prc: 0.9568 - val_auc-roc: 0.9580 - 16s/epoch - 56ms/step
Epoch 28/100
292/292 - 17s - loss: 0.1929 - acc: 0.9223 - auc-prc: 0.9774 - auc-roc: 0.9773 - val_loss: 0.2706 - val_acc: 0.8978 - val_auc-prc: 0.9569 - val_auc-roc: 0.9588 - 17s/epoch - 57ms/step
Epoch 29/100
292/292 - 17s - loss: 0.1879 - acc: 0.9246 - auc-prc: 0.9783 - auc-roc: 0.9784 - val_loss: 0.2908 - val_acc: 0.8881 - val_auc-prc: 0.9481 - val_auc-roc: 0.9527 - 17s/epoch - 57ms/step
Epoch 30/100
292/292 - 16s - loss: 0.1853 - acc: 0.9228 - auc-prc: 0.9793 - auc-roc: 0.9791 - val_loss: 0.3007 - val_acc: 0.8824 - val_auc-prc: 0.9476 - val_auc-roc: 0.9511 - 16s/epoch - 56ms/step
Epoch 31/100
292/292 - 17s - loss: 0.1770 - acc: 0.9284 - auc-prc: 0.9810 - auc-roc: 0.9808 - val_loss: 0.3072 - val_acc: 0.8881 - val_auc-prc: 0.9465 - val_auc-roc: 0.9498 - 17s/epoch - 57ms/step
Epoch 32/100
292/292 - 16s - loss: 0.1701 - acc: 0.9284 - auc-prc: 0.9823 - auc-roc: 0.9822 - val_loss: 0.3194 - val_acc: 0.8824 - val_auc-prc: 0.9425 - val_auc-roc: 0.9476 - 16s/epoch - 56ms/step
Epoch 33/100
292/292 - 16s - loss: 0.1691 - acc: 0.9310 - auc-prc: 0.9823 - auc-roc: 0.9823 - val_loss: 0.3141 - val_acc: 0.8949 - val_auc-prc: 0.9478 - val_auc-roc: 0.9522 - 16s/epoch - 56ms/step
Epoch 34/100
292/292 - 16s - loss: 0.1572 - acc: 0.9371 - auc-prc: 0.9848 - auc-roc: 0.9848 - val_loss: 0.2993 - val_acc: 0.8949 - val_auc-prc: 0.9503 - val_auc-roc: 0.9537 - 16s/epoch - 56ms/step
Epoch 35/100
292/292 - 16s - loss: 0.1540 - acc: 0.9364 - auc-prc: 0.9855 - auc-roc: 0.9854 - val_loss: 0.3061 - val_acc: 0.8910 - val_auc-prc: 0.9466 - val_auc-roc: 0.9509 - 16s/epoch - 56ms/step
Epoch 36/100
292/292 - 17s - loss: 0.1456 - acc: 0.9424 - auc-prc: 0.9871 - auc-roc: 0.9870 - val_loss: 0.3276 - val_acc: 0.8843 - val_auc-prc: 0.9482 - val_auc-roc: 0.9528 - 17s/epoch - 57ms/step
Epoch 37/100
292/292 - 17s - loss: 0.1393 - acc: 0.9443 - auc-prc: 0.9879 - auc-roc: 0.9880 - val_loss: 0.3377 - val_acc: 0.8852 - val_auc-prc: 0.9409 - val_auc-roc: 0.9484 - 17s/epoch - 57ms/step
Epoch 38/100
292/292 - 17s - loss: 0.1375 - acc: 0.9467 - auc-prc: 0.9879 - auc-roc: 0.9880 - val_loss: 0.3491 - val_acc: 0.8920 - val_auc-prc: 0.9414 - val_auc-roc: 0.9490 - 17s/epoch - 57ms/step
Epoch 39/100
292/292 - 17s - loss: 0.1250 - acc: 0.9520 - auc-prc: 0.9904 - auc-roc: 0.9904 - val_loss: 0.3821 - val_acc: 0.8862 - val_auc-prc: 0.9319 - val_auc-roc: 0.9425 - 17s/epoch - 58ms/step
Epoch 40/100
292/292 - 16s - loss: 0.1228 - acc: 0.9510 - auc-prc: 0.9907 - auc-roc: 0.9907 - val_loss: 0.3547 - val_acc: 0.8717 - val_auc-prc: 0.9378 - val_auc-roc: 0.9430 - 16s/epoch - 55ms/step
Epoch 41/100
292/292 - 17s - loss: 0.1180 - acc: 0.9543 - auc-prc: 0.9910 - auc-roc: 0.9912 - val_loss: 0.3718 - val_acc: 0.8862 - val_auc-prc: 0.9342 - val_auc-roc: 0.9425 - 17s/epoch - 57ms/step
Epoch 42/100
292/292 - 16s - loss: 0.1128 - acc: 0.9564 - auc-prc: 0.9917 - auc-roc: 0.9919 - val_loss: 0.3734 - val_acc: 0.8930 - val_auc-prc: 0.9402 - val_auc-roc: 0.9484 - 16s/epoch - 56ms/step
Epoch 43/100
292/292 - 16s - loss: 0.1081 - acc: 0.9580 - auc-prc: 0.9926 - auc-roc: 0.9927 - val_loss: 0.3775 - val_acc: 0.8901 - val_auc-prc: 0.9363 - val_auc-roc: 0.9450 - 16s/epoch - 55ms/step
Epoch 44/100
292/292 - 16s - loss: 0.1060 - acc: 0.9586 - auc-prc: 0.9928 - auc-roc: 0.9929 - val_loss: 0.3874 - val_acc: 0.8939 - val_auc-prc: 0.9323 - val_auc-roc: 0.9434 - 16s/epoch - 56ms/step
Epoch 45/100
292/292 - 16s - loss: 0.0985 - acc: 0.9621 - auc-prc: 0.9939 - auc-roc: 0.9939 - val_loss: 0.3865 - val_acc: 0.8843 - val_auc-prc: 0.9345 - val_auc-roc: 0.9436 - 16s/epoch - 54ms/step
Epoch 46/100
292/292 - 16s - loss: 0.0911 - acc: 0.9638 - auc-prc: 0.9949 - auc-roc: 0.9949 - val_loss: 0.3989 - val_acc: 0.8949 - val_auc-prc: 0.9368 - val_auc-roc: 0.9465 - 16s/epoch - 56ms/step
Epoch 47/100
292/292 - 17s - loss: 0.0955 - acc: 0.9632 - auc-prc: 0.9936 - auc-roc: 0.9939 - val_loss: 0.4215 - val_acc: 0.8795 - val_auc-prc: 0.9279 - val_auc-roc: 0.9391 - 17s/epoch - 57ms/step
Epoch 48/100
292/292 - 17s - loss: 0.0775 - acc: 0.9730 - auc-prc: 0.9960 - auc-roc: 0.9961 - val_loss: 0.4268 - val_acc: 0.8881 - val_auc-prc: 0.9319 - val_auc-roc: 0.9414 - 17s/epoch - 58ms/step
Epoch 49/100
292/292 - 17s - loss: 0.0837 - acc: 0.9691 - auc-prc: 0.9947 - auc-roc: 0.9950 - val_loss: 0.4741 - val_acc: 0.8852 - val_auc-prc: 0.9309 - val_auc-roc: 0.9416 - 17s/epoch - 57ms/step
Epoch 50/100
292/292 - 17s - loss: 0.0999 - acc: 0.9602 - auc-prc: 0.9933 - auc-roc: 0.9935 - val_loss: 0.4370 - val_acc: 0.8987 - val_auc-prc: 0.9326 - val_auc-roc: 0.9439 - 17s/epoch - 58ms/step
Epoch 51/100
292/292 - 16s - loss: 0.0744 - acc: 0.9722 - auc-prc: 0.9964 - auc-roc: 0.9964 - val_loss: 0.4499 - val_acc: 0.8843 - val_auc-prc: 0.9262 - val_auc-roc: 0.9380 - 16s/epoch - 57ms/step
Epoch 52/100
292/292 - 17s - loss: 0.0685 - acc: 0.9726 - auc-prc: 0.9969 - auc-roc: 0.9970 - val_loss: 0.4643 - val_acc: 0.8824 - val_auc-prc: 0.9216 - val_auc-roc: 0.9350 - 17s/epoch - 57ms/step
Epoch 53/100
292/292 - 17s - loss: 0.0677 - acc: 0.9753 - auc-prc: 0.9967 - auc-roc: 0.9968 - val_loss: 0.4864 - val_acc: 0.8891 - val_auc-prc: 0.9291 - val_auc-roc: 0.9403 - 17s/epoch - 57ms/step
Epoch 54/100
292/292 - 17s - loss: 0.0732 - acc: 0.9720 - auc-prc: 0.9963 - auc-roc: 0.9964 - val_loss: 0.4700 - val_acc: 0.8833 - val_auc-prc: 0.9253 - val_auc-roc: 0.9376 - 17s/epoch - 57ms/step
Epoch 55/100
292/292 - 17s - loss: 0.0678 - acc: 0.9752 - auc-prc: 0.9967 - auc-roc: 0.9969 - val_loss: 0.4830 - val_acc: 0.8833 - val_auc-prc: 0.9243 - val_auc-roc: 0.9363 - 17s/epoch - 57ms/step
Epoch 56/100
292/292 - 16s - loss: 0.0628 - acc: 0.9763 - auc-prc: 0.9976 - auc-roc: 0.9976 - val_loss: 0.5045 - val_acc: 0.8852 - val_auc-prc: 0.9176 - val_auc-roc: 0.9324 - 16s/epoch - 56ms/step
Epoch 57/100
292/292 - 16s - loss: 0.0621 - acc: 0.9761 - auc-prc: 0.9974 - auc-roc: 0.9974 - val_loss: 0.5144 - val_acc: 0.8795 - val_auc-prc: 0.9270 - val_auc-roc: 0.9388 - 16s/epoch - 55ms/step
Epoch 58/100
292/292 - 16s - loss: 0.0571 - acc: 0.9800 - auc-prc: 0.9975 - auc-roc: 0.9976 - val_loss: 0.5083 - val_acc: 0.8814 - val_auc-prc: 0.9235 - val_auc-roc: 0.9367 - 16s/epoch - 55ms/step
Epoch 59/100
292/292 - 16s - loss: 0.0518 - acc: 0.9800 - auc-prc: 0.9982 - auc-roc: 0.9983 - val_loss: 0.5267 - val_acc: 0.8862 - val_auc-prc: 0.9176 - val_auc-roc: 0.9324 - 16s/epoch - 57ms/step
Epoch 60/100
292/292 - 17s - loss: 0.0485 - acc: 0.9824 - auc-prc: 0.9985 - auc-roc: 0.9986 - val_loss: 0.5659 - val_acc: 0.8824 - val_auc-prc: 0.9093 - val_auc-roc: 0.9263 - 17s/epoch - 58ms/step
Epoch 61/100
292/292 - 17s - loss: 0.0540 - acc: 0.9809 - auc-prc: 0.9979 - auc-roc: 0.9980 - val_loss: 0.5414 - val_acc: 0.8901 - val_auc-prc: 0.9203 - val_auc-roc: 0.9345 - 17s/epoch - 57ms/step
Epoch 62/100
292/292 - 16s - loss: 0.0559 - acc: 0.9782 - auc-prc: 0.9977 - auc-roc: 0.9978 - val_loss: 0.5654 - val_acc: 0.8843 - val_auc-prc: 0.9128 - val_auc-roc: 0.9284 - 16s/epoch - 56ms/step
Epoch 63/100
292/292 - 16s - loss: 0.0540 - acc: 0.9788 - auc-prc: 0.9978 - auc-roc: 0.9979 - val_loss: 0.5301 - val_acc: 0.8843 - val_auc-prc: 0.9219 - val_auc-roc: 0.9356 - 16s/epoch - 55ms/step
Epoch 64/100
292/292 - 17s - loss: 0.0482 - acc: 0.9825 - auc-prc: 0.9981 - auc-roc: 0.9982 - val_loss: 0.5577 - val_acc: 0.8910 - val_auc-prc: 0.9244 - val_auc-roc: 0.9382 - 17s/epoch - 57ms/step
Epoch 65/100
292/292 - 17s - loss: 0.0434 - acc: 0.9843 - auc-prc: 0.9988 - auc-roc: 0.9988 - val_loss: 0.5488 - val_acc: 0.8930 - val_auc-prc: 0.9208 - val_auc-roc: 0.9350 - 17s/epoch - 57ms/step
Epoch 66/100
292/292 - 17s - loss: 0.0473 - acc: 0.9812 - auc-prc: 0.9985 - auc-roc: 0.9985 - val_loss: 0.6093 - val_acc: 0.8775 - val_auc-prc: 0.9180 - val_auc-roc: 0.9319 - 17s/epoch - 57ms/step
Epoch 67/100
292/292 - 16s - loss: 0.0532 - acc: 0.9801 - auc-prc: 0.9976 - auc-roc: 0.9978 - val_loss: 0.5860 - val_acc: 0.8910 - val_auc-prc: 0.9185 - val_auc-roc: 0.9328 - 16s/epoch - 56ms/step
Epoch 68/100
292/292 - 17s - loss: 0.0426 - acc: 0.9835 - auc-prc: 0.9987 - auc-roc: 0.9987 - val_loss: 0.6737 - val_acc: 0.8843 - val_auc-prc: 0.9099 - val_auc-roc: 0.9261 - 17s/epoch - 57ms/step
Epoch 69/100
292/292 - 16s - loss: 0.0410 - acc: 0.9844 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.5684 - val_acc: 0.8833 - val_auc-prc: 0.9188 - val_auc-roc: 0.9332 - 16s/epoch - 57ms/step
Epoch 70/100
292/292 - 17s - loss: 0.0425 - acc: 0.9845 - auc-prc: 0.9989 - auc-roc: 0.9989 - val_loss: 0.5804 - val_acc: 0.8872 - val_auc-prc: 0.9117 - val_auc-roc: 0.9279 - 17s/epoch - 57ms/step
Epoch 71/100
292/292 - 17s - loss: 0.0540 - acc: 0.9806 - auc-prc: 0.9971 - auc-roc: 0.9974 - val_loss: 0.5701 - val_acc: 0.8939 - val_auc-prc: 0.9164 - val_auc-roc: 0.9316 - 17s/epoch - 57ms/step
Epoch 72/100
292/292 - 17s - loss: 0.0563 - acc: 0.9794 - auc-prc: 0.9972 - auc-roc: 0.9975 - val_loss: 0.5924 - val_acc: 0.8862 - val_auc-prc: 0.9163 - val_auc-roc: 0.9313 - 17s/epoch - 57ms/step
Epoch 73/100
292/292 - 17s - loss: 0.0392 - acc: 0.9867 - auc-prc: 0.9988 - auc-roc: 0.9989 - val_loss: 0.6143 - val_acc: 0.8775 - val_auc-prc: 0.9101 - val_auc-roc: 0.9254 - 17s/epoch - 57ms/step
Epoch 74/100
292/292 - 17s - loss: 0.0491 - acc: 0.9832 - auc-prc: 0.9982 - auc-roc: 0.9983 - val_loss: 0.6115 - val_acc: 0.8852 - val_auc-prc: 0.9132 - val_auc-roc: 0.9287 - 17s/epoch - 57ms/step
Epoch 75/100
292/292 - 16s - loss: 0.0306 - acc: 0.9895 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.5996 - val_acc: 0.8949 - val_auc-prc: 0.9209 - val_auc-roc: 0.9353 - 16s/epoch - 55ms/step
Epoch 76/100
292/292 - 17s - loss: 0.0605 - acc: 0.9778 - auc-prc: 0.9968 - auc-roc: 0.9971 - val_loss: 0.5527 - val_acc: 0.8804 - val_auc-prc: 0.9194 - val_auc-roc: 0.9334 - 17s/epoch - 57ms/step
Epoch 77/100
292/292 - 17s - loss: 0.0410 - acc: 0.9855 - auc-prc: 0.9990 - auc-roc: 0.9990 - val_loss: 0.6088 - val_acc: 0.8804 - val_auc-prc: 0.9205 - val_auc-roc: 0.9340 - 17s/epoch - 57ms/step
Epoch 78/100
292/292 - 17s - loss: 0.0309 - acc: 0.9900 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.6130 - val_acc: 0.8949 - val_auc-prc: 0.9192 - val_auc-roc: 0.9342 - 17s/epoch - 58ms/step
Epoch 79/100
292/292 - 16s - loss: 0.0257 - acc: 0.9911 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.6469 - val_acc: 0.8862 - val_auc-prc: 0.9151 - val_auc-roc: 0.9309 - 16s/epoch - 56ms/step
Epoch 80/100
292/292 - 16s - loss: 0.0399 - acc: 0.9855 - auc-prc: 0.9988 - auc-roc: 0.9988 - val_loss: 0.6367 - val_acc: 0.8833 - val_auc-prc: 0.9155 - val_auc-roc: 0.9304 - 16s/epoch - 54ms/step
Epoch 81/100
292/292 - 16s - loss: 0.0389 - acc: 0.9864 - auc-prc: 0.9986 - auc-roc: 0.9987 - val_loss: 0.6899 - val_acc: 0.8843 - val_auc-prc: 0.9116 - val_auc-roc: 0.9278 - 16s/epoch - 54ms/step
Epoch 82/100
292/292 - 16s - loss: 0.0359 - acc: 0.9878 - auc-prc: 0.9991 - auc-roc: 0.9991 - val_loss: 0.6704 - val_acc: 0.8881 - val_auc-prc: 0.9117 - val_auc-roc: 0.9282 - 16s/epoch - 54ms/step
Epoch 83/100
292/292 - 16s - loss: 0.0247 - acc: 0.9910 - auc-prc: 0.9996 - auc-roc: 0.9996 - val_loss: 0.6871 - val_acc: 0.8804 - val_auc-prc: 0.9093 - val_auc-roc: 0.9256 - 16s/epoch - 54ms/step
Epoch 84/100
292/292 - 16s - loss: 0.0347 - acc: 0.9877 - auc-prc: 0.9993 - auc-roc: 0.9993 - val_loss: 0.6412 - val_acc: 0.8804 - val_auc-prc: 0.9139 - val_auc-roc: 0.9293 - 16s/epoch - 56ms/step
Epoch 85/100
292/292 - 16s - loss: 0.0371 - acc: 0.9867 - auc-prc: 0.9986 - auc-roc: 0.9988 - val_loss: 0.7694 - val_acc: 0.8814 - val_auc-prc: 0.9020 - val_auc-roc: 0.9198 - 16s/epoch - 53ms/step
Epoch 86/100
292/292 - 16s - loss: 0.0411 - acc: 0.9838 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.6705 - val_acc: 0.8824 - val_auc-prc: 0.9129 - val_auc-roc: 0.9291 - 16s/epoch - 54ms/step
Epoch 87/100
292/292 - 16s - loss: 0.0270 - acc: 0.9895 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.7064 - val_acc: 0.8795 - val_auc-prc: 0.9088 - val_auc-roc: 0.9251 - 16s/epoch - 53ms/step
Epoch 88/100
292/292 - 15s - loss: 0.0222 - acc: 0.9929 - auc-prc: 0.9995 - auc-roc: 0.9995 - val_loss: 0.7196 - val_acc: 0.8852 - val_auc-prc: 0.9099 - val_auc-roc: 0.9264 - 15s/epoch - 52ms/step
Epoch 89/100
292/292 - 16s - loss: 0.0286 - acc: 0.9894 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.7110 - val_acc: 0.8824 - val_auc-prc: 0.9067 - val_auc-roc: 0.9240 - 16s/epoch - 53ms/step
Epoch 90/100
292/292 - 16s - loss: 0.0312 - acc: 0.9876 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.7167 - val_acc: 0.8862 - val_auc-prc: 0.9118 - val_auc-roc: 0.9284 - 16s/epoch - 54ms/step
Epoch 91/100
292/292 - 16s - loss: 0.0197 - acc: 0.9929 - auc-prc: 0.9995 - auc-roc: 0.9996 - val_loss: 0.7935 - val_acc: 0.8727 - val_auc-prc: 0.9016 - val_auc-roc: 0.9193 - 16s/epoch - 54ms/step
Epoch 92/100
292/292 - 16s - loss: 0.0371 - acc: 0.9858 - auc-prc: 0.9987 - auc-roc: 0.9988 - val_loss: 0.6669 - val_acc: 0.8775 - val_auc-prc: 0.9140 - val_auc-roc: 0.9290 - 16s/epoch - 54ms/step
Epoch 93/100
292/292 - 16s - loss: 0.0247 - acc: 0.9918 - auc-prc: 0.9996 - auc-roc: 0.9996 - val_loss: 0.7873 - val_acc: 0.8766 - val_auc-prc: 0.9046 - val_auc-roc: 0.9221 - 16s/epoch - 54ms/step
Epoch 94/100
292/292 - 16s - loss: 0.0253 - acc: 0.9909 - auc-prc: 0.9992 - auc-roc: 0.9993 - val_loss: 0.7249 - val_acc: 0.8814 - val_auc-prc: 0.9092 - val_auc-roc: 0.9260 - 16s/epoch - 55ms/step
Epoch 95/100
292/292 - 16s - loss: 0.0451 - acc: 0.9827 - auc-prc: 0.9983 - auc-roc: 0.9984 - val_loss: 0.6971 - val_acc: 0.8814 - val_auc-prc: 0.9055 - val_auc-roc: 0.9230 - 16s/epoch - 56ms/step
Epoch 96/100
292/292 - 16s - loss: 0.0378 - acc: 0.9866 - auc-prc: 0.9985 - auc-roc: 0.9986 - val_loss: 0.6838 - val_acc: 0.8881 - val_auc-prc: 0.9081 - val_auc-roc: 0.9257 - 16s/epoch - 55ms/step
Epoch 97/100
292/292 - 16s - loss: 0.0424 - acc: 0.9823 - auc-prc: 0.9988 - auc-roc: 0.9988 - val_loss: 0.6917 - val_acc: 0.8824 - val_auc-prc: 0.9109 - val_auc-roc: 0.9278 - 16s/epoch - 56ms/step
Epoch 98/100
292/292 - 16s - loss: 0.0474 - acc: 0.9838 - auc-prc: 0.9976 - auc-roc: 0.9979 - val_loss: 0.7060 - val_acc: 0.8785 - val_auc-prc: 0.9068 - val_auc-roc: 0.9239 - 16s/epoch - 55ms/step
Epoch 99/100
292/292 - 16s - loss: 0.0314 - acc: 0.9886 - auc-prc: 0.9991 - auc-roc: 0.9992 - val_loss: 0.7850 - val_acc: 0.8746 - val_auc-prc: 0.9000 - val_auc-roc: 0.9182 - 16s/epoch - 54ms/step
Epoch 100/100
292/292 - 16s - loss: 0.0245 - acc: 0.9920 - auc-prc: 0.9994 - auc-roc: 0.9994 - val_loss: 0.6969 - val_acc: 0.8843 - val_auc-prc: 0.9139 - val_auc-roc: 0.9295 - 16s/epoch - 54ms/step
Early stopping epoch: 0
******Evaluating TEST set*********
33/33 - 1s - 760ms/epoch - 23ms/step
              precision    recall  f1-score   support

           0       0.88      0.87      0.87       403
           1       0.92      0.93      0.92       634

    accuracy                           0.90      1037
   macro avg       0.90      0.90      0.90      1037
weighted avg       0.90      0.90      0.90      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.38      0.48      0.42       403
           1       0.61      0.51      0.55       634

    accuracy                           0.50      1037
   macro avg       0.49      0.49      0.49      1037
weighted avg       0.52      0.50      0.50      1037

______________________________________________________
fold 8
Model: "model_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_9 (InputLayer)        [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_8 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_8 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_8 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_8 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 18s - loss: 0.3129 - acc: 0.8676 - auc-prc: 0.9384 - auc-roc: 0.9402 - val_loss: 0.3045 - val_acc: 0.8766 - val_auc-prc: 0.9423 - val_auc-roc: 0.9429 - 18s/epoch - 62ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2808 - acc: 0.8859 - auc-prc: 0.9496 - auc-roc: 0.9514 - val_loss: 0.3007 - val_acc: 0.8660 - val_auc-prc: 0.9451 - val_auc-roc: 0.9450 - 16s/epoch - 53ms/step
Epoch 3/100
292/292 - 15s - loss: 0.2728 - acc: 0.8893 - auc-prc: 0.9523 - auc-roc: 0.9539 - val_loss: 0.2939 - val_acc: 0.8775 - val_auc-prc: 0.9487 - val_auc-roc: 0.9484 - 15s/epoch - 53ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2632 - acc: 0.8956 - auc-prc: 0.9558 - auc-roc: 0.9570 - val_loss: 0.2907 - val_acc: 0.8804 - val_auc-prc: 0.9483 - val_auc-roc: 0.9484 - 16s/epoch - 56ms/step
Epoch 5/100
292/292 - 15s - loss: 0.2609 - acc: 0.8952 - auc-prc: 0.9568 - auc-roc: 0.9579 - val_loss: 0.2879 - val_acc: 0.8824 - val_auc-prc: 0.9490 - val_auc-roc: 0.9489 - 15s/epoch - 52ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2565 - acc: 0.8974 - auc-prc: 0.9584 - auc-roc: 0.9594 - val_loss: 0.2916 - val_acc: 0.8766 - val_auc-prc: 0.9510 - val_auc-roc: 0.9502 - 16s/epoch - 54ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2563 - acc: 0.8989 - auc-prc: 0.9582 - auc-roc: 0.9592 - val_loss: 0.2879 - val_acc: 0.8833 - val_auc-prc: 0.9490 - val_auc-roc: 0.9492 - 16s/epoch - 54ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2535 - acc: 0.8974 - auc-prc: 0.9593 - auc-roc: 0.9603 - val_loss: 0.2985 - val_acc: 0.8756 - val_auc-prc: 0.9504 - val_auc-roc: 0.9498 - 16s/epoch - 54ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2504 - acc: 0.8983 - auc-prc: 0.9610 - auc-roc: 0.9615 - val_loss: 0.2846 - val_acc: 0.8881 - val_auc-prc: 0.9511 - val_auc-roc: 0.9508 - 16s/epoch - 56ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2490 - acc: 0.8999 - auc-prc: 0.9610 - auc-roc: 0.9618 - val_loss: 0.2910 - val_acc: 0.8775 - val_auc-prc: 0.9493 - val_auc-roc: 0.9493 - 16s/epoch - 53ms/step
Epoch 11/100
292/292 - 15s - loss: 0.2444 - acc: 0.9002 - auc-prc: 0.9622 - auc-roc: 0.9632 - val_loss: 0.3052 - val_acc: 0.8708 - val_auc-prc: 0.9489 - val_auc-roc: 0.9483 - 15s/epoch - 53ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2437 - acc: 0.9002 - auc-prc: 0.9629 - auc-roc: 0.9634 - val_loss: 0.2954 - val_acc: 0.8669 - val_auc-prc: 0.9486 - val_auc-roc: 0.9482 - 16s/epoch - 54ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2387 - acc: 0.9042 - auc-prc: 0.9646 - auc-roc: 0.9647 - val_loss: 0.2990 - val_acc: 0.8727 - val_auc-prc: 0.9469 - val_auc-roc: 0.9475 - 16s/epoch - 55ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2395 - acc: 0.9028 - auc-prc: 0.9641 - auc-roc: 0.9646 - val_loss: 0.2853 - val_acc: 0.8852 - val_auc-prc: 0.9510 - val_auc-roc: 0.9509 - 16s/epoch - 54ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2339 - acc: 0.9054 - auc-prc: 0.9659 - auc-roc: 0.9662 - val_loss: 0.2935 - val_acc: 0.8698 - val_auc-prc: 0.9491 - val_auc-roc: 0.9485 - 16s/epoch - 54ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2311 - acc: 0.9062 - auc-prc: 0.9669 - auc-roc: 0.9671 - val_loss: 0.2936 - val_acc: 0.8708 - val_auc-prc: 0.9499 - val_auc-roc: 0.9494 - 16s/epoch - 53ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2290 - acc: 0.9081 - auc-prc: 0.9675 - auc-roc: 0.9677 - val_loss: 0.3052 - val_acc: 0.8650 - val_auc-prc: 0.9482 - val_auc-roc: 0.9473 - 16s/epoch - 55ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2291 - acc: 0.9082 - auc-prc: 0.9668 - auc-roc: 0.9675 - val_loss: 0.3017 - val_acc: 0.8660 - val_auc-prc: 0.9462 - val_auc-roc: 0.9455 - 16s/epoch - 54ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2269 - acc: 0.9089 - auc-prc: 0.9681 - auc-roc: 0.9682 - val_loss: 0.3028 - val_acc: 0.8679 - val_auc-prc: 0.9475 - val_auc-roc: 0.9481 - 16s/epoch - 54ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2229 - acc: 0.9105 - auc-prc: 0.9691 - auc-roc: 0.9693 - val_loss: 0.2997 - val_acc: 0.8746 - val_auc-prc: 0.9474 - val_auc-roc: 0.9476 - 16s/epoch - 54ms/step
Epoch 21/100
292/292 - 16s - loss: 0.2214 - acc: 0.9108 - auc-prc: 0.9698 - auc-roc: 0.9697 - val_loss: 0.2996 - val_acc: 0.8650 - val_auc-prc: 0.9441 - val_auc-roc: 0.9455 - 16s/epoch - 54ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 1s/epoch - 35ms/step
              precision    recall  f1-score   support

           0       0.87      0.83      0.85       403
           1       0.89      0.92      0.91       634

    accuracy                           0.89      1037
   macro avg       0.88      0.87      0.88      1037
weighted avg       0.88      0.89      0.88      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.41      0.55      0.47       403
           1       0.63      0.49      0.55       634

    accuracy                           0.51      1037
   macro avg       0.52      0.52      0.51      1037
weighted avg       0.54      0.51      0.52      1037

______________________________________________________
fold 9
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
292/292 - 20s - loss: 0.3144 - acc: 0.8685 - auc-prc: 0.9381 - auc-roc: 0.9394 - val_loss: 0.3181 - val_acc: 0.8698 - val_auc-prc: 0.9369 - val_auc-roc: 0.9406 - 20s/epoch - 67ms/step
Epoch 2/100
292/292 - 16s - loss: 0.2802 - acc: 0.8878 - auc-prc: 0.9496 - auc-roc: 0.9514 - val_loss: 0.2897 - val_acc: 0.8891 - val_auc-prc: 0.9442 - val_auc-roc: 0.9483 - 16s/epoch - 55ms/step
Epoch 3/100
292/292 - 16s - loss: 0.2709 - acc: 0.8929 - auc-prc: 0.9530 - auc-roc: 0.9542 - val_loss: 0.2763 - val_acc: 0.8910 - val_auc-prc: 0.9496 - val_auc-roc: 0.9533 - 16s/epoch - 55ms/step
Epoch 4/100
292/292 - 16s - loss: 0.2652 - acc: 0.8971 - auc-prc: 0.9551 - auc-roc: 0.9564 - val_loss: 0.2805 - val_acc: 0.8881 - val_auc-prc: 0.9473 - val_auc-roc: 0.9513 - 16s/epoch - 54ms/step
Epoch 5/100
292/292 - 16s - loss: 0.2609 - acc: 0.8941 - auc-prc: 0.9568 - auc-roc: 0.9578 - val_loss: 0.2744 - val_acc: 0.8997 - val_auc-prc: 0.9514 - val_auc-roc: 0.9547 - 16s/epoch - 54ms/step
Epoch 6/100
292/292 - 16s - loss: 0.2570 - acc: 0.8992 - auc-prc: 0.9584 - auc-roc: 0.9591 - val_loss: 0.2794 - val_acc: 0.8920 - val_auc-prc: 0.9485 - val_auc-roc: 0.9519 - 16s/epoch - 54ms/step
Epoch 7/100
292/292 - 16s - loss: 0.2565 - acc: 0.8987 - auc-prc: 0.9586 - auc-roc: 0.9593 - val_loss: 0.2696 - val_acc: 0.8987 - val_auc-prc: 0.9513 - val_auc-roc: 0.9553 - 16s/epoch - 55ms/step
Epoch 8/100
292/292 - 16s - loss: 0.2539 - acc: 0.8986 - auc-prc: 0.9594 - auc-roc: 0.9601 - val_loss: 0.2660 - val_acc: 0.8968 - val_auc-prc: 0.9519 - val_auc-roc: 0.9557 - 16s/epoch - 53ms/step
Epoch 9/100
292/292 - 16s - loss: 0.2533 - acc: 0.8970 - auc-prc: 0.9602 - auc-roc: 0.9605 - val_loss: 0.2658 - val_acc: 0.8968 - val_auc-prc: 0.9524 - val_auc-roc: 0.9561 - 16s/epoch - 55ms/step
Epoch 10/100
292/292 - 16s - loss: 0.2465 - acc: 0.9033 - auc-prc: 0.9618 - auc-roc: 0.9625 - val_loss: 0.2708 - val_acc: 0.8959 - val_auc-prc: 0.9514 - val_auc-roc: 0.9548 - 16s/epoch - 54ms/step
Epoch 11/100
292/292 - 16s - loss: 0.2463 - acc: 0.9016 - auc-prc: 0.9618 - auc-roc: 0.9623 - val_loss: 0.2691 - val_acc: 0.8997 - val_auc-prc: 0.9523 - val_auc-roc: 0.9557 - 16s/epoch - 54ms/step
Epoch 12/100
292/292 - 16s - loss: 0.2435 - acc: 0.9010 - auc-prc: 0.9631 - auc-roc: 0.9635 - val_loss: 0.2690 - val_acc: 0.9036 - val_auc-prc: 0.9531 - val_auc-roc: 0.9565 - 16s/epoch - 54ms/step
Epoch 13/100
292/292 - 16s - loss: 0.2436 - acc: 0.9012 - auc-prc: 0.9633 - auc-roc: 0.9634 - val_loss: 0.2718 - val_acc: 0.8959 - val_auc-prc: 0.9517 - val_auc-roc: 0.9550 - 16s/epoch - 54ms/step
Epoch 14/100
292/292 - 16s - loss: 0.2412 - acc: 0.9004 - auc-prc: 0.9636 - auc-roc: 0.9642 - val_loss: 0.2619 - val_acc: 0.8987 - val_auc-prc: 0.9554 - val_auc-roc: 0.9582 - 16s/epoch - 55ms/step
Epoch 15/100
292/292 - 16s - loss: 0.2369 - acc: 0.9038 - auc-prc: 0.9651 - auc-roc: 0.9655 - val_loss: 0.2568 - val_acc: 0.9036 - val_auc-prc: 0.9563 - val_auc-roc: 0.9592 - 16s/epoch - 55ms/step
Epoch 16/100
292/292 - 16s - loss: 0.2387 - acc: 0.9014 - auc-prc: 0.9648 - auc-roc: 0.9651 - val_loss: 0.2610 - val_acc: 0.8949 - val_auc-prc: 0.9574 - val_auc-roc: 0.9589 - 16s/epoch - 54ms/step
Epoch 17/100
292/292 - 16s - loss: 0.2311 - acc: 0.9046 - auc-prc: 0.9666 - auc-roc: 0.9671 - val_loss: 0.2566 - val_acc: 0.9074 - val_auc-prc: 0.9557 - val_auc-roc: 0.9587 - 16s/epoch - 54ms/step
Epoch 18/100
292/292 - 16s - loss: 0.2315 - acc: 0.9037 - auc-prc: 0.9670 - auc-roc: 0.9672 - val_loss: 0.2689 - val_acc: 0.9007 - val_auc-prc: 0.9550 - val_auc-roc: 0.9580 - 16s/epoch - 55ms/step
Epoch 19/100
292/292 - 16s - loss: 0.2283 - acc: 0.9090 - auc-prc: 0.9672 - auc-roc: 0.9678 - val_loss: 0.2582 - val_acc: 0.9026 - val_auc-prc: 0.9565 - val_auc-roc: 0.9590 - 16s/epoch - 53ms/step
Epoch 20/100
292/292 - 16s - loss: 0.2229 - acc: 0.9081 - auc-prc: 0.9691 - auc-roc: 0.9694 - val_loss: 0.2662 - val_acc: 0.9016 - val_auc-prc: 0.9560 - val_auc-roc: 0.9575 - 16s/epoch - 54ms/step
Epoch 21/100
292/292 - 15s - loss: 0.2240 - acc: 0.9078 - auc-prc: 0.9687 - auc-roc: 0.9690 - val_loss: 0.2652 - val_acc: 0.9026 - val_auc-prc: 0.9561 - val_auc-roc: 0.9585 - 15s/epoch - 52ms/step
Early stopping epoch: 20
******Evaluating TEST set*********
33/33 - 1s - 737ms/epoch - 22ms/step
              precision    recall  f1-score   support

           0       0.89      0.85      0.87       403
           1       0.91      0.94      0.92       634

    accuracy                           0.90      1037
   macro avg       0.90      0.89      0.90      1037
weighted avg       0.90      0.90      0.90      1037

******Evaluating RANDOM Model*********
              precision    recall  f1-score   support

           0       0.37      0.45      0.41       403
           1       0.60      0.52      0.56       634

    accuracy                           0.49      1037
   macro avg       0.49      0.49      0.48      1037
weighted avg       0.51      0.49      0.50      1037

______________________________________________________
Model: "model_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_10 (InputLayer)       [(None, 150, 6, 3)]       0         
                                                                 
 conv2d_9 (Conv2D)           (None, 146, 1, 64)        5824      
                                                                 
 lambda_9 (Lambda)           (None, 146, 64)           0         
                                                                 
 lstm (LSTM)                 [(None, 146, 64),         33024     
                              (None, 64),                        
                              (None, 64)]                        
                                                                 
 self_attention_9 (SelfAtten  ((None, 1024),           2560      
 tion)                        (None, 16, 146))                   
                                                                 
 dense_9 (Dense)             (None, 2)                 2050      
                                                                 
=================================================================
Total params: 43,458
Trainable params: 43,458
Non-trainable params: 0
_________________________________________________________________
None
Mean AUC_ROC[0.8921] IC [0.8846, 0.8996]
Mean Accuracy[0.9009] IC [0.8943, 0.9076]
Mean Recall[0.8921] IC [0.8846, 0.8996]
Mean F1[0.8949] IC [0.8878, 0.9021]
Median AUC_ROC[0.8952]
Median Accuracy[0.9031]
Median Recall[0.8952]
Median F1[0.8974]
